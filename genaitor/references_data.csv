,reference,content
0,https://docs.sciml.ai/DiffEqFlux/stable/,"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures Â· DiffEqFlux.jlHomeModelingModeling LanguagesModelingToolkitCatalystNBodySimulatorParameterizedFunctionsModel Libraries and ImportersModelingToolkitStandardLibraryModelingToolkitNeuralNetsDiffEqCallbacksFiniteStateProjectionCellMLToolkitSBMLToolkitBaseModelicaReactionNetworkImportersSymbolic ToolsModelOrderReductionSymbolicsSymbolicUtilsArray LibrariesRecursiveArrayToolsComponentArraysLabelledArraysMultiScaleArraysSolversEquation SolversLinearSolveNonlinearSolveDifferentialEquationsIntegralsDifferenceEquationsOptimizationJumpProcessesLineSearchInverse Problems / EstimationSciMLSensitivityDiffEqParamEstimDiffEqBayesPDE SolversMethodOfLinesNeuralPDENeuralOperatorsFEniCSHighDimPDEDiffEqOperatorsAdvanced Solver APIsOrdinaryDiffEqBoundaryValueDiffEqDiffEqGPUAnalysisParameter AnalysisEasyModelAnalysisGlobalSensitivityStructuralIdentifiabilityUncertainty QuantificationPolyChaosSciMLExpectationsMachine LearningFunction ApproximationSurrogatesReservoirComputingImplicit Layer Deep LearningDiffEqFluxDeepEquilibriumNetworksSymbolic LearningDataDrivenDiffEqSymbolicNumericIntegrationThird-Party Differentiation ToolingSparseDiffToolsFiniteDiffDeveloper ToolsNumerical UtilitiesExponentialUtilitiesDiffEqNoiseProcessPreallocationToolsEllipsisNotationDataInterpolationsPoissonRandomQuasiMonteCarloRuntimeGeneratedFunctionsMuladdMacroFindFirstFunctionsSparseDiffToolsHigh-Level InterfacesSciMLBaseSciMLStructuresADTypesSymbolicIndexingInterfaceTermInterfaceSciMLOperatorsSurrogatesBaseCommonSolveThird-Party InterfacesArrayInterfaceStaticArrayInterfaceDeveloper DocumentationSciMLStyleColPracDiffEq Developer DocumentationExtra ResourcesSciMLWorkshopExtended SciML TutorialsThe SciML BenchmarksModelingToolkitCourseCommercial SupportCommercial SupportJuliaHub offers commercial support for ModelingToolkit and the SciML ecosystem.  Contact us today to discuss your needs!Products built with SciML
        JuliaSim
    
        Pumas
    
        Cedar EDA
    
        Neuroblox
    
        Planting Space
    /DiffEqFlux.jlSearch docs (Ctrl + /)DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built ArchitecturesPre-Built ArchitecturesFlux.jl vs Lux.jlCitationReproducibilityDifferential Equation Machine Learning TutorialsNeural Ordinary Differential EquationsNeural ODEs on GPUsGPU-based MNIST Neural ODE ClassifierConvolutional Neural ODE MNIST Classifier on GPUAugmented Neural Ordinary Differential EquationsNeural Stochastic Differential Equations With Method of MomentsSmoothed Collocation for Fast Two-Stage TrainingContinuous Normalizing FlowsHamiltonian Neural NetworkPhysics-Informed Machine Learning (PIML) with TensorLayerMultiple ShootingWeather forecasting with neural ODEsNeural Graph Differential EquationsEnforcing Physical Constraints via Universal Differential-Algebraic EquationsLayer APIsContinuous Normalizing Flows LayerNeural Differential Equation LayersUtility Function APIsSmoothed CollocationMultiple Shooting FunctionalityVersionDiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built ArchitecturesDiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built ArchitecturesïGitHubïDiffEqFlux: High Level Pre-Built Architectures for Implicit Deep LearningDiffEqFlux.jl is an implicit deep learning library built using the SciML ecosystem. It is a high-level interface that pulls together all the tools with heuristics and helper functions to make training such deep implicit layer models fast and easy.NoteDiffEqFlux.jl is only for pre-built architectures and utility functions for deep implicit learning, mixing differential equations with machine learning. For details on automatic differentiation of equation solvers and adjoint techniques, and using these methods for doing things like calibrating models to data, nonlinear optimal control, and PDE-constrained optimization, see SciMLSensitivity.jl.Pre-Built ArchitecturesThe approach of this package is the easy and efficient training of Neural Ordinary Differential Equations and its variants. DiffEqFlux.jl provides architectures which match the interfaces of machine learning libraries such as Flux.jl and Lux.jl to make it easy to build continuous-time machine learning layers into larger machine learning applications.The following layer functions exist:Neural Ordinary Differential Equations (Neural ODEs)Collocation-Based Neural ODEs (Neural ODEs without a solver, by far the fastest way!)Multiple Shooting Neural Ordinary Differential EquationsNeural Stochastic Differential Equations (Neural SDEs)Neural Differential-Algebraic Equations (Neural DAEs)Neural Delay Differential Equations (Neural DDEs)Augmented Neural ODEsHamiltonian Neural Networks (with specialized second order and symplectic integrators)Continuous Normalizing Flows (CNF) and FFJORDExamples of how to build architectures from scratch, with tutorials on things like Graph Neural ODEs, can be found in the SciMLSensitivity.jl documentation.Flux.jl vs Lux.jlBoth Flux and Lux defined neural networks are supported by DiffEqFlux.jl. However, Lux.jl neural networks are greatly preferred for many correctness reasons. Particularly, a Flux Chain does not respect Julia's type promotion rules. This causes major problems in that the restructuring of a Flux neural network will not respect the chosen types from the solver. Demonstration:using Flux, Tracker

x = [0.8; 0.8]
ann = Chain(Dense(2, 10, tanh), Dense(10, 1))
p, re = Flux.destructure(ann)
z = re(Float64.(p))While one may think this recreates the neural network to act in Float64 precision, it does not and instead its values will silently downgrade everything to Float32. This is only fixed by Chain(Dense(2, 10, tanh), Dense(10, 1)) |> f64. Similar cases will lead to dropped gradients with complex numbers. This is not an issue with the automatic differentiation library commonly associated with Flux (Zygote.jl) but rather due to choices in the neural network library's decision for how to approach type handling and precision. Thus when using DiffEqFlux.jl with Flux, the user must be very careful to ensure that the precision of the arguments are correct, and anything that requires alternative types (like TrackerAdjoint tracked values and ForwardDiffSensitivity dual numbers) are suspect.Lux.jl has none of these issues, is simpler to work with due to the parameters in its function calls being explicit rather than implicit global references, and achieves higher performance. It is built on similar foundations as Flux.jl, such as Zygote and NNLib. The better performance comes from not having the overhead of restructure required and fusing common operations in LuxLib.jl. Thus we highly recommend people use Lux instead and only use the Flux fallbacks for legacy code.CitationIf you use DiffEqFlux.jl or are influenced by its ideas, please cite:@article{rackauckas2020universal,
  title={Universal differential equations for scientific machine learning},
  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
  journal={arXiv preprint arXiv:2001.04385},
  year={2020}
}ReproducibilityThe documentation of this SciML package was built using these direct dependencies,Status `/var/lib/buildkite-agent/builds/gpuci-1/julialang/diffeqflux-dot-jl/docs/Project.toml`
  [336ed68f] CSV v0.10.15
  [052768ef] CUDA v5.6.1
  [b0b7db55] ComponentArrays v0.15.24
  [124859b0] DataDeps v0.7.13
  [a93c6f00] DataFrames v1.7.0
  [aae7a2af] DiffEqFlux v4.2.0 `/var/lib/buildkite-agent/builds/gpuci-1/julialang/diffeqflux-dot-jl`
  [b4f34e82] Distances v0.10.12
  [31c24e10] Distributions v0.25.117
  [e30172f5] Documenter v1.8.1
  [587475ba] Flux v0.16.3
  [f6369f11] ForwardDiff v0.10.38
  [c8e1da08] IterTools v1.10.0
  [b2108857] Lux v1.8.0
  [d0bbae9a] LuxCUDA v0.3.3
  [eb30cadb] MLDatasets v0.7.18
  [f1d291b0] MLUtils v0.4.7
  [872c559c] NNlib v0.9.27
  [0b1bfda6] OneHotArrays v0.2.6
  [3bd65402] Optimisers v0.4.5
  [7f7a1694] Optimization v4.1.1
  [36348300] OptimizationOptimJL v0.4.1
  [42dfb2eb] OptimizationOptimisers v0.3.7
  [500b13db] OptimizationPolyalgorithms v0.3.0
  [1dea7af3] OrdinaryDiffEq v6.91.0
  [91a5bcdd] Plots v1.40.9
  [37e2e3b7] ReverseDiff v1.15.3
  [0bca4576] SciMLBase v2.75.0
  [1ed8b502] SciMLSensitivity v7.74.0
  [860ef19b] StableRNGs v1.0.2
  [789caeaf] StochasticDiffEq v6.74.0
â [e88e6eb3] Zygote v0.6.75
  [37e2e46d] LinearAlgebra
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics v1.10.0
  [8dfed614] Test
Info Packages marked with â have new versions available and may be upgradable.and using this machine and Julia version.Julia Version 1.10.8
Commit 4c16ff44be8 (2025-01-22 10:06 UTC)
Build Info:
  Official https://julialang.org/ release
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: 48 Ã AMD EPYC 7402 24-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-15.0.7 (ORCJIT, znver2)
Threads: 1 default, 0 interactive, 1 GC (on 2 virtual cores)
Environment:
  JULIA_CPU_THREADS = 2
  JULIA_DEBUG = Documenter
  JULIA_DEPOT_PATH = /root/.cache/julia-buildkite-plugin/depots/64dbdc29-d6e3-4071-807c-a2eda6e09bd8
  LD_LIBRARY_PATH = /usr/local/nvidia/lib:/usr/local/nvidia/lib64
  JULIA_PKG_SERVER =A more complete overview of all dependencies and their versions is also provided.Status `/var/lib/buildkite-agent/builds/gpuci-1/julialang/diffeqflux-dot-jl/docs/Manifest.toml`
  [47edcb42] ADTypes v1.13.0
  [a4c015fc] ANSIColoredPrinters v0.0.1
  [621f4979] AbstractFFTs v1.5.0
  [1520ce14] AbstractTrees v0.4.5
  [7d9f7c33] Accessors v0.1.41
  [79e6a3ab] Adapt v4.2.0
  [66dad0bd] AliasTables v1.1.3
  [dce04be8] ArgCheck v2.4.0
  [ec485272] ArnoldiMethod v0.4.0
  [4fba245c] ArrayInterface v7.18.0
  [4c555306] ArrayLayouts v1.11.1
  [a9b6321e] Atomix v1.1.0
  [a963bdd2] AtomsBase v0.5.1
  [ab4f0b2a] BFloat16s v0.5.0
  [198e06fe] BangBang v0.4.3
  [9718e550] Baselet v0.1.1
  [d1d4a3ce] BitFlags v0.1.9
  [62783981] BitTwiddlingConvenienceFunctions v0.1.6
  [4544d5e4] Boltz v1.1.1
  [70df07ce] BracketingNonlinearSolve v1.1.0
  [e1450e63] BufferedStreams v1.2.2
  [fa961155] CEnum v0.5.0
  [2a0fbf3d] CPUSummary v0.2.6
  [336ed68f] CSV v0.10.15
  [052768ef] CUDA v5.6.1
  [1af6417a] CUDA_Runtime_Discovery v0.3.5
  [7057c7e9] Cassette v0.3.14
  [082447d4] ChainRules v1.72.2
  [d360d2e6] ChainRulesCore v1.25.1
  [46823bd8] Chemfiles v0.10.42
  [fb6a15b2] CloseOpenIntervals v0.1.13
  [944b1d66] CodecZlib v0.7.8
  [35d6a980] ColorSchemes v3.29.0
  [3da002f7] ColorTypes v0.12.0
  [c3611d14] ColorVectorSpace v0.11.0
  [5ae59095] Colors v0.13.0
  [38540f10] CommonSolve v0.2.4
  [bbf7d656] CommonSubexpressions v0.3.1
  [f70d9fcc] CommonWorldInvalidations v1.0.0
  [34da2185] Compat v4.16.0
  [b0b7db55] ComponentArrays v0.15.24
  [a33af91c] CompositionsBase v0.1.2
  [2569d6c7] ConcreteStructs v0.2.3
  [f0e56b4a] ConcurrentUtilities v2.5.0
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [187b0558] ConstructionBase v1.5.8
  [6add18c4] ContextVariablesX v0.1.3
  [d38c429a] Contour v0.6.3
  [adafc99b] CpuId v0.3.1
  [a8cc5b0e] Crayons v4.1.1
  [9a962f9c] DataAPI v1.16.0
  [124859b0] DataDeps v0.7.13
  [a93c6f00] DataFrames v1.7.0
  [864edb3b] DataStructures v0.18.20
  [e2d170a0] DataValueInterfaces v1.0.0
  [244e2a9f] DefineSingletons v0.1.2
  [8bb1440f] DelimitedFiles v1.9.1
  [2b5f629d] DiffEqBase v6.164.1
  [459566f4] DiffEqCallbacks v4.3.0
  [aae7a2af] DiffEqFlux v4.2.0 `/var/lib/buildkite-agent/builds/gpuci-1/julialang/diffeqflux-dot-jl`
  [77a26b50] DiffEqNoiseProcess v5.24.1
  [163ba53b] DiffResults v1.1.0
  [b552c78f] DiffRules v1.15.1
  [a0c0ee7d] DifferentiationInterface v0.6.42
  [8d63f2c5] DispatchDoctor v0.4.19
  [b4f34e82] Distances v0.10.12
  [31c24e10] Distributions v0.25.117
  [ffbed154] DocStringExtensions v0.9.3
  [e30172f5] Documenter v1.8.1
  [4e289a0a] EnumX v1.0.4
  [7da242da] Enzyme v0.13.30
  [f151be2c] EnzymeCore v0.8.8
  [460bff9d] ExceptionUnwrapping v0.1.11
  [d4d017d3] ExponentialUtilities v1.27.0
  [e2ba6199] ExprTools v0.1.10
  [55351af7] ExproniconLite v0.10.14
  [c87230d0] FFMPEG v0.4.2
  [cc61a311] FLoops v0.2.2
  [b9860ae5] FLoopsBase v0.1.1
  [7034ab61] FastBroadcast v0.3.5
  [9aa1b823] FastClosures v0.3.2
  [442a2c76] FastGaussQuadrature v1.0.2
  [a4df4552] FastPower v1.1.1
  [5789e2e9] FileIO v1.16.6
  [48062228] FilePathsBase v0.9.23
  [1a297f60] FillArrays v1.13.0
  [6a86dc24] FiniteDiff v2.27.0
  [53c48c17] FixedPointNumbers v0.8.5
  [587475ba] Flux v0.16.3
  [1fa38f19] Format v1.3.7
  [f6369f11] ForwardDiff v0.10.38
  [f62d2435] FunctionProperties v0.1.2
  [069b7b12] FunctionWrappers v1.1.3
  [77dc65aa] FunctionWrappersWrappers v0.1.3
  [d9f16b24] Functors v0.5.2
  [0c68f7d7] GPUArrays v11.2.2
  [46192b85] GPUArraysCore v0.2.0
  [61eb1bfa] GPUCompiler v1.2.0
  [28b8d3ca] GR v0.73.13
  [92fee26a] GZip v0.6.2
  [c145ed77] GenericSchur v0.5.4
  [d7ba0133] Git v1.3.1
  [c27321d9] Glob v1.3.1
  [86223c79] Graphs v1.12.0
  [42e2da0e] Grisu v1.0.2
  [f67ccb44] HDF5 v0.17.2
  [cd3eb016] HTTP v1.10.15
  [076d061b] HashArrayMappedTries v0.2.0
  [0e44f5e4] Hwloc v3.3.0
  [34004b35] HypergeometricFunctions v0.3.27
  [b5f81e59] IOCapture v0.2.5
  [7869d1d1] IRTools v0.4.14
  [615f187c] IfElse v0.1.1
  [c817782e] ImageBase v0.1.7
  [a09fc81d] ImageCore v0.10.5
  [4e3cecfd] ImageShow v0.3.8
  [d25df0c9] Inflate v0.1.5
  [22cec73e] InitialValues v0.3.1
  [842dd82b] InlineStrings v1.4.3
  [7d512f48] InternedStrings v0.7.0
  [3587e190] InverseFunctions v0.1.17
  [41ab1584] InvertedIndices v1.3.1
  [92d709cd] IrrationalConstants v0.2.4
  [c8e1da08] IterTools v1.10.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [033835bb] JLD2 v0.5.11
  [1019f520] JLFzf v0.1.9
  [692b3bcd] JLLWrappers v1.7.0
  [682c06a0] JSON v0.21.4
  [0f8b85d8] JSON3 v1.14.1
  [ae98c720] Jieko v0.2.1
  [b14d175d] JuliaVariables v0.2.4
  [ccbc3e58] JumpProcesses v9.14.2
  [63c18a36] KernelAbstractions v0.9.34
  [ba0b0d4f] Krylov v0.9.10
  [5be7bae1] LBFGSB v0.4.1
  [929cbde3] LLVM v9.2.0
  [8b046642] LLVMLoopInfo v1.0.0
  [b964fa9f] LaTeXStrings v1.4.0
  [23fbe1c1] Latexify v0.16.6
  [10f19ff3] LayoutPointers v0.1.17
  [0e77f7df] LazilyInitializedFields v1.3.0
  [5078a376] LazyArrays v2.6.0
  [8cdb02fc] LazyModules v0.3.1
  [1d6d02ad] LeftChildRightSiblingTrees v0.2.0
  [2d8b4e74] LevyArea v1.0.0
  [87fe0de2] LineSearch v0.1.4
  [d3d80556] LineSearches v7.3.0
  [7ed4a6bd] LinearSolve v3.3.1
  [2ab3a3ac] LogExpFunctions v0.3.29
  [e6f89c97] LoggingExtras v1.1.0
  [b2108857] Lux v1.8.0
  [d0bbae9a] LuxCUDA v0.3.3
  [bb33d45b] LuxCore v1.2.2
  [82251201] LuxLib v1.6.1
  [23992714] MAT v0.10.7
  [c2834f40] MLCore v1.0.0
  [7e8f7934] MLDataDevices v1.6.10
  [eb30cadb] MLDatasets v0.7.18
  [d8e11817] MLStyle v0.4.17
  [f1d291b0] MLUtils v0.4.7
  [3da0fdf6] MPIPreferences v0.1.11
  [1914dd2f] MacroTools v0.5.15
  [d125e4d3] ManualMemory v0.1.8
  [dbb5928d] MappedArrays v0.4.2
  [d0879d2d] MarkdownAST v0.1.2
  [bb5d69b7] MaybeInplace v0.1.4
  [739be429] MbedTLS v1.1.9
  [442fdcdd] Measures v0.3.2
  [128add7d] MicroCollections v0.2.0
  [e1d29d7a] Missings v1.2.0
  [e94cdb99] MosaicViews v0.3.4
  [2e0e35c7] Moshi v0.3.5
  [46d2c3a1] MuladdMacro v0.2.4
  [d41bc354] NLSolversBase v7.8.3
  [2774e3e8] NLsolve v4.5.1
  [872c559c] NNlib v0.9.27
  [15e1cf62] NPZ v0.4.3
â [5da4648a] NVTX v0.3.5
  [77ba4419] NaNMath v1.1.2
  [71a1bf82] NameResolution v0.1.5
  [8913a72c] NonlinearSolve v4.4.0
  [be0214bd] NonlinearSolveBase v1.5.0
  [5959db7a] NonlinearSolveFirstOrder v1.3.0
  [9a2c21bd] NonlinearSolveQuasiNewton v1.2.0
  [26075421] NonlinearSolveSpectralMethods v1.1.0
  [d8793406] ObjectFile v0.4.3
  [6fe1bfb0] OffsetArrays v1.15.0
  [0b1bfda6] OneHotArrays v0.2.6
  [4d8831e6] OpenSSL v1.4.3
  [429524aa] Optim v1.11.0
  [3bd65402] Optimisers v0.4.5
  [7f7a1694] Optimization v4.1.1
  [bca83a33] OptimizationBase v2.4.0
  [36348300] OptimizationOptimJL v0.4.1
  [42dfb2eb] OptimizationOptimisers v0.3.7
  [500b13db] OptimizationPolyalgorithms v0.3.0
  [bac558e1] OrderedCollections v1.8.0
  [1dea7af3] OrdinaryDiffEq v6.91.0
  [89bda076] OrdinaryDiffEqAdamsBashforthMoulton v1.2.0
  [6ad6398a] OrdinaryDiffEqBDF v1.2.0
  [bbf590c4] OrdinaryDiffEqCore v1.18.1
  [50262376] OrdinaryDiffEqDefault v1.3.0
  [4302a76b] OrdinaryDiffEqDifferentiation v1.4.0
  [9286f039] OrdinaryDiffEqExplicitRK v1.1.0
  [e0540318] OrdinaryDiffEqExponentialRK v1.3.0
  [becaefa8] OrdinaryDiffEqExtrapolation v1.4.0
  [5960d6e9] OrdinaryDiffEqFIRK v1.7.0
  [101fe9f7] OrdinaryDiffEqFeagin v1.1.0
  [d3585ca7] OrdinaryDiffEqFunctionMap v1.1.1
  [d28bc4f8] OrdinaryDiffEqHighOrderRK v1.1.0
  [9f002381] OrdinaryDiffEqIMEXMultistep v1.2.0
  [521117fe] OrdinaryDiffEqLinear v1.1.0
  [1344f307] OrdinaryDiffEqLowOrderRK v1.2.0
  [b0944070] OrdinaryDiffEqLowStorageRK v1.2.1
  [127b3ac7] OrdinaryDiffEqNonlinearSolve v1.5.0
  [c9986a66] OrdinaryDiffEqNordsieck v1.1.0
  [5dd0a6cf] OrdinaryDiffEqPDIRK v1.2.0
  [5b33eab2] OrdinaryDiffEqPRK v1.1.0
  [04162be5] OrdinaryDiffEqQPRK v1.1.0
  [af6ede74] OrdinaryDiffEqRKN v1.1.0
  [43230ef6] OrdinaryDiffEqRosenbrock v1.6.0
  [2d112036] OrdinaryDiffEqSDIRK v1.2.0
  [669c94d9] OrdinaryDiffEqSSPRK v1.2.0
  [e3e12d00] OrdinaryDiffEqStabilizedIRK v1.2.0
  [358294b1] OrdinaryDiffEqStabilizedRK v1.1.0
  [fa646aed] OrdinaryDiffEqSymplecticRK v1.3.0
  [b1df2697] OrdinaryDiffEqTsit5 v1.1.0
  [79d7bb75] OrdinaryDiffEqVerner v1.1.1
  [90014a1f] PDMats v0.11.32
  [65ce6f38] PackageExtensionCompat v1.0.2
  [5432bcbf] PaddedViews v0.5.12
  [d96e819e] Parameters v0.12.3
  [69de0a69] Parsers v2.8.1
  [7b2266bf] PeriodicTable v1.2.1
  [fbb45041] Pickle v0.3.5
  [b98c9c47] Pipe v1.3.0
  [ccf2f8ad] PlotThemes v3.3.0
  [995b91a9] PlotUtils v1.4.3
  [91a5bcdd] Plots v1.40.9
  [e409e4f3] PoissonRandom v0.4.4
  [f517fe37] Polyester v0.7.16
  [1d0040c9] PolyesterWeave v0.2.2
  [2dfb63ee] PooledArrays v1.4.3
  [85a6dd25] PositiveFactorizations v0.2.4
  [d236fae5] PreallocationTools v0.4.25
  [aea7be01] PrecompileTools v1.2.1
  [21216c6a] Preferences v1.4.3
  [8162dcfd] PrettyPrint v0.2.0
  [08abe8d2] PrettyTables v2.4.0
  [33c8b6b6] ProgressLogging v0.1.4
  [92933f4c] ProgressMeter v1.10.2
  [43287f4e] PtrArrays v1.3.0
  [1fd47b50] QuadGK v2.11.2
  [74087812] Random123 v1.7.0
  [e6cf234a] RandomNumbers v1.6.0
  [c1ae055f] RealDot v0.1.0
  [3cdcf5f2] RecipesBase v1.3.4
  [01d81517] RecipesPipeline v0.6.12
  [731186ca] RecursiveArrayTools v3.30.0
  [189a3867] Reexport v1.2.2
  [2792f1a3] RegistryInstances v0.1.0
  [05181044] RelocatableFolders v1.0.1
  [ae029012] Requires v1.3.0
  [ae5879a3] ResettableStacks v1.1.1
  [37e2e3b7] ReverseDiff v1.15.3
  [79098fc4] Rmath v0.8.0
  [7e49a35a] RuntimeGeneratedFunctions v0.5.13
  [94e857df] SIMDTypes v0.1.0
  [0bca4576] SciMLBase v2.75.0
  [19f34311] SciMLJacobianOperators v0.1.1
  [c0aeaf25] SciMLOperators v0.3.12
  [1ed8b502] SciMLSensitivity v7.74.0
  [53ae85a6] SciMLStructures v1.6.1
  [7e506255] ScopedValues v1.3.0
  [6c6a2e73] Scratch v1.2.1
  [91c51154] SentinelArrays v1.4.8
  [efcf1570] Setfield v1.1.1
  [605ecd9f] ShowCases v0.1.0
  [992d4aef] Showoff v1.0.3
  [777ac1f9] SimpleBufferStream v1.2.0
  [727e6d20] SimpleNonlinearSolve v2.1.0
  [699a6c99] SimpleTraits v0.9.4
  [ce78b400] SimpleUnPack v1.1.0
  [a2af1166] SortingAlgorithms v1.2.1
  [9f842d2f] SparseConnectivityTracer v0.6.13
  [47a9eef4] SparseDiffTools v2.23.1
  [dc90abb0] SparseInverseSubset v0.1.2
  [0a514795] SparseMatrixColorings v0.4.13
  [276daf66] SpecialFunctions v2.5.0
  [171d559e] SplittablesBase v0.1.15
  [860ef19b] StableRNGs v1.0.2
  [cae243ae] StackViews v0.1.1
  [aedffcd0] Static v1.1.1
  [0d7ed370] StaticArrayInterface v1.8.0
  [90137ffa] StaticArrays v1.9.12
  [1e83bf80] StaticArraysCore v1.4.3
  [82ae8749] StatsAPI v1.7.0
  [2913bbd2] StatsBase v0.34.4
  [4c63d2b9] StatsFuns v1.3.2
  [789caeaf] StochasticDiffEq v6.74.0
  [7792a7ef] StrideArraysCore v0.5.7
â [4db3bf67] StridedViews v0.2.2
  [69024149] StringEncodings v0.3.7
  [892a3eda] StringManipulation v0.4.1
â [09ab397b] StructArrays v0.6.21
  [53d494c1] StructIO v0.3.1
  [856f2bd8] StructTypes v1.11.0
  [2efcf032] SymbolicIndexingInterface v0.3.38
  [3783bdb8] TableTraits v1.0.1
  [bd369af6] Tables v1.12.0
  [62fd8b95] TensorCore v0.1.1
  [5d786b92] TerminalLoggers v0.1.7
  [8290d209] ThreadingUtilities v0.5.2
  [a759f4b9] TimerOutputs v0.5.27
  [9f7883ad] Tracker v0.2.37
  [3bb67fe8] TranscodingStreams v0.11.3
  [28d57a85] Transducers v0.4.84
  [781d530d] TruncatedStacktraces v1.4.0
  [5c2747f8] URIs v1.5.1
  [3a884ed6] UnPack v1.0.2
  [1cfade01] UnicodeFun v0.4.1
  [1986cc42] Unitful v1.22.0
  [a7773ee8] UnitfulAtomic v1.0.0
  [45397f5d] UnitfulLatexify v1.6.4
  [013be700] UnsafeAtomics v0.3.0
  [41fe7b60] Unzip v0.2.0
  [19fa3120] VertexSafeGraphs v0.2.0
  [ea10d353] WeakRefStrings v1.4.2
  [d49dbf32] WeightInitializers v1.1.1
  [76eceee3] WorkerUtilities v1.6.1
  [a5390f91] ZipFile v0.10.1
â [e88e6eb3] Zygote v0.6.75
  [700de1a5] ZygoteRules v0.2.7
  [02a925ec] cuDNN v1.4.1
  [6e34b625] Bzip2_jll v1.0.9+0
â [4ee394cb] CUDA_Driver_jll v0.10.4+0
â [76a88914] CUDA_Runtime_jll v0.15.5+0
â [62b44479] CUDNN_jll v9.4.0+0
  [83423d85] Cairo_jll v1.18.2+1
  [78a364fa] Chemfiles_jll v0.10.4+0
  [ee1fde0b] Dbus_jll v1.14.10+0
  [7cc45869] Enzyme_jll v0.0.172+0
  [2702e6a9] EpollShim_jll v0.0.20230411+1
  [2e619515] Expat_jll v2.6.5+0
â [b22a6f82] FFMPEG_jll v4.4.4+1
  [a3f928ae] Fontconfig_jll v2.15.0+0
  [d7e528f0] FreeType2_jll v2.13.3+1
  [559328eb] FriBidi_jll v1.0.16+0
  [0656b61e] GLFW_jll v3.4.0+2
  [d2c73de3] GR_jll v0.73.13+0
  [78b55507] Gettext_jll v0.21.0+0
  [f8c6e375] Git_jll v2.47.1+0
  [7746bdde] Glib_jll v2.82.4+0
  [3b182d85] Graphite2_jll v1.3.14+1
  [0234f1f7] HDF5_jll v1.14.5+0
  [2e76f6c2] HarfBuzz_jll v8.5.0+0
  [e33a78d0] Hwloc_jll v2.12.0+0
  [1d5cc7b8] IntelOpenMP_jll v2025.0.4+0
  [aacddb02] JpegTurbo_jll v3.1.1+0
  [9c1d0b0a] JuliaNVTXCallbacks_jll v0.2.1+0
  [c1c5ebd0] LAME_jll v3.100.2+0
  [88015f11] LERC_jll v4.0.1+0
  [dad2f222] LLVMExtra_jll v0.0.35+0
  [1d63c593] LLVMOpenMP_jll v18.1.7+0
  [dd4b983a] LZO_jll v2.10.3+0
  [81d17ec3] L_BFGS_B_jll v3.0.1+0
â [e9f186c6] Libffi_jll v3.2.2+2
  [d4300ac3] Libgcrypt_jll v1.11.0+0
  [7e76a0d4] Libglvnd_jll v1.7.0+0
  [7add5ba3] Libgpg_error_jll v1.51.1+0
  [94ce4f54] Libiconv_jll v1.18.0+0
  [4b2f31a3] Libmount_jll v2.40.3+0
  [89763e89] Libtiff_jll v4.7.1+0
  [38a345b3] Libuuid_jll v2.40.3+0
  [856f044c] MKL_jll v2025.0.1+1
  [7cb0a576] MPICH_jll v4.3.0+0
  [f1f71cc9] MPItrampoline_jll v5.5.2+0
  [9237b28f] MicrosoftMPI_jll v10.1.4+3
  [e98f9f5b] NVTX_jll v3.1.1+0
  [e7412a2a] Ogg_jll v1.3.5+1
  [fe0851c0] OpenMPI_jll v5.0.7+0
  [458c3c95] OpenSSL_jll v3.0.16+0
  [efe28fd5] OpenSpecFun_jll v0.5.6+0
  [91d4177d] Opus_jll v1.3.3+0
  [36c8627f] Pango_jll v1.56.1+0
â [30392449] Pixman_jll v0.43.4+0
â [c0090381] Qt6Base_jll v6.7.1+1
â [629bc702] Qt6Declarative_jll v6.7.1+2
â [ce943373] Qt6ShaderTools_jll v6.7.1+1
â [e99dba38] Qt6Wayland_jll v6.7.1+1
  [f50d1b31] Rmath_jll v0.5.1+0
  [a44049a8] Vulkan_Loader_jll v1.3.243+0
  [a2964d1f] Wayland_jll v1.21.0+2
  [2381bf8a] Wayland_protocols_jll v1.36.0+0
  [02c8fc9c] XML2_jll v2.13.6+0
  [aed1982a] XSLT_jll v1.1.42+0
  [ffd25f8a] XZ_jll v5.6.4+1
  [f67eecfb] Xorg_libICE_jll v1.1.1+0
  [c834827a] Xorg_libSM_jll v1.2.4+0
  [4f6342f7] Xorg_libX11_jll v1.8.6+3
  [0c0b7dd1] Xorg_libXau_jll v1.0.12+0
  [935fb764] Xorg_libXcursor_jll v1.2.3+0
  [a3789734] Xorg_libXdmcp_jll v1.1.5+0
  [1082639a] Xorg_libXext_jll v1.3.6+3
  [d091e8ba] Xorg_libXfixes_jll v6.0.0+0
  [a51aa0fd] Xorg_libXi_jll v1.8.2+0
  [d1454406] Xorg_libXinerama_jll v1.1.5+0
  [ec84b674] Xorg_libXrandr_jll v1.5.4+0
  [ea2f1a96] Xorg_libXrender_jll v0.9.11+1
  [14d82f49] Xorg_libpthread_stubs_jll v0.1.2+0
  [c7cfdc94] Xorg_libxcb_jll v1.17.0+3
  [cc61e674] Xorg_libxkbfile_jll v1.1.2+1
  [e920d4aa] Xorg_xcb_util_cursor_jll v0.1.4+0
  [12413925] Xorg_xcb_util_image_jll v0.4.0+1
  [2def613f] Xorg_xcb_util_jll v0.4.0+1
  [975044d2] Xorg_xcb_util_keysyms_jll v0.4.0+1
  [0d47668e] Xorg_xcb_util_renderutil_jll v0.3.9+1
  [c22f9ab0] Xorg_xcb_util_wm_jll v0.4.1+1
  [35661453] Xorg_xkbcomp_jll v1.4.6+1
  [33bec58e] Xorg_xkeyboard_config_jll v2.39.0+0
  [c5fb5394] Xorg_xtrans_jll v1.5.1+0
  [3161d3a3] Zstd_jll v1.5.7+1
  [1e29f10c] demumble_jll v1.3.0+0
  [35ca27e7] eudev_jll v3.2.9+0
  [214eeab7] fzf_jll v0.56.3+0
  [1a1c6b14] gperf_jll v3.1.1+1
  [477f73a3] libaec_jll v1.1.3+0
  [a4ae2306] libaom_jll v3.11.0+0
  [0ac62f75] libass_jll v0.15.2+0
  [1183f4f0] libdecor_jll v0.2.2+0
  [2db6ffa8] libevdev_jll v1.11.0+0
  [f638f0a6] libfdk_aac_jll v2.0.3+0
  [36db933b] libinput_jll v1.18.0+0
  [b53b4c65] libpng_jll v1.6.46+0
  [f27f6e37] libvorbis_jll v1.3.7+2
  [009596ad] mtdev_jll v1.1.6+0
  [1317d2d5] oneTBB_jll v2022.0.0+0
â [1270edf5] x264_jll v2021.5.5+0
â [dfaa095f] x265_jll v3.5.0+0
  [d8fb68d0] xkbcommon_jll v1.4.1+2
  [0dad84c5] ArgTools v1.1.1
  [56f22d72] Artifacts
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [f43a241f] Downloads v1.6.0
  [7b1f6079] FileWatching
  [9fa8497b] Future
  [b77e0a4c] InteractiveUtils
  [4af54fe1] LazyArtifacts
  [b27032c2] LibCURL v0.6.4
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [ca575930] NetworkOptions v1.2.0
  [44cfe95a] Pkg v1.10.0
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA v0.7.0
  [9e88b42a] Serialization
  [1a1011a3] SharedArrays
  [6462fe0b] Sockets
  [2f01184e] SparseArrays v1.10.0
  [10745b16] Statistics v1.10.0
  [4607b0f0] SuiteSparse
  [fa267f1f] TOML v1.0.3
  [a4e569a6] Tar v1.10.0
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
  [e66e0078] CompilerSupportLibraries_jll v1.1.1+0
  [deac9b47] LibCURL_jll v8.4.0+0
  [e37daf67] LibGit2_jll v1.6.4+0
  [29816b5a] LibSSH2_jll v1.11.0+1
  [c8ffd9c3] MbedTLS_jll v2.28.2+1
  [14a3606d] MozillaCACerts_jll v2023.1.10
  [4536629a] OpenBLAS_jll v0.3.23+4
  [05823500] OpenLibm_jll v0.8.1+2
  [efcefdf7] PCRE2_jll v10.42.0+1
  [bea87d4a] SuiteSparse_jll v7.2.1+1
  [83775a58] Zlib_jll v1.2.13+1
  [8e850b90] libblastrampoline_jll v5.11.0+0
  [8e850ede] nghttp2_jll v1.52.0+1
  [3f19e933] p7zip_jll v17.4.0+2
Info Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`You can also download the manifest file and the project file.Neural Ordinary Differential Equations Â»Powered by Documenter.jl and the Julia Programming Language.SettingsThemeAutomatic (OS)documenter-lightdocumenter-darkcatppuccin-lattecatppuccin-frappecatppuccin-macchiatocatppuccin-mochaThis document was generated with Documenter.jl version 1.8.1 on Sunday 23 February 2025. Using Julia version 1.10.8."
1,https://www.tensorflow.org/probability?hl=pt-br,"

















TensorFlow Probability








      
      Ir para o conteúdo principal
    



























    Instalar
  
    



    Aprender
  
    








                      Introdução
                    

                      Ainda não conhece o TensorFlow?
                    





                      TensorFlow
                    

                      A principal biblioteca de código aberto de ML
                    





                      Para JavaScript
                    

                      TensorFlow.js para ML com JavaScript
                    





                      Para dispositivos móveis e Internet das Coisas (IoT)
                    

                      TensorFlow Lite para dispositivos móveis e incorporados
                    





                      Para produção
                    

                      TensorFlow Extended para componentes de ML de ponta a ponta
                    









    API
  
    








                      TensorFlow (2.12)
                    





                      Versions…
                    









                      TensorFlow.js
                    





                      TensorFlow Lite
                    





                      TFX
                    









    Recursos
  
    








                      Modelos e conjuntos de dados
                    

                      Conjuntos de dados e modelos pré-treinados criados pelo Google e pela comunidade
                    





                      Ferramentas
                    

                      Ecossistema de ferramentas que ajudam a usar o TensorFlow
                    





                      Bibliotecas e extensões
                    

                      Bibliotecas e extensões criadas no TensorFlow
                    





                      Programa de certificação do TensorFlow
                    

                      Demonstre sua proficiência em ML e se destaque
                    





                      Aprender sobre ML
                    

                      Recursos educacionais para aprender os fundamentos de ML com o TensorFlow
                    





                      IA responsável
                    

                      Recursos e ferramentas para integrar práticas de IA responsável ao seu fluxo de trabalho de ML
                    









    Comunidade
  
    








                      Participar
                    

                      Veja como participar
                    





                      Fórum ↗
                    

                      Plataforma de discussão para a comunidade do TensorFlow
                    





                      Grupos
                    

                      Grupos de usuários, grupos de interesse e listas de e-mails
                    





                      Contribuir
                    

                      Guia para contribuir com o código e a documentação
                    









    Por que usar o TensorFlow
  
    








                      Sobre
                    





                      Estudos de caso
                    





                      Parceiros de serviços de IA
                    



















/










English


Español


Español – América Latina


Français


Indonesia


Italiano


Polski


Português


Português – Brasil


Tiếng Việt


Türkçe


Русский


עברית


العربيّة


فارسی


हिंदी


বাংলা


ภาษาไทย


中文 – 简体


中文 – 繁體


日本語


한국어




  GitHub


Fazer login











    
        Probability
      
  



                TensorFlow Probability é uma biblioteca para raciocínio probabilístico e análise estatística.

              







    Visão geral
  
    



    Guia e tutoriais
  
    



    API
  
    






































      Instalar
   







      Aprender
   





      Mais
   









      API
   





      Mais
   









      Recursos
   





      Mais
   









      Visão geral
   





      Guia e tutoriais
   







      API
   









      Comunidade
   





      Mais
   









      Por que usar o TensorFlow
   





      Mais
   









      GitHub
   









      Introdução
   





      TensorFlow
   





      Para JavaScript
   





      Para dispositivos móveis e Internet das Coisas (IoT)
   





      Para produção
   







      TensorFlow (2.12)
   





      Versions…
   





      TensorFlow.js
   





      TensorFlow Lite
   





      TFX
   







      Modelos e conjuntos de dados
   





      Ferramentas
   





      Bibliotecas e extensões
   





      Programa de certificação do TensorFlow
   





      Aprender sobre ML
   





      IA responsável
   







      Participar
   





      Fórum ↗
   





      Grupos
   





      Contribuir
   







      Sobre
   





      Estudos de caso
   





      Parceiros de serviços de IA
   





















          Aprenda o que há de mais recente em aprendizado de máquina, IA generativa e muito mais no WiML Symposium 2023 Registre-se







    
        TensorFlow
      
  




    
        Recursos
      
  




    
        Probability
      
  






      
      Mantenha tudo organizado com as coleções
    

      
      Salve e categorize o conteúdo com base nas suas preferências.
    









      
    
        A TensorFlow Probability é uma biblioteca para raciocínio probabilístico e análise estatística.
      
  
    






import tensorflow as tf
import tensorflow_probability as tfp

# Pretend to load synthetic data set.
features = tfp.distributions.Normal(loc=0., scale=1.).sample(int(100e3))
labels = tfp.distributions.Bernoulli(logits=1.618 * features).sample()

# Specify model.
model = tfp.glm.Bernoulli()

# Fit model given data.
coeffs, linear_response, is_converged, num_iter = tfp.glm.fit(
    model_matrix=features[:, tf.newaxis],
    response=tf.cast(labels, dtype=tf.float32),
    model=model)
# ==> coeffs is approximately [1.618] (We're golden!)
Executar em um notebook





A TensorFlow Probability (TFP) é uma biblioteca Python criada no TensorFlow que facilita a combinação de modelos probabilísticos e aprendizado profundo em hardware moderno (TPU, GPU). Foi desenvolvida para cientistas de dados, estatísticos, pesquisadores de ML e profissionais que querem codificar o conhecimento do domínio para entender os dados e fazer previsões. A TFP inclui: 
uma ampla seleção de distribuições de probabilidade e bijetoras;
ferramentas para criar modelos probabilísticos profundos, incluindo camadas probabilísticas
  e uma abstração ""JointDistribution"";
inferência variacional e cadeia de Markov de Monte Carlo;
otimizadores como Nelder-Mead, BFGS e SGLD.
 Como a TFP herda os benefícios do TensorFlow, é possível criar, ajustar e implantar um modelo usando uma única linguagem durante todo o ciclo de vida da exploração e produção do modelo. A TFP é de código aberto e está disponível no GitHub. Para começar, consulte o guia da TensorFlow Probability.

          

















    
        Aprender com confiança (conferência de desenvolvedores do TensorFlow 2019)
      
  


Assistir ao vídeo


















    
        Modelagem de série temporal estruturada na TFP
      
  


Ler no blog do TensorFlow


















    
        Codificadores automáticos variacionais com a TFP
      
  


Ler no blog do TensorFlow


















    
        Regressão com camadas probabilísticas na TFP
      
  


Ler no blog do TensorFlow
























    
        Introdução à programação probabilística
      
  


O tutorial prático de introdução a métodos bayesianos para hackers já está disponível com exemplos na TensorFlow Probability.

          

Ler no blog do TensorFlow


















    
        Análise de erros em modelos financeiros com a TFP
      
  


Ler no blog do TensorFlow


















    
        IA industrial: aprendizado profundo probabilístico baseado em física usando a TFP
      
  


Ler no blog do TensorFlow


















    
        TensorFlow Probability no GitHub
      
  


Ver no GitHub
























Permanecer conectado



            
          
            Blog
          
          



            
          
            Fórum
          
          



            
          
            GitHub
          
          



            
          
            Twitter
          
          



            
              
              
            
          
            YouTube
          
          




Suporte



            
          
            Issue Tracker
          
          



            
          
            Notas da versão
          
          



            
          
            Stack Overflow
          
          



            
          
            Diretrizes da marca
          
          



            
              
              
            
          
            Menções do TensorFlow
          
          












          Termos de Serviço
        



          Privacidade
        



          Manage cookies
        


Faça sua inscrição para receber newsletters do TensorFlow

          Inscrever-se
        





English


Español


Español – América Latina


Français


Indonesia


Italiano


Polski


Português


Português – Brasil


Tiếng Việt


Türkçe


Русский


עברית


العربيّة


فارسی


हिंदी


বাংলা


ภาษาไทย


中文 – 简体


中文 – 繁體


日本語


한국어




















"
2,https://www.pymc.io/welcome.html,"













Home — PyMC project website














































Skip to main content



    Back to top
  










Ctrl+K



















    Site Navigation
  



                        Home
                      



                        Examples
                      



                        Learn
                      



                        API
                      



                        Community
                      



                        Contributing
                      











GitHub



Twitter



YouTube



Discourse




















    Site Navigation
  



                        Home
                      



                        Examples
                      



                        Learn
                      



                        API
                      



                        Community
                      



                        Contributing
                      








GitHub



Twitter



YouTube



Discourse







Section Navigation

PyMC ecosystem
History
Testimonials

External links

Discourse
Twitter
YouTube
LinkedIn
Meetup
GitHub


























Home









Home#

PyMC is a probabilistic programming library for Python that allows users to build Bayesian models with a simple Python API and fit them using Markov chain Monte Carlo (MCMC) methods.

Features#
PyMC strives to make Bayesian modeling as simple and painless as possible, allowing users to focus on their problem rather than the methods.
Here is what sets it apart:

Modern: Includes state-of-the-art inference algorithms, including MCMC (NUTS) and variational inference (ADVI).
User friendly: Write your models using friendly Python syntax. Learn Bayesian modeling from the many example notebooks.
Fast: Uses PyTensor as its computational backend to compile through C, Numba or JAX, run your models on the GPU, and benefit from complex graph-optimizations.
Batteries included: Includes probability distributions, Gaussian processes, ABC, SMC and much more. It integrates nicely with ArviZ for visualizations and diagnostics, as well as Bambi for high-level mixed-effect models.
Community focused: Ask questions on discourse, join MeetUp events, follow us on Twitter, and start contributing.



Example from Linear Regression#
This example demonstrates how to perform Bayesian inference for a linear regression model to predict plant growth based on environmental factors.
Plant growth can be influenced by multiple factors, and understanding these relationships is crucial for optimizing agricultural practices.
Independent Variables:

Sunlight Hours: Number of hours the plant is exposed to sunlight daily.
Water Amount: Daily water amount given to the plant (in milliliters).
Soil Nitrogen Content: Percentage of nitrogen content in the soil.

Dependent Variable:

Plant Growth (y): Measured as the increase in plant height (in centimeters) over a certain period.

import pymc as pm

# Taking draws from a normal distribution
seed = 42
x_dist = pm.Normal.dist(shape=(100, 3))
x_data = pm.draw(x_dist, random_seed=seed)

# Define coordinate values for all dimensions of the data
coords={
 ""trial"": range(100),
 ""features"": [""sunlight hours"", ""water amount"", ""soil nitrogen""],
}

# Define generative model
with pm.Model(coords=coords) as generative_model:
   x = pm.Data(""x"", x_data, dims=[""trial"", ""features""])

   # Model parameters
   betas = pm.Normal(""betas"", dims=""features"")
   sigma = pm.HalfNormal(""sigma"")

   # Linear model
   mu = x @ betas

   # Likelihood
   # Assuming we measure deviation of each plant from baseline
   plant_growth = pm.Normal(""plant growth"", mu, sigma, dims=""trial"")


# Generating data from model by fixing parameters
fixed_parameters = {
 ""betas"": [5, 20, 2],
 ""sigma"": 0.5,
}
with pm.do(generative_model, fixed_parameters) as synthetic_model:
   idata = pm.sample_prior_predictive(random_seed=seed) # Sample from prior predictive distribution.
   synthetic_y = idata.prior[""plant growth""].sel(draw=0, chain=0)


# Infer parameters conditioned on observed data
with pm.observe(generative_model, {""plant growth"": synthetic_y}) as inference_model:
   idata = pm.sample(random_seed=seed)

   summary = pm.stats.summary(idata, var_names=[""betas"", ""sigma""])
   print(summary)


From the summary, we can see that the mean of the inferred parameters are very close to the fixed parameters


Params
mean
sd
hdi_3%
hdi_97%
mcse_mean
mcse_sd
ess_bulk
ess_tail
r_hat



betas[sunlight hours]
4.972
0.054
4.866
5.066
0.001
0.001
3003
1257
1

betas[water amount]
19.963
0.051
19.872
20.062
0.001
0.001
3112
1658
1

betas[soil nitrogen]
1.994
0.055
1.899
2.107
0.001
0.001
3221
1559
1

sigma
0.511
0.037
0.438
0.575
0.001
0
2945
1522
1



# Simulate new data conditioned on inferred parameters
new_x_data = pm.draw(
    pm.Normal.dist(shape=(3, 3)),
    random_seed=seed,
)
new_coords = coords | {""trial"": [0, 1, 2]}

with inference_model:
    pm.set_data({""x"": new_x_data}, coords=new_coords)
    pm.sample_posterior_predictive(
        idata,
        predictions=True,
        extend_inferencedata=True,
        random_seed=seed,
    )

pm.stats.summary(idata.predictions, kind=""stats"")


The new data conditioned on inferred parameters would look like:


Output
mean
sd
hdi_3%
hdi_97%



plant growth[0]
14.229
0.515
13.325
15.272

plant growth[1]
24.418
0.511
23.428
25.326

plant growth[2]
-6.747
0.511
-7.740
-5.797



# Simulate new data, under a scenario where the first beta is zero
with pm.do(
    inference_model,
    {inference_model[""betas""]: inference_model[""betas""] * [0, 1, 1]},
) as plant_growth_model:
    new_predictions = pm.sample_posterior_predictive(
        idata,
        predictions=True,
        random_seed=seed,
    )

pm.stats.summary(new_predictions, kind=""stats"")


The new data, under the above scenario would look like:


Output
mean
sd
hdi_3%
hdi_97%



plant growth[0]
12.149
0.515
11.193
13.135

plant growth[1]
29.809
0.508
28.832
30.717

plant growth[2]
-0.131
0.507
-1.121
0.791





Get started#

Installation instructions
Beginner guide (if you do not know Bayesian modeling)
API quickstart (if you do know Bayesian modeling)
Example gallery
Discourse help forum



Announcements#






Release announcement



PyMC forked Aesara to PyTensor
PyTensor will allow for new features such as labeled arrays, as well as speed up development and streamline the PyMC codebase and user experience.

PyMC forked Aesara to PyTensor




Release announcement



PyMC 4.0 is officially released!
PyMC 4.0 is a major rewrite of the library with many great new features while keeping the same modeling API of PyMC3.

PyMC 4.0 Release Announcement




Event



PyMC - Office Hours
The PyMC team has recently started hosting office hours regularly.
Subscribe on Discourse to be notified of the next event!

https://discourse.pymc.io/tag/office-hours




Talk



Probabilistic Programming in PyMC
Austin Rochford gave the coolest talk on Probabilistic Programming in PyMC 4.0

https://austinrochford.com/posts/intro-prob-prog-pymc.html




Blog post



Sprint testimonials
Read about the recent PyMC-Data Umbrella sprint in this interview with
Sandra Meneses, one of the participants who submitted a PR

Participating in the PyMC-Data Umbrella sprint: Interview with Sandra Meneses






Sponsors#







NumFOCUS

NumFOCUS is our non-profit umbrella organization.

https://numfocus.org





PyMC Labs

PyMC Labs offers professional consulting services for PyMC.

https://pymc-labs.io





Mistplay

Mistplay is the world’s leading Loyalty Program for mobile gamers.

https://www.mistplay.com/





ODSC

The future of AI gathers here.

https://odsc.com/california/?utm_source=pymc&utm_medium=referral





Adia Lab

Dedicated to basic and applied research in data and computational sciences.

https://www.adialab.ae/


















previous
The PyMC library




next
PyMC ecosystem









 On this page
  


Features
Example from Linear Regression
Get started
Announcements
Sponsors










      
      
        
          Edit on GitHub
        
      
    





 Show Source
    





 Support PyMC
    
















    
      © Copyright 2022, PyMC Team.
      




    Created using Sphinx 8.0.2.
    






  Built with the PyData Sphinx Theme 0.14.4.





"
3,https://scipy.org/,"








SciPy









































          Install
        

          Documentation
        

          Community
        

          About Us
        

          Contribute
        









                  SciPy
                  



                      Fundamental algorithms for scientific computing in Python
                  

Get started







 SciPy 1.15.2 released!
2025-02-16









      Fundamental algorithms
    
      SciPy provides algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems.
   






      Broadly applicable
    
      The algorithms and data structures provided by SciPy are broadly applicable across domains.
   






      Foundational
    
      Extends NumPy providing additional tools for array computing and provides specialized data structures, such as sparse matrices and k-dimensional trees.
   






      Performant
    
      SciPy wraps highly-optimized implementations written in low-level languages like Fortran, C, and C++. Enjoy the flexibility of Python with the speed of compiled code.
   






      Easy to use
    
      SciPy’s high level syntax makes it accessible and productive for programmers from any background or experience level.
   






      Open source
    
      Distributed under a liberal BSD license, SciPy is developed and maintained publicly on GitHub by a vibrant, responsive, and diverse community.
   
















            Install
          



            Documentation
          



            Citing SciPy
          



            Roadmap
          





            About Us
          



            Community
          



            SciPy Conference
          



            Contribute
          



            Code of Conduct
          





            FAQ
          



            Terms of Use
          



            Privacy
          



            Press Kit
          



            Social Media
          











© 2025 . All rights reserved.










"
4,https://pythonhosted.org/PySPH/overview.html,"


  



PySPH: a Python-based SPH framework — PySPH 1.0a4 documentation











 PySPH
          

          
          

                1.0a4
              










PySPH: a Python-based SPH framework
Features
SPH formulations
Credits
Citing PySPH
History
Support
Changelog
1.0a4
1.0a3
1.0a2
1.0a1






Installation and getting started
Learning the ropes
A more detailed tutorial


The PySPH framework
Using the PySPH library
Introduction to PyZoltan


PySPH Reference Documentation
Solver Interfaces







PySPH





Docs »
PySPH: a Python-based SPH framework

 View page source







PySPH: a Python-based SPH frameworkÂ¶
PySPH is an open source framework for Smoothed Particle Hydrodynamics (SPH)
simulations.  It is implemented in Python and the performance critical parts
are implemented in Cython.
PySPH is implemented in a way that allows a user to specify the entire SPH
simulation in pure Python. High-performance code is generated from this
high-level Python code, compiled on the fly and executed.  PySPH can use OpenMP
to utilize multi-core CPUs effectively.  PySPH also features optional automatic
parallelization (multi-CPU) using mpi4py_ and Zoltan.  If you wish to use the
parallel capabilities you will need to have these installed.
Here are videos of simulations made with PySPH.



PySPH is hosted on bitbucket.  Please see
the bitbucket site for development
details.

FeaturesÂ¶


User scripts and equations are written in pure Python.
Flexibility to define arbitrary SPH equations operating on particles.
Ability to define your own multi-step integrators in pure Python.
High-performance: our performance is comparable to hand-written solvers
implemented in FORTRAN.
Seamless multi-core support with OpenMP.
Seamless parallel integration using Zoltan.
BSD license.




SPH formulationsÂ¶
Currently, PySPH has numerous examples to solve the viscous, incompressible
Navier-Stokes equations using the weakly compressible (WCSPH) approach. The
following formulations are currently implemented:

Weakly Compressible SPH (WCSPH) for free-surface flows (Gesteira et al. 2010, Journal of Hydraulic Research, 48, pp. 6–27)



3D dam-break past an obstacle SPHERIC benchmark Test 2


Transport Velocity Formulation for incompressilbe fluids (Adami et al. 2013, JCP, 241, pp. 292–307).



Streamlines for a driven cavity


SPH for elastic dynamics (Gray et al. 2001, CMAME, Vol. 190, pp 6641–6662)



Collision of two elastic rings.


Compressible SPH (Puri et al. 2014, JCP, Vol. 256, pp 308–333)



CreditsÂ¶
PySPH is primarily developed at the Department of Aerospace
Engineering, IIT Bombay. We are grateful
to IIT Bombay for the support.  Our primary goal is to build a
powerful SPH-based tool for both application and research. We hope that
this makes it easy to perform reproducible computational research.
Lead developers:

Prabhu Ramachandran
Kunal Puri

Earlier developers:

Pankaj Pandey (stress solver and improved load balancing, 2011)
Chandrashekhar Kaushik (original parallel and serial implementation in 2009)

The following have contributed bug-fixes, features, documentation etc.

Arkopal Dutt, Arpit Agarwal, Sarang Minhas, S Saravanan, Vishnu Sivadasan



Citing PySPHÂ¶
We are in the process of writing up an article on the new PySPH
framework as it stands today.  In the meanwhile, if you use PySPH and
wish to cite it you may use this:


Prabhu Ramachandran and Kunal Puri, PySPH: A framework for parallel
particle simulations, In proceedings of the 3rd International
Conference on Particle-Based Methods (Particles 2013), Stuttgart,
Germany, 18th September 2013.




HistoryÂ¶

2009: PySPH started with a simple Cython based 1D implementation written by
Prabhu.
2009-2010: Chandrashekhar Kaushik worked on a full 3D SPH implementation with
a more general purpose design.  The implementation was in a mix of Cython and
Python.
2010-2012: The previous implementation was a little too complex and was
largely overhauled by Kunal and Pankaj.  This became the PySPH 0.9beta
release.  The difficulty with this version was that it was almost entirely
written in Cython, making it hard to extend or add new formulations without
writing more Cython code.  Doing this was difficult and not too pleasant.  In
addition it was not as fast as we would have liked it. It ended up feeling
like we might as well have implemented it all in C++ and exposed a Python
interface to that.
2011-2012: Kunal also implemented SPH2D and another internal version called
ZSPH in Cython which included Zoltan based parallelization using PyZoltan.
This was specific to his PhD research and again required writing Cython
making it difficult for the average user to extend.
2013-present In early 2013, Prabhu reimplemented the core of PySPH to be
almost entirely auto-generated from pure Python.  The resulting code was
faster than previous implementations and very easy to extend entirely from
pure Python.  Kunal and Prabhu integrated PyZoltan into PySPH and the current
version of PySPH was born.  Subsequently, OpenMP support was also added in
2015.



SupportÂ¶
If you have any questions or are running into any difficulties with PySPH,
please email or post your questions on the pysph-users mailing list here:
https://groups.google.com/d/forum/pysph-users
Please also take a look at the PySPH issue tracker.


ChangelogÂ¶

1.0a4Â¶

Release date: 14th July, 2016.
Improve many examples to make it easier to make comparisons.
Many equation parameters no longer have defaults to prevent accidental
errors from not specifying important parameters.
Added support for Scheme classes that manage the generation of equations
and solvers.  A user simply needs to create the particles and setup a scheme
with the appropriate parameters to simulate a problem.
Add support to easily handle multiple rigid bodies.
Add support to dump HDF5 files if h5py is installed.
Add support to directly dump VTK files using either Mayavi or PyVisfile,
see pysph dump_vtk
Improved the nearest neighbor code, which gives about 30% increase in
performance in 3D.
Remove the need for the windows_env.bat script on Windows.  This is
automatically setup internally.
Add test that checks if all examples run.
Remove unused command line options and add a --max-steps option to allow
a user to run a specified number of iterations.
Added Ghia et al.’s results for lid-driven-cavity flow for easy comparison.
Added some experimental results for the dam break problem.
Use argparse instead of optparse as it is deprecated in Python 3.x.
Add pysph.tools.automation to facilitate easier automation and
reproducibility of PySPH simulations.
Add spatial hash and extended spatial hash NNPS algorithms for comparison.
Refactor and cleanup the NNPS related code.
Add several gas-dynamics examples and the ADEKEScheme.
Work with mpi4py_ version 2.0.0 and older versions.
Fixed major bug with TVF implementation and add support for 3D simulations
with the TVF.
Fix bug with uploaded tarballs that breaks pip install pysph on Windows.
Fix the viewer UI to continue playing files when refresh is pushed.
Fix bugs with the timestep values dumped in the outputs.
Fix floating point issues with timesteps, where examples would run a final
extremely tiny timestep in order to exactly hit the final time.



1.0a3Â¶

Release date: 18th August, 2015.
Fix bug with output_at_times specification for solver.
Put generated sources and extensions into a platform specific directory in
~/.pysph/sources/<platform-specific-dir> to avoid problems with multiple
Python versions, operating systems etc.
Use locking while creating extension modules to prevent problems when
multiple processes generate the same extesion.
Improve the Application class so users can subclass it to create
examples. The users can also add their own command line arguments and add
pre/post step/stage callbacks by creating appropriate methods.
Moved examples into the pysph.examples.  This makes the examples
reusable and easier to run as installation of pysph will also make the
examples available.  The examples also perform the post-processing to make
them completely self-contained.
Add support to write compressed output.
Add support to set the kernel from the command line.
Add a new pysph script that supports view, run, and test
sub-commands.  The pysph_viewer is now removed, use pysph view
instead.
Add a simple remeshing tool in pysph.solver.tools.SimpleRemesher.
Cleanup the symmetric eigenvalue computing routines used for solid
mechanics problems and allow them to be used with OpenMP.
The viewer can now view the velocity magnitude (vmag) even if it
is not present in the data.
Port all examples to use new Application API.
Do not display unnecessary compiler warnings when there are no errors but
display verbose details when there is an error.



1.0a2Â¶

Release date: 12th June, 2015
Support for tox, this makes it trivial to test PySPH on py26, py27 and py34
(and potentially more if needed).
Fix bug in code generator where it is unable to import pysph before it is
installed.
Support installation via pip by allowing egg_info to be run without
cython or numpy.
Added Codeship CI build using tox
for py27 and py34.
CI builds for Python 2.7.x and 3.4.x.
Support for Python-3.4.x.
Support for Python-2.6.x.



1.0a1Â¶

Release date: 3rd June, 2015.
First public release of the new PySPH code which uses code-generation and is
hosted on bitbucket.
OpenMP support.
MPI support using Zoltan.
Automatic code generation from high-level Python code.
Support for various multi-step integrators.
Added an interpolator utility module that interpolates the particle data
onto a desired set of points (or grids).
Support for inlets and outlets.
Support for basic Gmsh input/output.
Plenty of examples for various SPH formulations.
Improved documentation.
Continuous integration builds on Shippable,
Drone.io, and AppVeyor.








Next 
 Previous




        © Copyright 2013-2015, PySPH developers.

    

  Built with Sphinx using a theme provided by Read the Docs. 














"
5,https://gpy.readthedocs.io/en/deploy/,"


  



GPy - A Gaussian Process (GP) framework in Python — GPy __version__ = ""1.12.0""
 documentation

























 GPy
          

          
          

                deploy
              









For developers

Creating new Models
Creating new kernels
Defining a new plotting function in GPy
Parameterization handling

API Documentation

GPy.core package
GPy.core.parameterization package
GPy.models package
GPy.kern package
GPy.likelihoods package
GPy.mappings package
GPy.examples package
GPy.util package
GPy.plotting package
GPy.inference.optimization package
GPy.inference.latent_function_inference package
GPy.inference.mcmc package







GPy





Docs »
GPy - A Gaussian Process (GP) framework in Python

 Edit on GitHub







GPy - A Gaussian Process (GP) framework in Python¶

Introduction¶
GPy is a Gaussian Process (GP) framework written in Python, from the Sheffield machine learning group. It includes support for basic GP regression, multiple output GPs (using coregionalization), various noise models, sparse GPs, non-parametric regression and latent variables.
The GPy homepage contains tutorials for users and further information on the project, including installation instructions.
The documentation hosted here is mostly aimed at developers interacting closely with the code-base.


Source Code¶
The code can be found on our Github project page. It is open source and provided under the BSD license.


Installation¶
Installation instructions can currently be found on our Github project page.


Tutorials¶
Several tutorials have been developed in the form of Jupyter Notebooks.


Architecture¶
GPy is a big, powerful package, with many features. The concept of how to use GPy in general terms is roughly as follows. A model (GPy.models) is created - this is at the heart of GPy from a user perspective. A kernel (GPy.kern), data and, usually, a representation of noise are assigned to the model. Specific models require, or can make use of, additional information. The kernel and noise are controlled by hyperparameters - calling the optimize (GPy.core.gp.GP.optimize) method against the model invokes an iterative process which seeks optimal hyperparameter values. The model object can be used to make plots and predictions (GPy.core.gp.GP.predict).


For developers

Creating new Models
Creating new kernels
Defining a new plotting function in GPy
Parameterization handling



API Documentation

GPy.core package
GPy.core.parameterization package
GPy.models package
GPy.kern package
GPy.likelihoods package
GPy.mappings package
GPy.examples package
GPy.util package
GPy.plotting package
GPy.inference.optimization package
GPy.inference.latent_function_inference package
GPy.inference.mcmc package








Next 




        © Copyright 2020, GPy Authors, see https://github.com/SheffieldML/GPy/graphs/contributors
      
        
          Revision 62544515.
        


  Built with Sphinx using a theme provided by Read the Docs. 








"
6,https://pypi.org/project/diffeqpy/,"








diffeqpy · PyPI










 

















Skip to main content

Switch to mobile version    







Warning

Some features may not work without JavaScript. Please try enabling it if you encounter problems.


 












Search PyPI



Search



 


Help
Sponsors
Log in
Register




Menu      




Help
Sponsors
Log in
Register



 




Search PyPI



Search








        diffeqpy 2.5.3
      


pip install diffeqpy


Copy PIP instructions






Latest version


Released: 
  Dec 5, 2024
 





 
Solving Differential Equations in Python
 







Navigation





Project description                




Release history                




Download files                






Verified details    

These details have been verified by PyPI
Maintainers






            ChrisRackauckas
          




Unverified details
These details have not been verified by PyPI
Project links



Homepage
      



Meta



License: MIT License (MIT)
      



Author: Chris Rackauckas and Takafumi Arakaki





Tags

        differential,      

        equations,      

        stochastic,      

        ordinary,      

        delay,      

        differential-algebraic,      

        dae,      

        ode,      

        sde,      

        dde,      

        oneapi,      

        AMD,      

        ROCm,      

        CUDA,      

        Metal,      

        GPU      





Classifiers


Development Status



            4 - Beta
          




License



            OSI Approved :: MIT License
          




Programming Language



            Python :: 3.8
          



            Python :: 3.9
          



            Python :: 3.10
          



            Python :: 3.11
          



            Python :: 3.12
          




Topic



            Scientific/Engineering :: Mathematics
          



            Scientific/Engineering :: Physics
          















Project description              




Project details              




Release history            




Download files              




Project description

diffeqpy


diffeqpy is a package for solving differential equations in Python. It utilizes
DifferentialEquations.jl for its core routines
to give high performance solving of many different types of differential equations,
including:

Discrete equations (function maps, discrete stochastic (Gillespie/Markov)
simulations)
Ordinary differential equations (ODEs)
Split and Partitioned ODEs (Symplectic integrators, IMEX Methods)
Stochastic ordinary differential equations (SODEs or SDEs)
Random differential equations (RODEs or RDEs)
Differential algebraic equations (DAEs)
Delay differential equations (DDEs)
Mixed discrete and continuous equations (Hybrid Equations, Jump Diffusions)

directly in Python.
If you have any questions, or just want to chat about solvers/using the package,
please feel free to chat in the Gitter channel. For bug reports, feature requests, etc., please submit an issue.
Installation
To install diffeqpy, use pip:
pip install diffeqpy

and you're good!
Collab Notebook Examples

Solving the Lorenz equation faster than SciPy+Numba
Solving ODEs on GPUs Fast in Python with diffeqpy

General Flow
Import and setup the solvers available in DifferentialEquations.jl via the command:
from diffeqpy import de

In case only the solvers available in OrdinaryDiffEq.jl are required then use the command:
from diffeqpy import ode

The general flow for using the package is to follow exactly as would be done
in Julia, except add de. or ode. in front. Note that ode. has lesser loading time and a smaller memory footprint compared to de..
Most of the commands will work without any modification. Thus
the DifferentialEquations.jl documentation
and the DiffEqTutorials
are the main in-depth documentation for this package. Below we will show how to
translate these docs to Python code.
Note about !
Python does not allow ! in function names, so this is also a limitation of pyjulia
To use functions which on the Julia side have a !, like step!, replace ! by _b, for example:
from diffeqpy import de

def f(u,p,t):
    return -u

u0 = 0.5
tspan = (0., 1.)
prob = de.ODEProblem(f, u0, tspan)
integrator = de.init(prob, de.Tsit5())
de.step_b(integrator)

is valid Python code for using the integrator interface.
Ordinary Differential Equation (ODE) Examples
One-dimensional ODEs
from diffeqpy import de

def f(u,p,t):
    return -u

u0 = 0.5
tspan = (0., 1.)
prob = de.ODEProblem(f, u0, tspan)
sol = de.solve(prob)

The solution object is the same as the one described
in the DiffEq tutorials
and in the solution handling documentation
(note: the array interface is missing). Thus for example the solution time points
are saved in sol.t and the solution values are saved in sol.u. Additionally,
the interpolation sol(t) gives a continuous solution.
We can plot the solution values using matplotlib:
import matplotlib.pyplot as plt
plt.plot(sol.t,sol.u)
plt.show()


We can utilize the interpolation to get a finer solution:
import numpy
t = numpy.linspace(0,1,100)
u = sol(t)
plt.plot(t,u)
plt.show()


Solve commands
The common interface arguments
can be used to control the solve command. For example, let's use saveat to
save the solution at every t=0.1, and let's utilize the Vern9() 9th order
Runge-Kutta method along with low tolerances abstol=reltol=1e-10:
sol = de.solve(prob,de.Vern9(),saveat=0.1,abstol=1e-10,reltol=1e-10)

The set of algorithms for ODEs is described
at the ODE solvers page.
Compilation with de.jit and Julia
When solving a differential equation, it's pertinent that your derivative
function f is fast since it occurs in the inner loop of the solver. We can
convert the entire ode problem to symbolic form, optimize that symbolic form,
and emit efficient native code to simulate it using de.jit to improve the
efficiency of the solver at the expense of added setup time:
fast_prob = de.jit(prob)
sol = de.solve(fast_prob)

Additionally, you can directly define the functions in Julia. This will also
allow for specialization and could be helpful to increase the efficiency for
repeat or long calls. This is done via seval:
jul_f = de.seval(""(u,p,t)->-u"") # Define the anonymous function in Julia
prob = de.ODEProblem(jul_f, u0, tspan)
sol = de.solve(prob)

Limitations
de.jit, uses ModelingToolkit.jl's modelingtoolkitize internally and some
restrictions apply. Not all models can be jitted. See the
modelingtoolkitize documentation
for more info.
Systems of ODEs: Lorenz Equations
To solve systems of ODEs, simply use an array as your initial condition and
define f as an array function:
def f(u,p,t):
    x, y, z = u
    sigma, rho, beta = p
    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]

u0 = [1.0,0.0,0.0]
tspan = (0., 100.)
p = [10.0,28.0,8/3]
prob = de.ODEProblem(f, u0, tspan, p)
sol = de.solve(prob,saveat=0.01)

plt.plot(sol.t,de.transpose(de.stack(sol.u)))
plt.show()


or we can draw the phase plot:
us = de.stack(sol.u)
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot(us[0,:],us[1,:],us[2,:])
plt.show()


In-Place Mutating Form
When dealing with systems of equations, in many cases it's helpful to reduce
memory allocations by using mutating functions. In diffeqpy, the mutating
form adds the mutating vector to the front. Let's make a fast version of the
Lorenz derivative, i.e. mutating and JIT compiled:
def f(du,u,p,t):
    x, y, z = u
    sigma, rho, beta = p
    du[0] = sigma * (y - x)
    du[1] = x * (rho - z) - y
    du[2] = x * y - beta * z

u0 = [1.0,0.0,0.0]
tspan = (0., 100.)
p = [10.0,28.0,2.66]
prob = de.ODEProblem(f, u0, tspan, p)
jit_prob = de.jit(prob)
sol = de.solve(jit_prob)

or using a Julia function:
jul_f = de.seval(""""""
function f(du,u,p,t)
  x, y, z = u
  sigma, rho, beta = p
  du[1] = sigma * (y - x)
  du[2] = x * (rho - z) - y
  du[3] = x * y - beta * z
end"""""")
u0 = [1.0,0.0,0.0]
tspan = (0., 100.)
p = [10.0,28.0,2.66]
prob = de.ODEProblem(jul_f, u0, tspan, p)
sol = de.solve(prob)

Stochastic Differential Equation (SDE) Examples
One-dimensional SDEs
Solving one-dimensonal SDEs du = f(u,t)dt + g(u,t)dW_t is like an ODE except
with an extra function for the diffusion (randomness or noise) term. The steps
follow the SDE tutorial.
def f(u,p,t):
  return 1.01*u

def g(u,p,t):
  return 0.87*u

u0 = 0.5
tspan = (0.0,1.0)
prob = de.SDEProblem(f,g,u0,tspan)
sol = de.solve(prob,reltol=1e-3,abstol=1e-3)

plt.plot(sol.t,de.stack(sol.u))
plt.show()


Systems of SDEs with Diagonal Noise
An SDE with diagonal noise is where a different Wiener process is applied to
every part of the system. This is common for models with phenomenological noise.
Let's add multiplicative noise to the Lorenz equation:
def f(du,u,p,t):
    x, y, z = u
    sigma, rho, beta = p
    du[0] = sigma * (y - x)
    du[1] = x * (rho - z) - y
    du[2] = x * y - beta * z

def g(du,u,p,t):
    du[0] = 0.3*u[0]
    du[1] = 0.3*u[1]
    du[2] = 0.3*u[2]

u0 = [1.0,0.0,0.0]
tspan = (0., 100.)
p = [10.0,28.0,2.66]
prob = de.jit(de.SDEProblem(f, g, u0, tspan, p))
sol = de.solve(prob)

# Now let's draw a phase plot

us = de.stack(sol.u)
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot(us[0,:],us[1,:],us[2,:])
plt.show()


Systems of SDEs with Non-Diagonal Noise
In many cases you may want to share noise terms across the system. This is
known as non-diagonal noise. The
DifferentialEquations.jl SDE Tutorial
explains how the matrix form of the diffusion term corresponds to the
summation style of multiple Wiener processes. Essentially, the row corresponds
to which system the term is applied to, and the column is which noise term.
So du[i,j] is the amount of noise due to the jth Wiener process that's
applied to u[i]. We solve the Lorenz system with correlated noise as follows:
def f(du,u,p,t):
  x, y, z = u
  sigma, rho, beta = p
  du[0] = sigma * (y - x)
  du[1] = x * (rho - z) - y
  du[2] = x * y - beta * z

def g(du,u,p,t):
  du[0,0] = 0.3*u[0]
  du[1,0] = 0.6*u[0]
  du[2,0] = 0.2*u[0]
  du[0,1] = 1.2*u[1]
  du[1,1] = 0.2*u[1]
  du[2,1] = 0.3*u[1]


u0 = [1.0,0.0,0.0]
tspan = (0.0,100.0)
p = [10.0,28.0,2.66]
nrp = numpy.zeros((3,2))
prob = de.SDEProblem(f,g,u0,tspan,p,noise_rate_prototype=nrp)
jit_prob = de.jit(prob)
sol = de.solve(jit_prob,saveat=0.005)

# Now let's draw a phase plot

us = de.stack(sol.u)
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot(us[0,:],us[1,:],us[2,:])
plt.show()


Here you can see that the warping effect of the noise correlations is quite visible!
Differential-Algebraic Equation (DAE) Examples
A differential-algebraic equation is defined by an implicit function
f(du,u,p,t)=0. All of the controls are the same as the other examples, except
here you define a function which returns the residuals for each part of the
equation to define the DAE. The initial value u0 and the initial derivative
du0 are required, though they do not necessarily have to satisfy f (known
as inconsistent initial conditions). The methods will automatically find
consistent initial conditions. In order for this to occur, differential_vars
must be set. This vector states which of the variables are differential (have a
derivative term), with false meaning that the variable is purely algebraic.
This example shows how to solve the Robertson equation:
def f(du,u,p,t):
  resid1 = - 0.04*u[0]               + 1e4*u[1]*u[2] - du[0]
  resid2 = + 0.04*u[0] - 3e7*u[1]**2 - 1e4*u[1]*u[2] - du[1]
  resid3 = u[0] + u[1] + u[2] - 1.0
  return [resid1,resid2,resid3]

u0 = [1.0, 0.0, 0.0]
du0 = [-0.04, 0.04, 0.0]
tspan = (0.0,100000.0)
differential_vars = [True,True,False]
prob = de.DAEProblem(f,du0,u0,tspan,differential_vars=differential_vars)
sol = de.solve(prob)


and the in-place JIT compiled form:
def f(resid,du,u,p,t):
  resid[0] = - 0.04*u[0]               + 1e4*u[1]*u[2] - du[0]
  resid[1] = + 0.04*u[0] - 3e7*u[1]**2 - 1e4*u[1]*u[2] - du[1]
  resid[2] = u[0] + u[1] + u[2] - 1.0

prob = de.DAEProblem(f,du0,u0,tspan,differential_vars=differential_vars)
jit_prob = de.jit(prob) # Error: no method matching matching modelingtoolkitize(::SciMLBase.DAEProblem{...})
sol = de.solve(jit_prob)

Mass Matrices, Sparse Arrays, and More
Mass matrix DAEs, along with many other forms, can be handled by doing an explicit conversion to the Julia types.
See the PythonCall module's documentation for more details.
As an example, let's convert the mass matrix ODE tutorial in diffeqpy.
To do this, the one aspect we need to handle is the conversion of the mass matrix in to a Julia array object. This is done as follows:
from diffeqpy import de
from juliacall import Main as jl
import numpy as np

def rober(du, u, p, t):
    y1, y2, y3 = u
    k1, k2, k3 = p
    du[0] = -k1 * y1 + k3 * y2 * y3
    du[1] = k1 * y1 - k3 * y2 * y3 - k2 * y2**2
    du[2] = y1 + y2 + y3 - 1
    return

M = np.array([[1.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]])
f = de.ODEFunction(rober, mass_matrix = jl.convert(jl.Array,M))
prob_mm = de.ODEProblem(f, [1.0, 0.0, 0.0], (0.0, 1e5), (0.04, 3e7, 1e4))
sol = de.solve(prob_mm, de.Rodas5P(), reltol = 1e-8, abstol = 1e-8)

Notice the only addition is to create the np.array object and to perform the manual conversion via jl.convert(jl.Array,M) to receive the
Julia Array object. This can be done in any case where diffeqpy is not adequately auto-converting to the right Julia type. In some cases this
can be used to improve performance, though here we do it simply for compatability.
Similarly, sparse matrices can be passed in much the same way. For example:
import scipy
spM = scipy.sparse.csr_array(M)
jl.seval(""using SparseArrays"")

f = de.ODEFunction(rober, mass_matrix = jl.convert(jl.SparseMatrixCSC,M))
prob_mm = de.ODEProblem(f, [1.0, 0.0, 0.0], (0.0, 1e5), (0.04, 3e7, 1e4))
sol = de.solve(prob_mm, de.Rodas5P(), reltol = 1e-8, abstol = 1e-8)

Delay Differential Equations
A delay differential equation is an ODE which allows the use of previous values.
In this case, the function needs to be a JIT compiled Julia function. It looks
just like the ODE, except in this case there is a function h(p,t) which allows
you to interpolate and grab previous values.
We must provide a history function h(p,t) that gives values for u before t0.
Here we assume that the solution was constant before the initial time point.
Additionally, we pass constant_lags = [20.0] to tell the solver that only
constant-time lags were used and what the lag length was. This helps improve
the solver accuracy by accurately stepping at the points of discontinuity.
Together this is:
f = de.seval(""""""
function f(du, u, h, p, t)
  du[1] = 1.1/(1 + sqrt(10)*(h(p, t-20)[1])^(5/4)) - 10*u[1]/(1 + 40*u[2])
  du[2] = 100*u[1]/(1 + 40*u[2]) - 2.43*u[2]
end"""""")
u0 = [1.05767027/3, 1.030713491/3]

h = de.seval(""""""
function h(p,t)
  [1.05767027/3, 1.030713491/3]
end
"""""")

tspan = (0.0, 100.0)
constant_lags = [20.0]
prob = de.DDEProblem(f,u0,h,tspan,constant_lags=constant_lags)
sol = de.solve(prob,saveat=0.1)

u1 = [sol.u[i][0] for i in range(0,len(sol.u))]
u2 = [sol.u[i][1] for i in range(0,len(sol.u))]

import matplotlib.pyplot as plt
plt.plot(sol.t,u1)
plt.plot(sol.t,u2)
plt.show()


Notice that the solver accurately is able to simulate the kink (discontinuity)
at t=20 due to the discontinuity of the derivative at the initial time point!
This is why declaring discontinuities can enhance the solver accuracy.
GPU-Accelerated ODE Solving of Ensembles
In many cases one is interested in solving the same ODE many times over many
different initial conditions and parameters. In diffeqpy parlance this is called
an ensemble solve. diffeqpy inherits the parallelism tools of the
SciML ecosystem that are used for things like
automated equation discovery and acceleration.
Here we will demonstrate using these parallel tools to accelerate the solving
of an ensemble.
First, let's define the JIT-accelerated Lorenz equation like before:
from diffeqpy import de

def f(u,p,t):
    x, y, z = u
    sigma, rho, beta = p
    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]

u0 = [1.0,0.0,0.0]
tspan = (0., 100.)
p = [10.0,28.0,8/3]
prob = de.ODEProblem(f, u0, tspan, p)
fast_prob = de.jit32(prob)
sol = de.solve(fast_prob,saveat=0.01)

Note that here we used de.jit32 to JIT-compile the problem into a Float32 form in order to make it more
efficient on most GPUs.
Now we use the EnsembleProblem as defined on the
ensemble parallelism page of the documentation:
Let's build an ensemble by utilizing uniform random numbers to randomize the
initial conditions and parameters:
import random
def prob_func(prob,i,rep):
  return de.remake(prob,u0=[random.uniform(0, 1)*u0[i] for i in range(0,3)],
            p=[random.uniform(0, 1)*p[i] for i in range(0,3)])

ensembleprob = de.EnsembleProblem(fast_prob, prob_func=prob_func, safetycopy=False)

Now we solve the ensemble in serial:
sol = de.solve(ensembleprob,de.Tsit5(),de.EnsembleSerial(),trajectories=10000,saveat=0.01)

To add GPUs to the mix, we need to bring in DiffEqGPU.
The command from diffeqpy import cuda will install CUDA for you and bring all of the bindings into the returned object:
Note: from diffeqpy import cuda can take awhile to run the first time as it installs the drivers!
Now we simply use EnsembleGPUKernel(cuda.CUDABackend()) with a
GPU-specialized ODE solver cuda.GPUTsit5() to solve 10,000 ODEs on the GPU in
parallel:
sol = de.solve(ensembleprob,cuda.GPUTsit5(),cuda.EnsembleGPUKernel(cuda.CUDABackend()),trajectories=10000,saveat=0.01)

For the full list of choices for specialized GPU solvers, see
the DiffEqGPU.jl documentation.
Note that EnsembleGPUArray can be used as well, like:
sol = de.solve(ensembleprob,de.Tsit5(),cuda.EnsembleGPUArray(cuda.CUDABackend()),trajectories=10000,saveat=0.01)

though we highly recommend the EnsembleGPUKernel methods for more speed. Given
the way the JIT compilation performed will also ensure that the faster kernel
generation methods work, EnsembleGPUKernel is almost certainly the
better choice in most applications.
Benchmark
To see how much of an effect the parallelism has, let's test this against R's
deSolve package. This is exactly the same problem as the documentation example
for deSolve, so let's copy that verbatim and then add a function to do the
ensemble generation:
import numpy as np
from scipy.integrate import odeint

def lorenz(state, t, sigma, beta, rho):
    x, y, z = state

    dx = sigma * (y - x)
    dy = x * (rho - z) - y
    dz = x * y - beta * z

    return [dx, dy, dz]

sigma = 10.0
beta = 8.0 / 3.0
rho = 28.0
p = (sigma, beta, rho)
y0 = [1.0, 1.0, 1.0]

t = np.arange(0.0, 100.0, 0.01)
result = odeint(lorenz, y0, t, p)

Using lapply to generate the ensemble we get:
import timeit
def time_func():
    for itr in range(1, 1001):
        result = odeint(lorenz, y0, t, p)

timeit.Timer(time_func).timeit(number=1)

# 38.08861699999761 seconds

Now let's see how the JIT-accelerated serial Julia version stacks up against that:
def time_func():
    sol = de.solve(ensembleprob,de.Tsit5(),de.EnsembleSerial(),trajectories=1000,saveat=0.01)

timeit.Timer(time_func).timeit(number=1)

# 3.1903300999983912

Julia is already about 12x faster than the pure Python solvers here! Now let's add
GPU-acceleration to the mix:
def time_func():
    sol = de.solve(ensembleprob,cuda.GPUTsit5(),cuda.EnsembleGPUKernel(cuda.CUDABackend()),trajectories=1000,saveat=0.01)

timeit.Timer(time_func).timeit(number=1)

# 0.013322799997695256

Already 2900x faster than SciPy! But the GPU acceleration is made for massively
parallel problems, so let's up the trajectories a bit. We will not use more
trajectories from R because that would take too much computing power, so let's
see what happens to the Julia serial and GPU at 10,000 trajectories:
def time_func():
    sol = de.solve(ensembleprob,de.Tsit5(),de.EnsembleSerial(),trajectories=10000,saveat=0.01)

timeit.Timer(time_func).timeit(number=1)

# 68.80795999999827

def time_func():
    sol = de.solve(ensembleprob,cuda.GPUTsit5(),cuda.EnsembleGPUKernel(cuda.CUDABackend()),trajectories=10000,saveat=0.01)

timeit.Timer(time_func).timeit(number=1)

# 0.10774460000175168

To compare this to the pure Julia code:
using OrdinaryDiffEq, DiffEqGPU, CUDA, StaticArrays
function lorenz(u, p, t)
    σ = p[1]
    ρ = p[2]
    β = p[3]
    du1 = σ * (u[2] - u[1])
    du2 = u[1] * (ρ - u[3]) - u[2]
    du3 = u[1] * u[2] - β * u[3]
    return SVector{3}(du1, du2, du3)
end

u0 = SA[1.0f0; 0.0f0; 0.0f0]
tspan = (0.0f0, 10.0f0)
p = SA[10.0f0, 28.0f0, 8 / 3.0f0]
prob = ODEProblem{false}(lorenz, u0, tspan, p)
prob_func = (prob, i, repeat) -> remake(prob, p = (@SVector rand(Float32, 3)) .* p)
monteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy = false)
@time sol = solve(monteprob, GPUTsit5(), EnsembleGPUKernel(CUDA.CUDABackend()),
    trajectories = 10_000,
    saveat = 0.01);

# 0.014481 seconds (257.64 k allocations: 13.130 MiB)

which is about an order of magnitude faster for computing 10,000 trajectories,
note that the major factors are that we cannot define 32-bit floating point values
from Python and the prob_func for generating the initial conditions and parameters
is a major bottleneck since this function is written in Python.
To see how this scales in Julia, let's take it to insane heights. First, let's
reduce the amount we're saving:
@time sol = solve(monteprob,GPUTsit5(),EnsembleGPUKernel(CUDA.CUDABackend()),trajectories=10_000,saveat=1.0f0)
0.015040 seconds (257.64 k allocations: 13.130 MiB)

This highlights that controlling memory pressure is key with GPU usage: you will
get much better performance when requiring less saved points on the GPU.
@time sol = solve(monteprob,GPUTsit5(),EnsembleGPUKernel(CUDA.CUDABackend()),trajectories=100_000,saveat=1.0f0)
# 0.150901 seconds (2.60 M allocations: 131.576 MiB)

compared to serial:
@time sol = solve(monteprob,Tsit5(),EnsembleSerial(),trajectories=100_000,saveat=1.0f0)
# 22.136743 seconds (16.40 M allocations: 1.628 GiB, 42.98% gc time)

And now we start to see that scaling power! Let's solve 1 million trajectories:
@time sol = solve(monteprob,GPUTsit5(),EnsembleGPUKernel(CUDA.CUDABackend()),trajectories=1_000_000,saveat=1.0f0)
# 1.031295 seconds (3.40 M allocations: 241.075 MiB)

For reference, let's look at deSolve with the change to only save that much:
t = np.arange(0.0, 100.0, 1.0)
def time_func():
    for itr in range(1, 1001):
        result = odeint(lorenz, y0, t, p)

timeit.Timer(time_func).timeit(number=1)

# 37.42609280000033

The GPU version is solving 1000x as many trajectories, 37x as fast! So conclusion,
if you need the most speed, you may want to move to the Julia version to get the
most out of your GPU due to Float32's, and when using GPUs make sure it's a problem
with a relatively average or low memory pressure, and these methods will give
orders of magnitude acceleration compared to what you might be used to.
GPU Backend Choices
Just like DiffEqGPU.jl, diffeqpy supports many different GPU venders. from diffeqpy import cuda
is just for cuda, but the following others are supported:

from diffeqpy import cuda with cuda.CUDABackend for NVIDIA GPUs via CUDA
from diffeqpy import amdgpu with amdgpu.AMDGPUBackend for AMD GPUs
from diffeqpy import oneapi with oneapi.oneAPIBackend for Intel's oneAPI GPUs
from diffeqpy import metal with metal.MetalBackend for Apple's Metal GPUs (on M-series processors)

For more information, see the DiffEqGPU.jl documentation.
Known Limitations

Autodiff does not work on Python functions. When applicable, either define the derivative function
as a Julia function or set the algorithm to use finite differencing, i.e. Rodas5(autodiff=false).
All default methods use autodiff.
Delay differential equations have to use Julia-defined functions otherwise the history function is
not appropriately typed with the overloads.

Testing
Unit tests can be run by tox.
tox

Troubleshooting
In case you encounter silent failure from tox, try running it with
-- -s (e.g., tox -e py36 -- -s) where -s option (--capture=no,
i.e., don't capture stdio) is passed to py.test.  It may show an
error message ""error initializing LibGit2 module"".  In this case,
setting environment variable SSL_CERT_FILE may help; e.g., try:
SSL_CERT_FILE=PATH/TO/cert.pem tox -e py36

See also: julia#18693.



Project details


Verified details    

These details have been verified by PyPI
Maintainers






            ChrisRackauckas
          




Unverified details
These details have not been verified by PyPI
Project links



Homepage
      



Meta



License: MIT License (MIT)
      



Author: Chris Rackauckas and Takafumi Arakaki





Tags

        differential,      

        equations,      

        stochastic,      

        ordinary,      

        delay,      

        differential-algebraic,      

        dae,      

        ode,      

        sde,      

        dde,      

        oneapi,      

        AMD,      

        ROCm,      

        CUDA,      

        Metal,      

        GPU      





Classifiers


Development Status



            4 - Beta
          




License



            OSI Approved :: MIT License
          




Programming Language



            Python :: 3.8
          



            Python :: 3.9
          



            Python :: 3.10
          



            Python :: 3.11
          



            Python :: 3.12
          




Topic



            Scientific/Engineering :: Mathematics
          



            Scientific/Engineering :: Physics
          





 



Release history

Release notifications |
              RSS feed 





This version







                  2.5.3
                


  Dec 5, 2024













                  2.5.2
                


  Dec 5, 2024













                  2.5.1
                


  Dec 5, 2024













                  2.5.0
                


  Dec 1, 2024













                  2.4.2
                


  Oct 10, 2024













                  2.4.1
                


  Mar 18, 2024













                  2.4.0
                


  Dec 10, 2023













                  2.3.0
                


  Oct 23, 2023













                  2.2.0
                


  Oct 20, 2023













                  2.1.0
                


  Oct 10, 2023













                  2.0.0
                


  Oct 10, 2023













                  1.2.0
                


  May 20, 2021













                  1.1.0
                


  Jul 7, 2019













                  1.0.0
                


  Dec 21, 2018













                  0.4
                


  Apr 28, 2018













                  0.3
                


  Apr 26, 2018













                  0.2
                


  Apr 22, 2018













                  0.1
                


  Apr 21, 2018







Download files
Download the file for your platform. If you're not sure which to choose, learn more about installing packages.

Source Distribution            






          diffeqpy-2.5.3.tar.gz
        
        (23.6 kB
        view details)
        
          Uploaded 
  Dec 5, 2024

Source





File details
Details for the file diffeqpy-2.5.3.tar.gz.
File metadata



        Download URL: 
          diffeqpy-2.5.3.tar.gz
        

Upload date: 
  Dec 5, 2024

Size: 23.6 kB
Tags: Source

Uploaded using Trusted Publishing? No      
Uploaded via: twine/5.1.1 CPython/3.9.6


File hashes


Hashes for diffeqpy-2.5.3.tar.gz


Algorithm
Hash digest





SHA256
1136f0e0510e76d86976f072f34773ae417f60e771ace5d6f667014b8725e13a


Copy            



MD5
dacdf490eb20f6ac91c09683f475976c


Copy            



BLAKE2b-256
b47c799ae7379aeecb93c55d2b9a0130b94198519307be06761d84f9a8b4cac6


Copy            





See more details on using hashes here. 













Help


Installing packages
Uploading packages
User guide
Project name retention
FAQs




About PyPI


PyPI Blog
Infrastructure dashboard
Statistics
Logos & trademarks
Our sponsors




Contributing to PyPI


Bugs and feedback
Contribute on GitHub
Translate PyPI
Sponsor PyPI
Development credits




Using PyPI


Terms of Service
Report security issue
Code of conduct
Privacy Notice
Acceptable Use Policy






Status:
all systems operational


Developed and maintained by the Python community, for the Python community.          
Donate today!


          ""PyPI"", ""Python Package Index"", and the blocks logos are registered trademarks of the Python Software Foundation.


          © 2025 Python Software Foundation
Site map




Switch to desktop version        







              English
            



              español
            



              français
            



              日本語
            



              português (Brasil)
            



              українська
            



              Ελληνικά
            



              Deutsch
            



              中文 (简体)
            



              中文 (繁體)
            



              русский
            



              עברית
            



              Esperanto
            



              한국어
            





Supported by



AWS

            Cloud computing and Security Sponsor
          



Datadog

            Monitoring
          



Fastly

            CDN
          



Google

            Download Analytics
          



Pingdom

            Monitoring
          



Sentry

            Error logging
          



StatusPage

            Status page
          



"
7,https://arxiv.org/pdf/2111.03794,"Physics-Informed Neural Operator
for Learning Partial Differential Equations
Zongyi Li*, Hongkai Zheng*, Nikola Kovachki, David Jin, Haoxuan Chen,
Burigede Liu, Kamyar Azizzadenesheli, Anima Anandkumar
Abstract
In this paper, we propose physics-informed neural operators (PINO) that combine training data and physics
constraints to learn the solution operator of a given family of parametric Partial Differential Equations (PDE). PINO
is the first hybrid approach incorporating data and PDE constraints at different resolutions to learn the operator.
Specifically, in PINO, we combine coarse-resolution training data with PDE constraints imposed at a higher resolution.
The resulting PINO model can accurately approximate the ground-truth solution operator for many popular PDE
families and shows no degradation in accuracy even under zero-shot super-resolution, i.e., being able to predict beyond
the resolution of training data. PINO uses the Fourier neural operator (FNO) framework that is guaranteed to be a
universal approximator for any continuous operator and discretization convergent in the limit of mesh refinement. By
adding PDE constraints to FNO at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth
operator. Moreover, PINO succeeds in settings where no training data is available and only PDE constraints are
imposed, while previous approaches, such as the Physics-Informed Neural Network (PINN), fail due to optimization
challenges, e.g., in multi-scale dynamic systems such as Kolmogorov flows.
1 Introduction
Machine learning methods have recently shown promise in solving partial differential equations (PDEs) [ 27,29,30,36,
6]. A recent breakthrough is the paradigm of operator learning for solving PDEs. Unlike standard neural networks
that learn using inputs and outputs of fixed dimensions, neural operators learn operators, which are mappings between
function spaces [ 27,29,30]. The class of neural operators is guaranteed to be a universal approximator for any
continuous operator [ 27] and hence, has the capacity to approximate any operator including any solution operator of a
given family of parametric PDEs. Note that the solution operator is the mapping from the input function (initial and
boundary conditions) to the output solution function. Previous works show that neural operators can capture complex
multi-scale dynamic processes and are significantly faster than numerical solvers [34, 56, 43, 33, 54, 3, 55].
Neural operators are proven to be discretization convergent in the limit of mesh refinement [ 27], meaning they
converge to a continuum operator in the limit as the discretization is refined. Consequently, they can be evaluated at any
data discretization or resolution at inference time without the need for retraining. For example, neural operators such as
Fourier neural operator (FNO) can extrapolate to frequencies that are not seen during training in Kolmogorov Flows,
as shown in Figure 1, while standard approaches such as training a UNet and adding trilinear interpolation leads to
significantly worse results at higher resolutions.
Even though FNO follows the general trend of the Kolmogorov flow in Figure 1, it cannot perfectly match it in
the regime of super-resolution, i.e., beyond the frequencies seen during training. More generally, neural operators
cannot perfectly approximate the ground-truth operator when only coarse-resolution training data is provided. This is
a fundamental limitation of data-driven operator learning methods which depend on the availability of training data,
which can come either from existing numerical solvers or direct observations of the physical phenomena. In many
scenarios, such data can be expensive to generate, unavailable, or available only as low-resolution observations [ 19].
This limits the ability of neural operators to learn high-fidelity models. Moreover, the generalization of the learned
neural operators to unseen scenarios and conditions that are different from training data is challenging.
1arXiv:2111.03794v4  [cs.LG]  29 Jul 2023Figure 1: PINO uses both training data and PDE loss function and perfectly extrapolates to unseen frequencies in
Kolmogorov Flows. FNO uses only training data and does not have further information on higher frequencies, but
still follows the general trend of the ground-truth spectrum. On the other hand, using a trained UNet with trilinear
interpolation (NN+Interpolation) has severe distortions at higher frequencies. Details in Section 4.2.
1.1 Our Approach and Contributions
In this paper, we remedy the above shortcomings of data-driven operator learning methods through the framework
of physics-informed neural operators (PINO). Here, we take a hybrid approach of combining training data (when
available) with a PDE loss function at a higher resolution. This allows us to approximate the solution operator of
many PDE families nearly perfectly. While there have been many physics-informed approaches proposed previously
(discussed in 1.2), ours is the first to incorporate PDE constraints at a higher resolution as a remedy for low resolution
training data. We show that this results in high-fidelity solution operator approximations. As shown in Figure 1, PINO
extrapolates to unseen frequencies in Kolmogorov Flows. Thus, we show that the PINO model learned from such
multi-resolution hybrid loss functions has almost no degradation in accuracy even on high-resolution test instances
when only low-resolution training data is available. Further, our PINO approach also overcomes the optimization
challenges in approaches such as Physics-Informed Neural Network (PINN) [ 44] that are purely based on PDE loss
functions and do not use training data, and thus, PINO can solve more challenging problems such as time-dependent
PDEs.
PINO utilizes both the data and equation loss functions (whichever are available) for operator learning. To further
improve accuracy at test time, we fine-tune the learned operator on the given PDE instance using only the equation loss
function. This allows us to provide a nearly-zero error for the given PDE instance at all resolutions. A schematic of
PINO is shown in Figure 2, where the neural operator architecture is based on Fourier neural operator (FNO) [ 29]. The
derivatives needed for the equation loss in PINO are computed explicitly through the operator layers in function spaces.
In particular, we efficiently compute the explicit gradients on function space through Fourier-space computations. In
contrast, previous auto-differentiation methods must compute the derivatives at sampling locations.
The PDE loss function added to PINO vastly improves generalization and physical validity in operator learning
compared to purely data-driven methods. PINO requires fewer to no training data and generalizes better compared to
the data-driven FNO [ 31], especially on high-resolution test instances. On average, the relative error is 7% lower on
both transient and Kolmogorov flows, while matching the speedup of data-trained FNO architecture (400x) compared
to the GPU-based pseudo-spectral solver [ 17]. Further, the PINO model on the Navier-Stokes equation can be easily
transferred to different Reynolds numbers ranging from 100to500using instance-wise fine-tuning.
We also use PINO for solving inverse problems by either: (1) learning the forward solution operator and using
2Figure 2: PINO trains neural operator with both training data and PDE loss function. The figure shows the neural
operator architecture with the lifting point-wise operator that receives input function aand outputs function v0with
a larger co-dimension. This operation is followed by Lblocks that compute linear integral operators followed by
non-linearity, and the last layer of which outputs the function vL. The pointwise projection operator projects vLto
output function u. Both vLanduare functions and all their derivatives ( DvL,Du) can be computed in their exact forms
at any query points x.
gradient-based optimization to obtain the inverse solution, or (2) learning the inverse solution operator directly. Imposing
the PDE loss guarantees the inverse solution is physically valid in both approaches. We find that of these two approaches,
the latter is more accurate for recovering the coefficient function in Darcy flow. We show this approach is 3000x faster
than the conventional solvers using accelerated Markov Chain Monte-Carlo (MCMC) [8].
1.2 Related Work
Learning solution to PDEs has been proposed under two paradigms: (i) data-driven learning and (ii) physics-informed
optimization. The former utilizes data from existing solvers or experiments, while the latter is purely based on PDE
constraints. An example of data-driven methods is the class of neural operators for learning the solution operator
of a given family of parametric PDEs. An example of the physics-based approach is the Physics-Informed Neural
Network (PINN) for optimizing the PDE constraints to obtain the solution function of a given PDE instance. Both these
approaches have shortcomings. Neural operators require data, and when that is limited or not available, they are unable
to learn the solution operator faithfully. PINN, on the other hand, does not require data but is prone to failure, especially
on multi-scale dynamic systems due to optimization challenges.
Neural operators learn the solution operator of a family of PDEs, defined by the map from the input–initial conditions
and boundary conditions, to the output–solution functions. In this case, usually, a dataset of input-output pairs from
an existing solver or real-world observation is given. There are two main aspects to consider (a) models: the design
of models for learning highly complicated PDE solution operators, and (b) data: minimizing data requirements and
improving generalization. Recent advances in operator learning replace traditional convolutional neural networks and
U-Nets from computer vision with operator-based models tailored to PDEs with greatly improved model expressiveness
[31,36,41,49,10]. Specifically, the neural operator generalizes the neural network to the operator setting where the
input and output spaces are infinite-dimensional. The framework has successfully approximated solution operators for
highly non-linear problems such as turbulence flow [ 30,29]. However, the data challenges remain. In particular, (1)
training data from an existing solver or an experimental setup is costly to obtain, (2) models struggle in generalizing
away from the training distribution, and (3) constructing the most efficient approximation for given data remains elusive.
Moreover, it is also evident that in many real-world applications, observational data often is available at only low
resolutions [19], limiting the model’s ability to generalize.
Alternatives to data-driven approaches for solving PDEs are physics-based approaches that require no training data.
A popular framework known as Physics-Informed Neural Network (PINN) [ 44] uses optimization to find the solution
function of a given PDE instance. PINN uses a neural network as the ansatz of the solution function and optimizes a
3Figure 3: solve for one specific instance verse learn the entire solution operator
Left: numerical solvers and PINNs focus on solving one specific instance. Right: neural operators learn the solution
operator for a family of equations.
loss function to minimize the violation of the given equation by taking advantage of auto-differentiation to compute the
exact derivatives. PINN overcomes the need to choose a discretization grid that most numerical solvers require, e.g.,
finite difference methods (FDM) and finite element methods (FEM). It has shown promise in solving PDEs for a wide
range of applications, including higher dimensional problems. [ 38,16,18,23]. Recently, researchers have developed
many variations of PINN with promising results for solving inverse problems and partially observed tasks [ 35,58,47].
However, PINN fails in many multi-scale dynamic PDE systems [ 50,13,45] due to two main reasons, viz., (1)
the challenging optimization landscape of the PDE constraints [ 51] and its sensitivity to hyper-parameter selection
[48], and (2) the difficulty in propagating information from the initial or boundary conditions to unseen parts of the
interior or to future times [ 11]. Moreover, PINN only learns the solution function of a single PDE instance and cannot
generalize to other instances without re-optimization. Concurrent work on physics-informed DeepONet that imposes
PDE losses on DeepONet [ 52] overcomes this limitation and can learn across multiple PDE instances. While the PDE
loss is computed at any query points, the input is limited to a fixed grid in standard DeepONet [ 27], and its architecture
is a linear method of approximation [ 28]. Our work overcomes all previously mentioned limitations. Further, a unique
feature that PINO enjoys over other hybrid learning methods [ 58,57,20] is its ability to incorporate data and PDE
loss functions at different resolutions. This has not been attempted before, and none of the previous works focus on
extrapolation to higher resolutions, beyond what is seen in training data.
2 Preliminaries and problem settings
In this section, we first define the stationary and dynamic PDE systems that we consider. We give an overview of the
physics-informed setting and operator-learning setting. In the end, we define the Fourier neural operator as a specific
model for operator learning.
2.1 Problem settings
We consider two natural classes of PDEs. In the first, we consider the stationary system
P(u, a) = 0 , inD⊂Rd
u=g, in∂D(1)
where Dis a bounded domain, a∈ A ⊆ V is a PDE coefficient/parameter, u∈ U is the unknown, and P:U ×A → F
is a possibly non-linear partial differential operator with (U,V,F)a triplet of Banach spaces. Usually, the function
gis a fixed boundary condition but can also potentially enter as a parameter. This formulation gives rise to the
solution operator G†:A → U defined by a7→u. A prototypical example is the second-order elliptic equation
P(u, a) =−∇ · (a∇u) +f.
4In the second setting, we consider the dynamical system
du
dt=R(u), inD×(0,∞)
u=g, in∂D×(0,∞)
u=a in¯D× {0}(2)
where a=u(0)∈ A ⊆ V is the initial condition, u(t)∈ U fort >0is the unknown, and Ris a possibly non-linear
partial differential operator with U, andVBanach spaces. As before, we take gto be a known boundary condition.
We assume that uexists and is bounded for all time and for every u0∈ U. This formulation gives rise to the solution
operator G†:A → C 
(0, T];U
defined by a7→u. Prototypical examples include the Burgers’ equation and the
Navier-Stokes equation.
2.2 Solving equation using the physics-informed neural networks
Given an instance aand a solution operator G†defined by equations (1)or(2), we denote by u†=G†(a)the unique
ground truth. The equation-solving task is to approximate u†. This setting consists of the ML-enhanced conventional
solvers such as learned finite element, finite difference, and multigrid solvers [ 25,42,15], as well as purely neural
network-based solvers such as the Physics-Informed Neural Networks (PINNs), Deep Galerkin Method, and Deep Ritz
Method [ 44,46,53]. Especially, these PINN-type methods use a neural network uθwith parameters θas the ansatz to
approximate the solution function u†. The parameters θare found by minimizing the physics-informed loss with exact
derivatives computed using automatic differentiation (autograd). In the stationary case, the physics-informed loss is
defined by minimizing the l.h.s. of equation (1)in the squared norm of F. A typical choice is F=L2(D), giving the
loss function
Lpde(a, uθ) =P(a, uθ)2
L2(D)+αuθ|∂D−g2
L2(∂D)
=Z
D|P(uθ(x), a(x))|2dx+αZ
∂D|uθ(x)−g(x)|2dx(3)
In the case of a dynamical system, one minimizes the residual of equation (2)in some natural norm up to a fixed
final time T >0. A typical choice is the L2 
(0, T];L2(D)
norm, yielding
Lpde(a, uθ) =duθ
dt− R(uθ)2
L2(T;D)+αuθ|∂D−g2
L2(T;∂D)+βuθ|t=0−a2
L2(D)
=ZT
0Z
D|duθ
dt(t, x)− R(uθ)(t, x)|2dxdt
+αZT
0Z
∂D|uθ(t, x)−g(t, x)|2dxdt
+βZ
D|uθ(0, x)−a(x)|2dx(4)
The PDE loss consists of the physics loss in the interior and the data loss on the boundary and initial conditions, with
hyper-parameters α, β > 0. Alternatively, the optimization can be formulated via the variational form [53].
Challenges of PINN PINNs take advantage of the universal approximability of neural networks, but, in return, suffer
from the low-frequency induced bias. Empirically, PINNs often fail to solve challenging PDEs when the solution
exhibits high-frequency or multi-scale structure [ 51,50,13,45]. Further, as an iterative solver, PINNs have difficulty
propagating information from the initial condition or boundary condition to unseen parts of the interior or to future times
[11]. For example, in challenging problems such as turbulence, PINNs are only able to solve the PDE on a relatively
small domain [ 22], or otherwise, require extra observational data which is not always available in practice [ 45,7]. In
this work, we propose to overcome the challenges posed by optimization by integrating operator learning with PINNs.
52.3 Learning the solution operator via neural operator
An alternative setting is to learn the solution operator G. Given a PDE as defined in (1)or(2)and the corresponding
solution operator G†, one can use a neural operator Gθwith parameters θas a surrogate model to approximate G†.
Usually we assume a dataset {aj, uj}N
j=1is available, where G†(aj) =ujandaj∼µare i.i.d. samples from some
distribution µsupported on A. In this case, one can optimize the solution operator by minimizing the empirical data
loss on a given data pair
Ldata(u,Gθ(a)) =∥u− Gθ(a)∥2
U=Z
D|u(x)− Gθ(a)(x)|2dx (5)
where we assume the setting of (1)for simplicity of the exposition. The operator data loss is defined as the average
error across all possible inputs
Jdata(Gθ) =∥G†− Gθ∥2
L2µ(A;U)=Ea∼µ[Ldata(a, θ)]≈1
NNX
j=1Z
D|uj(x)− Gθ(aj)(x)|2dx. (6)
Similarly, one can define the operator PDE loss as
Jpde(Gθ) =Ea∼µ[Lpde(a,Gθ(a))]. (7)
In general, it is non-trivial to compute the derivatives dGθ(a)/dxanddGθ(a)/dtfor model Gθ. In the following
section, we will discuss how to compute these derivatives for Fourier neural operator.
2.4 Neural operators
In this work, we will focus on the neural operator model designed for the operator learning problem [ 31]. The neural
operator is formulated as a generalization of standard deep neural networks to the operator setting. Neural operator
composes linear integral operator Kwith pointwise non-linear activation function σto approximate highly non-linear
operators.
Definition 1 (Neural operator Gθ)Define the neural operator
Gθ:=Q ◦(WL+KL)◦ ··· ◦ σ(W1+K1)◦ P (8)
where PandQare pointwise operators, parameterized with neural networks P:Rda→Rd1andQ:RdL→Rdu,
where dais the co-dimension of an input function a∈Aandduis the co-dimension of the output function u.P
operator lifts the lower dimension function into higher dimensional space and Qoperator projects the higher dimension
function back to the lower dimensional space. The model stacks Llayers of σ(Wl+Kl)where Ware pointwise
linear operators parameterized as matrices Wl∈Rdl+1×dl,Kl:{D→Rdl} → { D→Rdl+1}are integral kernel
operators, and σare fixed activation functions. The parameters θconsists of all the parameters in P,Q,Wl,Kl.
Definition 2 (Kernel Integral Operators) We define the kernel integral operator Kused in (8). Let κ(l)∈C(D×
D;Rdl+1×dl)and let νbe a Borel measure on D. Then we define Kby
(Kvl)(x) =Z
Dκ(l)(x, y)vl(y)dν(y)∀x∈D. (9)
The kernel integral operator can be discretized and implemented with graph neural networks as in graph neural operators
[31].
(Kvl)(x) =X
B(x)κ(l)(x, y)vl(y)∀x∈D. (10)
where B(x)is a ball of center at x. As a generalization, the kernel function can also take the form of (Kvl)(x) =P
B(x)κ(l)(x, y, v l(y)).
Recently, [ 29] proposes the Fourier neural operator (FNO) that restricts the integral operator Kto convolution. In
this case, it can apply the Fast Fourier Transform (FFT) to efficiently compute K. This leads to a fast architecture that
obtains state-of-the-art results for PDE problems.
6Definition 3 (Fourier convolution operator) One specific form of the kernel integral operator is the Fourier convolu-
tion operator 
Kvl
(x) =F−1
R·(Fvl)
(x)∀x∈D (11)
where F,F−1are the Fast Fourier transform and its inverse; Ris part of the parameter θto be learn.
One can build a neural operator with mixed kernel integral layers and Fourier convolution layers. If the input and output
query points are sampled from non-uniform mesh, we can use the graph kernel operator as the first and last layer for
continuous evaluation, while using the Fourier layers in the middle for efficient computation, similar to [33].
Challenges of operator learning. Operator learning is similar to supervised learning in computer vision and language
where data play a very important role. One needs to assume the training points and testing points follow the same
problem setting and the same distribution. Especially, the previous FNO model trained on one coefficient (e.g. Reynolds
number) or one geometry cannot be easily generalized to another. Moreover, for more challenging PDEs where the
solver is very slow or the solver is even not existent, it is hard to gather a representative dataset. On the other hand, since
prior training methods for FNO do not use any knowledge of the equation, the trained models cannot get arbitrarily
close to the ground truth by using the higher resolution as in conventional solvers, leaving a gap of generalization error.
These challenges limit the applications of the prior works beyond accelerating the solver and modeling real-world
experiments. In the following section, we will introduce the PINO framework to overcome these problems by using the
equation constraints.
Discretization convergent. Resolution and discretization convergence is defined as obtaining a unique continuum
operator in the limit of mesh refinement [ 27]. The work [ 1] recently introduced a new concept of representation
equivalence, which requires zero aliasing error at each layer, which PINO does not fulfill. When all the Fourier modes
in FNO are active, an aliasing error is inevitably present. However, in many practical applications, this is typically
not an issue, and degraded performance due to aliasing is rarely observed, since the maximum number of modes in
an FNO is typically far fewer than the grid size. In fact, the non-linear transformations allow for re-capturing the
truncated high-frequency modes which allows for generalization beyond the see training data. Requiring representation
equivalence leads to linear methods of approximation which are know to be sub-optimal in their representation capacity
[28].
Related work. Many machine learning models have been explored for operator learning [ 2,40,41]. Besides the
above line of work, the deep operator network (DeepONet) is one of the most famous operator models that have
shown enormous promise in applications [ 36]. The work from [ 26] compares the polynomial chaos expansion (PCE),
DeepONet, and FNO, and shows that DeepONet has a higher approximation accuracy over PCE. According to Figure 5
in [26], standard DeepONet and FNO share a similar convergence rate. A similar comparison study is reported by de
Hoop et. al. [ 9] where FNO seems to converge faster. We choose FNO as our base model for its scalability to large
problems.
3 Physics-informed neural operator (PINO)
We propose the PINO framework that uses one neural operator model Gθfor solving both operator learning problems
and equation solving problems. It consists of two phases
•operator learning : learn a neural operator Gθto approximate the target solution operator G†using either/both
the data loss Jdata or/and the PDE loss Jpde.
•instance-wise fine-tuning : useGθ(a)as the ansatz to approximate u†with the pde loss Lpdeand/or an additional
operator loss Lopobtained from the operator learning phase.
73.1 Physics-informed operator learning
For operator learning, we use the physics constraints Jpdeand supervision from data to train the neural operator.
Especially one can sample an unlimited amount of virtual PDE instances by drawing additional initial conditions or
coefficient conditions aj∼µfor training. In this sense, we have access to the unlimited dataset by sampling new input
ajin each training iteration. This advantage of using PDE constraints removes the requirement on the dataset and
makes the supervised problem into a semi-supervised one.
While PINO can be trained with physics constraints Jpdeonly, the Jdata can provide stronger supervision than
physics constraints and thus make the optimization much easier. PINO leverages the supervision from any available
data to combine with physics constraints for better optimization landscape and thus learning accurate neural operators.
A special case is to train a neural operator on low-resolution data instances with high-resolution PDE constraint, which
will be studied in section 4.
3.2 Instance-wise fine-tuning of trained operator ansatz
Given a learned operator Gθ, we use Gθ(a)as the ansatz to solve for u†. The optimization procedure is similar to PINNs
where it computes the PDE loss Lpdeona, except that we propose to use a neural operator instead of a neural network.
Since the PDE loss is a soft constraint and challenging to optimize, we also add an optional operator loss Lop(anchor
loss) to bound the further fine-tuned model from the learned operator model
Lop 
Gθi(a),Gθ0(a):=∥Gθi(a)− Gθ0(a)∥2
U
where Gθi(a)is the model at ithtraining epoch. We update the operator Gθusing the loss Lpde+αLop. It is possible
to further apply optimization techniques to fine-tune the last fewer layers of the neural operator and progressive training
that gradually increase the grid resolution and use finer resolution in test time.
Optimization landscape. Using the operator as the ansatz has two major advantages: (1) PINN does point-wise
optimization, while PINO does optimization in the space of functions. In the linear integral operation K, the operator
parameterizes the solution function as a sum of the basis function. Optimization of the set of coefficients and basis
is easier than just optimizing a single function as in PINNs. (2) we can learn these basis functions in the operator
learning phase which makes the later instance-wise fine-tuning even easier. In PINO, we do not need to propagate the
information from the initial condition and boundary condition to the interior. It just requires fine-tuning the solution
function parameterized by the solution operator.
Trade-off. (1) complexity and accuracy: instance-wise fine-tuning is an option to spend more computation in exchange
for better accuracy. The learned operator is extremely fast since it is performing inference on the neural operator.
On the other hand, instance-wise fine-tuning can improve accuracy while incurring more computational costs. (2)
resolution effects on optimization landscape and truncation error (i.e. the error of the numerical differentiation): using a
higher resolution and finer grid will reduce the truncation error. However, it has a higher computational complexity and
memory consumption. A higher resolution may also potentially make the optimization unstable. Using hard constraints
such as the anchor loss Loprelieves such a problem.
3.3 Derivatives of neural operators
In order to use the equation loss Lpde, one of the major technical challenges is to efficiently compute the derivatives
D(Gθa) =d(Gθa)/dxfor neural operators. In this section, we discuss three efficient methods to compute the derivatives
of the neural operator Gθas defined in (8).
Numerical differentiation. A simple but efficient approach is to use conventional numerical derivatives such as finite
difference and Fourier differentiation [ 58,14]. These numerical differentiation methods are fast and memory-efficient:
given a n-points grid, finite difference requires O(n), and the Fourier method requires O(nlogn). These methods are
agnostic to the underlying more. It can be applied to the neural operator with Graph layer 2 or Fourier layer 3 or neural
networks such as UNet.
8However, the numerical differentiation methods face the same challenges as the corresponding numerical solvers:
finite difference methods require a fine-resolution uniform grid; spectral methods require smoothness and uniform grids.
Especially. These numerical errors on the derivatives will be amplified on the output solution.
Pointwise differentiation with autograd. Similar to PINN [ 44], the most general way to compute the exact derivatives
is to use the auto-differentiation library of neural networks (autograd). To apply autograd, one needs to use a neural
network to parameterize the solution function u:x7→u(x). However, it is not straightforward to write out the
solution function in the neural operator which directly outputs the numerical solution u=Gθ(a)on a grid, especially
for FNO which uses FFT. To apply autograd, we design a query function uthat input xand output u(x). Recall
Gθ:=Q ◦(WL+KL)◦ ··· ◦ σ(W1+K1)◦ Pandu=Gθa=QvL=Q(WL+KL)vL−1. . .. Since Qis pointwise,
u(x) =Q(vL)(x) =Q(vL(x)) =Q 
(WLvL−1)(x) +KLvL−1(x)
(12)
For both the kernel operator and Fourier operator, we either remove the pointwise residual term of the last layer
(WLvL−1)(x)or define the query function as an interpolation function on WL.
For kernel integral operator 2, the kernel function can directly take the query points are input. So the query function
u(x) =Q X
B(x)κ(l)(x, y, v L−1(y))
where we omit the derivative of the support B(x). We can apply auto-differentiation to compute the derivatives
u′(x) =Q′ 
vL(x)
·X
B(x)κ(l)′(x, y, v L−1(y)) (13)
Similarly, for the Fourier convolution operator, we need to evaluate the Fourier convolution KLvL−1(x)on the
query points x. It can be done by writing out the output function as Fourier series composing with Q:
u(x) =Q ◦ F−1
R·(FvL−1))
(x) =Q1
kmaxkmaxX
k=0 
Rk(FvL−1)k
expi2πk
D(x)
Where Fis the discrete Fourier transform. The inverse discrete Fourier transform is the sum of kmax Fourier series
with the coefficients 
Rk(FvL−1)k
coming from the previous layer.
u′(x) =Q′ 
vL(x)
·1
kmaxkmaxX
k=0 
Rk(FvL−1)k
exp′i2πk
D(x) (14)
Notice exp′i2πk
D(x) =i2πk
Dexpi2πk
D(x), just as the numerical Fourier method. If the query points xare a uniform
grid, the derivative can be efficiently computed with the Fast Fourier transform.
The autograd method is general and exact, however, it is less efficient. Since the number of parameters |θ|is usually
much greater than the grid size n, the numerical methods are indeed significantly faster. Empirically, the autograd
method is usually slower and memory-consuming.
Function-wise differentiation. While it is expensive to apply the auto differentiation per query point, the derivative
can be batched and computed in a function-wise manner. We develop an efficient and exact derivatives method based
on the architecture of the neural operator that can compute the full gradient field. The idea is similar to the autograd,
but we explicitly write out the derivatives on the Fourier space and apply the chain rule. Given the explicit form (14),u′
can be directly computed on the Fourier space.
u′=Q′ 
vL
· F−1i2π
DK·(FvL))
(15)
Therefore, to exactly compute the derivative of the Fourier neural operator, one just needs to run the numerical Fourier
differentiation. Especially the derivative and be efficiently computed with the Fast Fourier transform when the query
9is uniform. Similarly, if the kernel function κ(l)in(13) has a structured form, we can also write out its gradient field
explicitly.
Next, we show how to compute higher orders derivatives in their exact form, without evoking the autograd method.
To this end, we can directly apply the chain rule for the higher-order derivatives without calling autograd. For
example, the first order derivatives is u′= (Q◦vL)′=Q′(vL)·v′
Land the 2nd-order derivatives is u′′= (QvL)′′=
v′2
L· Q′′(vL) +Q′(vL)·v′′
L. Higher-order derivatives can be similarly computed using the chain rule. Furthermore,
derivative-based quantities on vL, e.g., v′
Lcan be computed in its exact form in the Fourier domain. Similarly, we
can write out the higher-order derivatives of Qusing the chain rule. Usually Qis parameterized as a two layer neural
networks Q(x) = (A2σ(A1x+b1) +b2). SoQ′(x) =A2σ′(A1x+b1)A1. In this manner, we have got the explicit
formula of the derivatives for all neural operators.
Fourier continuation. The Fourier method has its best performance when applied to periodic problems. If the target
function is non-periodic or non-smooth, the Fourier differentiation is not accurate. To deal with this issue, we apply the
Fourier continuation method that embeds the problem domain into a larger and periodic space. The extension can be
simply done by padding zeros in the input. The loss is computed at the original space during training. The Fourier
neural operator will automatically generate a smooth extension. The details are given in Appendix C.
3.4 Inverse problem
The physics-informed method can be used to solve the inverse problem, where given the output function u, the goal
is to recover (a distribution of) the input function a. By imposing the constraint P(u, a) = 0 , we can restrict ato a
physically valid manifold. We propose two formulations to do the optimization-based inverse problem with PINO: the
forward operator model and the inverse operator model.
•Forward model : learn the forward operator Gθ:a7→uwith data. Initialize ˆato approximate a†. Optimize ˆa
using
Jforward :=Lpde(ˆa, u†) +Ldata(Gθ(ˆa)) +R(ˆa). (16)
•inverse model : learn the inverse operator Fθ:u7→awith data. Use Fθ(u†)to approximate a†. Optimize Fθ
using
Jbackward :=Lpde(Fθ(u†), u†) +Lop(Fθ(u†),Fθ0(u†)) +R(Fθ(u†) (17)
Where Lpdeis the PDE loss; Lopis the operator loss from the learned operator; R(a)is the regularization term. We
use the PDE loss Lpdeto deal with the small error in Gθand the ill-defining issue of Fθ. We provide a numerical study
in section 4.3.
4 Experiments
In this section, we conduct empirical experiments to examine the efficacy of the proposed PINO. We present the PDE
settings, their domains, and function spaces. In 4.1, we show using PDE constraint in operator learning results in
neural operators that (1) generalize to significantly high-resolution unseen data. (2) achieve smaller generalization
errors with fewer to no data. Then in 4.2, we investigate how PINO uses the operator ansatz to solve harder equations
with improved speed and accuracy. We study three concrete cases of PDEs on Burgers’ Equation, Darcy’s Equation,
and Navier-Stokes equation. In 4.3 we study the inverse problems. The implementation details of PINO and baseline
methods are listed in Appendix A.
Burgers’ Equation. The 1-d Burgers’ equation is a non-linear PDE with periodic boundary conditions where
u0∈L2
per((0,1);R)is the initial condition and ν= 0.01is the viscosity coefficient. We aim to learn the operator
mapping the initial condition to the solution, G†:u07→u|[0,1].
∂tu(x, t) +∂x(u2(x, t)/2) = ν∂xxu(x, t), x ∈(0,1), t∈(0,1]
u(x,0) = u0(x), x ∈(0,1)(18)
10/uni00000014/uni00000013/uni00000014
/uni00000014/uni00000013/uni00000013/uni00000014/uni00000013/uni00000014/uni00000014/uni00000013/uni00000015
/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni0000000b/uni00000056/uni0000000c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000035/uni00000048/uni0000004f/uni00000044/uni00000057/uni0000004c/uni00000059/uni00000048/uni00000003L2/uni00000003/uni00000048/uni00000055/uni00000055/uni00000052/uni00000055
/uni00000033/uni0000002c/uni00000031/uni00000032/uni00000003/uni0000000b/uni00000052/uni00000053/uni00000048/uni00000055/uni00000044/uni00000057/uni00000052/uni00000055/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a/uni0000000c
/uni00000033/uni0000002c/uni00000031/uni00000032/uni00000003/uni0000000b/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000010/uni0000005a/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000049/uni0000004c/uni00000051/uni00000048/uni00000057/uni00000058/uni00000051/uni0000004c/uni00000051/uni0000004a/uni0000000c
/uni00000033/uni0000002c/uni00000031/uni00000031
/uni0000002f/uni00000024/uni00000024/uni00000029/uni00000010/uni00000033/uni0000002c/uni00000031/uni00000031
/uni00000036/uni00000024/uni00000010/uni00000033/uni0000002c/uni00000031/uni00000031
/uni00000014/uni00000013/uni00000014
/uni00000014/uni00000013/uni00000013/uni00000014/uni00000013/uni00000014/uni00000014/uni00000013/uni00000015/uni00000014/uni00000013/uni00000016
/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni0000000b/uni00000056/uni0000000c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000035/uni00000048/uni0000004f/uni00000044/uni00000057/uni0000004c/uni00000059/uni00000048/uni00000003L2/uni00000003/uni00000048/uni00000055/uni00000055/uni00000052/uni00000055
/uni00000033/uni0000002c/uni00000031/uni00000032/uni00000003/uni0000000b/uni00000052/uni00000053/uni00000048/uni00000055/uni00000044/uni00000057/uni00000052/uni00000055/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a/uni0000000c
/uni00000033/uni0000002c/uni00000031/uni00000032/uni00000003/uni0000000b/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000010/uni0000005a/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000049/uni0000004c/uni00000051/uni00000048/uni00000057/uni00000058/uni00000051/uni0000004c/uni00000051/uni0000004a/uni0000000c
/uni00000033/uni0000002c/uni00000031/uni00000031
/uni0000002f/uni00000024/uni00000024/uni00000029/uni00000010/uni00000033/uni0000002c/uni00000031/uni00000031
/uni00000036/uni00000024/uni00000010/uni00000033/uni0000002c/uni00000031/uni00000031Figure 4: Plot of test relative L2error versus runtime step for the Kolmogorov flow with Re500, T=0.5s. Left: resolution
64×64×65; right: resolution 128×128×129. Averaged over 20 instances. LAAF-PINN: PINN with locally adaptive
activation functions. SA-PINN: self-adaptive PINN.
Darcy Flow. The 2-d steady-state Darcy Flow equation on the unit box which is the second order linear elliptic PDE
with a Dirichlet boundary where a∈L∞((0,1)2;R+)is a piecewise constant diffusion coefficient and f= 1 is a
fixed forcing function. We are interested in learning the operator mapping the diffusion coefficient to the solution,
G†:a7→u. Note that although the PDE is linear, the operator G†is not.
−∇ · (a(x)∇u(x)) =f(x) x∈(0,1)2
u(x) = 0 x∈∂(0,1)2(19)
Since ais inLinf, we considered both the strong form Lpde(u) =∇ ·(a∇u)−fand the weak form minimization
lossLpde(u) =−1
2(a∇u,∇u)−(u, f), u∈H1. Experiments show the strong form has a better performance.
Navier-Stokes Equation. We consider the 2-d Navier-Stokes equation for a viscous, incompressible fluid in vorticity
form on the unit torus, where u∈C([0, T];Hr
per((0, l)2;R2))for any r >0is the velocity field, w=∇ ×uis the
vorticity, w0∈L2
per((0, l)2;R)is the initial vorticity, ν∈R+is the viscosity coefficient, and f∈L2
per((0, l)2;R)is
the forcing function. We want to learn the operator mapping the vorticity from the initial condition to the full solution
G†:w07→w|[0,T].
∂tw(x, t) +u(x, t)· ∇w(x, t) =ν∆w(x, t) +f(x), x ∈(0, l)2, t∈(0, T]
∇ ·u(x, t) = 0 , x ∈(0, l)2, t∈[0, T]
w(x,0) = w0(x), x ∈(0, l)2(20)
Specially, we consider two problem settings:
•Long temporal transient flow : we study the build-up of the flow from the initial condition u0near-zero velocity
touTthat reaches the ergodic state. We choose t∈[0,50],l= 1,Re= 20 as in Li et al. [29]. The main
challenge is to predict the long time interval.
•Chaotic Kolmogorov flow : In this case ulies in the attractor where arbitrary starting time t0. We choose
t∈[t0, t0+ 0.5]or[t0, t0+ 1],l= 2π,Re= 500 similar to Li et al. [32]. The main challenge is to capture the
small details that evolve chaotically.
•Lid cavity flow : In this case, we assume the no-slip boundary condition where u(x, t) = (0 ,0)at left, bottom,
and right walls and u(x, t) = (1 ,0)on top, similar to Bruneau and Saad [4]. We choose t∈[5,10],l= 1,
Re= 500 . The main challenge is to address the boundary using the velocity-pressure formulation.
11Figure 5: PINO on Kolmogorov flow (left) and Lid-cavity flow (right)
4.1 Operator learning with physics constraints
We show that we can utilize the equation constraints to improve neural operator training. For this purpose, we train
neural operators on fixed-resolution data in the presence of physics loss, Jpde, and test the performance of the trained
operators on high-resolution data. In particular, we test the performance of the trained model on data with the same
resolution of the training data, 1x, 2x, and 4x, of the training data resolution Table 1. We observe that incorporating the
Jpdein the training results in operators that, with high accuracy, generalize across data resolution. In this experiment,
the training data for Burgers equation setting is in 32×25(spatio-temporal), and the Jpdeis imposed in 128×100
resolution. We use 800 low-resolution data and the same 800 PDE instances. The mean relative L2error and its standard
deviation are reported over 200 test instances at resolution 32×25,64×50, and 128×100.
Accordingly, the training data for the Darcy equation setting is at the spatial resolution of 11×11and the Jpde
is imposed in 61×61resolution. We use 1000 low-resolution data and the same 1000 PDE instances. The mean
and standard error are reported over 500 test instances at resolution 11×11,61×61, and 211×211. Darcy flow
is unresolved at the 11×11resolution, training on such a coarse grid causes higher errors. However, adding higher
resolution PDE loss helps the operator to resolve.
The training data for Kolmogorov flow is in 64×64×33and the Jpdeis imposed in 256×256×65resolution for
the time interval [0,0.125]. We use 800 low-resolution data and 2200 PDE instances. The mean and std of the relative
L2error are reported over 200 test instances, at resolution 64×64×33,128×128×33, and 256×256×65.
PDE Training setting Error at low
data resolutionError at 2×
data resolutionError at 4×
data resolution
BurgersData 0.32±0.01% 3.32±0.02% 3.76±0.02%
Data & PDE loss 0.17±0.01% 0.28±0.01% 0.38±0.01%
DarcyData 5.41±0.12% 9.01±0.07% 9.46±0.07%
Data & PDE loss 5.23±0.12% 1.56±0.05% 1.58±0.06%
Kolmogorov flowData 8.28%±0.15% 8.27%±0.15% 8.30%±0.15%
Data & PDE loss 6.04%±0.12% 6.02%±0.12% 6.01%±0.12%
Table 1: Operator-learning using fixed resolution data and PDE loss allows us to train operators with high accuracy on
higher resolution unseen data.
Burgers equation and Darcy equation. PINO can learn the solution operator without any data on simpler problems
such as Burgers and Darcy. Compared to other PDE-constrained operators, PINO is more expressive and thereby
12achieves better accuracy. On Burgers (18), PI-DeepONet achieves 1.38% [52]; PINO achieves 0.38% . Similarly, on
Darcy flow (19), PINO outperforms FNO by utilizing physics constraints, as shown in Table 2. For these simpler
equations, instance-wise fine-tuning may not be needed. The implementation detail and the search space of parameters
are included in Appendix A.1 and A.2.
Method Solution error
DeepONet with data [36] 6.97±0.09%
PINO with data 1.22±0.03%
PINO w/o data 1.50±0.03%
Table 2: Operator learning on Darcy Flow equation. Incorporating physics constraints in operator learning improves the
performance of neural operators.
# data samples # PDE instances Solution error
0 2200 6.22%±0.11%
800 2200 6.01%±0.12%
2200 2200 5.04%±0.11%
Table 3: Physics-informed neural operator learning on Kolmogorov flow Re= 500 . PINO is effective and flexible in
combining physics constraints and any amount of available data. The mean and standard error of the relative L2test
error is reported over 200 instances and evaluated on resolution 256×256×65.
Chaotic Kolmogorov flow. We conduct an empirical study on how PINO can improve the generalization of neural
operators by enforcing more physics. In the first experiment, we consider the Kolmogorov flow with T= 0.125. We
train PINO with 2200 initial conditions and different amounts of low-resolution data. As shown in Table 3, PINO
achieves 6.22% error even without any data. We also observe that adding more low-resolution data to training makes
the optimization easier and consistently improves the accuracy of the learned operator, showing that PINO is effective
and flexible in combining physics constraints and any amount of available data.
The second experiment considers the Kolmogorov flow with T= 0.5. The training set consists of 4000 data points
of the initial condition and corresponding solution. For operator learning, we sample high-resolution initial conditions
from a Gaussian random field. Table 7 compare the generalization error of neural operators trained by different schemes
and different amounts of simulated data. The result shows that training neural operator with additional PDE instances
consistently improves the generalization error on all three resolutions we are evaluating. Note that the relative L2error
in this setting is much higher than the first one because the time horizon is 4 times longer. Next, we show how to solve
for specific instances by finetuning the learned operator.
4.2 Solve equation using operator ansatz
We solve specific equation instances by fine-tuning the learned operator ansatz.
Long temporal transient flow. It is extremely challenging to propagate the information from the initial condition to
future time steps over such a long interval T= [0,50]just using the soft physics constraint. Neither the PINN nor PINO
(from scratch) can handle this case (error >50%), no matter solving the full interval at once or solving per smaller
steps. However, when the data is available for PINO, we can use the learned neural operator ansatz and the anchor
lossLop. The anchor loss is a hard constraint that makes the optimization much easier. Providing N= 4800 training
data, the PINO without instance-wise fine-tuning achieves 2.87% error, lower than FNO 3.04% and it retains a 400x
speedup compared to the GPU-based pseudo-spectral solver [ 17], matching FNO. Further doing test time optimization
with the anchor loss and PDE loss, PINO reduces the error to 1.84% .
Chaotic Kolmogorov flow. Based on the solution operators learned in Section 4.1, the second operator-learning
setting, we continue to do instance-wise fine-tuning. We compare our method against other physics-informed learning
13methods including PINN [ 44], LAAF-PINN [ 21], and SA-PINN [ 39], as shown in Figure 4 and Table 4. Overall, PINO
outperforms PINN and its improved variants by 20xsmaller error and 25xspeedup. Using a learned operator model
makes PINO converge faster. The implementation detail and the search space of parameters are included in Appendix
A.4.
Method # data samples # PDE instances Solution error (w)Time cost
PINNs - - 18.7% 4577s
PINO 0 0 0.9% 608s
PINO 0.4k 0 0.9% 536s
PINO 0.4k 160k 0.9% 473s
Table 4: Instance-wise fine-tuning on Kolmogorov flow Re= 500 ,T= 0.5. Using the learned operator as the initial
condition helps fine-tuning converge faster.
Zero-shot super-resolution. The neural operator models are discretization-convergent, meaning they can take the
training dataset of variant resolutions and be evaluated at higher resolution. As shown in Figure 1, we train the FNO,
PINO, and UNet model with 64×64×32Kolmogorov Flows dataset and evaluate them at 256×256×65resolution.
Any frequencies higher than 64 are unseen during the training time. Conventional models such as UNet are not capable
of direct super-resolution. For compassion, we equip it with tri-linear interpolation. For PINO, we also do test-time
optimization. As shown in Figure 1, the spectrums of the predictions are averaged over 50 instances. PINO with the
test-time optimization achieves a very high accuracy rate, and its spectrum overlaps with the ground truth spectrum.
However, Conventional models such as UNet+Interpolation have noising prediction with oscillating high frequencies.
On the other hand, with the help of test-time optimization, PINO can extrapolate to unseen frequencies with high
accuracy.
Transfer Reynolds numbers. The extrapolation of different parameters and conditions is one of the biggest challenges
for ML-based methods. It poses a domain shift problem. In this experiment, we train the source operator model on one
Reynolds number and then fine-tune the model to another Reynolds number, on the Kolmogorov flow with T= 1. As
shown in Table 8 by doing instance-wise fine-tuning, PINO can be easily transferred to different Reynolds numbers
ranging from 100to500. This transferability shows PINO learned the dynamics shared across different Reynolds
numbers. Such property envisions broad applications including transferring the learned operator to different boundary
conditions or geometries.
Lid cavity flow. We demonstrate an additional example using PINO to solve for lid-cavity flow on T= [5,10]with
Re= 500 . In this case, we do not have the operator-learning phase and directly solve the equation (instance-wise
fine-tuning). We use PINO with the velocity-pressure formulation and resolution 65×65×50plus the Fourier numerical
gradient. It takes 2minutes to achieve a relative error of 14.52%. Figure 5 shows the ground truth and prediction of the
velocity field at t= 10 where the PINO accurately predicts the ground truth. The experiment shows that PINO can
address non-periodic boundary conditions and multiple output fields.
Convergence of accuracy with respect to resolution. We study the convergence rate of PINO in the instance-wise
optimization setting, where we minimize the PDE loss under different resolutions without any data. For PINO, using a
higher resolution is more effective compared to running gradient descent for longer iterations. We test PINO on the
Kolmogorov flow with Re = 500 and T = 0.125. We use the Fourier method in the spatial dimension and the finite
difference method in the temporal dimension. As shown in Table 5, PINO shares the same convergence rate of its
differentiation methods with no obvious limitation from optimization. It has a first-order convergence rate in time
when dxis fine enough and an exponential convergence rate when dtis fine enough. It implies the PDE constraint can
achieve high accuracy given a reasonable computational cost, and the virtual instances are almost as good as the data
instances generated by the solver. Since the PDE loss can be computed on an unlimited amount of virtual instances in
the operator learning setting, it is possible to reduce the generalization error going to zero by sampling virtual instances.
140 10 20 30 40 50 600
10
20
30
40
50
60(a) Ground truth input a
0 10 20 30 40 50 600
10
20
30
40
50
60 (b) Inversion using only data con-
straint
0 10 20 30 40 50 600
10
20
30
40
50
60(c) Inversion using data and PDE
constraints
0 10 20 30 40 50 600
10
20
30
40
50
60
(d) Observed output function
0 10 20 30 40 50 600
10
20
30
40
50
60 (e) Output function of inversion
using only data constraint
0 10 20 30 40 50 600
10
20
30
40
50
60(f) Output function of inversion
using data and PDE constraints
Figure 6: In the above figures, (6a) represents the ground truth input function a†, and (6d) demonstrates the corresponding
solution u†, i.e., the output function. Given the output u†, we aim to recover what acould have generated the output
function u†. Using only data constraint, (6b) shows that our method can find an athat results in an output function
very close to the ground truth u†(6e). However, the recovered ais far from satisfying the PDE equation. Using both
data and PDE constraints, (6c) shows that our physics-informed method can find an athat not only results in an output
function very close to the ground truth u†(6f), but also the recovered asatisfies the PDE constraint and is close to the
underlying a†.
15dxdt 2−62−72−82−92−10
2−40.4081 0.3150 0.3149 0.3179 0.3196
2−50.1819 0.1817 0.1780 0.1773 0.1757
2−60.0730 0.0436 0.0398 0.0386 0.0382
2−70.0582 0.0234 0.0122 0.0066 0.0034
Table 5: relative L2 error of PINO (Finite-difference in time) on Kolmogorov flow with Re= 500 andT= 0.125.
PINO inherits the convergence rate of its differentiation method with no limitation of optimization
Figure 7: Darcy inverse problem: comparing PINO forward, inverse models with numerical solver with MCMC.
4.3 Inverse problem
One of the major advantages of the physics-informed method is to solve the inverse problem. In the experiment, we
investigate PINO on the inverse problem of the Darcy equation to recover the coefficient function a†from the given
solution function u†. We assume a dataset {aj, uj}is available to learn the operator. The coefficient function ais a
piecewise constant (representing two types of media), so the inverse problem can be viewed as a classification problem.
We define R(a)as the total variance.
The PDE loss strongly improves the prediction of the inverse problem. The plain neural operator model, while
accurate in the forward problem, is vulnerable under perturbation and shift of the input a, which is a common behavior
of deep-learning models. This domain-shift problem is critical for optimization-based inverse problems. During the
optimization, ais likely to go out of the training distribution, which makes the neural operator model inaccurate. As
shown in Figure 6 (b), the prediction of ais less accurate, while the model believes its output 6 (e) is the same as the
target. This issue is mitigated by adding the PDE constraints, which restrict the prediction ato the physically-valid
manifold where P(a, u) = 0 . As shown in Figure 6 (c), the initial condition recovered with PDE loss is very close to
the ground truth.
Comparing the PINO forward model with the inverse model, the inverse model Fθ:u7→a(17) has the best
performance. As Shown in Figure 7, the inverse model has 2.29% relative l2 error on the output uand97.10%
classification accuracy on the input a; the forward model has 6.43% error on the output and 95.38% accuracy on the
input. Both models converge with 200 iterations. The major advantage of the PINO inverse model compared to the
PINO forward model is that it uses a neural operator Fθ(u†)as the ansatz for the coefficient function, which is used
as regularization Lop. Similar to the forward problem, the operator ansatz has an easier optimization landscape while
being expressive.
As a reference, we compare the PINO inverse frameworks with PINN and the conventional solvers using the
accelerated MCMC method with 500,000 steps [ 8]. The posterior mean of the MCMC has a 4.52% error and 90.30%
respectively ( Notice the Bayesian method outputs the posterior distribution, which is beyond obtaining a maximum a
posteriori estimation). Meanwhile, PINO methods are 3000x faster compared to MCMC PINN does not converge in
16this case. Please refer to D for further study on the importance of imposing physics constraints in approaching inverse
problems in PDE.
Besides the speedup with respect to the online cost, the offline training of PINO only takes around 1 hour on a single
GPU on the Darcy problem. Once trained, the model can be used without any further training cost. As a comparison,
it takes considerably longer to deploy a finite element solver and an MCMC solver compared to a machine learning
model. Generally speaking, numerical solvers usually have a more complicated codebase and it is non-trivial to specify
boundary conditions, time schemes, and meshes. In the end, it can be easier to prepare a machine learning model than a
standard numerical solver. Flexibility and accessibility are some of the major advantages of these machine learning
methods.
5 Conclusion and future work
In this work, we develop the physics-informed neural operator (PINO) that bridges the gap between physics-informed
optimization and data-driven neural operator learning. We introduce operator-learning and instance-wise fine-tuning
schemes for PINO to utilize both the data and physics constraints. In the operator learning phase, PINO learns an
operator ansatz over multiple instances of a parametric PDE family. The instance-wise fine-tuning scheme allows us to
take advantage of the learned neural operator ansatz and solve for the solution function on the querying instance faster
and more accurately.
While PINO shows many promising applications, it also shares some limitations as in the previous work. For
example, since PINO is currently implemented with the FNO backbone with the Fast-Fourier transform, it is hard to
extend to higher dimensional problems. Besides, as shown in Figure 9, finetuning PINO using gradient descent methods
does not converge as fast as using a finer grid as in Table 5. Further optimization techniques are to be developed.
There are many exciting future directions. Most of the techniques and analyses of PINN can be transferred to PINO.
It is also interesting to ask how to overcome the hard trade-off of accuracy and complexity, and how the PINO model
transfers across different geometries. Furthermore, it is promising to develop a software library of pre-trained models.
PINO’s excellent extrapolation property allows it to be applied on a broad set of conditions, as shown in Transfer
Reynold’s number experiments.
Acknowledgement
The authors want to thank Sifan Wang for meaningful discussions.
Z. Li gratefully acknowledges the financial support from the Kortschak Scholars, PIMCO Fellows, and Amazon
AI4Science Fellows programs. N. Kovachki is partially supported by the Amazon AI4Science Fellowship. A.
Anandkumar is supported in part by Bren endowed chair professorship.
This work was carried out on (1) the NVIDIA NGC as part of Zongyi Li’s internship and (2) the Resnick High
Performance Computing Center, a facility supported by Resnick Sustainability Institute at the California Institute of
Technology
References
[1]Francesca Bartolucci, Emmanuel de Bézenac, Bogdan Raoni ´c, Roberto Molinaro, Siddhartha Mishra, and Rima
Alaifari. Are neural operators really neural operators? frame theory meets operator learning. arXiv preprint
arXiv:2305.19913 , 2023.
[2]Kaushik Bhattacharya, Bamdad Hosseini, Nikola B Kovachki, and Andrew M Stuart. Model reduction and neural
networks for parametric pde(s). arXiv preprint arXiv:2005.03180 , 2020.
[3]Boris Bonev, Thorsten Kurth, Christian Hundt, Jaideep Pathak, Maximilian Baust, Karthik Kashinath, and
Anima Anandkumar. Spherical fourier neural operators: Learning stable dynamics on the sphere. arXiv preprint
arXiv:2306.03838 , 2023.
[4]Charles-Henri Bruneau and Mazen Saad. The 2d lid-driven cavity problem revisited. Computers & fluids , 35(3):
326–348, 2006.
17[5]Oscar P Bruno, Youngae Han, and Matthew M Pohlman. Accurate, high-order representation of complex three-
dimensional surfaces via fourier continuation analysis. Journal of computational Physics , 227(2):1094–1125,
2007.
[6]Steven L Brunton, Bernd R Noack, and Petros Koumoutsakos. Machine learning for fluid mechanics. Annual
Review of Fluid Mechanics , 52:477–508, 2020.
[7]Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics-informed neural
networks (pinns) for fluid mechanics: A review. arXiv preprint arXiv:2105.09506 , 2021.
[8]Simon L Cotter, Gareth O Roberts, Andrew M Stuart, and David White. Mcmc methods for functions: modifying
old algorithms to make them faster. Statistical Science , 28(3):424–446, 2013.
[9]Maarten V de Hoop, Daniel Zhengyu Huang, Elizabeth Qian, and Andrew M Stuart. The cost-accuracy trade-off
in operator learning with neural networks. arXiv preprint arXiv:2203.13181 , 2022.
[10] James Duvall, Karthik Duraisamy, and Shaowu Pan. Non-linear independent dual system (nids) for discretization-
independent surrogate modeling over complex geometries, 2021.
[11] Vikas Dwivedi and Balaji Srinivasan. Physics informed extreme learning machine (pielm)–a rapid method for the
numerical solution of partial differential equations. Neurocomputing , 391:96–118, 2020.
[12] Vladimir Fanaskov and Ivan Oseledets. Spectral neural operators. arXiv preprint arXiv:2205.10573 , 2022.
[13] Olga Fuks and Hamdi A Tchelepi. Limitations of physics informed machine learning for nonlinear two-phase
transport in porous media. Journal of Machine Learning for Modeling and Computing , 1(1), 2020.
[14] Han Gao, Luning Sun, and Jian-Xun Wang. Phygeonet: physics-informed geometry-adaptive convolutional neural
networks for solving parameterized steady-state pdes on irregular domain. Journal of Computational Physics ,
428:110079, 2021.
[15] Daniel Greenfeld, Meirav Galun, Ronen Basri, Irad Yavneh, and Ron Kimmel. Learning to optimize multigrid
pde solvers. In International Conference on Machine Learning , pages 2415–2423. PMLR, 2019.
[16] Jiequn Han, Arnulf Jentzen, and E Weinan. Solving high-dimensional partial differential equations using deep
learning. Proceedings of the National Academy of Sciences , 115(34):8505–8510, 2018.
[17] Yinnian He and Weiwei Sun. Stability and convergence of the crank–nicolson/adams–bashforth scheme for the
time-dependent navier–stokes equations. SIAM Journal on Numerical Analysis , 45(2):837–869, 2007.
[18] Oliver Hennigh, Susheela Narasimhan, Mohammad Amin Nabian, Akshay Subramaniam, Kaustubh Tangsali,
Zhiwei Fang, Max Rietmann, Wonmin Byeon, and Sanjay Choudhry. Nvidia simnet ™: An ai-accelerated multi-
physics simulation framework. In International Conference on Computational Science , pages 447–461. Springer,
2021.
[19] Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, András Horányi, Joaquín Muñoz-Sabater, Julien
Nicolas, Carole Peubey, Raluca Radu, Dinand Schepers, et al. The era5 global reanalysis. Quarterly Journal of
the Royal Meteorological Society , 146(730):1999–2049, 2020.
[20] Xiang Huang, Zhanhong Ye, Hongsheng Liu, Beiji Shi, Zidong Wang, Kang Yang, Yang Li, Bingya Weng, Min
Wang, Haotian Chu, et al. Meta-auto-decoder for solving parametric partial differential equations. arXiv preprint
arXiv:2111.08823 , 2021.
[21] Ameya D Jagtap, Kenji Kawaguchi, and George Em Karniadakis. Locally adaptive activation functions with
slope recovery for deep and physics-informed neural networks. Proceedings of the Royal Society A , 476(2239):
20200334, 2020.
[22] Xiaowei Jin, Shengze Cai, Hui Li, and George Em Karniadakis. Nsfnets (navier-stokes flow nets): Physics-
informed neural networks for the incompressible navier-stokes equations. Journal of Computational Physics , 426:
109951, 2021.
18[23] K Kashinath, M Mustafa, A Albert, JL Wu, C Jiang, S Esmaeilzadeh, K Azizzadenesheli, R Wang, A Chat-
topadhyay, A Singh, et al. Physics-informed machine learning: case studies for weather and climate modelling.
Philosophical Transactions of the Royal Society A , 379(2194):20200093, 2021.
[24] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 ,
2014.
[25] Dmitrii Kochkov, Jamie A Smith, Ayya Alieva, Qing Wang, Michael P Brenner, and Stephan Hoyer. Machine
learning accelerated computational fluid dynamics. arXiv preprint arXiv:2102.01010 , 2021.
[26] Katiana Kontolati, Somdatta Goswami, Michael D Shields, and George Em Karniadakis. On the influence of
over-parameterization in manifold based surrogates and deep neural operators. Journal of Computational Physics ,
479:112008, 2023.
[27] Nikola Kovachki, Zongyi Li, Burigede Liu, Kamyar Azizzadenesheli, Kaushik Bhattacharya, Andrew Stuart, and
Anima Anandkumar. Neural operator: Learning maps between function spaces. arXiv preprint arXiv:2108.08481 ,
2021.
[28] Samuel Lanthaler, Roberto Molinaro, Patrik Hadorn, and Siddhartha Mishra. Nonlinear reconstruction for operator
learning of pdes with discontinuities. arXiv preprint arXiv:2210.01074 , 2022.
[29] Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and
Anima Anandkumar. Fourier neural operator for parametric partial differential equations, 2020.
[30] Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and
Anima Anandkumar. Multipole graph neural operator for parametric partial differential equations, 2020.
[31] Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and
Anima Anandkumar. Neural operator: Graph kernel network for partial differential equations. arXiv preprint
arXiv:2003.03485 , 2020.
[32] Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and
Anima Anandkumar. Markov neural operators for learning chaotic systems. arXiv preprint arXiv:2106.06898 ,
2021.
[33] Zongyi Li, Daniel Zhengyu Huang, Burigede Liu, and Anima Anandkumar. Fourier neural operator with learned
deformations for pdes on general geometries. arXiv preprint arXiv:2207.05209 , 2022.
[34] Burigede Liu, Nikola Kovachki, Zongyi Li, Kamyar Azizzadenesheli, Anima Anandkumar, Andrew M Stuart,
and Kaushik Bhattacharya. A learning-based multiscale method and its application to inelastic impact problems.
Journal of the Mechanics and Physics of Solids , 158:104668, 2022.
[35] Denghui Lu, Han Wang, Mohan Chen, Lin Lin, Roberto Car, E Weinan, Weile Jia, and Linfeng Zhang. 86 pflops
deep potential molecular dynamics simulation of 100 million atoms with ab initio accuracy. Computer Physics
Communications , 259:107624, 2021.
[36] Lu Lu, Pengzhan Jin, and George Em Karniadakis. Deeponet: Learning nonlinear operators for identifying
differential equations based on the universal approximation theorem of operators. arXiv preprint arXiv:1910.03193 ,
2019.
[37] Lu Lu, Xuhui Meng, Shengze Cai, Zhiping Mao, Somdatta Goswami, Zhongqiang Zhang, and George Em
Karniadakis. A comprehensive and fair comparison of two neural operators (with practical extensions) based on
fair data. arXiv preprint arXiv:2111.05512 , 2021.
[38] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. DeepXDE: A deep learning library for solving
differential equations. SIAM Review , 63(1):208–228, 2021. doi: 10.1137/19M1274067.
[39] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft attention
mechanism. arXiv preprint arXiv:2009.04544 , 2020.
19[40] NH Nelsen and AM Stuart. The random feature model for input-output maps between banach spaces. arXiv
preprint arXiv:2005.10224 , 2020.
[41] Ravi G Patel, Nathaniel A Trask, Mitchell A Wood, and Eric C Cyr. A physics-informed operator regression frame-
work for extracting data-driven continuum models. Computer Methods in Applied Mechanics and Engineering ,
373:113500, 2021.
[42] Jaideep Pathak, Mustafa Mustafa, Karthik Kashinath, Emmanuel Motheau, Thorsten Kurth, and Marcus Day.
Ml-pde: A framework for a machine learning enhanced pde solver. Bulletin of the American Physical Society ,
2021.
[43] Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay, Morteza Mardani,
Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, et al. Fourcastnet: A global data-driven high-
resolution weather model using adaptive fourier neural operators. arXiv preprint arXiv:2202.11214 , 2022.
[44] Maziar Raissi, Paris Perdikaris, and George E Karniadakis. Physics-informed neural networks: A deep learning
framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of
Computational Physics , 378:686–707, 2019.
[45] Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning velocity and
pressure fields from flow visualizations. Science , 367(6481):1026–1030, 2020.
[46] Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial differential
equations. Journal of computational physics , 375:1339–1364, 2018.
[47] Jonathan D Smith, Zachary E Ross, Kamyar Azizzadenesheli, and Jack B Muir. Hyposvi: Hypocenter inversion
with stein variational inference and physics informed neural networks. arXiv , 2021.
[48] Luning Sun, Han Gao, Shaowu Pan, and Jian-Xun Wang. Surrogate modeling for fluid flows based on physics-
constrained deep learning without simulation data. Computer Methods in Applied Mechanics and Engineering ,
361:112732, 2020.
[49] Rui Wang, Karthik Kashinath, Mustafa Mustafa, Adrian Albert, and Rose Yu. Towards physics-informed deep
learning for turbulent flow prediction. In Proceedings of the 26th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining , pages 1457–1466, 2020.
[50] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why pinns fail to train: A neural tangent kernel
perspective. arXiv preprint arXiv:2007.14527 , 2020.
[51] Sifan Wang, Yujun Teng, and Paris Perdikaris. Understanding and mitigating gradient flow pathologies in
physics-informed neural networks. SIAM Journal on Scientific Computing , 43(5):A3055–A3081, 2021.
[52] Sifan Wang, Hanwen Wang, and Paris Perdikaris. Learning the solution operator of parametric partial differential
equations with physics-informed deeponets. arXiv preprint arXiv:2103.10974 , 2021.
[53] E Weinan and Bing Yu. The deep ritz method: a deep learning-based numerical algorithm for solving variational
problems. Communications in Mathematics and Statistics , 6(1):1–12, 2018.
[54] Gege Wen, Zongyi Li, Qirui Long, Kamyar Azizzadenesheli, Anima Anandkumar, and Sally M Benson. Accel-
erating carbon capture and storage modeling using fourier neural operators. arXiv preprint arXiv:2210.17051 ,
2022.
[55] Gege Wen, Zongyi Li, Qirui Long, Kamyar Azizzadenesheli, Anima Anandkumar, and Sally M Benson. Real-time
high-resolution co 2 geological storage prediction using nested fourier neural operators. Energy & Environmental
Science , 16(4):1732–1741, 2023.
[56] Haoyu Yang, Zongyi Li, Kumara Sastry, Saumyadip Mukhopadhyay, Mark Kilgard, Anima Anandkumar, Brucek
Khailany, Vivek Singh, and Haoxing Ren. Generic lithography modeling with dual-band optics-inspired neural
networks. arXiv preprint arXiv:2203.08616 , 2022.
20[57] Lulu Zhang, Tao Luo, Yaoyu Zhang, Zhi-Qin John Xu, and Zheng Ma. Mod-net: A machine learning approach
via model-operator-data network for solving pdes. arXiv preprint arXiv:2107.03673 , 2021.
[58] Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, and Paris Perdikaris. Physics-constrained deep
learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data. Journal of
Computational Physics , 394:56–81, 2019.
21A Implementation details
In this section, we list the detailed experiment setups and parameter searching for each experiment in Section 4.
Without specification, we use Fourier neural operator backbone with width = 64 ,mode = 8or12,L= 4, and GeLU
activations. The numerical experiments are performed on Nvidia V100 GPUs and A100 GPUs.
A.1 Burgers Equation
We use the 1000 initial conditions u0∼µwhere µ=N(0,625(−∆ + 25 I)−2)to train the solution operator on PINO
withwidth = 64 ,mode = 15 , and GeLU activation. We use the numerical method to take the gradient. We use Adam
optimizer with the learning rate 0.001that decays by half every 100epochs. 500epochs in total. The total training time
is about 20minutes on a single Nvidia 3090 GPU. PINO achieves 0.38% relative l2 error averaged over 200 testing
instances. PINN-DeepONet achieves 1.38% which is taken from Wang et al. [52] which uses the same problem setting.
A.2 Darcy Flow
We use the 1000 coefficient conditions ato train the solution operator where a∼µwhere µ=ψ#N(0,(−∆ +9 I)−2),
ψ(a(x)) = 12 ifa(x)≥0;ψ(a(x)) = 3 ifa(x)<0. The zero boundary condition is enforced by multiplying a
mollifier m(x) = sin( πx) sin(πy)for all methods. The parameter of PINO on Darcy Flow is the same as in the
Burgers equation above. It takes around 1 hour to train the PINO model on a single Nvidia V100 GPU. Regarding the
implementation detail of the baselines: as for FNO, we use the same hyperparameters as its paper did [ 31] and set
width = 64, mode = 20, depth = 4; DeepONet [ 36] did not study Darcy flow so we grid search the hyperparameters
of DeepONet: depth from 2 to 12, width from 50 to 100. The best result of DeepONet is achieved by depth 8, and width
50. The results are shown in Table 2. All the models are trained on resolution 61×61and evaluated on resolution
61×61.
A.3 Long temporal transient flow.
We study the build-up of the flow from the initial condition u0near-zero velocity to uTthat reaches the ergodic state.
We choose T= 50, l= 1 as in Li et al. [29]. We choose the weight parameters of error α=β= 5. The initial
condition w0(x)is generated according to w0∼µwhere µ=N(0,73/2(−∆ + 49 I)−2.5)with periodic boundary
conditions. The forcing is kept fixed f(x) = 0 .1(sin(2 π(x1+x2)) + cos(2 π(x1+x2))). We compare FNO, PINO
(no instance-wise fine-tuning), and PINO (with instance-wise fine-tuning). They get 3.04%,2.87%, and 1.84% relative
l2 error on the last time step u(50) over 5 testing instance.
A.4 Chaotic Kolmogorov flow.
For this experiment, ulies in the attractor. We choose T= 0.125,0.5or1, and l= 1, similar to Li et al. [32]. For
T= 0.5s, the training set consists of 4000 initial condition functions and corresponding solution functions with a spatial
resolution of 64×64and a temporal resolution of 65. Extra initial conditions are generated from Gaussian random
fieldN 
0,73/2(−∆ + 49 I)−5/2
. We estimate the generalization error of the operator on a test set that contains 300
instances of Kolmogorov flow and reports the average relative L2error. Each neural operator is trained with 4k data
points plus a number of extra sampled initial conditions. The Reynolds number in this problem is 500. The reported
generalization error is averaged over 300 instances. It takes up to 2 days to train the model on a single Nvidia V100
GPU. For the experiments in Table 1, T= 0.125and the training set has data with spatial resolution 64×64and
temporal resolution 33. The test set has 200 instances with spatial resolution 256×256and temporal resolution 65. For
the experiments in Table 6, T= 0.125and the training set contains 800 instances in even lower resolution 32×32×17.
The test set has 200 instances with spatial resolution 256×256and temporal resolution 65.
Comparison study. The baseline method PINN, LAAF-PINN, and SA-PINN are implemented using library DeepXDE
[38] with TensorFlow as the backend. We use the two-step optimization strategy (Adam [ 24] and L-BFGS) following
the same practice as NSFNet [ 22], which applies PINNs to solving Navier Stokes equations. We grid search the
hyperparameters: network depth from 4 to 6, width from 50 to 100, learning rate from 0.01 to 0.0001, and the weight of
boundary loss from 10 to 100 for all experiments of PINNs. Comparison between PINO and PINNs on instance-wise
22fine-tuning. The results are averaged over 20 instances of the Navier-Stokes equation with Reynolds number 500. The
best result is obtained by PINO using learned operator ansatz and virtual sampling. The neural operator ansatz used
here is trained on 400 data points. The authors acknowledge that there could exist more sophisticated variants of PINN
that perform better in our test cases.
Test resolution FNO PINO
64x64x33 9.73±0.15% 6.30±0.11%
128x128x33 9.74±0.16% 6.28±0.11%
256x256x65 9.84±0.16% 6.22±0.11%
Table 6: Comparison between data only (FNO) and data + PDE (PINO) on higher resolutions while trained on much
lower resolution 32×32×17.
# data samples # additional PDE instances Resolution Solution error Equation error
400 0128×128×65 33.32% 1.8779
64×64×65 33.31% 1.8830
32×32×33 30.61% 1.8421
400 40k128×128×65 31.74% 1.8179
64×64×65 31.72% 1.8227
32×32×33 29.60% 1.8296
400 160k128×128×65 31.32% 1.7840
64×64×65 31.29% 1.7864
32×32×33 29.28% 1.8524
4k 0128×128×65 25.15% 1.8223
64×64×65 25.16% 1.8257
32×32×33 21.41% 1.8468
4k 100k128×128×65 24.15% 1.6112
64×64×65 24.11% 1.6159
32×32×33 20.85% 1.8251
4k 400k128×128×65 24.22% 1.4596
64×64×65 23.95% 1.4656
32×32×33 20.10% 1.9146
0 100k128×128×65 74.36% 0.3741
64×64×65 74.38% 0.3899
32×32×33 74.14% 0.5226
Table 7: Each neural operator is trained with 400 or 4000 data points additionally sampled free initial conditions. The
Reynolds number is 500. The reported generalization error is averaged over 300 instances. Training on additional initial
conditions boosts the generalization ability of the operator.
A.5 Transfer learning across Reynolds numbers
We study the instance-wise fine-tuning with different Reynolds numbers on the T= 1 Kolmogorov flow. For the
higher Reynolds number problem Re= 500 ,400, fine-tuning the source operator shows better convergence accuracy
than learning from scratch. In all cases, the fine-tuning of the source operator shows better convergence speed as
demonstrated in Figure 8. The results are shown in Table 8 where the error is averaged over 40 instances. Each row is a
testing case, and each column is a source operator.
23Testing Re From scratch 100 200 250 300 350 400 500
500 0.0493 0.0383 0.0393 0.0315 0.0477 0.0446 0.0434 0.0436
400 0.0296 0.0243 0.0245 0.0244 0.0300 0.0271 0.0273 0.0240
350 0.0192 0.0210 0.0211 0.0213 0.0233 0.0222 0.0222 0.0212
300 0.0168 0.0161 0.0164 0.0151 0.0177 0.0173 0.0170 0.0160
250 0.0151 0.0150 0.0153 0.0151 0.016 0.0156 0.0160 0.0151
200 0.00921 0.00913 0.00921 0.00915 0.00985 0.00945 0.00923 0.00892
100 0.00234 0.00235 0.00236 0.00235 0.00239 0.00239 0.00237 0.00237
Table 8: Reynolds number transfer learning. Each row is a test set of PDEs with corresponding Reynolds number. Each
column represents the operator ansatz we use as the starting point of instance-wise fine-tuning. For example, column
header “100” means the operator ansatz is trained over a set of PDEs with Reynolds number 100. The relative L2errors
is averaged over 40 instances of the corresponding test set.
Figure 8: Plot of relative L2error versus update step for the Kolmogorov flow with Reynolds number 500,T= 1.
The test error is averaged over 40 instances. We observe that all the operator ansatzs trained over PDE instances with
different Reynolds numbers can boost the instance-wise fine-tuning accuracy and convergence speed compared to
training from scratch.
24(a) The long-temporal transient flow with Re∼20, T= 50 . PINO outputs the full trajectory in one step, which leads
to a 400x speedup compared to the GPU solver. PINN cannot converge to a reasonable error rate due to the long time
window. (b) The chaotic Kolmogorov flow with Re=∼500, T= 0.5. PINO converges faster compared to PINN, but
their convergence rates with gradient descent are less effective compared to using higher resolutions in the GPU solver.
Figure 9: The accuracy-complexity trade-off on PINO, PINN, and the GPU-based pseudo-spectral solver.
B Additional experiments
B.1 Additional baselines
We add a comparison experiment against the Locally adaptive activation functions for PINN (LAAF-PINN) [ 21] and
Self-Adaptive PINN (SA-PINN) [ 39]. For the Kolmogorov flow problem, we set Re=500, T=[0, 0.5]. We search among
the following hyperparameters combinations: LAAF-PINN: n: 10, 100, learning rate: 0.1, 0.01, 0.001, depth 4, 6.
SA-PINNs: learning rate 0.001, 0.005, 0.01, 0.05, network width 50, 100, 200, depth 4, 6, 8.
As shown in Figure 4, both LAAF-PINN and SA-PINN converge much faster than the original PINN method, but
there is still a big gap with PINO. LAAF-PINN adds learnable parameters before the activation function; SA-PINN adds
the weight parameter for each collocation point. These techniques help to alleviate the PINNs‘ optimization problem
significantly. However, they didn’t alter the optimization landscape effectively in the authors’ opinion. On the other
hand, by using the operator ansatz, PINO optimizes function-wise where the optimization is fundamentally different.
Note that the contribution of PINO is orthogonal to the above methods. One can apply the adaptive activation
functions or self-adaptive loss in the PINO framework too. All these techniques of PINNs can be straightforwardly
transferred to PINO. We believe it would be interesting future directions to study how all these methods work with each
other in different problems.
B.2 Lid Cavity flow.
We demonstrate an addition example using PINO to solve for lid-cavity flow on T= [5,10]withRe= 500 . In this
case, we do not have the operator-learning phase and directly solve the equation (instance-wise fine-tuning). We use
PINO with the velocity-pressure formulation and resolution 65×65×50plus the Fourier numerical gradient. It takes
2minutes to achieve a relative error of 14.52%. Figure 5 shows the ground truth and prediction of the velocity field at
t= 10 where the PINO accurately predicts the ground truth.
We assume a no-slip boundary where u(x, t) = (0 ,0)at left, bottom, and right walls and u(x, t) = (1 ,0)on top,
similar to Bruneau and Saad [4]. We choose t∈[5,10],l= 1,Re= 500 . We use the velocity-pressure formulation as
in Jin et al. [22] where the neural operator output the velocity field in x,y, and the pressure field. We set width = 32 ,
mode = 20 with a learning rate 0.0005 which decreases by half every 5000 iterations, 5000 iterations in total. We use
the Fourier method with Fourier continuation to compute the numerical gradient and minimize the residual error on the
velocity, the divergence-free condition, as well as the initial condition and boundary condition. The weight parameters
(α, β) between different error terms are all chosen as 1. Figure 5 shows the ground truth and prediction of the velocity
field at t= 10 where the PINO accurately predicts the ground truth.
25Figure 10: Fourier Continuation by padding zeros. The x-axis is the spatial dimension; the y-axis is the temporal
dimension. FNO extends the output smoothly on the padded domain.
C Fourier continuation
The Fourier neural operator can be applied to arbitrary geometry via Fourier continuations. Given any compact manifold
M, we can always embed it into a periodic cube (torus),
i:M → Tn
where we can do the regular FFT. Conventionally, people would define the embedding ias a continuous extension by
fitting polynomials [ 5]. However, in Fourier neural operator, it can be simply done by padding zeros in the input. The
loss is computed at the original space during training. The Fourier neural operator will automatically generate a smooth
extension to do a padded domain in the output, as shown in Figure 10.
This technique is first used in the original Fourier neural operator paper [ 29] to deal with the time dimension in the
Navier-Stokes equation. Similarly, Lu et al. [37] apply FNO with extension and interpolation on diverse geometries on
the Darcy equation. In the work, we use Fourier continuation widely for non-periodic boundary conditions (Darcy, time
dimension). We also added an example of lid-cavity to demonstrate that PINO can work with non-periodic boundary
conditions.
Furthermore, this Fourier continuation technique helps to take the derivatives of the Fourier neural operator. Since
the output of FNO is always on a periodic domain, the numerical Fourier gradient is usually efficient and accurate,
except if there is shock (in this case, we will use the exact gradient method).
D PDE constraints in inverse problems
In subsection 3.4 we presented the study of inverse problems where we propose a new approach to tackle inverse
problems. We propose to incorporate both data and PDE constraints for the inverse problem. The data constraint makes
sure the recovered input function, when fed to the neural operator, results in an output that matches the observed data
u†. The PDE constraint, imposed using Lpde, is a crucial physics-based constraint that is the key to having an accurate
approach for inverse problems. This constraint reinforces that the pairs of recovered input and their corresponding
output are physical. In other words, they satisfy the underlying PDE. When the physics-based constraint is imposed, the
search space of (a, u)is confined to the solutions manifold of the PDE, i.e., pairs satisfying the underlying PDE.
E Discretization convergence and representation equivalence
In this paper, we follow the definition of resolution and discretization convergence (previously named discretization
invariance) provided in the definition of neural operators established in [ 27]. This definition states resolution convergence
in the limit of mesh refinement. As the mesh refinement goes to infinity, a discretization convergent operator converges
to its limit in the infinite-dimensional function space. It may get a higher error at a coarse discretization, but as the
training resolution increases, the model should converge to an accurate model.
Another class of neural operator, named representation equivalent neural operator, is proposed later in [ 1]. Repre-
sentation equivalent neural operators are defined as these neural operators with no aliasing error. Such neural operators
26are invariant under any discretization. FNOs do not satisfy representation equivalence because it has a pointwise
non-linearity in every layer applied in physical space which can re-introduce Fourier modes of size greater than
the current grid so, under the assumption that all modes are active for the input discretization, this will necessarily
introduce aliasing error. This remains true for any architecture which uses pointwise non-linearities in physical space,
encompassing most of the deep learning.
Hence, resolution convergent [ 27] and representation equivalence [ 1] are different goals to achieve. The former
holds for FNO and PINO, which have the expressive power to approximate the underlying operator as the resolution
goes to infinity. This allows them to make predictions at any resolution and hence, they can extrapolate to higher
resolutions than their training data. On the other hand, representation equivalent models such as SNO [ 12] and PCA-Net
[2] are limited to fixed-dimensional representation, and they cannot generate higher frequencies beyond what they are
trained on.
As shown in the figure below, PINO trained on 64x64 resolution data can extrapolate to unseen higher frequencies.
In contrast, representation-equivalent models cannot generate new frequencies since their representation space is fixed.
Therefore they introduce an irreducible approximation error based on the size of the predefined representation space.
Since the goal of operator learning is to find the underlying solution operator in the continuum, we believe discretization
convergent is a more useful property.
27"
8,https://www.geeksforgeeks.org/variational-autoencoders/,"

















































Variational AutoEncoders | GeeksforGeeks









































Skip to content









CoursesDSA to DevelopmentMachine Learning & Data ScienceGenerative AI & ChatGPTBecome AWS CertifiedDSA CoursesData Structure & Algorithm(C++/JAVA)Data Structure & Algorithm(Python)Data Structure & Algorithm(JavaScript)Programming LanguagesCPPJavaPythonJavaScriptCAll CoursesTutorialsPythonPython TutorialPython ProgramsPython QuizPython ProjectsPython Interview QuestionsPython Data StructuresJavaJava TutorialJava CollectionsJava 8 TutorialJava ProgramsJava QuizJava ProjectsJava Interview QuestionsAdvanced JavaProgramming LanguagesJavaScriptC++R TutorialSQLPHPC#CScalaPerlGo LanguageKotlinInterview CornerSystem Design TutorialCompany PreparationTop TopicsPractice Company QuestionsInterview ExperiencesExperienced InterviewsInternship InterviewsCompetitive ProgrammingMultiple Choice QuizzesAptitude for PlacementsComputer Science SubjectsOperating SystemDBMSComputer NetworksEngineering MathematicsComputer Organization and ArchitectureTheory of ComputationCompiler DesignDigital LogicSoftware EngineeringDevOps and LinuxDevOps TutorialGITAWSDockerKubernetesMicrosoft Azure TutorialGoogle Cloud PlatformLinux TutorialSoftware TestingSoftware Testing TutorialSoftware Engineering TutorialTesting Interview QuestionsJiraDatabasesDBMS TutorialSQL TutorialPostgreSQL TutorialMongoDB TutorialSQL Interview QuestionsMySQL Interview QuestionsPL/SQL Interview QuestionsAndroidAndroid TutorialAndroid Studio TutorialKotlin For AndroidAndroid ProjectsAndroid Interview Questions6 Weeks of Android App DevelopmentExcelMS Excel TutorialIntroduction to MS ExcelData Analysis in ExcelBasic Excel Formulas & FunctionsData Analysis in Advanced ExcelWorkbooksStatistical FunctionsData Visualization in ExcelPivot Tables in ExcelExcel Spreadsheets in PythonBasic Excel ShortcutsMathematicsNumber SystemAlgebraLinear AlgebraTrigonometrySet TheoryStatisticsProbabilityGeometryMensurationLogarithmsCalculusDSADSA TutorialPracticePractice Coding ProblemsProblem of the DayGfG SDE SheetCompetitive ProgrammingCompany Wise SDE SheetsFacebook SDE SheetAmazon SDE SheetApple SDE SheetNetflix SDE SheetGoogle SDE SheetTop Interview QuestionsPuzzlesAll PuzzlesTop 100 Puzzles Asked In InterviewsTop 20 Puzzles Commonly Asked During SDE InterviewsData SciencePython TutorialR TutorialMachine LearningData Science using PythonData Science using RData Science PackagesPandas TutorialNumPy TutorialData VisualizationPython Data Visualization TutorialData Visualization with RData AnalysisData Analysis with PythonData Analysis with RDeep LearningNLP TutorialWeb TechHTML TutorialCSS TutorialJavaScript TutorialPHP TutorialReactJS TutorialNodeJS TutorialBootstrap TutorialTypescriptWeb Development Using PythonDjango TutorialFlask TutorialPostmanGithubCheat SheetsHTML Cheat SheetCSS Cheat SheetJavaScript Cheat SheetReact Cheat SheetAngular Cheat SheetjQuery Cheat SheetBootstrap Cheat SheetLearn Complete Web Development





 









































Data ScienceData Science ProjectsData AnalysisData VisualizationMachine LearningML ProjectsDeep LearningNLPComputer VisionArtificial Intelligence 




▲












Open In App











Next Article:
Contractive Autoencoder (CAE)

























Variational AutoEncoders



Last Updated : 
04 Mar, 2025






Summarize






Comments







Improve



























Suggest changes


 


Like Article



Like








Share







Report







Follow





Variational Autoencoders (VAEs) are generative models in machine learning (ML) that create new data similar to the input they are trained on. Along with data generation they also perform common autoencoder tasks like denoising. Like all autoencoders VAEs consist of:
Encoder: Learns important patterns (latent variables) from input data.Decoder: It uses those latent variables to reconstruct the input.Unlike traditional autoencoders that encode a fixed representation VAEs learn a continuous probabilistic representation of latent space. This allows them to reconstruct input data accurately and generate new data samples that resemble the original input.
Architecture of Variational AutoencoderVAE is a special kind of autoencoder that can generate new data instead of just compressing and reconstructing it. It has three main parts:
1. Encoder (Understanding the Input)The encoder takes the input data like an image or text and tries to understand its most important features.Instead of creating a fixed compressed version like a normal autoencoder it creates two things:Mean (μ): A central value representing the data.Standard Deviation (σ): It is a measure of how much the values can vary.These two values define a range of possibilities instead of a single number.2. Latent Space (Adding Some Randomness)Instead of encoding input into a fixed number VAEs introduce randomness to create variations.The model picks a point from the range to create different variations of the data.This is what makes VAEs great for generating new slightly different but realistic data.3. Decoder (Reconstructing or Creating New Data)The decoder takes this sampled value and tries to reconstruct the original input.Since the encoder creates a range of possibilities instead of a fixed number the decoder can generate new similar data instead of just memorizing the input.Variational AutoencoderMathematics behind Variational AutoencoderVariational autoencoder uses KL-divergence as its loss function the goal of this is to minimize the difference between a supposed distribution and original distribution of dataset.
Suppose we have a distribution z and we want to generate the observation x from it.  In other words we want to calculate [Tex]p\left( {z|x} \right) [/Tex]We can do it by following way:
[Tex]p\left( {z|x} \right) = \frac{{p\left( {x|z} \right)p\left( z \right)}}{{p\left( x \right)}} [/Tex]
But, the calculation of p(x) can be quite difficult:
[Tex]p\left( x \right) = \int {p\left( {x|z} \right)p\left(z\right)dz} [/Tex]
This usually makes it an intractable distribution. Hence, we need to approximate p(z|x) to q(z|x) to make it a tractable distribution. To better approximate p(z|x) to q(z|x), we will minimize the KL-divergence loss which calculates how similar two distributions are:
[Tex]\min KL\left( {q\left( {z|x} \right)||p\left( {z|x} \right)} \right) [/Tex]
By simplifying, the above minimization problem is equivalent to the following maximization problem :
[Tex]{E_{q\left( {z|x} \right)}}\log p\left( {x|z} \right) – KL\left( {q\left( {z|x} \right)||p\left( z \right)} \right) [/Tex]
The first term represents the reconstruction likelihood and the other term ensures that our learned distribution q is similar to the true prior distribution p.
Thus our total loss consists of two terms one is reconstruction error and other is KL-divergence loss:
[Tex]Loss = L\left( {x, \hat x} \right) + \sum\limits_j {KL\left( {{q_j}\left( {z|x} \right)||p\left( z \right)} \right)} [/Tex]
Implementing Variational Autoencoder In this implementation we will be using the Fashion-MNIST dataset this dataset is already available in keras.datasets API so we don’t need to add or upload manually. You can also find the implementation in the from an. 
Step 1: Importing Libraries In this first we need to import the necessary packages to our python environment. we will be using Keras package with TensorFlow as a backend.

python

import numpy as np
import tensorflow as tf
import keras
from keras import layers

Step 2: Creating a Sampling LayerFor Variational autoencoders we need to define the architecture of two parts encoder and decoder but first we will define the bottleneck layer of architecture the sampling layer.

python

class Sampling(layers.Layer):
    """"""Uses (mean, log_var) to sample z, the vector encoding a digit.""""""

    def call(self, inputs):
        mean, log_var = inputs
        batch = tf.shape(mean)[0]
        dim = tf.shape(mean)[1]
        epsilon = tf.random.normal(shape=(batch, dim))
        return mean + tf.exp(0.5 * log_var) * epsilon

Step 3: Define Encoder Block Now we define the architecture of encoder part of our autoencoder this part takes images as input and encodes their representation in the Sampling layer.

Python

latent_dim = 2

encoder_inputs = keras.Input(shape=(28, 28, 1))
x = layers.Conv2D(64, 3, activation=""relu"", strides=2, padding=""same"")(encoder_inputs)
x = layers.Conv2D(128, 3, activation=""relu"", strides=2, padding=""same"")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation=""relu"")(x)
mean = layers.Dense(latent_dim, name=""mean"")(x)
log_var = layers.Dense(latent_dim, name=""log_var"")(x)
z = Sampling()([mean, log_var])
encoder = keras.Model(encoder_inputs, [mean, log_var, z], name=""encoder"")
encoder.summary()

Output: 
Step 4: Define Decoder BlockNow we define the architecture of decoder part of our autoencoder this part takes the output of the sampling layer as input and output an image of size (28, 28, 1) .

python

latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(7 * 7 * 64, activation=""relu"")(latent_inputs)
x = layers.Reshape((7, 7, 64))(x)
x = layers.Conv2DTranspose(128, 3, activation=""relu"", strides=2, padding=""same"")(x)
x = layers.Conv2DTranspose(64, 3, activation=""relu"", strides=2, padding=""same"")(x)
decoder_outputs = layers.Conv2DTranspose(1, 3, activation=""sigmoid"", padding=""same"")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name=""decoder"")
decoder.summary()

Output: 
Step 5: Define the VAE Model In this step we combine the model and define the training procedure with loss functions.

python

class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name=""total_loss"")
        self.reconstruction_loss_tracker = keras.metrics.Mean(
            name=""reconstruction_loss""
        )
        self.kl_loss_tracker = keras.metrics.Mean(name=""kl_loss"")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            mean,log_var, z = self.encoder(data)
            reconstruction = self.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(1, 2),
                )
            )
            kl_loss = -0.5 * (1 + log_var - tf.square(mean) - tf.exp(log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            ""loss"": self.total_loss_tracker.result(),
            ""reconstruction_loss"": self.reconstruction_loss_tracker.result(),
            ""kl_loss"": self.kl_loss_tracker.result(),
        }

Step 6: Train the VAENow it’s the right time to train our Variational autoencoder model we will train it for 10 epochs.  But first we need to import the fashion MNIST dataset.

python

(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()
fashion_mnist = np.concatenate([x_train, x_test], axis=0)
fashion_mnist = np.expand_dims(fashion_mnist, -1).astype(""float32"") / 255

vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(fashion_mnist, epochs=10, batch_size=128)

Output: 
Step 7: Display Sampled Images In this step we display training result and we will be displaying these results according to their values in latent space vectors.

python

import matplotlib.pyplot as plt

def plot_latent_space(vae, n=10, figsize=5):
    
    img_size = 28
    scale = 0.5
    figure = np.zeros((img_size * n, img_size * n))
    
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(sample, verbose=0)
            images = x_decoded[0].reshape(img_size, img_size)
            figure[
                i * img_size : (i + 1) * img_size,
                j * img_size : (j + 1) * img_size,
            ] = images

    plt.figure(figsize=(figsize, figsize))
    start_range = img_size // 2
    end_range = n * img_size + start_range
    pixel_range = np.arange(start_range, end_range, img_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel(""z[0]"")
    plt.ylabel(""z[1]"")
    plt.imshow(figure, cmap=""Greys_r"")
    plt.show()


plot_latent_space(vae)

Output:
Step 8: Display Latent Space Clusters To get a more clear view of our representational latent vectors values we will be plotting the scatter plot of training data on the basis of their values of corresponding latent dimensions generated from the encoder .

python

def plot_label_clusters(encoder, decoder, data, test_lab):
	z_mean, _, _ = encoder.predict(data)
	plt.figure(figsize =(12, 10))
	sc = plt.scatter(z_mean[:, 0], z_mean[:, 1], c = test_lab)
	cbar = plt.colorbar(sc, ticks = range(10))
	cbar.ax.set_yticklabels([labels.get(i) for i in range(10)])
	plt.xlabel(""z[0]"")
	plt.ylabel(""z[1]"")
	plt.show()


labels = {0 :""T-shirt / top"",
1: ""Trouser"",
2: ""Pullover"",
3: ""Dress"",
4: ""Coat"",
5: ""Sandal"",
6: ""Shirt"",
7: ""Sneaker"",
8: ""Bag"",
9: ""Ankle boot""}

(x_train, y_train), _ = keras.datasets.fashion_mnist.load_data()
x_train = np.expand_dims(x_train, -1).astype(""float32"") / 255
plot_label_clusters(encoder, decoder, x_train, y_train)

Output: 
FAQs on Variational Autoencoders What is the difference between variational and standard autoencoder?Variational autoencoders introduce a probabilistic interpretation in the latent space, allowing for the generation of diverse outputs by sampling from learned distributions. This contrasts with standard autoencoders, which use a deterministic mapping in the latent space. 
What are the uses of VAEs?VAE have various applications due to their ability to model complex probability distributions like – image generation, data generation, anomaly detection, data imputation, and more. 
What is the difference between PCA and Variational autoencoder?PCA focuses on finding the principal components to represent existing data in a lower-dimensional space, while VAEs learn probabilistic mapping that allows for generating new data points. 
What is the drawback of VAE?VAEs has a drawback of generating blurry reconstructions and unrealistic outputs. 
What is better GANs or VAE?For image generation GANs is a better option as it generates high quality samples and VAE is a better option to use in signal analysis.











        Comment
    More info
Advertise with us



Next Article




Contractive Autoencoder (CAE)









P




 

pawangfg 





 Follow 















Improve






Article Tags : 


AI-ML-DS


Machine Learning
 


Practice Tags : 

Machine Learning 





Similar Reads


Deep Learning Tutorial
                    
Deep Learning tutorial covers the basics and more advanced topics, making it perfect for beginners and those with experience. Whether you're just starting or looking to expand your knowledge, this guide makes it easy to learn about the different technologies of Deep Learning. Deep Learning is a bran



5 min read

Introduction to Deep Learning
Introduction to Deep Learning
                    
Deep Learning is transforming the way machines understand, learn, and interact with complex data. Deep learning mimics neural networks of the human brain, it enables computers to autonomously uncover patterns and make informed decisions from vast amounts of unstructured data. Deep Learning leverages



8 min read


Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
                    
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: ""Artificial"" meaning something made by humans or non-natural things and ""Intelligence"" meaning the ability to understand or think ac



14 min read

Basic Neural Network
Difference between ANN and BNN
                    
Do you ever think of what it's like to build anything like a brain, how these things work, or what they do? Let us look at how nodes communicate with neurons and what are some differences between artificial and biological neural networks. 1. Artificial Neural Network: Artificial Neural Network (ANN)



3 min read


Single Layer Perceptron in TensorFlow
                    
In this article, we will be understanding the single-layer perceptron and its implementation in Python using the TensorFlow library. Neural Networks work in the same way that our biological neuron works. Biological neuron has three basic functionality Receive signal from outside.Process the signal a



3 min read


Multi-Layer Perceptron Learning in Tensorflow
                    
Multi-Layer Perceptron (MLP) is an artificial neural network widely used for solving classification and regression tasks. MLP consists of fully connected dense layers that transform input data from one dimension to another. It is called ""multi-layer"" because it contains an input layer, one or more h



9 min read


Deep Neural net with forward and back propagation from scratch - Python
                    
This article aims to implement a deep neural network from scratch. We will implement a deep neural network containing two input layers, a hidden layer with four units and one output layer. The implementation will go from scratch and the following steps will be implemented. Algorithm:1. Loading and v



6 min read


Understanding Multi-Layer Feed Forward Networks
                    
Let's understand how errors are calculated and weights are updated in backpropagation networks(BPNs). Consider the following network in the below figure. The network in the above figure is a simple multi-layer feed-forward network or backpropagation network. It contains three layers, the input layer



7 min read


List of Deep Learning Layers
                    
Deep learning (DL) is characterized by the use of neural networks with multiple layers to model and solve complex problems. Each layer in the neural network plays a unique role in the process of converting input data into meaningful and insightful outputs. The article explores the layers that are us



7 min read

Activation Functions
Activation Functions
                    
To put it in simple terms, an artificial neuron calculates the 'weighted sum' of its inputs and adds a bias, as shown in the figure below by the net input. Mathematically, [Tex]\text{Net Input} =\sum \text{(Weight} \times \text{Input)+Bias}[/Tex] Now the value of net input can be any anything from -



3 min read


Types Of Activation Function in ANN
                    
The biological neural network has been modeled in the form of Artificial Neural Networks with artificial neurons simulating the function of a biological neuron. The artificial neuron is depicted in the below picture: Each neuron consists of three major components:Â  A set of 'i' synapses having weigh



4 min read


Activation Functions in Pytorch
                    
In this article, we will Understand PyTorch Activation Functions. What is an activation function and why to use them?Activation functions are the building blocks of Pytorch. Before coming to types of activation function, let us first understand the working of neurons in the human brain. In the Artif



5 min read


Understanding Activation Functions in Depth
                    
In artificial neural networks, the activation function of a neuron determines its output for a given input. This output serves as the input for subsequent neurons in the network, continuing the process until the network solves the original problem. Consider a binary classification problem, where the



6 min read

Artificial Neural Network
Artificial Neural Networks and its Applications
                    
As you read this article, which organ in your body is thinking about it? It's the brain of course! But do you know how the brain works? Well, it has neurons or nerve cells that are the primary units of both the brain and the nervous system. These neurons receive sensory input from the outside world



9 min read


Gradient Descent Optimization in Tensorflow
                    
Gradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function. In other words, gradient descent is an iterative algorithm that helps to find the optimal solution to a given problem. In this blog, we will discuss gr



15+ min read


Choose Optimal Number of Epochs to Train a Neural Network in Keras
                    
One of the critical issues while training a neural network on the sample data is Overfitting. When the number of epochs used to train a neural network model is more than necessary, the training model learns patterns that are specific to sample data to a great extent. This makes the model incapable t



6 min read

Classification
Python | Classify Handwritten Digits with Tensorflow
                    
Classifying handwritten digits is the basic problem of the machine learning and can be solved in many ways here we will implement them by using TensorFlowUsing a Linear Classifier Algorithm with tf.contrib.learn linear classifier achieves the classification of handwritten digits by making a choice b



4 min read


Train a Deep Learning Model With Pytorch
                    
Neural Network is a type of machine learning model inspired by the structure and function of human brain. It consists of layers of interconnected nodes called neurons which process and transmit information. Neural networks are particularly well-suited for tasks such as image and speech recognition,



6 min read

Regression
Linear Regression using PyTorch
                    
Linear Regression is a very commonly used statistical method that allows us to determine and study the relationship between two continuous variables. The various properties of linear regression and its Python implementation have been covered in this article previously. Now, we shall find out how to



4 min read


Linear Regression Using Tensorflow
                    
We will briefly summarize Linear Regression before implementing it using TensorFlow. Since we will not get into the details of either Linear Regression or Tensorflow, please read the following articles for more details: Linear Regression (Python Implementation)Introduction to TensorFlowIntroduction



6 min read

Hyperparameter tuning
Hyperparameter tuning
                    
Machine Learning model is defined as a mathematical model with several parameters that need to be learned from the data. By training a model with existing data we can fit the model parameters. However there is another kind of parameter known as hyperparameters which cannot be directly learned from t



8 min read

Introduction to Convolution Neural Network
Introduction to Convolution Neural Network
                    
A Convolutional Neural Network (CNN) is a type of Deep Learning neural network architecture commonly used in Computer Vision. Computer vision is a field of Artificial Intelligence that enables a computer to understand and interpret the image or visual data. When it comes to Machine Learning, Artific



10 min read


Digital Image Processing Basics
                    
Digital Image Processing means processing digital image by means of a digital computer. We can also say that it is a use of computer algorithms, in order to get enhanced image either to extract some useful information. Digital image processing is the use of algorithms and mathematical models to proc



7 min read


Difference between Image Processing and Computer Vision
                    
Image processing and Computer Vision both are very exciting field of Computer Science. Computer Vision: In Computer Vision, computers or machines are made to gain high-level understanding from the input digital images or videos with the purpose of automating tasks that the human visual system can do



2 min read


CNN | Introduction to Pooling Layer
                    
Pooling layer is used in CNNs to reduce the spatial dimensions (width and height) of the input feature maps while retaining the most important information. It involves sliding a two-dimensional filter over each channel of a feature map and summarizing the features within the region covered by the fi



5 min read


CIFAR-10 Image Classification in TensorFlow
                    
Prerequisites:Image ClassificationConvolution Neural Networks including basic pooling, convolution layers with normalization in neural networks, and dropout.Data Augmentation.Neural Networks.Numpy arrays.In this article, we are going to discuss how to classify images using TensorFlow. Image Classifi



8 min read


Implementation of a CNN based Image Classifier using PyTorch
                    
Introduction: Introduced in the 1980s by Yann LeCun, Convolution Neural Networks(also called CNNs or ConvNets) have come a long way. From being employed for simple digit classification tasks, CNN-based architectures are being used very profoundly over much Deep Learning and Computer Vision-related t



9 min read


Convolutional Neural Network (CNN) Architectures
                    
Convolutional Neural Network(CNN) is a neural network architecture in Deep Learning, used to recognize the pattern from structured arrays. However, over many years, CNN architectures have evolved. Many variants of the fundamental CNN Architecture This been developed, leading to amazing advances in t



11 min read


Object Detection  vs Object Recognition vs Image Segmentation
                    
Object Recognition: Object recognition is the technique of identifying the object present in images and videos. It is one of the most important applications of machine learning and deep learning. The goal of this field is to teach machines to understand (recognize) the content of an image just like



5 min read


YOLO v2 - Object Detection
                    
In terms of speed, YOLO is one of the best models in object recognition, able to recognize objects and process frames at the rate up to 150 FPS for small networks. However, In terms of accuracy mAP, YOLO was not the state of the art model but has fairly good Mean average Precision (mAP) of 63% when



6 min read

Recurrent Neural Network
Natural Language Processing (NLP) Tutorial
                    
Natural Language Processing (NLP) is the branch of Artificial Intelligence (AI) that gives the ability to machine understand and process human languages. Human languages can be in the form of text or audio format. Applications of NLPThe applications of Natural Language Processing are as follows: Voi



5 min read


Introduction to NLTK: Tokenization, Stemming, Lemmatization, POS Tagging
                    
Natural Language Toolkit (NLTK) is one of the largest Python libraries for performing various Natural Language Processing tasks. From rudimentary tasks such as text pre-processing to tasks like vectorized representation of text - NLTK's API has covered everything. In this article, we will accustom o



5 min read


Word Embeddings in NLP
                    
Word Embeddings are numeric representations of words in a lower-dimensional space, capturing semantic and syntactic information. They play a vital role in Natural Language Processing (NLP) tasks. This article explores traditional and neural approaches, such as TF-IDF, Word2Vec, and GloVe, offering i



15+ min read


Introduction to Recurrent Neural Networks
                    
Recurrent Neural Networks (RNNs) work a bit different from regular neural networks. In neural network the information flows in one direction from input to output. However in RNN information is fed back into the system after each step. Think of it like reading a sentence, when you're trying to predic



12 min read


Recurrent Neural Networks Explanation
                    
Today, different Machine Learning techniques are used to handle different types of data. One of the most difficult types of data to handle and the forecast is sequential data. Sequential data is different from other types of data in the sense that while all the features of a typical dataset can be a



8 min read


Sentiment Analysis with an Recurrent Neural Networks (RNN)
                    
Recurrent Neural Networks (RNNs) excel in sequence tasks such as sentiment analysis due to their ability to capture context from sequential data. In this article we will be apply RNNs to analyze the sentiment of customer reviews from Swiggy food delivery platform. The goal is to classify reviews as



3 min read


Short term Memory
                    
In the wider community of neurologists and those who are researching the brain, It is agreed that two temporarily distinct processes contribute to the acquisition and expression of brain functions. These variations can result in long-lasting alterations in neuron operations, for instance through act



5 min read


What is LSTM - Long Short Term Memory?
                    
Long Short-Term Memory (LSTM) is an enhanced version of the Recurrent Neural Network (RNN) designed by Hochreiter & Schmidhuber. LSTMs can capture long-term dependencies in sequential data making them ideal for tasks like language translation, speech recognition and time series forecasting. Unli



8 min read


Long Short Term Memory Networks Explanation
                    
Prerequisites: Recurrent Neural Networks To solve the problem of Vanishing and Exploding Gradients in a Deep Recurrent Neural Network, many variations were developed. One of the most famous of them is the Long Short Term Memory Network(LSTM). In concept, an LSTM recurrent unit tries to ""remember"" al



7 min read


LSTM - Derivation of Back propagation through time
                    
Long Short-Term Memory (LSTM) are a type of neural network designed to handle long-term dependencies by handling the vanishing gradient problem. One of the fundamental techniques used to train LSTMs is Backpropagation Through Time (BPTT) where we have sequential data. In this article we summarize ho



4 min read


Text Generation using Recurrent Long Short Term Memory Network
                    
LSTMs are a type of neural network that are well-suited for tasks involving sequential data such as text generation. They are particularly useful because they can remember long-term dependencies in the data which is crucial when dealing with text that often has context that spans over multiple words



6 min read








Like





















 
























































































Corporate & Communications Address:

                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    





Registered Address:
                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      

























Advertise with us



CompanyAbout UsLegalPrivacy PolicyIn MediaContact UsAdvertise with usGFG Corporate SolutionPlacement Training ProgramGeeksforGeeks CommunityLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialTutorials ArchiveDSAData StructuresAlgorithmsDSA for BeginnersBasic DSA ProblemsDSA RoadmapTop 100 DSA Interview ProblemsDSA Roadmap by Sandeep JainAll Cheat SheetsData Science & MLData Science With PythonData Science For BeginnerMachine LearningML MathsData VisualisationPandasNumPyNLPDeep LearningWeb TechnologiesHTMLCSSJavaScriptTypeScriptReactJSNextJSBootstrapWeb DesignPython TutorialPython Programming ExamplesPython ProjectsPython TkinterWeb ScrapingOpenCV TutorialPython Interview QuestionDjangoComputer ScienceOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsSoftware DevelopmentSoftware TestingDevOpsGitLinuxAWSDockerKubernetesAzureGCPDevOps RoadmapSystem DesignHigh Level DesignLow Level DesignUML DiagramsInterview GuideDesign PatternsOOADSystem Design BootcampInterview QuestionsInteview PreparationCompetitive ProgrammingTop DS or Algo for CPCompany-Wise Recruitment ProcessCompany-Wise PreparationAptitude PreparationPuzzlesSchool SubjectsMathematicsPhysicsChemistryBiologySocial ScienceEnglish GrammarCommerceWorld GKGeeksforGeeks VideosDSAPythonJavaC++Web DevelopmentData ScienceCS Subjects 

 





@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved










        We use cookies to ensure you have the best browsing experience on our website. By using our site, you
        acknowledge that you have read and understood our
        Cookie Policy &
        Privacy Policy


        Got It !
    














Improvement







Suggest changes





Suggest Changes
Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.







Create Improvement
Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.















Suggest Changes






min 4 words, max Words Limit:1000




Thank You!
Your suggestions are valuable to us.






























What kind of Experience do you want to share?









Interview Experiences







Admission Experiences







Career Journeys







Work Experiences







Campus Experiences







Competitive Exam Experiences














"
9,https://arxiv.org/pdf/1611.01673,"Published as a conference paper at ICLR 2017
GENERATIVE MULTI -ADVERSARIAL NETWORKS
Ishan Durugkar∗, Ian Gemp∗, Sridhar Mahadevan
College of Information and Computer Sciences
University of Massachusetts, Amherst
Amherst, MA 01060, USA
{idurugkar,imgemp,mahadeva }@cs.umass.edu
ABSTRACT
Generative adversarial networks (GANs) are a framework for producing a gen-
erative model by way of a two-player minimax game. In this paper, we propose
theGenerative Multi-Adversarial Network (GMAN), a framework that extends
GANs to multiple discriminators. In previous work, the successful training of
GANs requires modifying the minimax objective to accelerate training early on.
In contrast, GMAN can be reliably trained with the original, untampered objec-
tive. We explore a number of design perspectives with the discriminator role rang-
ing from formidable adversary to forgiving teacher. Image generation tasks com-
paring the proposed framework to standard GANs demonstrate GMAN produces
higher quality samples in a fraction of the iterations when measured by a pairwise
GAM-type metric.
1 I NTRODUCTION
Generative adversarial networks (Goodfellow et al. (2014)) (GANs) are a framework for producing
a generative model by way of a two-player minimax game. One player, the generator, attempts to
generate realistic data samples by transforming noisy samples, z, drawn from a simple distribution
(e.g.,z∼N (0,1)) using a transformation function Gθ(z)with learned weights, θ. The generator
receives feedback as to how realistic its synthetic sample is from another player, the discriminator,
which attempts to discern between synthetic data samples produced by the generator and samples
drawn from an actual dataset using a function Dω(x)with learned weights, ω.
The GAN framework is one of the more recent successes in a line of research on adversarial train-
ing in machine learning (Schmidhuber (1992); Bagnell (2005); Ajakan et al. (2014)) where games
between learners are carefully crafted so that Nash equilibria coincide with some set of desired op-
timality criteria. Preliminary work on GANs focused on generating images (e.g., MNIST (LeCun
et al. (1998)), CIFAR (Krizhevsky (2009))), however, GANs have proven useful in a variety of appli-
cation domains including learning censored representations (Edwards & Storkey (2015)), imitating
expert policies (Ho & Ermon (2016)), and domain transfer (Yoo et al. (2016)). Work extending
GANs to semi-supervised learning (Chen et al. (2016); Mirza & Osindero (2014); Gauthier (2014);
Springenberg (2015)), inference (Makhzani et al. (2015); Dumoulin et al. (2016)), feature learning
(Donahue et al. (2016)), and improved image generation (Im et al. (2016); Denton et al. (2015);
Radford et al. (2015)) have shown promise as well.
Despite these successes, GANs are reputably difﬁcult to train. While research is still underway to
improve training techniques and heuristics (Salimans et al. (2016)), most approaches have focused
on understanding and generalizing GANs theoretically with the aim of exploring more tractable
formulations (Zhao et al. (2016); Li et al. (2015); Uehara et al. (2016); Nowozin et al. (2016)).
In this paper, we theoretically and empirically justify generalizing the GAN framework to multiple
discriminators. We review GANs and summarize our extension in Section 2. In Sections 3 and 4,
we present our N-discriminator extension to the GAN framework ( Generative Multi-Adversarial
Networks ) with several variants which range the role of the discriminator from formidable adversary
to forgiving teacher. Section 4.2 explains how this extension makes training with the untampered
minimax objective tractable. In Section 5, we deﬁne an intuitive metric (GMAM) to quantify GMAN
∗Equal contribution
1
arXiv:1611.01673v3  [cs.LG]  2 Mar 2017Published as a conference paper at ICLR 2017
performance and evaluate our framework on a variety of image generation tasks. Section 6 concludes
with a summary of our contributions and directions for future research.
Contributions —To summarize, our main contributions are: i) a multi-discriminator GAN frame-
work, GMAN, that allows training with the original, untampered minimax objective; ii) a generative
multi-adversarial metric (GMAM) to perform pairwise evaluation of separately trained frameworks;
iii) a particular instance of GMAN, GMAN∗, that allows the generator to automatically regulate
training and reach higher performance (as measured by GMAM) in a fraction of the training time
required for the standard GAN model.
2 G ENERATIVE ADVERSARIAL NETWORKS TO GMAN
The original formulation of a GAN is a minimax game between a generator, Gθ(z) :z→x, and a
discriminator, Dω(x) :x→[0,1],
min
Gmax
D∈DV(D,G ) =Ex∼pdata(x)/bracketleftBig
log(D(x))/bracketrightBig
+Ez∼pz(z)/bracketleftBig
log(1−D(G(z)))/bracketrightBig
, (1)
wherepdata(x)is the true data distribution and pz(z)is a simple (usually ﬁxed) distribution that is
easy to draw samples from (e.g., N(0,1)). We differentiate between the function space of discrim-
inators,D, and elements of this space, D. LetpG(x)be the distribution induced by the generator,
Gθ(z). We assume D,G to be deep neural networks as is typically the case.
In their original work, Goodfellow et al. (2014) proved that given sufﬁcient network capacities
and an oracle providing the optimal discriminator, D∗=argmaxDV(D,G ), gradient descent on
pG(x)will recover the desired globally optimal solution, pG(x) =pdata(x), so that the generator
distribution exactly matches the data distribution. In practice, they replaced the second term, log(1−
D(G(z))), with−log(D(G(z)))to enhance gradient signals at the start of the game; note this is no
longer a zero-sum game. Part of their convergence and optimality proof involves using the oracle,
D∗, to reduce the minimax game to a minimization over Gonly:
min
GV(D∗,G) = min
G/braceleftBig
C(G) =−log(4) + 2·JSD (pdata||pG)/bracerightBig
(2)
whereJSD denotes Jensen-Shannon divergence. Minimizing C(G)necessarily minimizes JSD ,
however, we rarely know D∗and so we instead minimize V(D,G ), which is only a lower bound.
This perspective of minimizing the distance between the distributions, pdata andpG, motivated
Li et al. (2015) to develop a generative model that matches all moments of pG(x)withpdata(x)(at
optimality) by minimizing maximum mean discrepancy (MMD). Another approach, EBGAN, (Zhao
et al. (2016)) explores a larger class of games (non-zero-sum games) which generalize the generator
and discriminator objectives to take real-valued “energies” as input instead of probabilities. Nowozin
et al. (2016) and then Uehara et al. (2016) extended the JSD perspective on GANs to more general
divergences, speciﬁcally f-divergences and then Bregman-divergences respectively.
In general, these approaches focus on exploring fundamental reformulations of V(D,G ). Similarly,
our work focuses on a fundamental reformulation, however, our aim is to provide a framework that
accelerates training of the generator to a more robust state irrespective of the choice of V.
2.1 GMAN: A M ULTI -ADVERSARIAL EXTENSION
We propose introducing multiple discriminators, which brings with it a number of design possibil-
ities. We explore approaches ranging between two extremes: 1) a more discriminating D(better
approximating maxDV(D,G )) and 2) aDbetter matched to the generator’s capabilities. Math-
ematically, we reformulate G’s objective as minGmaxF(V(D1,G),...,V (DN,G))for different
choices ofF(see Figure 1). Each Diis still expected to independently maximize its own V(Di,G)
(i.e. no cooperation). We sometimes abbreviate V(Di,G)withViandF(V1,...,VN)withFG(Vi).
3 A F ORMIDABLE ADVERSARY
Here, we consider multi-discriminator variants that attempt to better approximate maxDV(D,G ),
providing a harsher critic to the generator.
2Published as a conference paper at ICLR 2017
G 
DN D2 D1 V(DN,G) V(D2,G) V(D1,G) F( · ) 
Figure 1: (GMAN) The generator trains using feedback aggregated over multiple discriminators. If
F:= max ,Gtrains against the best discriminator. If F:=mean ,Gtrains against an ensemble.
We explore other alternatives to Fin Sections 4.1 & 4.4 that improve on both these options.
3.1 M AXIMIZING V(D,G)
For a ﬁxedG, maximizing FG(Vi)withF:= max andNrandomly instantiated copies of our dis-
criminator is functionally equivalent to optimizing V(e.g., stochastic gradient ascent) with random
restarts in parallel and then presenting maxi∈{1,...,N}V(Di,G)as the loss to the generator —a very
pragmatic approach to the difﬁculties presented by the non-convexity of Vcaused by the deep net.
Requiring the generator to minimize the max forcesGto generate high ﬁdelity samples that must
hold up under the scrutiny of all Ndiscriminators, each potentially representing a distinct max.
In practice, maxDi∈DV(Di,G)is not performed to convergence (or global optimality), so the
above problem is oversimpliﬁed. Furthermore, introducing Ndiscriminators affects the dynam-
ics of the game which affects the trajectories of the discriminators. This prevents us from claiming
max{V1(t),...,VN(t)}>max{V/prime
1(t)}∀teven if we initalize D1(0) =D/prime
1(0)as it is unlikely that
D1(t) =D/prime
1(t)at some time tafter the start of the game.
3.2 B OOSTING
We can also consider taking the max overNdiscriminators as a form of boosting for the discrim-
inator’s online classiﬁcation problem (online because Gcan produce an inﬁnite data stream). The
boosted discriminator is given a sample xtand must predict whether it came from the generator or
the dataset. The booster then makes its prediction using the predictions of the NweakerDi.
There are a few differences between taking the max (case 1) and online boosting (case 2). In case 1,
our booster is limited to selecting a single weak discriminator (i.e. a pure strategy), while in case 2,
many boosting algorithms more generally use linear combinations of the discriminators. Moreover,
in case 2, a booster must make a prediction before receiving a loss function. In case 1, we assume
access to the loss function at prediction time, which allows us to compute the max.
It is possible to train the weak discriminators using boosting and then ignore the booster’s prediction
by instead presenting max{Vi}. We explore both variants in our experiments, using the adaptive al-
gorithm proposed in Beygelzimer et al. (2015). Unfortunately, boosting failed to produce promising
results on the image generation tasks. It is possible that boosting produces too strong an adversary
for learning which motivates the next section. Boosting results appear in Appendix A.7.
4 A F ORGIVING TEACHER
The previous perspectives focus on improving the discriminator with the goal of presenting a better
approximation of maxDV(D,G )to the generator. Our next perspective asks the question, “Is
maxDV(D,G )too harsh a critic?”
4.1 Soft-DISCRIMINATOR
In practice, training against a far superior discriminator can impede the generator’s learning. This
is because the generator is unlikely to generate any samples considered “realistic” by the discrimi-
nator’s standards, and so the generator will receive uniformly negative feedback. This is problem-
3Published as a conference paper at ICLR 2017
atic because the information contained in the gradient derived from negative feedback only dictates
where to drive down pG(x), not speciﬁcally where to increase pG(x). Furthermore, driving down
pG(x)necessarily increases pG(x)in other regions of X(to maintain/integraltext
XpG(x) = 1 ) which may or
may not contain samples from the true dataset ( whack-a-mole dilemma). In contrast, a generator is
more likely to see positive feedback against a more lenient discriminator, which may better guide a
generator towards amassing pG(x)in approximately correct regions of X.
For this reason, we explore a variety of functions that allow us to soften themax operator. We
choose to focus on soft versions of the three classical Pythagorean means parameterized by λwhere
λ= 0corresponds to the mean and the max is recovered as λ→∞ :
AMsoft(V,λ) =N/summationdisplay
iwiVi (3)
GMsoft(V,λ) =−exp/parenleftBigN/summationdisplay
iwilog(−Vi)/parenrightBig
(4)
HMsoft(V,λ) =/parenleftBigN/summationdisplay
iwiV−1
i/parenrightBig−1
(5)
wherewi=eλVi/ΣjeλVjwithλ≥0,Vi<0. Using a softmax also has the well known advantage of
being differentiable (as opposed to subdifferentiable for max). Note that we only require continuity
to guarantee that computing the softmax is actually equivalent to computing V(˜D,G )where ˜Dis
some convex combination of Di(see Appendix A.5).
4.2 U SING THE ORIGINAL MINIMAX OBJECTIVE
To illustrate the effect the softmax has on training, observe that the component of AMsoft(V,0)
relevant to generator training can be rewritten as
1
NN/summationdisplay
iEx∼pG(x)/bracketleftBig
log(1−Di(x))/bracketrightBig
=1
NEx∼pG(x)/bracketleftBig
log(z)/bracketrightBig
. (6)
wherez=/producttextN
i(1−Di(x)). Note that the generator gradient, |∂log(z)
∂z|, is minimized at z= 1over
z∈(0,1]1. From this form, it is clear that z= 1 if and only if Di= 0∀i, soGonly receives a
vanishing gradient if all Diagree that the sample is fake; this is especially unlikely for large N. In
other words, Gonly needs to fool a single Dito receive constructive feedback. This result allows the
generator to successfully minimize the original generator objective, log(1−D). This is in contrast
to the more popular −log(D)introduced to artiﬁcially enhance gradients at the start of training.
At the beginning of training, when maxDiV(Di,G)is likely too harsh a critic for the generator, we
can setλcloser to zero to use the mean, increasing the odds of providing constructive feedback to
the generator. In addition, the discriminators have the added beneﬁt of functioning as an ensemble,
reducing the variance of the feedback presented to the generator, which is especially important
when the discriminators are far from optimal and are still learning a reasonable decision boundary.
As training progresses and the discriminators improve, we can increase λto become more critical
of the generator for more reﬁned training.
4.3 M AINTAINING MULTIPLE HYPOTHESES
We argue for this ensemble approach on a more fundamental level as well. Here, we draw on
the density ratio estimation perspective of GANs (Uehara et al. (2016)). The original GAN proof
assumes we have access to pdata(x), if only implicitly. In most cases of interest, the discriminator
only has access to a ﬁnite dataset sampled from pdata(x); therefore, when computing expectations
ofV(D,G ), we only draw samples from our ﬁnite dataset. This is equivalent to training a GAN
withpdata(x) = ˜pdatawhich is a distribution consisting of point masses on all the data points in the
dataset. For the sake of argument, let’s assume we are training a discriminator and generator, each
1∇GV=−/summationtext
iDi
z∂Di
∂G/producttext
j/negationslash=i(1−Dj) =−1
z∂Dk
∂GforDk= 1,D/negationslash=k= 0. Our argument ignores∂Dk
∂G.
4Published as a conference paper at ICLR 2017
with inﬁnite capacity. In this case, the global optimum ( pG(x) = ˜pdata(x)) fails to capture any of
the interesting structure from pdata(x), the true distribution we are trying to learn. Therefore, it is
actually critical that we avoid this global optimum.
x p(x) 
Figure 2: Consider a dataset consisting of the nine 1-dimensional samples in black. Their corre-
sponding probability mass function is given in light gray. After training GMAN, three discrimina-
tors converge to distinct local optima which implicitly deﬁne distributions over the data (red, blue,
yellow). Each discriminator may specialize in discriminating a region of the data space (placing
more diffuse mass in other regions). Averaging over the three discriminators results in the distribu-
tion in black, which we expect has higher likelihood under reasonable assumptions on the structure
of the true distribution.
In practice, this degenerate result is avoided by employing learners with limited capacity and corrupt-
ing data samples with noise (i.e., dropout), but we might better accomplish this by simultaneously
training a variety of limited capacity discriminators. With this approach, we might obtain a diverse
set of seemingly tenable hypotheses for the true pdata(x). Averaging over these multiple locally
optimal discriminators increases the entropy of ˜pdata(x)by diffusing the probability mass over the
data space (see Figure 2 for an example).
4.4 A UTOMATING REGULATION
The problem of keeping the discriminator and generator in balance has been widely recognized in
previous work with GANs. Issues with unstable dynamics, oscillatory behavior, and generator col-
lapse are not uncommon. In addition, the discriminator is often times able to achieve a high degree of
classiﬁcation accuracy (producing a single scalar) before the generator has made sufﬁcient progress
on the arguably more difﬁcult generative task (producing a high dimensional sample). Salimans
et al. (2016) suggested label smoothing to reduce the vulnerability of the generator to a relatively
superior discriminator. Here, we explore an approach that enables the generator to automatically
temper the performance of the discriminator when necessary, but still encourages the generator to
challenge itself against more accurate adversaries. Speciﬁcally, we augment the generator objective:
min
G,λ> 0FG(Vi)−f(λ) (7)
wheref(λ)is monotonically increasing in λwhich appears in the softmax equations, (3)—(5). In
experiments, we simply set f(λ) =cλwithca constant (e.g., 0.001). The generator is incentivized
to increaseλto reduce its objective at the expense of competing against the best available adversary
D∗(see Appendix A.6).
5 E VALUATION
Evaluating GANs is still an open problem. In their original work, Goodfellow et al. (2014) report
log likelihood estimates from Gaussian Parzen windows, which they admit, has high variance and
is known not to perform well in high dimensions. Theis et al. (2016) recommend avoiding Parzen
windows and argue that generative models should be evaluated with respect to their intended appli-
cation. Salimans et al. (2016) suggest an Inception score , however, it assumes labels exist for the
dataset. Recently, Im et al. (2016) introduced the Generative Adversarial Metric (GAM) for mak-
ing pairwise comparisons between independently trained GAN models. The core idea behind their
approach is given two generator, discriminator pairs ( G1,D1) and (G2,D2), we should be able to
learn their relative performance by judging each generator under the opponent’s discriminator.
5Published as a conference paper at ICLR 2017
5.1 M ETRIC
In GMAN, the opponent may have multiple discriminators, which makes it unclear how to perform
the swaps needed for GAM. We introduce a variant of GAM, the generative multi-adversarial metric
(GMAM), that is amenable to training with multiple discriminators,
GMAM = log/parenleftBigFa
Gb(Va
i)
Fa
Ga(Va
i)/slashBigFa
Ga(Vb
i)
Fb
Gb(Vb
i)/parenrightBig
. (8)
whereaandbrefer to the two GMAN variants (see Section 3 for notation FG(Vi)). The idea here is
similar. IfG2performs better than G1with respect to both D1andD2, then GMAM >0 (remember
V≤0always). IfG1performs better in both cases, GMAM <0, otherwise, the result is indeterminate.
5.2 E XPERIMENTS
We evaluate the aforementioned variations of GMAN on a variety of image generation tasks: MNIST
(LeCun et al. (1998)), CIFAR-10 (Krizhevsky (2009)) and CelebA (Liu et al. (2015)). We focus on
rates of convergence to steady state along with quality of the steady state generator according to the
GMAM metric. To summarize, loosely in order of increasing discriminator leniency, we compare
•F-boost: A single AdaBoost.OL -boosted discriminator (see Appendix A.7).
•P-boost:Diis trained according to AdaBoost.OL . Amax over the weak learner losses is
presented to the generator instead of the boosted prediction (see Appendix A.7).
•GMAN- max:max{Vi}is presented to the generator.
•GAN: Standard GAN with a single discriminator (see Appendix A.2).
•mod-GAN: GAN with modiﬁed objective (generator minimizes −log(D(G(z))).
•GMAN-λ: GMAN with F:=arithmetic softmax with parameter λ.
•GMAN∗: The arithmetic softmax is controlled by the generator through λ.
All generator and discriminator models are deep (de)convolutional networks (Radford et al. (2015)),
and aside from the boosted variants, all are trained with Adam (Kingma & Ba (2014)) and batch
normalization (Ioffe & Szegedy (2015)). Discriminators convert the real-valued outputs of their
networks to probabilities with squashed -sigmoids to prevent saturating logarithms in the minimax
objective (/epsilon1+1−2/epsilon1
1+e−z). See Appendix A.8 for further details. We test GMAN systems with N=
{2,5}discriminators. We maintain discriminator diversity by varying dropout and network depth.
5.2.1 MNIST
Figure 3 reveals that increasing the number of discriminators reduces the number of iterations to
steady-state by 2x on MNIST; increasing N(the size of the discriminator ensemble) also has the
added beneﬁt of reducing the variance the minimax objective over runs. Figure 4 displays the vari-
ance of the same objective over a sliding time window, reafﬁrming GMAN’s acceleration to steady-
state. Figure 5 corroborates this conclusion with recognizable digits appearing approximately an
epoch before the single discriminator run; digits at steady-state appear slightly sharper as well.
Our GMAM metric (see Table 1) agrees with the relative quality of images in Figure 5 with GMAN∗
achieving the best overall performance. Figure 6 reveals GMAN∗’s attempt to regulate the difﬁculty
Score Variant GMAN∗GMAN-0 GMAN- max mod-GANBetter→0.127 GMAN∗-−0.020±0.009−0.028±0.019−0.089±0.036
0.007 GMAN-0 0.020±0.009 -−0.013±0.015−0.018±0.027
−0.034 GMAN- max 0.028±0.019 0.013±0.015 -−0.011±0.024
−0.122 mod-GAN 0.089±0.036 0.018±0.027 0.011±0.024 -
Table 1: Pairwise GMAM metric means with stdev for select models on MNIST. For each column, a
positive GMAM indicates better performance relative to the row opponent; negative implies worse.
Scores are obtained by summing each variant’s column.
6Published as a conference paper at ICLR 2017
Figure 3: Generator objective, F, averaged
over 5 training runs on MNIST. Increas-
ing the number of discriminators accelerates
convergence of Fto steady state (solid line)
and reduces its variance, σ2(ﬁlled shadow
±1σ). Figure 4 provides alternative evidence
of GMAN∗’s accelerated convergence.
Figure 4: Stdev ,σ, of the generator objec-
tive over a sliding window of 500 iterations.
Lower values indicate a more steady-state.
GMAN∗withN= 5 achieves steady-state
at≈2x speed of GAN ( N= 1). Note Fig-
ure 3’s ﬁlled shadows reveal stdev ofFover
runs, while this plot shows stdev over time.
Figure 5: Comparison of image quality across epochs for N={1,2,5}using GMAN-0 on MNIST.
of the game to accelerate learning. Figure 7 displays the GMAM scores comparing ﬁxed λ’s to the
variableλcontrolled by GMAN∗.
Figure 6: GMAN∗regulates difﬁculty of the
game by adjusting λ. Initially,Greducesλto
ease learning and then gradually increases λ
for a more challenging learning environment.Scoreλλ∗λ= 1λ= 0(N= 5)Better→0.028λ∗ -−0.008
±0.009−0.019
±0.010
0.001λ= 10.008
±0.009-−0.008
±0.010
−0.025λ= 00.019
±0.0100.008
±0.010-
Figure 7: PairwiseGMAM
stdev (GMAM)for GMAN-λand
GMAN∗(λ∗) over 5 runs on MNIST.
7Published as a conference paper at ICLR 2017
5.2.2 C ELEB A & CIFAR-10
We see similar accelerated convergence behavior for the CelebA dataset in Figure 8.
Figure 8: Image quality improvement across number of generators at same number of iterations for
GMAN-0 on CelebA.
Figure 9 displays images generated by GMAN-0 on CIFAR-10. See Appendix A.3 for more results.
Figure 9: Images generated by GMAN-0 on the CIFAR-10 dataset.
We also found that GMAN is robust to mode collapse . We believe this is because the generator
must appease a diverse set of discriminators in each minibatch. Emitting a single sample will score
well for one discriminator at the expense of the rest of the discriminators. Current solutions (e.g.,
minibatch discrimination) are quadratic in batch size. GMAN, however, is linear in batch size.
6 C ONCLUSION
We introduced multiple discriminators into the GAN framework and explored discriminator roles
ranging from a formidable adversary to a forgiving teacher. Allowing the generator to automatically
tune its learning schedule (GMAN∗) outperformed GANs with a single discriminator on MNIST. In
general, GMAN variants achieved faster convergence to a higher quality steady state on a variety of
tasks as measured by a GAM-type metric (GMAM). In addition, GMAN makes using the original
GAN objective possible by increasing the odds of the generator receiving constructive feedback.
In future work, we will look at more sophisticated mechanisms for letting the generator control
the game as well as other ways to ensure diversity among the discriminators. Introducing multiple
generators is conceptually an obvious next step, however, we expect difﬁculties to arise from more
complex game dynamics. For this reason, game theory and game design will likely be important.
ACKNOWLEDGMENTS
We acknowledge helpful conversations with Stefan Dernbach, Archan Ray, Luke Vilnis, Ben Turtel,
Stephen Giguere, Rajarshi Das, and Subhransu Maji. We also thank NVIDIA for donating a K40
GPU. This material is based upon work supported by the National Science Foundation under Grant
Nos. IIS-1564032. Any opinions, ﬁndings, and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reﬂect the views of the NSF.
8Published as a conference paper at ICLR 2017
BIBLIOGRAPHY
Martın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S
Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al. Tensorﬂow: Large-scale machine
learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467 , 2016.
Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc ¸ois Laviolette, and Mario Marchand.
Domain-adversarial neural networks. arXiv preprint arXiv:1412.4446 , 2014.
J Andrew Bagnell. Robust supervised learning. In Proceedings Of The National Conference On
Artiﬁcial Intelligence , volume 20, pp. 714. Menlo Park, CA; Cambridge, MA; London; AAAI
Press; MIT Press; 1999, 2005.
Alina Beygelzimer, Satyen Kale, and Haipeng Luo. Optimal and adaptive algorithms for online
boosting. arXiv preprint arXiv:1502.02651 , 2015.
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Info-
gan: Interpretable representation learning by information maximizing generative adversarial nets.
arXiv preprint arXiv:1606.03657 , 2016.
Emily L Denton, Soumith Chintala, Rob Fergus, et al. Deep generative image models using a
laplacian pyramid of adversarial networks. In Advances in neural information processing systems ,
pp. 1486–1494, 2015.
Jeff Donahue, Philipp Kr ¨ahenb ¨uhl, and Trevor Darrell. Adversarial feature learning. arXiv preprint
arXiv:1605.09782 , 2016.
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropi-
etro, and Aaron Courville. Adversarially learned inference. arXiv preprint arXiv:1606.00704 ,
2016.
Harrison Edwards and Amos Storkey. Censoring representations with an adversary. arXiv preprint
arXiv:1511.05897 , 2015.
Jon Gauthier. Conditional generative adversarial nets for convolutional face generation. Class
Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter
semester , 2014, 2014.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Infor-
mation Processing Systems , pp. 2672–2680, 2014.
Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning. arXiv preprint
arXiv:1606.03476 , 2016.
Daniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang, and Roland Memisevic. Generating images
with recurrent adversarial networks. arXiv preprint arXiv:1602.05110 , 2016.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167 , 2015.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Master’s Thesis , 2009.
Yann LeCun, Corinna Cortes, and Christopher JC Burges. The mnist database of handwritten digits,
1998.
Yujia Li, Kevin Swersky, and Richard Zemel. Generative moment matching networks. In Interna-
tional Conference on Machine Learning , pp. 1718–1727, 2015.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.
InProceedings of International Conference on Computer Vision (ICCV) , December 2015.
9Published as a conference paper at ICLR 2017
Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian Goodfellow. Adversarial autoencoders.
arXiv preprint arXiv:1511.05644 , 2015.
Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint
arXiv:1411.1784 , 2014.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. arXiv preprint arXiv:1606.00709 , 2016.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 , 2015.
Siamak Ravanbakhsh, Francois Lanusse, Rachel Mandelbaum, Jeff Schneider, and Barnabas Poczos.
Enabling dark energy science with deep generative models of galaxy images. arXiv preprint
arXiv:1609.05796 , 2016.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. arXiv preprint arXiv:1606.03498 , 2016.
J¨urgen Schmidhuber. Learning factorial codes by predictability minimization. Neural Computation ,
4(6):863–879, 1992.
Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative
adversarial networks. arXiv preprint arXiv:1511.06390 , 2015.
Lucas Theis, A ¨aron van den Oord, and Matthias Bethge. A note on the evaluation of generative
models. arXiv preprint arXiv:1511.01844v3 , 2016.
Masatoshi Uehara, Issei Sato, Masahiro Suzuki, Kotaro Nakayama, and Yutaka Matsuo. Generative
adversarial nets from a density ratio estimation perspective. arXiv preprint arXiv:1610.02920 ,
2016.
Donggeun Yoo, Namil Kim, Sunggyun Park, Anthony S Paek, and In So Kweon. Pixel-level domain
transfer. arXiv preprint arXiv:1603.07442 , 2016.
Matthew D Zeiler, Dilip Krishnan, Graham W Taylor, and Rob Fergus. Deconvolutional networks.
InComputer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on , pp. 2528–2535.
IEEE, 2010.
Junbo Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network.
arXiv preprint arXiv:1609.03126 , 2016.
10Published as a conference paper at ICLR 2017
A A PPENDIX
A.1 A CCELERATED CONVERGENCE & R EDUCED VARIANCE
See Figures 10, 11, 12, and 13.
Figure 10: Generator objective, F, averaged
over 5 training runs on CelebA. Increasing
N(# ofD) accelerates convergence of Fto
steady state (solid line) and reduces its vari-
ance,σ2(ﬁlled shadow±1σ). Figure 11 pro-
vides alternative evidence of GMAN-0’s ac-
celerated convergence.
Figure 11: Stdev ,σ, of the generator objec-
tive over a sliding window of 500 iterations.
Lower values indicate a more steady-state.
GMAN-0 with N= 5 achieves steady-state
at≈2x speed of GAN ( N= 1). Note Fig-
ure 10’s ﬁlled shadows reveal stdev ofFover
runs, while this plot shows stdev over time.
Figure 12: Generator objective, F, averaged
over 5 training runs on CIFAR-10. Increas-
ingN(# ofD) accelerates convergence of
Fto steady state (solid line) and reduces its
variance,σ2(ﬁlled shadow±1σ). Figure 13
provides alternative evidence of GMAN-0’s
accelerated convergence.
Figure 13: Stdev ,σ, of the generator objec-
tive over a sliding window of 500 iterations.
Lower values indicate a more steady-state.
GMAN-0 with N= 5 achieves steady-state
at≈2x speed of GAN ( N= 1). Note Fig-
ure 12’s ﬁlled shadows reveal stdev ofFover
runs, while this plot shows stdev over time.
A.2 A DDITIONAL GMAM T ABLES
See Tables 2, 3, 4, 5, 6. Increasing the number of discriminators from 2 to 5 on CIFAR-10 signif-
icantly improves scores over the standard GAN both in terms of the GMAM metric and Inception
scores.
A.3 G ENERATED IMAGES
See Figures 14 and 15.
11Published as a conference paper at ICLR 2017
Score Variant GMAN∗GMAN-1 GAN GMAN-0 GMAN- max mod-GANBetter→0.184 GMAN∗-−0.007−0.040−0.020−0.028−0.089
0.067 GMAN-1 0.007 -−0.008−0.008−0.021−0.037
0.030 GAN 0.040 0.008 - 0.002−0.018−0.058
0.005 GMAN-0 0.020 0.008 0.002 -−0.013−0.018
−0.091 GMAN- max 0.028 0.021 0.018 0.013 -−0.011
−0.213 mod-GAN 0.089 0.037 0.058 0.018 0.011 -
Table 2: Pairwise GMAM metric means for select models on MNIST. For each column, a positive
GMAM indicates better performance relative to the row opponent; negative implies worse. Scores
are obtained by summing each column.
Score Variant GMAN-0 GMAN-1 GMAN∗mod-GANBetter→0.172 GMAN-0 -−0.022−0.062−0.088
0.050 GMAN-1 0.022 - 0.006−0.078
−0.055 GMAN∗0.062−0.006 -−0.001
−0.167 mod-GAN 0.088 0.078 0.001 -
Table 3: Pairwise GMAM metric means for select models on CIFAR-10. For each column, a positive
GMAM indicates better performance relative to the row opponent; negative implies worse. Scores
are obtained by summing each column. GMAN variants were trained with twodiscriminators.
GMAN-0 GMAN-1 mod-GAN GMAN∗
Score 5.878±0.193 5.765±0.168 5.738±0.176 5.539±0.099
Table 4: Inception score means with standard deviations for select models on CIFAR-10. Higher
scores are better. GMAN variants were trained with twodiscriminators.
Score Variant GMAN-0 GMAN∗GMAN-1 mod-GANBetter→0.180 GMAN-0 -−0.008−0.041−0.132
0.122 GMAN∗0.008 -−0.038−0.092
0.010 GMAN-1 0.041 0.038 -−0.089
−0.313 mod-GAN 0.132 0.092 0.089 -
Table 5: Pairwise GMAM metric means for select models on CIFAR-10. For each column, a positive
GMAM indicates better performance relative to the row opponent; negative implies worse. Scores
are obtained by summing each column. GMAN variants were trained with ﬁvediscriminators.
GMAN-1 GMAN-0 GMAN∗mod-GAN
Score 6.001±0.194 5.957±0.135 5.955±0.153 5.738±0.176
Table 6: Inception score means with standard deviations for select models on CIFAR-10. Higher
scores are better. GMAN variants were trained with ﬁvediscriminators.
Figure 14: Sample of pictures generated on CelebA cropped dataset.
12Published as a conference paper at ICLR 2017
Figure 15: Sample of pictures generated by GMAN-0 on CIFAR dataset.
A.4 S OMEWHAT RELATED WORK
A GAN framework with two discriminators appeared in Yoo et al. (2016), however, it is applica-
ble only in a semi-supervised case where a label can be assigned to subsets of the dataset (e.g.,
X={X1=Domain 1,X2=Domain 2,...}). In contrast, our framework applies to an unsu-
pervised scenario where an obvious partition of the dataset is unknown. Furthermore, extending
GMAN to the semi-supervised domain-adaptation scenario would suggest multiple discriminators
per domain, therefore our line of research is strictly orthogonal to that of their multi-domain dis-
criminator approach. Also, note that assigning a discriminator to each domain is akin to prescribing
a new discriminator to each value of a conditional variable in conditional GANs (Mirza & Osindero
(2014)). In this case, we interpret GMAN as introducing multiple conditional discriminators and not
a discriminator for each of the possibly exponentially many conditional labels.
In Section 4.4, we describe an approach to customize adversarial training to better suit the devel-
opment of the generator. An approach with similar conceptual underpinnings was described in
Ravanbakhsh et al. (2016), however, similar to the above, it is only admissible in a semi-supervised
scenario whereas our applies to the unsupervised case.
A.5 Softmax REPRESENTABILITY
Letsoftmax (Vi) =ˆV∈[minVi,maxVi]. Also leta=argminiVi,b=argmaxiVi, andV(t) =
V((1−t)Da+tDb)so thatV(0) =VaandV(1) =Vb. The softmax and minimax objective
V(Di,G)are both continuous in their inputs, so by the intermediate value theorem , we have that
∃ˆt∈[0,1]s.t.V(ˆt) = ˆV, which implies∃ˆD∈Ds.t. V (ˆD,G ) = ˆV. This result implies that
thesoftmax (and any other continuous substitute) can be interpreted as returning V(ˆD,G )for some
ˆDselected by computing an another, unknown function over the space of the discriminators. This
result holds even if ˆDis not representable by the architecture chosen for D’s neural network.
13Published as a conference paper at ICLR 2017
A.6 U NCONSTRAINED OPTIMIZATION
To convert GMAN∗minimax formulation to an unconstrained minimax formulation, we introduce
an auxiliary variable, Λ, deﬁneλ(Λ) = log(1 + eΛ), and let the generator minimize over Λ∈R.
A.7 B OOSTING WITH AdaBoost.OL
AdaBoost.OL (Beygelzimer et al. (2015)) does not require knowledge of the weak learner’s slight
edge over random guessing ( P(correct label) = 0.5 +γ∈(0,0.5]), and in fact, allows γ <0. This
is crucial because our weak learners are deep nets with unknown, possibly negative, γ’s.
Figure 16: Sample of pictures generated across 4 independent runs on MNIST with F-boost (similar
results with P-boost).
A.8 E XPERIMENTAL SETUP
All experiments were conducted using an architecture similar to DCGAN (Radford et al. (2015)).
We use convolutional transpose layers (Zeiler et al. (2010)) for Gand strided convolutions for D
except for the input of Gand the last layer of D. We use the single step gradient method as in
(Nowozin et al. (2016)), and batch normalization (Ioffe & Szegedy (2015)) was used in each of
the generator layers. The different discriminators were trained with varying dropout rates from
[0.3,0.7]. Variations in the discriminators were effected in two ways. We varied the architecture by
varying the number of ﬁlters in the discriminator layers (reduced by factors of 2, 4 and so on), as
well as varying dropout rates. Secondly we also decorrelated the samples that the disriminators were
training on by splitting the minibatch across the discriminators. The code was written in Tensorﬂow
(Abadi et al. (2016)) and run on Nvidia GTX 980 GPUs. Code to reproduce experiments and plots
is at https://github.com/iDurugkar/GMAN. Speciﬁcs for the MNIST architecture and training are:
•Generator latent variables z∼U(−1,1)100
•Generator convolution transpose layers: (4,4,128),(8,8,64),(16,16,32),(32,32,1)
•Base Discriminator architecture: (32,32,1),(16,16,32),(8,8,64),(4,4,128) .
•Variants have either convolution 3 (4,4,128) removed or all the ﬁlter sizes
are divided by 2 or 4. That is, (32,32,1),(16,16,16),(8,8,32),(4,4,64) or
(32,32,1),(16,16,8),(8,8,16),(4,4,32).
•ReLu activations for all the hidden units. Tanh activation at the output units of the generator.
Sigmoid at the output of the Discriminator.
•Training was performed with Adam (Kingma & Ba (2014)) ( lr= 2×10−4,β1= 0.5).
•MNIST was trained for 20 epochs with a minibatch of size 100.
•CelebA and CIFAR were trained over 24000 iterations with a minibatch of size 100.
14"
10,https://arxiv.org/pdf/2503.18892,"SimpleRL-Zoo
SimpleRL-Zoo: Investigating and Taming Zero Reinforcement
Learning for Open Base Models in the Wild
Weihao Zeng∗1Yuzhen Huang∗1Qian Liu∗2Wei Liu1Keqing He3
Zejun Ma2Junxian He1
1HKUST2TikTok3BUPT
https://github.com/hkust-nlp/simpleRL-reason
Abstract
DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can
naturally emerge through a simple reinforcement learning (RL) framework
with rule-based rewards, where the training may directly start from the
base models—a paradigm referred to as zero RL training . Most recent ef-
forts to reproduce zero RL training have primarily focused on the Qwen2.5
model series, which may not be representative as we find the base models
already exhibit strong instruction-following and self-reflection abilities. In
this work, we investigate zero RL training across 10 diverse base models,
spanning different families and sizes including LLama3-8B, Mistral-7B/24B,
DeepSeek-Math-7B, Qwen2.5-math-7B, and all Qwen2.5 models from 0.5B
to 32B. Leveraging several key design strategies—such as adjusting format
reward and controlling query difficulty—we achieve substantial improve-
ments in both reasoning accuracy and response length across most settings.
However, by carefully monitoring the training dynamics, we observe that
different base models exhibit distinct patterns during training. For instance,
the increased response length does not always correlate with the emergence
of certain cognitive behaviors such as verification (i.e., the “aha moment”).
Notably, we observe the “aha moment” for the first time in small models
not from the Qwen family. We share the key designs that enable successful
zero RL training, along with our findings and practices. To facilitate further
research, we open-source the code, models, and analysis tools.
0 25 50 75 100481216
Mistral-7B-v0.1
1.53.04.56.0
0 25 50 75 1005101520
Llama-3.1-8B
0.51.01.52.0
0 25 50 75 100612182430
DeepSeek-Math-7B
0.40.60.81.01.2
0 50 100 1501624324048
Mistral-Small-24B
1.53.04.56.0
0 25 50 75 10048121620
Qwen-2.5-0.5B
0.50.60.80.9
0 50 1008162432
Qwen-2.5-1.5B
0.40.60.81.01.2
0 50 1003036424854
Qwen-2.5-7B
0.70.80.91.0
0 50 100 15032404856
Qwen-2.5-32B
0.50.60.70.8
Accuracy (%)
Response Length (K)
Accuracy Response Length
Figure 1: Accuracy and response length across training iterations for different models,
averaged on GSM8K, MATH500, Minerva Math, OlympiadBench, AIME24, and AMC23.
Per-benchmark results are in Figure 12 (Appendix A). All training starts from base models.
∗Equal Contribution. Correspondence to Weihao Zeng (wzengak@connect.ust.hk), Yuzhen Huang
(yhuanghj@cse.ust.hk), and Junxian He (junxianh@cse.ust.hk).
1arXiv:2503.18892v1  [cs.LG]  24 Mar 2025SimpleRL-Zoo
1 Introduction
Large reasoning models, including OpenAI-o1 (Jaech et al., 2024), DeepSeek-R1 (DeepSeek-
AI et al., 2025a), and Kimi-k1.5 (Team et al., 2025), demonstrate remarkable abilities. These
models excel at generating long Chains-of-Thought (CoT) (Wei et al., 2022) responses when
solving complex tasks and exhibit advanced, reflection-like reasoning behaviors. Recently,
DeepSeek-R1 (DeepSeek-AI et al., 2025a) has revealed that starting from pretrained models
(i.e., base models), pure reinforcement learning (RL) with rule-based reward can lead to the
spontaneous emergence of long CoT and self-reflection behaviors, called the “aha moment”.
This RL training paradigm starting from base models is often referred to as zero RL training .
While the success of zero RL training was initially demonstrated using DeepSeek-
V3 (DeepSeek-AI et al., 2025b), a model with 671B parameters, it remained unclear whether
such emergent phenomena persist in generally smaller and less capable open base models.
Recent open-source efforts exploring zero-training approaches have predominantly centered
on the Qwen2.5-series models (Zeng et al., 2025a; Yeo et al., 2025; Xie et al., 2025; Hu et al.,
2025; Yu et al., 2025), which, even as base models, exhibit strong instruction-following capa-
bilities and display notable cognitive behaviors such as backtracking and verification from
the beginning, as we will detail in §2.5. Moreover, the analyses of model behavior in these
studies remain largely superficial, focusing primarily on metrics such as response length
and accuracy. These observations neither clearly establish whether the models’ reasoning
behaviors actually change nor clarify the mechanisms underlying the emergence of effective
reasoning, leaving a significant gap in understanding.
To provide a more transparent understanding of zero RL training across different base
models in the wild, this paper addresses the following key questions: (1) How do reasoning
capabilities develop across various models during zero RL training? (2) Does an “aha
moment” still occur for base models that initially lack strong instruction-following and
self-verification abilities? (3) What are the critical factors for ensuring successful zero RL
training across diverse base models?
To this end, we perform zero RL training across a diverse range of model series and sizes,
including Mistral-7B (Jiang et al., 2023), Mistral-24B (Mistral AI, 2025), Llama3-8B (Dubey
et al., 2024), DeepSeek-Math-7B (Shao et al., 2024), Qwen2.5-0.5B/1.5B/7B/14B/32B (Yang
et al., 2024a), as well as Qwen2.5-Math-7B (Yang et al., 2024b). To maintain simplicity in
the training recipe, our experiments rely exclusively on the training sets of GSM8K (Cobbe
et al., 2021) and MATH (Hendrycks et al., 2021) datasets for rule-based reward modeling. It
is worth noting that we adopt the same training hyperparameters to train all the models.
Using GRPO (Shao et al., 2024) as the RL algorithm, combined with several critical factors
that we identified, we obtain significant improvements in model accuracy across all base
models, along with a notable increase in response length for 9 out of the 10 models, with the
exception of Qwen2.5-Math-7B. However, through careful monitoring of training dynamics
and reasoning behaviors, we find that different base models exhibit distinct patterns during
training. Also, certain specific factors require careful attention to ensure successful zero RL
training. Below, we summarize our key findings.
1.Increased response length does not always correspond to an “aha moment” –
Interestingly, for most Qwen2.5 models, which form the foundation of most recent
open-source efforts, we do not observe a rise in the frequency of certain cognitive
behaviors, such as self-reflection, despite the increase in response length. (§2.5)
2.For the first time, we observe a significant increase in the frequency of specific
cognitive reasoning behaviors, such as verification, in small models outside the
Qwen family, notably in the Llama3-8B and DeepSeek-Math-7B models. (§2.5)
3.Enforcing rigid format reward (e.g., enclosing answers within boxes) (DeepSeek-
AI et al., 2025a) significantly penalizes exploration (Singh et al., 2023; Wang et al.,
2024), particularly for base models that initially struggle with instruction following.
This restriction lowers their performance ceiling and often induces overthinking
behaviors (Chen et al., 2024). (§3.1)
2SimpleRL-Zoo
4.The difficulty level of the training data must align closely with the base model’s
intrinsic exploration capabilities, otherwise zero RL will fail. (§3.2)
5.In contrast to the observation in Shao et al. (2024), zero RL training lifts pass@k
accuracy by 10-30 absolute points, a strong evidence confirming zero RL training
is not just reranking responses. (§2.4)
6.We revisit the traditional training pipeline that performs SFT to learn to follow
instructions before RL training. Specifically, we use conventional SFT datasets
as a cold start for RL—a de facto approach prior to the release of DeepSeek-R1.
While high-quality CoT data (Li et al., 2024) can rapidly enhance a base model’s
performance through imitation, we find that it significantly limits the model’s
ability to explore freely during RL. This constraint diminishes post-RL performance
and suppresses the emergence of advanced reasoning capabilities. (§4)
2 On Emerging Reasoning in Zero RL Training
Existing works on studying zero RL training mostly focus on Qwen2.5-series models, and
only track superficial metrics such as accuracy and response length (Zeng et al., 2025a;
Hu et al., 2025; Yu et al., 2025). First, while Qwen2.5 models exhibit strong performance,
they may not be representative of base models commonly encountered in the wild. This
is because Qwen2.5 models incorporate a substantial amount of synthetic data during
pretraining and already display robust instruction-following abilities and certain reflective
behaviors, as observed in our preliminary trials. Second, an increase in response length can
result from various factors and does not necessarily imply an “aha moment”, the emergence
of specific cognitive behaviors such as self-reflection. For instance, we observe that response
length increases can sometimes be unhealthy, stemming from meaningless repetition. To
address these gaps, this section investigates zero RL training across a diverse range of base
models spanning multiple families and sizes. By carefully monitoring training dynamics
across a variety of metrics beyond accuracy and response length, we aim to provide a more
comprehensive and transparent understanding of zero RL training for open base models in
the wild.
2.1 Background: “Zero RL Training”
In our study, we follow the zero RL training recipe in DeepSeek-AI et al. (2025a) using
various open base models, employing the GRPO algorithm (Shao et al., 2024). GRPO
optimizes computational efficiency by eliminating the need for a separate value model;
instead, it directly utilizes group-normalized rewards to estimate advantages. For a query
qand a set of responses O={o1,o2,. . .,oG}sampled from the old policy model πold, we
adopt a token-level, length-rectified GRPO objective to optimize the policy model π:1
JGRPO(θ) =1
∑G
i=1|oi|G
∑
i=1|oi|
∑
t=1min
ri,t(θ)ˆAi, clip (ri,t(θ); 1−ϵ, 1+ϵ)ˆAi
| {z }
Clipped policy update−βDKL[πθ∥πref]| {z }
KL penalty
where ri,t(θ) =πθ(oi,t|q,oi,<t)
πθold(oi,t|q,oi,<t)
(1)
where πrefrepresents the reference model, and the term DKLintroduces a KL divergence
constraint to limit how much the model can deviate from this reference. The advantage
1The original GRPO objective has a length normalization term that introduces length biases. We
remove the length normalization term similar to concurrent works (Yu et al., 2025; Liu et al., 2025)
– this length-rectified objective was the default implementation of GRPO in our adapted codebase,
verl (Sheng et al., 2024).
3SimpleRL-Zoo
estimate ˆAimeasures how much better the response oiis compared to the average response,
which is computed using a group of rewards {r1,r2, . . . , rG}for the responses in set O:
ˆAi=ri−mean ({r1,r2, . . . , rG})
std({r1,r2, . . . , rG})(2)
2.2 Experimental Setup
Dataset: To keep the training recipe simple, we select training data exclusively from the
GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021) datasets. For the MATH
dataset, following prior studies (Lightman et al., 2023; Wang et al., 2023; Sun et al., 2024), we
reserve the MATH500 subset as the test set, uniformly sample an additional 500 problems for
validation, and combine the remaining 4,000 test problems with the original 7,500 training
problems to form our training set. Each example in the MATH dataset is originally labeled
with a difficulty level ranging from 1 to 5. In our experiments, we find that data difficulty
is critical for successful zero RL ( §3.2) and it is necessary to use data that aligns with the
model’s capability. To investigate this phenomenon, we categorize the data into three
difficulty levels: Easy (GSM8K and MATH lv.1), Medium (MATH lv.1–4), and Hard (MATH
lv.3–5), with each category containing roughly 8,000 problems. For our main training runs,
we use Easy for LLama-3.1-8B, Mistral- v0.1-7B, and DeepSeek-Math-7B; Medium for Qwen-
2.5-0.5B; Hard for Mistral-Small-24B, Qwen-2.5-Math-7B, and Qwen-2.5-1.5B/7B/14B/32B,
and we will report ablation study on data difficulty in §3.2.
Reward: We use a rule-based reward function that assigns rewards solely based on the
correctness of the generated response: a correct final answer receives a reward of +1, while
an incorrect one receives a reward of 0. Recent studies (Luo et al., 2025; Chen et al., 2025)
often incorporate format-based rules into reward calculation, encouraging the model to
follow specific output formats. However, we find that this approach may hinder the model’s
exploration and ultimately harm its performance particularly for the base models which
struggle with following the format in the initial stage, as detailed in §3.1.
Models: We conduct zero RL training experiments on Llama-3.1-8B (Dubey et al., 2024),
DeepSeek-Math-7B (Shao et al., 2024), Mistral-v0.1-7B (Jiang et al., 2023), Mistral-Small-24b-
Base-2501 (Mistral AI, 2025), and Qwen-2.5 (0.5B, 1.5B, 7B, 14B, 32B) (Yang et al., 2024a).
As we perform experiments for a variety of models, under extremely simple settings with
small, simple datasets and only correctness reward, we refer to our obtained models as
SimpleRL-Zoo to represent a simple training recipe for a zoo of open base models. For
models with weaker instruction-following capabilities (Llama-3.1-8B, Mistral-v0.1-7B, and
Qwen-2.5-0.5B/1.5B), we employ simpler prompts (Chern et al., 2023) requiring only step-
by-step reasoning. For models with stronger instruction-following abilities, we use more
complex prompts (Yang et al., 2024a) that require the final answers to be placed in boxes.
In our preliminary experiments, we observe that using complex prompts with models that
have weak instruction-following capabilities often results in large amounts of irrelevant or
nonsensical content being generated early in training, leading to instability. The content of
simpler prompts and more complex prompts is shown in Figure 11 in Appendix.
Benchmark: We evaluate performance on standard mathematical reasoning benchmarks,
including GSM8K (Cobbe et al., 2021), MATH 500 (Hendrycks et al., 2021), Minerva
Math (Lewkowycz et al., 2022), and OlympiadBench (He et al., 2024), as well as on
competition-level benchmarks such as AIME 2024 and AMC 2023.
Other Configurations: We train our models using the verl (Sheng et al., 2024) framework.
Specifically, during training, we use a prompt batch size of 1024, generate 8 rollouts per
prompt, set a maximum rollout length of 8,192 tokens, and train using a mini-batch size of
256. It is worth noting that we use the same training hyperparameters to train all the models.
During evaluation, we set the sampling temperature to 1.0 and allow a maximum generation
length of 16,384 tokens. For most benchmarks, we report pass@1 results. However, for the
AIME 2024 benchmark specifically, we report both pass@1 and average accuracy computed
4SimpleRL-Zoo
over 32 samples (avg@32) due to limited data points. We provide detailed training and
evaluation details in the Appendix B.
2.3 Evaluation Metrics
During training, we monitor standard metrics such as accuracy and response length across
benchmarks. As discussed before, however, we observe that response length as a metric is
quite superficial and cannot accurately reflect changes in the model’s reasoning behavior.
Therefore, we adopt the following metrics additionally:
Reasoning Behavior Ratio: To better understand the model’s reasoning patterns through-
out the training process, we adopt the cognitive behavior framework proposed by Gandhi
et al. (2025) and use GPT-4o (Hurst et al., 2024) to identify reasoning-related behaviors,
including “Backtracking”, “Verification”, “Subgoal Setting”, and “Enumeration”. We report
the ratio of responses that contain such cognitive behaviors. While some recent studies
suggest tracking reflection behavior using related keywords (Yeo et al., 2025; Xie et al., 2025)
as monitoring signals, we argue that these keywords only exhibit only a weak correlation
with high-level reasoning patterns like reflection and verification. As a result, they fail to
adequately capture the development of these reasoning processes. Further details can be
found in Appendix F.1.
Clip Ratio: In the early stages of training, the base model exhibits weak instruction-
following ability and often fails to stop appropriately, resulting in irrelevant or excessively
long outputs. After training collapses, the model may also generate repetitive or overly
extended responses. Since the model has a fixed maximum context length, such outputs
may be truncated during both training and evaluation. To monitor this issue, we define the
proportion of truncated outputs as the “Clip Ratio”.
Average Stopped Length: Generations that are truncated often result from issues such as
repetitive patterns or incomplete reasoning, which typically do not contribute to effective
trajectories. To account for this factor, we introduce a new metric to track the average
length of responses that are stopped under normal conditions. It is a more reliable metric to
consider only valid responses, thereby eliminating the interference caused by unstopped
responses.
Pass@k Accuracy: We track the pass@k accuracy, which represents the percentage of
questions for which at least one correct response is obtained when sampling k responses
per question. Pass@k serves as an indicator of the model’s exploration capabilities and is
particularly relevant for RL, as it reflects the model’s ability to generate responses that can
achieve a positive reward. Previously, some researchers believed that RL training might
merely reorder responses within the original model distribution, as evidenced by the lack of
improvement in pass@k accuracy following RL training (Shao et al., 2024).
2.4 Main Results
Zero RL Training Improves both Accuracy and Response Length Significantly: Figure 1
and Figure 12 in Appendix A illustrate a steady improvement in both response length and
average accuracy across various benchmarks. Table 1 provides a detailed breakdown of the
results. Remarkably, even with only 8K training data for training, we observe significant
performance gains across all benchmarks. For example, Qwen-32b’s Pass@1 on AIME 24
surges from 10.0 to 36.7, and on MATH 500, it increases from 68.6 to 82.4. Despite the
limited training data, consisting solely of GSM8K and MATH 500, we observe substantial
performance gains on competition-level benchmarks such as AIME 2024 and AMC 2023.
This highlights the impressive generalization abilities of zero RL training allowing the
model to bridge the gap from easy to hard.
In addition to the Qwen series models, we also significantly improve both performance and
response length for other models that initially starts with low baselines. For instance, the
5SimpleRL-Zoo
Model GSM8KMATH
500Minerva
MathOlympiad
BenchAIME24
(Pass@1)AIME24
(Avg@32)AMC23 Avg.
Llama, DeepSeek and Mistral Models
Mistral-v0.1-7B 21.2 4.2 4.0 2.4 0.0 0.0 0.0 5.3
,→+ SimpleRL-Zoo 75.0 15.8 6.6 4.1 0.0 0.2 10.0 18.6
Llama-3.1-8B 39.7 13.6 4.8 3.1 0.0 0.2 2.5 10.6
,→+ SimpleRL-Zoo 79.2 23.0 9.6 5.3 0.0 0.2 15.0 22.0
DeepSeek-Math-7B 28.4 19.4 5.5 4.7 0.0 0.0 10.0 11.3
,→+ SimpleRL-Zoo 78.5 39.6 21.0 12.6 3.3 0.6 20.0 29.2
Mistral-Small-24B 78.6 43.6 10.7 11.6 3.3 0.5 17.5 27.6
,→+ SimpleRL-Zoo 92.0 70.6 36.8 36.6 16.7 13.1 45.0 49.6
Qwen Series Models
Qwen-2.5-0.5B 36.7 15.8 4.8 2.8 0.0 0.3 12.5 12.1
,→+ SimpleRL-Zoo 49.5 34.4 10.3 8.9 0.0 0.7 22.5 20.9
Qwen-2.5-1.5B 55.7 29.6 6.6 6.5 0.0 0.1 12.5 18.5
,→+ SimpleRL-Zoo 74.4 59.0 20.2 21.0 6.7 4.2 35.0 36.1
Qwen-2.5-7B 88.2 64.6 25.7 30.1 3.3 0.3 30.0 40.3
,→+ SimpleRL-Zoo 91.7 78.2 38.6 40.4 20.0 15.6 62.5 55.2
Qwen-2.5-Math-7B 65.5 63.6 12.5 25.8 13.3 8.6 42.5 37.2
,→+ SimpleRL-Zoo 90.2 80.2 37.5 39.0 40.0 24.0 70.0 59.5
Qwen-2.5-14B 91.6 65.4 24.3 33.5 6.7 3.4 37.5 43.2
,→+ SimpleRL-Zoo 94.4 80.2 40.4 44.9 23.3 14.2 57.6 56.8
Qwen-2.5-32B 92.9 68.6 27.9 31.1 10.0 4.5 45.0 45.9
,→+ SimpleRL-Zoo 95.9 82.4 42.6 46.4 36.7 27.2 67.5 61.9
Table 1: Detailed performance of various models across multiple benchmarks. The blue lines
represent the models trained with our recipe. AIME is evaluated in two ways: Pass@1 (single
run) and Avg@32 (average score from 32 runs). For AIME24 (Pass@1) and other benchmarks,
baselines use greedy decoding, and models with SimpleRL-Zoo use temperature=1.0 and
top-p=0.95. For AIME24 (Avg@32), we sample 32 responses per model with the same
settings. Average scores are based on AIME (Pass@1) and other benchmarks.
0 20 40 60 80 100010203040506070Accuracy (%)
 14.034.037.139.1 38.536.060.958.661.972.1Average
0 20 40 60 80 100010203040
0.03.3 3.310.0 10.0
6.726.7
23.330.043.3AIME24
0 20 40 60 80 100020406080
15.037.540.0 40.0
35.040.072.5
67.570.087.5AMC23
0 20 40 60 80 100020406080
27.061.268.0 67.470.4
61.283.485.0 85.8 85.6Math500
Pass@1 Pass@8
Figure 2: Pass@1 and Pass@8 accuracy over the training iterations of Mistral-Small-24B. The
model is trained on the hard data (MATH levels 3–5) as described in §2.2. We evaluate its
performance on three benchmarks: AIME24, AMC23, and Math500. The reported average
score is the mean across these three benchmarks.
DeepSeek-Math-7B model initially had a performance score of around 10.0. After just 80
training iterations, its performance increases more than threefold, while its response length
grows from around 300 to over 1200 tokens.
Steady Improvement of Pass@k Accuracy: As shown in Figure 2, Mistral-Small-24B ex-
hibits robust growth in pass@8 on MATH 500. Furthermore, as training progresses, the
model’s pass@1 results eventually surpass the initial pass@8 results of the base model. Sur-
prisingly, the gap between Pass@1 and Pass@8 does not diminish during training; instead, it
widens as training progresses. By iteration 100, the two metrics differ by more than 30 abso-
lute points on average. This suggests significant potential for further improvements in RL,
as pass@8 represents the model’s ability to explore correct responses. Furthermore, Figure 3
shows that a significant gap in pass@k performance persists between the base model and
the model after RL training, even at higher values of k. Notably, after just 100 training itera-
tions, the model achieves a pass@1 performance comparable to the base model’s pass@16.
6SimpleRL-Zoo
0 25 50 75 100020406080100
Mistral-7B-v0.1
0.30.60.91.21.5
0 25 50 75 100020406080100
Llama-3.1-8B
0.30.60.91.21.5
0 25 50 75 100020406080100
DeepSeek-Math-7B
0.30.40.50.6
0 50 100 150020406080100
Mistral-Small-24B
1.53.04.56.0
0 25 50 75 100020406080100
Qwen-2.5-0.5B
0.50.60.80.9
0 50 100020406080100
Qwen-2.5-1.5B
0.40.60.81.01.2
0 50 100020406080100
Qwen-2.5-7B
0.70.80.91.0
0 50 100 150020406080100
Qwen-2.5-32B
0.50.60.70.8
Clip Ratio (%)
Average Stopped Length (K)
Clip Ratio Average Stopped Length
Figure 4: Average clip ratio and stopped length across training iterations for different models.
We assess the models every five steps on a variety of math benchmarks, including GSM8K,
MATH500, Minerva Math, and OlympiadBench, as well as competition-level benchmarks
like AIME24 and AMC23. The red line indicates the clip ratio, while the blue line represents
the stopped length. Per-benchmark results are in Figure 13 (Appendix A).
1 2 4 8 16 32 64 128
Pass@K010203040506070Accuracy (%)
4.68.012.919.427.336.445.954.6
26.434.142.750.957.462.165.768.3 Iteration 0
Iteration 100
Figure 3: Pass@k of Mistral-24B based
on the average results from AIME24 and
AMC23.This suggests that zero RL training not only ad-
justs the model’s output distribution to favor
correct responses within the top k candidates
but also enhances the model’s internal reason-
ing abilities.
Growth in Response Length May be Un-
healthy: Response length does not always
reflect genuine growth in reasoning. In some
cases, unstable training can cause models to
generate excessive repetitive content until they
hit the context length limit, artificially inflating
response length without improving reasoning
depth. For example, Figure 4 shows that while
most models maintain a low clip ratio – below
5% of the data – when their average stopping length steadily increases, Mistral-7B-v0.1
exhibits a high clip ratio and significant fluctuations in stopping length. Upon closer in-
spection of its responses, we find that the responses consist of incoherent, mixed-language
gibberish, suggesting that its thinking process is not genuinely expanding. We note that
such patterns would not be captured by response length as in Figure 1. These findings
indicate that most models demonstrate a meaningful and structured increase in response
length. This raises an important question: What exactly do models learn as their thinking
time increases? We answer this question next.
2.5 The “Aha Moment” – Quantifying Emergence of Reasoning Behavior
Figure 5 illustrates the reasoning behavior ratio on OlympiadBench during model training.
By comparing Figure 5 with Figure 4, we observe that fluctuations in the reasoning behavior
ratio effectively account for variations in the average stopped length. Interestingly, we find
that different models exhibit entirely distinct trends in reasoning behavior changes.
Smaller models, such as Qwen-2.5-0.5B and Qwen-2.5-1.5B, tend to prioritize learning the
”Subgoal Setting” behavior, with its proportion increasing by approximately 4–5 times.
Additionally, the proportions of ”Verification” and ”Enumeration” also show noticeable
7SimpleRL-Zoo
01020304050607080901000.00.10.10.20.2
Mistral-7B-v0.1
01020304050607080901000.00.10.20.20.3
Llama-3.1-8B
01020304050607080901000.00.20.30.5
DeepSeek-Math-7B
01020304050607080901000.00.20.40.6
Mistral-Small-24B
01020304050607080901000.00.20.30.5
Qwen-2.5-0.5B
01020304050607080901000.00.20.30.50.6
Qwen-2.5-1.5B
01020304050607080901000.00.20.40.6
Qwen-2.5-7B
01020304050607080901000.00.20.40.6
Qwen-2.5-32BAverage Frequency
Backtracking Verification Enumeration Subgoal Setting
Figure 5: The change in reasoning behavior over the training iterations across all models.
As described in §2.2, we use GPT-4o to extract and track shifts in reasoning behaviors on
OlympiadBench. We focus on four reasoning-related behaviors: “Backtracking”, “Verifica-
tion”, “Subgoal Setting”, and “Enumeration”.
growth. In contrast, for other base models that inherently possess step-by-step reasoning
capabilities, adjustments in ”Subgoal Setting” during the RL training process are relatively
minor.
During training, we observe that DeepSeek-Math-7B, Llama-3.1-8B, and Mistral-Small-24B
exhibit substantial increases in the proportions of “Enumeration” and “Verification” be-
haviors, rising from relatively low initial levels by approximately 3-4 times. This growth
correlates closely with their changes in average stopped length, suggesting a shift in reason-
ing patterns over time. For instance, in Mistral-Small-24B, reflection-oriented behaviors such
as “Verification” and “Backtracking” increase dramatically from nearly 0% to approximately
50%, indicating the emergence of reflection behavior from scratch. This shift suggests that
the model progressively internalizes verification mechanisms as part of its reasoning process,
offering a promising trajectory for further enhancement.
In contrast, Qwen-2.5-7B and 32B demonstrate strong reasoning behaviors from the outset,
with minimal changes throughout training. This stability aligns with their slow length
adjustments (Figure 1) and suggests that Qwen models inherently possess robust reasoning
capabilities. Rather than undergoing a structural shift in their reasoning processes, they
primarily benefit from small increases in thinking time, which yield significant performance
improvements. Finally, we observe that Mistral-7B-v0.1 consistently exhibits low reasoning
behaviors with no noticeable growth, further supporting our earlier analysis in §2.4.
To intuitively illustrate the changes in reasoning behavior, we present examples of Mistral
24B’s reasoning before and after ”zero training” in Figures 6. Additional examples and
comprehensive case studies involving other models are available in the Appendix F.3. In
Figure 6, we observe that unlike the base model, the zero training model actively attempts
to verify if its initial solution is valid by substituting it back into the original expression.
Upon recognizing that the first solution does not meet the necessary conditions, the model
explicitly initiates a backtracking approach, stating ”let’s try another possibility,” eventually
arriving at the correct answer.
3 Key Factors Shaping Zero Training
In this section, we identify key factors that influence stability and performance during
zero RL training, particularly when dealing with early-stage or weaker models. First, we
explore how an over-reliance on format rewards restricts exploration. Next, we analyze how
8SimpleRL-Zoo
Let $f(x) = x^3 + 3x^2 + 1.$  There exist real numbers $a \\neq 0$ and $b,$ such that
\\[f(x) - f(a) = (x - a)^2 (x - b).\\] Enter the ordered pair $(a,b).$
Factor the left side of the equation as follows:
\\[f(x) - f(a) = (x - a) (x^2 + 2x + 1 + 3x + 3a).\\]
Compare the coefficients of $x^2$ and $x$ in the two expressions for $f(x) - f(a)$ to
find the values of $a$ and $b$ that satisfy the equation. The solution is:
\\[\\boxed{(a, b) = (-1, -1)}\\]
To find the real numbers $a \\neq 0$ and $b$ such that
\\[ f(x) - f(a) = (x - a)^2 (x - b), \\]
we first need to compute $f(a)$:
\\[ f(a) = a^3 + 3a^2 + 1. \\]
.......
Substituting $b = 0$ into $b + 2a = -3$, we get:
\\[ 0 + 2a = -3 \\implies 2a = -3 \\implies a = -\\frac{3}{2}. \\]
Now, we can verify that this value of $a$ also satisfies 
the equation $2ab + a^2 = 0$:
\\[ 2ab + a^2 = 2 \\left( -\\frac{3}{2} \\right) \\cdot 0 + \\left( -\\frac{3}{2}
\\right)^2 = 0 + \\frac{9}{4} = \\frac{9}{4}. \\]
.....
Therefore, the ordered pair \\((a, b)\\) is \\(\\boxed{(-2, 1)}\\).Question
Base Solution
Let's check if $b = 0$ is a valid solution:
However, this does not equal $0$. So, $b = 0$ is not a valid solution.
Let's try another possibility:Zero SolutionVerification
Backtracking
Figure 6: A comparison of Mistral-24B’s ”verification” and ”backtraining” behavior before
and after ”zero training.” Here, ”base solution” represents the response of the Mistral-24B
base model, while ”zero solution” represents the response of the model after training.
0 20 40 60 803036424854
55.2
47.8
0.81.01.21.41.6
0.8K1.2KAccuracy (%)
Response Length (K)W/ Format Reward
W/o Format Reward
(a) Qwen-2.5-7B
0 5 10 15 20 25 30 35 4005101520
20.5
5.2
0.02.04.06.08.0
1.3K1.5KAccuracy (%)
Response Length (K)W/ Format Reward
W/o Format Reward (b) Llama-3.1-8B
Figure 7: Comparison of accuracy and response length with and without format rewards.
0 25 50 75 100481216Accuracy (%)
0 25 50 75 1000.01.53.04.56.0Response Length (K)
GSM8K & Math lv.1 Math lv.1-4 Math lv.3-5
(a) Mistral-7b-v0.1
0 25 50 75 1003036424854Accuracy (%)
0 25 50 75 1000.60.70.80.9Response Length (K)
GSM8K & Math lv.1 Math lv.1-4 Math lv.3-5 (b) Qwen-2.5-7B
Figure 8: Comparison of accuracy and response length across different data difficulty levels.
We examine three levels of data: Easy (GSM8K and MATH lv.1), Medium (MATH lv.1–4),
and Hard (MATH lv.3–5), with each category containing approximately 8,000 problems.
data difficulty impacts exploratory behavior, illustrating how exposure to varying levels of
difficulty shapes the exploration dynamics of base models. We also discuss the impact of
some exploration-related hyperparameters in Appendix D.
9SimpleRL-Zoo
3.1 Over-Reliance on Format Rewards
We find that enforcing strict formatting constraints, such as requiring the final answer
to be enclosed in a latex command \boxed{}, can hinder model’s freely exploration and
ultimately degrades performance. This is because many base models cannot follow the
format constraint well in the initial stage, and imposing a format reward will penalize many
correct explorations. We compare two reward functions: one without format constraints,
which rewards responses solely based on answer correctness (our default design in §2.2),
and another that strictly enforces formatting by penalizing responses with a reward of -1 if
they fail to adhere to the required format.
As illustrated in Figure 7, weaker models like Llama-3.1-8B struggle under strict formatting
requirements, leading to a rapid increase in response length early in training without
performancec improvement. The model expends excessive effort on adhering to the format
but fails to learn how to answer correctly, ultimately resulting in model collapse. Figure 7(a)
further reveals that even stronger models, such as Qwen-2.5-7B, which initially comply
with formatting constraints, suffer in later training stages. This includes both performance
degradation and a significant reduction in CoT length. Moreover, the strict formatting
constraints limit the model’s upper performance potential, suggesting that rigid constraints
stifle its ability to explore and refine solutions effectively.
These findings highlight a crucial insight: in a zero RL training setting, rather than imposing
rigid formatting rules, we should prioritize maintaining response verifiability while allowing
sufficient flexibility for exploration.
3.2 Data Difficulty on Exploratory Behavior
Base models exhibit varying performance and CoT behaviors when trained on different
RL data. Figure 8 compare the performance of Mistral-7B and Qwen-2.5-7B across Easy
(GSM8K, MATH Lv.1), Medium (MATH Lv.1-4), and Hard (MATH Lv.3-5) datasets. We
observe a clear trend: as data difficulty increases, Mistral-7B’s performance progressively
deteriorates. When faced with high-difficulty data (Hard: MATH levels 3-5), the model
struggles to generate responses that receive positive feedback from the reward system.
This failure results in a significant increase in response length without any corresponding
improvement in accuracy, signaling a breakdown in the training process—often referred
to as training collapse. Figure 8 demonstrates that Qwen-2.5-7B exhibits a pattern entirely
opposite to Mistral-7B-v0.1. Specifically, as dataset difficulty decreases, both the model’s
average accuracy and response length decline, with the effect being most pronounced
on the simplest dataset, where even response length decreases. This finding aligns with
our previous analysis of Qwen-2.5-7B in §2.5, reinforcing the notion that Qwen inherently
possesses strong reasoning capabilities. To further improve its response length, training
should incorporate more challenging datasets, such as competition-level problems, to
encourage deeper reasoning and extended thinking time.
The analysis highlights a key insight: zero RL training data must align with the base model’s
inherent reasoning capabilities, such as considering metrics like its Pass@K performance.
4 How Traditional SFT Influences RL-Driven Reasoning Emergence
As base models may not follow instruction well and pose a major challenge for zero RL
training, one may wonder a simple SFT stage as a cold start may be helpful to learn to follow
instructions well. In this section, we revisit the impact of traditional SFT methods (where
the responses are not from long CoT models) as a cold start on RL training performance
and reasoning behavior–notably, this was the most commonly used post-training pipeline
with RL following an SFT stage, before DeepSeek-R1. Specifically, we use a subset of
the NuminaMath (Li et al., 2024) dataset derived from GSM8K and MATH2, containing
2We also conduct experiments using general SFT dataset beyond math-related ones, which can be
found in Appendix C and implies similar conclusion.
10SimpleRL-Zoo
0 50 1000.40.60.8Frequency
Subgoal Setting
0 50 1000.20.30.4
Enumeration
0 50 1000.20.40.6
Verification
0 50 1000.10.20.3
Backtracking
Base Step 100 Step 500
Figure 9: Reasoning behavior ratio over RL training iterations after using different SFT steps
as starting points. “Base” refers to the base Mistral-Small-24B model without any SFT, while
“Step 100” and “Step 500” represent 100 and 500 steps of SFT on the base model, respectively.
As described in §2.2, we use GPT-4o to extract and track shifts in reasoning behaviors on
OlympiadBench.
approximately 15K high-quality short CoT responses. We conduct SFT using Mistral 24B on
this data and select models at 100 and 500 training steps as starting points for RL training.
0 50 1001624324048Accuracy (%)
0 50 1001.53.04.5Response Length (K)
Base Step 100 Step 500
Figure 10: Accuracy and response length
averaged on the six benchmarks over RL
training iterations after running different
SFT steps as starting points. “Base” refers to
the base Mistral-Small-24B model without
any SFT, while “Step 100” and “Step 500”
represent 100 and 500 steps of SFT on the
base model, respectively.In Figure 10, we illustrate how model accu-
racy and output length evolve during RL
training when different initial models are
used. Our results indicate that starting from
SFT models initially boosts performance sig-
nificantly; however, these models encounter
notable limitations in their maximum achiev-
able accuracy and response length compared
to starting from the base model during ex-
tended RL training. Crucially, we observe
that these limitations become increasingly
pronounced as the number of initial SFT steps
grows. For instance, while the base model can
attain a pass@1 accuracy of approximately
49.6% during RL training, models initialized
with 100 and 500 SFT steps achieve maximum
accuracies of only about 47.3% and 40.3%, re-
spectively.
To further investigate how initial SFT affects
the emergence of reasoning behaviors, we analyze how often specific reasoning behaviors
appeared during training at different starting points, as shown in Figure 9. Our analysis
reveals that initial SFT negatively impacts the development of critical reasoning behaviors.
Specifically, models with 100 SFT steps exhibit reduced upper limits in essential reason-
ing behaviors such as ”enumeration,” ”verification,” and ”backtracking,” compared to
the base model. Even more notably, models with 500 SFT steps experience significant
declines in ”enumeration” and ”verification” behaviors in later training stages, highlighting
a detrimental long-term effect of extensive sft on reasoning capabilities.
This prompts a reconsideration of whether traditional SFT inherently restricts model explo-
ration, perhaps highlighting the need for future cold-start strategies to prioritize exploration
capacity—whether by incorporating long CoT data (DeepSeek-AI et al., 2025a; Yeo et al.,
2025) or designing SFT techniques (Li et al., 2025) that strike a balance between imitation
and exploration—to enable sustained improvements in model reasoning performance.
5 Conclusion
Our paper demonstrates the effectiveness of zero RL training across a diverse range of base
models, yielding significant improvements in reasoning accuracy and response length. We
provide strong evidence that zero-shot RL training is not merely reranking, but rather a
genuine enhancement. Furthermore, we identify key factors such as reward design, data
11SimpleRL-Zoo
difficulty, and models’ inherent abilities that shape the emergence of advanced reasoning
behaviors. Our findings also indicate that starting RL training from models with traditional
SFT may limit the development of advanced reasoning behaviors. Overall, our work
highlights key factors for effective zero RL training and offers insights for future model
improvements.
References
Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song,
Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, et al. Do not think that much for 2+ 3=?
on the overthinking of o1-like llms. arXiv preprint arXiv:2412.21187 , 2024.
Zhipeng Chen, Yingqian Min, Beichen Zhang, Jie Chen, Jinhao Jiang, Daixuan Cheng,
Wayne Xin Zhao, Zheng Liu, Xu Miao, Yang Lu, et al. An empirical study on eliciting and
improving r1-like reasoning models. arXiv preprint arXiv:2503.04548 , 2025.
Ethan Chern, Haoyang Zou, Xuefeng Li, Jiewen Hu, Kehua Feng, Junlong Li, and Pengfei
Liu. Generative ai for math: Abel. https://github.com/GAIR-NLP/abel , 2023.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers
to solve math word problems. arXiv preprint arXiv:2110.14168 , 2021.
DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin
Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu,
Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan
Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu
Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong
Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu,
Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong
Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L.
Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin
Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang,
Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun
Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu
Chen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L.
Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu
Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu,
Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao,
Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An,
Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie,
Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin,
Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou,
Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao
Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong,
Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo,
Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo,
Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X. Zhu, Yanhong Xu, Yanping Huang, Yaohui
Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z. Z. Ren,
Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao,
Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie,
Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang.
Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025a.
URL https://arxiv.org/abs/2501.12948 .
DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu,
Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo,
Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo,
Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng
Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L.
12SimpleRL-Zoo
Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang
Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao,
Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang
Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua
Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang,
Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge,
Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S. S. Li,
Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng
Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan,
T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W. L. Xiao, Wangding Zeng, Wanjia Zhao, Wei
An, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, X. Q. Li, Xiangyue
Jin, Xianzu Wang, Xiao Bi, Xiaodong Liu, Xiaohan Wang, Xiaojin Shen, Xiaokang Chen,
Xiaokang Zhang, Xiaosha Chen, Xiaotao Nie, Xiaowen Sun, Xiaoxiang Wang, Xin Cheng,
Xin Liu, Xin Xie, Xingchao Liu, Xingkai Yu, Xinnan Song, Xinxia Shan, Xinyi Zhou, Xinyu
Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. X. Zhu,
Yang Zhang, Yanhong Xu, Yanhong Xu, Yanping Huang, Yao Li, Yao Zhao, Yaofeng Sun,
Yaohui Li, Yaohui Wang, Yi Yu, Yi Zheng, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying
He, Ying Tang, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang
Guo, Yu Wu, Yuan Ou, Yuchen Zhu, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He,
Yukun Zha, Yunfan Xiong, Yunxian Ma, Yuting Yan, Yuxiang Luo, Yuxiang You, Yuxuan
Liu, Yuyang Zhou, Z. F. Wu, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhen
Huang, Zhen Zhang, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhibin Gou, Zhicheng
Ma, Zhigang Yan, Zhihong Shao, Zhipeng Xu, Zhiyu Wu, Zhongyu Zhang, Zhuoshu Li,
Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Ziyi Gao, and Zizheng
Pan. Deepseek-v3 technical report, 2025b. URL https://arxiv.org/abs/2412.19437 .
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,
Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3
herd of models. arXiv preprint arXiv:2407.21783 , 2024.
Kanishk Gandhi, Ayush Chakravarthy, Anikait Singh, Nathan Lile, and Noah D Good-
man. Cognitive behaviors that enable self-improving reasoners, or, four habits of highly
effective stars. arXiv preprint arXiv:2503.01307 , 2025.
Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Leng Thai, Junhao Shen, Jinyi
Hu, Xu Han, Yujie Huang, Yuxiang Zhang, et al. Olympiadbench: A challenging bench-
mark for promoting agi with olympiad-level bilingual multimodal scientific problems.
arXiv preprint arXiv:2402.14008 , 2024.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,
Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the
math dataset. arXiv preprint arXiv:2103.03874 , 2021.
Jingcheng Hu, Yinmin Zhang, Qi Han, Daxin Jiang, and Heung-Yeung Shum Xiangyu Zhang.
Open-reasoner-zero: An open source approach to scaling reinforcement learning on the
base model. https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero , 2025.
Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark,
AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv
preprint arXiv:2410.21276 , 2024.
Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low,
Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card.
arXiv preprint arXiv:2412.16720 , 2024.
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh
Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile
Saulnier, L ´elio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut
Lavril, Thomas Wang, Timoth ´ee Lacroix, and William El Sayed. Mistral 7b, 2023. URL
https://arxiv.org/abs/2310.06825 .
13SimpleRL-Zoo
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski,
Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al.
Solving quantitative reasoning problems with language models. Advances in Neural
Information Processing Systems , 35:3843–3857, 2022.
Jia Li, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Huang,
Kashif Rasul, Longhui Yu, Albert Q Jiang, Ziju Shen, et al. Numinamath: The largest
public dataset in ai4maths with 860k pairs of competition math problems and solutions.
Hugging Face repository , 13:9, 2024.
Ziniu Li, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Zhi-Quan Luo, and Ruoyu Sun.
Preserving diversity in supervised fine-tuning of large language models. In The Thirteenth
International Conference on Learning Representations , 2025. URL https://openreview.net/
forum?id=NQEe7B7bSw .
Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy
Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step.
InThe Twelfth International Conference on Learning Representations , 2023.
Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, Wee Sun
Lee, and Min Lin. Understanding r1-zero-like training: A critical perspective. https:
//github.com/sail-sg/understand-r1-zero , 2025.
Michael Luo, Sijun Tan, Justin Wong, Xiaoxiang Shi, William Y. Tang, Manan Roongta, Colin
Cai, Jeffrey Luo, Tianjun Zhang, Li Erran Li, Raluca Ada Popa, and Ion Stoica. Deepscaler:
Surpassing o1-preview with a 1.5b model by scaling rl, 2025. Notion Blog.
Mistral AI. Mistral small 3, January 2025. URL https://mistral.ai/news/mistral-small-3 .
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang,
Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical
reasoning in open language models. arXiv preprint arXiv:2402.03300 , 2024.
Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua
Peng, Haibin Lin, and Chuan Wu. Hybridflow: A flexible and efficient rlhf framework.
arXiv preprint arXiv:2409.19256 , 2024.
Avi Singh, John D Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Xavier Garcia,
Peter J Liu, James Harrison, Jaehoon Lee, Kelvin Xu, et al. Beyond human data: Scaling
self-training for problem-solving with language models. arXiv preprint arXiv:2312.06585 ,
2023.
Zhiqing Sun, Longhui Yu, Yikang Shen, Weiyang Liu, Yiming Yang, Sean Welleck, and
Chuang Gan. Easy-to-hard generalization: Scalable alignment beyond human supervision.
arXiv preprint arXiv:2403.09472 , 2024.
Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li,
Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et al. Kimi k1. 5: Scaling reinforcement
learning with llms. arXiv preprint arXiv:2501.12599 , 2025.
Evan Wang, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen
Han, Sean Hendryx, Summer Yue, and Hugh Zhang. Planning in natural language
improves llm search for code generation. arXiv preprint arXiv:2409.03733 , 2024.
Peiyi Wang, Lei Li, Zhihong Shao, RX Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and
Zhifang Sui. Math-shepherd: Verify and reinforce llms step-by-step without human
annotations. arXiv preprint arXiv:2312.08935 , 2023.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language
models. Advances in neural information processing systems , 35:24824–24837, 2022.
14SimpleRL-Zoo
Tian Xie, Zitian Gao, Qingnan Ren, Haoming Luo, Yuqian Hong, Bryan Dai, Joey Zhou, Kai
Qiu, Zhirong Wu, and Chong Luo. Logic-rl: Unleashing llm reasoning with rule-based
reinforcement learning. arXiv preprint arXiv:2502.14768 , 2025.
An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,
Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2. 5 technical report. arXiv preprint
arXiv:2412.15115 , 2024a.
An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu,
Jianhong Tu, Jingren Zhou, Junyang Lin, et al. Qwen2. 5-math technical report: Toward
mathematical expert model via self-improvement. arXiv preprint arXiv:2409.12122 , 2024b.
Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, and Xiang Yue. Demystifying long
chain-of-thought reasoning in llms. arXiv preprint arXiv:2502.03373 , 2025.
Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Tiantian Fan,
Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng,
Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen,
Jiangjie Chen, Chengyi Wang, Hongli Yu, Weinan Dai, Yuxuan Song, Xiangpeng Wei, Hao
Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui Wu, and
Mingxuan Wang. Dapo: An open-source llm reinforcement learning system at scale, 2025.
URL https://arxiv.org/abs/2503.14476 .
Weihao Zeng, Yuzhen Huang, Wei Liu, Keqing He, Qian Liu, Zejun Ma, and Junxian He. 7b
model and 8k examples: Emerging reasoning with reinforcement learning is both effective
and efficient. https://hkust-nlp.notion.site/simplerl-reason , 2025a. Notion Blog.
Weihao Zeng, Yuzhen Huang, Lulu Zhao, Yijun Wang, Zifei Shan, and Junxian He. B-
STar: Monitoring and balancing exploration and exploitation in self-taught reasoners.
InThe Thirteenth International Conference on Learning Representations , 2025b. URL https:
//openreview.net/forum?id=P6dwZJpJ4m .
Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, and Zheyan Luo. LlamaFactory:
Unified efficient fine-tuning of 100+ language models. In Yixin Cao, Yang Feng, and Deyi
Xiong (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational
Linguistics (Volume 3: System Demonstrations) , pp. 400–410, Bangkok, Thailand, August
2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-demos.38.
URL https://aclanthology.org/2024.acl-demos.38/ .
15SimpleRL-Zoo
Simple Prompt
Question:
{input}
Answer:
Let's think step by step.
Complex Prompt
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
{input}
Please reason step by step, and put your final answer 
within \\boxed{}.<|im_end|>
<|im_start|>assistant
{output}
Figure 11: Comparison between simple prompts and more complex prompts.
A Detailed Result of SimpleRL
Following the setup described in Section 2.2, we perform “zero training” on various base
models. The trained models are then evaluated on multiple benchmarks, including GSM8K,
MATH 500, Minerva Math, OlympiadBench, AIME2024, and AMC2023. The average results
across all these benchmarks are presented in Figures 1 and 4. In this section, we provide
more detailed results. Figure 12 illustrates the trends in accuracy and response length, while
Figure 13 shows the trends in clip ratio and stopped length.
B Training and Evaluation Details
We typically use the same set of hyperparameters to train and evaluate all models in the
SimpleRL-Zoo series in default main experiment setting.
B.1 Training
We use a prompt batch size of 1,024 and generate 8 rollouts per prompt, with a maximum
rollout length of 8,192 tokens. Training is performed using a mini-batch size of 256. The
default sampling temperature is set to 1.0, and the clip ratio is 0.2. For models ranging from
0.5B to 14B parameters, we use a KL loss coefficient of 1e-4. For models larger than 14B, the
KL loss coefficient is set to 1e-3.
B.2 Evaluation
We build our evaluation script based on Yang et al. (2024b), using a temperature of 1.0 and
a maximum generation length of 16K tokens. To ensure consistency, we adopt the same
prompt template used during training. For most benchmarks, we report pass@1 results.
However, for AIME 2024, which contains fewer problems, we report both pass@1 and
average accuracy (avg@32), computed over 32 generated samples per problem.
16SimpleRL-Zoo
0 50 10000123Accuracy (%)
AIME24
0 50 10046810
AMC23
0 50 1001530456075
GSM8K
0 50 1003691215
Math500
0 50 1003456
Minerva Math
0 50 1001234
OlympiadBench
2.04.06.08.0
2.04.06.0
0.01.02.03.04.0
1.53.04.56.0
1.53.04.56.0
2.04.06.08.0
Response Length (K)
Mistral-7B-v0.1
0 50 10000123Accuracy (%)
AIME24
0 50 100481216
AMC23
0 50 1001530456075
GSM8K
0 50 100510152025
Math500
0 50 10046810
Minerva Math
0 50 10013467
OlympiadBench
1.02.03.04.0
0.61.21.82.4
0.10.20.30.4
0.40.81.21.6
0.40.81.21.6
0.61.21.82.4
Response Length (K)
Llama-3.1-8B
0 50 10000123Accuracy (%)
AIME24
0 50 10048121620
AMC23
0 50 1001530456075
GSM8K
0 50 100816243240
Math500
0 50 100481216
Minerva Math
0 50 100571012
OlympiadBench
0.40.81.21.62.0
0.40.60.81.01.2
0.20.20.20.2
0.30.50.60.80.9
0.30.50.60.80.9
0.30.60.91.21.5
Response Length (K)
DeepSeek-Math-7B
0 50 100 1500481216Accuracy (%)
AIME24
0 50 100 1501624324048
AMC23
0 50 100 15045607590
GSM8K
0 50 100 1503040506070
Math500
0 50 100 15016243240
Minerva Math
0 50 100 150816243240
OlympiadBench
2.04.06.08.0
1.53.04.56.0
0.01.02.03.04.0
1.53.04.56.0
1.53.04.56.0
1.53.04.56.07.5
Response Length (K)
Mistral-Small-24B
0 50 10000000Accuracy (%)
AIME24
0 50 1005101520
AMC23
0 50 10020304050
GSM8K
0 50 1008162432
Math500
0 50 100246810
Minerva Math
0 50 1002468
OlympiadBench
0.60.91.21.5
0.40.60.81.01.2
0.20.20.20.30.3
0.40.50.60.6
0.60.60.70.8
0.60.80.9
Response Length (K)
Qwen-2.5-0.5B
0 50 100025710Accuracy (%)
AIME24
0 50 10010203040
AMC23
0 50 10030456075
GSM8K
0 50 10015304560
Math500
0 50 1005101520
Minerva Math
0 50 1005101520
OlympiadBench
0.51.01.52.02.5
0.40.81.21.6
0.20.20.30.30.4
0.50.60.8
0.50.60.80.9
0.60.81.01.2
Response Length (K)
Qwen-2.5-1.5B
0 50 1009121518Accuracy (%)
AIME24
0 50 10030405060
AMC23
0 50 1006672788490
GSM8K
0 50 10048566472
Math500
0 50 1001824303642
Minerva Math
0 50 1002025303540
OlympiadBench
1.21.31.41.5
0.80.91.11.2
0.30.30.40.40.4
0.60.70.70.70.7
0.70.70.70.8
0.80.91.01.0
Response Length (K)
Qwen-2.5-7B
0 50 100 150812162024Accuracy (%)
AIME24
0 50 100 150485664
AMC23
0 50 100 1508587909295
GSM8K
0 50 100 1505460667278
Math500
0 50 100 1501824303642
Minerva Math
0 50 100 15024303642
OlympiadBench
0.81.01.21.41.6
0.80.91.01.01.1
0.30.30.30.30.3
0.50.50.60.70.7
0.60.60.70.7
0.70.80.91.01.1
Response Length (K)
Qwen-2.5-14B
0 50 100 1508162432Accuracy (%)
AIME24
0 50 100 15030456075
AMC23
0 50 100 1507580859095
GSM8K
0 50 100 1504856647280
Math500
0 50 100 15024303642
Minerva Math
0 50 100 15024324048
OlympiadBench
0.60.81.01.21.4
0.50.60.80.9
0.30.30.3
0.50.60.60.7
0.40.50.50.60.7
0.60.80.91.1
Response Length (K)
Qwen-2.5-32B
0 50 100 150816243240Accuracy (%)
AIME24
0 50 100 15040485664
AMC23
0 50 100 15045607590
GSM8K
0 50 100 1504050607080
Math500
0 50 100 1501218243036
Minerva Math
0 50 100 15024303642
OlympiadBench
1.21.41.51.6
0.70.80.91.0
0.30.40.50.6
0.60.70.80.9
0.60.70.70.8
0.90.91.01.01.0
Response Length (K)
Qwen-2.5-Math-7B
Figure 12: A detailed evaluation of accuracy and response length throughout the training
steps for various models. The x-axis represents the training steps, with the purple line
showing the accuracy trend and the yellow line depicting the response length.
17SimpleRL-Zoo
0 50 100020406080100Clip Ratio (%)
AIME24
0 50 100020406080100
AMC23
0 50 100020406080100
GSM8K
0 50 100020406080100
Math500
0 50 100020406080100
Minerva Math
0 50 100020406080100
OlympiadBench
0.01.53.04.5
0.20.50.81.0
0.10.20.20.20.3
0.20.20.30.40.5
0.30.40.50.6
0.50.60.80.9
Stopped Length (K)
Mistral-7B-v0.1
0 50 100020406080100Clip Ratio (%)
AIME24
0 50 100020406080100
AMC23
0 50 100020406080100
GSM8K
0 50 100020406080100
Math500
0 50 100020406080100
Minerva Math
0 50 100020406080100
OlympiadBench
0.81.62.4
0.40.81.21.6
0.10.20.20.30.4
0.20.50.81.01.2
0.40.81.21.6
0.40.81.21.6
Stopped Length (K)
Llama-3.1-8B
0 50 100020406080100Clip Ratio (%)
AIME24
0 50 100020406080100
AMC23
0 50 100020406080100
GSM8K
0 50 100020406080100
Math500
0 50 100020406080100
Minerva Math
0 50 100020406080100
OlympiadBench
0.50.60.80.91.1
0.30.50.60.8
0.20.20.20.2
0.20.30.40.40.5
0.30.40.50.6
0.30.50.60.8
Stopped Length (K)
DeepSeek-Math-7B
0 100020406080100Clip Ratio (%)
AIME24
0 100020406080100
AMC23
0 100020406080100
GSM8K
0 100020406080100
Math500
0 100020406080100
Minerva Math
0 100020406080100
OlympiadBench
2.04.06.08.0
1.53.04.56.0
0.01.02.03.04.0
1.53.04.5
1.53.04.56.0
1.53.04.56.0
Stopped Length (K)
Mistral-Small-24B
0 50 100020406080100Clip Ratio (%)
AIME24
0 50 100020406080100
AMC23
0 50 100020406080100
GSM8K
0 50 100020406080100
Math500
0 50 100020406080100
Minerva Math
0 50 100020406080100
OlympiadBench
0.60.91.21.5
0.40.60.81.01.2
0.20.20.20.30.3
0.40.50.60.6
0.50.60.70.8
0.60.80.9
Stopped Length (K)
Qwen-2.5-0.5B
0 50 100020406080100Clip Ratio (%)
AIME24
0 50 100020406080100
AMC23
0 50 100020406080100
GSM8K
0 50 100020406080100
Math500
0 50 100020406080100
Minerva Math
0 50 100020406080100
OlympiadBench
0.51.01.52.0
0.40.81.21.6
0.20.20.30.30.4
0.50.60.8
0.50.60.80.9
0.60.81.01.2
Stopped Length (K)
Qwen-2.5-1.5B
0 50 100020406080100Clip Ratio (%)
AIME24
0 50 100020406080100
AMC23
0 50 100020406080100
GSM8K
0 50 100020406080100
Math500
0 50 100020406080100
Minerva Math
0 50 100020406080100
OlympiadBench
0.91.11.21.41.5
0.80.91.11.2
0.30.30.40.40.4
0.60.60.70.70.7
0.70.70.70.8
0.80.91.01.0
Stopped Length (K)
Qwen-2.5-7B
0 100020406080100Clip Ratio (%)
AIME24
0 100020406080100
AMC23
0 100020406080100
GSM8K
0 100020406080100
Math500
0 100020406080100
Minerva Math
0 100020406080100
OlympiadBench
0.81.01.21.41.6
0.80.91.01.01.1
0.30.30.30.3
0.50.60.60.7
0.50.60.60.7
0.80.91.1
Stopped Length (K)
Qwen-2.5-14B
0 100020406080100Clip Ratio (%)
AIME24
0 100020406080100
AMC23
0 100020406080100
GSM8K
0 100020406080100
Math500
0 100020406080100
Minerva Math
0 100020406080100
OlympiadBench
0.60.81.01.21.4
0.50.60.80.9
0.20.20.30.3
0.50.60.60.7
0.40.50.50.60.7
0.60.80.91.1
Stopped Length (K)
Qwen-2.5-32B
0 100020406080100Clip Ratio (%)
AIME24
0 100020406080100
AMC23
0 100020406080100
GSM8K
0 100020406080100
Math500
0 100020406080100
Minerva Math
0 100020406080100
OlympiadBench
0.80.91.11.2
0.70.70.80.8
0.30.30.40.50.5
0.50.60.60.60.7
0.60.60.60.7
0.80.80.80.80.9
Stopped Length (K)
Qwen-2.5-Math-7B
Figure 13: A detailed evaluation of clip ratio and stopped length throughout the training
steps for various models. The x-axis represents the training steps, with the red line showing
the clip ratio trend and the blue line depicting the average stopped length.
18SimpleRL-Zoo
Init Model GSM8KMATH
500Minerva
MathOlympiad
BenchAIME24
(pass@1)AMC23 Avg.
0 Step 92.0 70.6 36.8 36.6 16.7 45.0 49.6
10 Step 93.0 69.4 39.7 32.3 10.4 44.1 48.2
20 Step 92.6 65.2 34.2 30.7 6.7 38.4 44.6
200 Step 90.3 59.0 31.6 23.3 2.1 26.9 38.9
1000 Step 88.9 48.8 27.6 20.7 2.5 18.1 34.4
2000 Step 89.8 49.0 23.2 18.1 0.8 20.3 33.5
4000 Step 87.7 52.0 23.5 17.2 2.1 21.6 34.0
Table 2: Experimental results from multiple Mistral-Small-24B models, each fine-tuned with
a different number of SFT steps on a general SFT dataset for RL. The ”number of steps”
refers to the number of SFT steps applied. The reported benchmarks reflect the performance
metrics on various evaluation benchmarks, measured using the model that achieved the
best average performance after 100 iterations of reinforcement learning training.
CImpact of General SFT on the Performance of Reinforcement Learning
We also investigated the general SFT setting beyond math-related datasets. In this setup,
we first conducted SFT on Mistral-Small-24B using the widely adopted OpenHermes-2.5
dataset.3We implement with LLaMA-Factory (Zheng et al., 2024) and adopt common
hyperparameters of SFT, including 512 examples per batch with a constant learning rate
of 1e-5. For consistency with our other experiments, we fine-tuned the model using the
Qwen chat template. After SFT, we preserved multiple checkpoints at different training
steps, and nearly 800 steps correspond to 1 epochs on the SFT dataset. We then performed
reinforcement learning on these models using identical hyperparameters as in our zero-RL
training experiments.
Table 2 presents our findings, with performance reported as the best results achieved during
RL training up to 100 iterations. The results demonstrate an inverse relationship between
SFT steps and subsequent RL performance: models with more SFT steps showed diminished
performance after RL training. While the average performance after 10 SFT steps remained
comparable to the base model, it still exhibited some negative effects. More significantly,
models with more than 20 steps showed substantially reduced RL potential. Therefore, we
conclude that RL training produces the best performance gain when applied directly to the
base model without any supervised fine-tuning, i.e., the zero RL training.
D Impact of Exploration-Related Hyperparameters
In this section, we examine the effects of exploration-related hyperparameters on ”zero-
training.” Drawing inspiration from Zeng et al. (2025b), we focus on two key factors:
sampling size (the number of responses per query) and sampling temperature.
Sampling Size: We examine how varying sampling sizes N∈ {1, 4, 8, 16, 32 }influence the
training process using the Mistral 24B model; these results are presented in Figure 14. Our
analysis reveals a clear trend: as Nincreases, the model’s average performance notably im-
proves, and variability in response lengths becomes significantly more stable. For example,
after 100 training steps, the scenario with N=32 achieves an average accuracy approxi-
mately 6 points higher than that with N=8. Conversely, smaller sampling sizes ( N=1
and N=4) cause training instability and potential collapse, indicated by rapid growth
in generated length without corresponding accuracy improvements. We hypothesize that
larger sample sizes enable the model to explore a broader and more diverse training space,
which stabilizes advantage estimation and sustains continuous performance improvement.
3https://huggingface.co/datasets/teknium/OpenHermes-2.5
19SimpleRL-Zoo
0 50 10020304050Accuracy (%)
0 50 1000.01.53.04.5Response Length (K)
N=1 N=4 N=8 N=32
Figure 14: Comparison of accuracy and response length using different sampling numbers
N = 1, 4, 8, 32. The training data is the Hard part (MATH lv.3–5) with the same setting in
main results, as described in § 2.2.
Sampling Temperature: We conduct research on Qwen-2.5-0.5B to analyze the impact of
sampling temperature during both training and evaluation on model performance. The
results, presented in Figure 18 , indicate that training with higher temperatures generally
leads to better average performance. For instance, models trained with temperatures of 1.0
and 1.2 outperform those trained with 0.8 and 0.6. Additionally, we find that the optimal
evaluation temperature depends on the training temperature. Specifically, models trained
at higher temperatures require higher sampling temperatures during evaluation, as using
greedy sampling often results in repetitive outputs. Conversely, models trained at lower
temperatures perform best when evaluated with lower sampling temperatures.
E SimpleRL-Zoo For Qwen2.5-Math-7B
In this section, we conduct experiments on Qwen2.5-Math-7B (Yang et al., 2024a) using the
“hard part” data, as described in §2.2, which consists of only 8K examples from MATH
lv3-5. We apply both the PPO and GRPO algorithms to train our base model, and the overall
evaluation results across training steps are shown in Figure 15. The final performance
and response length for both algorithms converge to similar values, with GRPO slightly
outperforming PPO. While the performance continues to improve, the response length
does not exhibit a similar trend. Specifically, the stopping length for both algorithms
remains relatively unchanged, and fluctuations in the average response length are primarily
attributed to changes in the clip ratio. There are two main reasons for this behavior: First,
the maximum context length for Qwen2.5-Math-7B is 4K, which is limited compared to
other models with context lengths exceeding 8K, leading to a high clip ratio. Second, as a
math-specific model, Qwen2.5-Math-7B already performs very well on MATH, the dataset
we used for training, so it may not face enough challenge to further extend its response
length. Therefore, we hypothesize that more challenging data might be needed to push this
capable model further.
F Reasoning Behavior Analysis
We apply Gandhi et al. (2025)’s cognitive behavior framework to perform a detailed analysis
of how model reasoning behaviors change during ”zero training.” We first describe our
analysis setup, then compare reflection keyword tracking against this framework to monitor
reflective behaviors. Finally, we use case studies to illustrate how the reasoning behaviors
of various models evolve during training.
F.1 Setup
We use GPT4-o to identify and analyze the following key reasoning behaviors exhibited in
the model’s responses, with the prompt shown in Figure 16:
20SimpleRL-Zoo
0 20 40 60 80 100 120
Training Iterations2432404856
52.956.6
0.80.91.11.2
1.0K
0.8KAccuracy (%)
Response Length (K)PPO
GRPO
0 20 40 60 80 100 120
Training Iterations020406080100
12.7
5.8
0.50.60.60.7
0.7K
0.7KClip Ratio (%)
Average Stopped Length (K)PPO
GRPO
Figure 15: Comparison of accuracy and response length between PPO and GRPO on
Qwen2.5-Math-7B. The base model is trained using 8K examples from MATH lv3-5, with
the same settings described in § 2.2.
(1)Backtracking : The model actively identifies errors during response generation and
explicitly revises previously used methods.
(2)Verification : The model systematically checks intermediate results to ensure correctness.
(3)Subgoal Setting : The model decomposes complex problems into smaller, manageable
steps.
(4)Enumeration : The model exhaustively considers multiple cases or possibilities to solve
problems.
Note that we replaced ”Backward Chaining” with ”Enumeration,” as the former was not
relevant to our task.
F.2 Comparison of Different Reasoning Behavior Tracking Methods
Using DeepSeek Math’s ”zero-training” process as an example, we compare two different
methods for monitoring reasoning behavior. The first method tracks the occurrence of
specific keywords in the model’s responses, such as ”recheck,” ”rethink,” ”try again,”
”wait,” ”alternatively,” ”retry,” and ”however.” The second method employs (Gandhi et al.,
2025)’s cognitive framework for evaluation. Figure 17 illustrates the observed changes in
reasoning behavior according to these two approaches. During the training process, we
observe that the proportion of specified keywords in the DeepSeek math model’s responses
remains consistently low, exhibiting minimal variation. Conversely, reasoning behaviors
identified by the cognitive framework demonstrate a significant upward trend.
To understand this intriguing discrepancy, we manually review the reasoning behaviors
recorded by the cognitive framework. Our analysis reveals that many of these reasoning
behaviors do not necessarily involve the predefined keywords. For instance, in Figure 19,
the observed reasoning behaviors include Verification and Backtracking, neither of which
contains the specified keywords. This indicates that keywords alone cannot effectively
distinguish or capture the nuanced differences between such behaviors. Similarly, in
Figure 20, the reasoning process involves implicit verification steps, including recalculating
intermediate results such as the dot product and magnitudes before determining the cosine
of the angle. Again, these subtle verification steps are not represented by the designated
keywords. In Figure 22, the reasoning involves considering multiple possible scenarios or
outcomes. This type of exploratory reasoning is also inadequately captured by keyword-
based approaches. These examples collectively illustrate that relying solely on keyword
presence is insufficient for accurately identifying and differentiating complex reasoning
behaviors within model responses.
21SimpleRL-Zoo
Prompt for Identifying and Analyzing Reasoning Behaviors
Below is a chain-of-reasoning generated by a Language Model when attempting to solve 
a math problem. Evaluate this chain-of-reasoning to determine whether it demonstrates 
beneficial problem-solving behaviors that deviate from typical linear, monotonic 
reasoning patterns commonly observed in language models.
<start_of_reasoning>
{input}
<end_of_reasoning>
Specifically, actively identify and emphasize beneficial behaviors such as:
(1) Backtracking: Explicitly revising approaches upon identifying errors or dead ends
 (e.g., ""This approach won't work because..."").
(2) Verification: Systematically checking intermediate results or reasoning steps 
(e.g., ""Let's verify this result by..."").
(3) Subgoal Setting: Breaking down complex problems into smaller, manageable steps 
(e.g., ""To solve this, we first need to..."").
(4) Enumeration: Solving problems by exhaustively considering multiple cases or 
possibilities.
Additionally, remain attentive to and encourage the identification of other 
beneficial behaviors not explicitly listed here, such as creative analogies, 
abstraction to simpler cases, or insightful generalizations.
Important:
Clearly specify each beneficial behavior you identify.
Provide explicit examples from the reasoning chain.
If no beneficial behaviors are observed, explicitly return an empty list.
Provide your evaluation clearly, formatted as follows:
```json
{
  ""behaviour"": """",
  ""example"": """"
}
```
Figure 16: Prompt for identifying and analyzing reasoning behaviors.
F.3 Reasoning Behavior Variations Across Different Models
We present cases illustrating notable improvements in model reasoning behavior during
training (Figure 5). Specifically, these improvements are demonstrated in the following
models: Mistral 24B (Figure 6 and Figure 23), Qwen 2.5-0.5B (Figure 24, Figure 25 and
Figure 26), Qwen 2.5-1.5B (Figure 27 and Figure 28), DeepSeek-math-7B-base (Figure 19,
Figure 20, Figure 21 and Figure 22), and Llama 3.1-8B (Figure 29 and Figure 30).
22SimpleRL-Zoo
0 10 20 30 40 50 60 70 80 90 1000.00.10.20.30.4Frequency
Subgoal Setting
Enumeration
Backtracking
Verification
Keywords
Figure 17: Changes in reflection behavior iden-
tified by different methods.
T em = 1.0 T em = 0.6 T em = 0.0
T emperature (Evaluation)T em = 1.2 T em = 1.0 T em = 0.8 T em = 0.6T emperature (Train)19.3 20.5 19.6
20.9 20.8 20.2
19.5 19.5 19.9
18.5 19.8 19.5
18.519.019.520.020.5Figure 18: Impact of training and
evaluation temperatures on Qwen-
2.5-0.5b’s average final performance
(x-axis: evaluation temp, y-axis:
training temp).
23SimpleRL-Zoo
The average of three consecutive multiples of 3 is $a$.\n\nThe average of four
consecutive multiples of 4 is $a+27$.\n\nThe average of the smallest and largest of
these seven integers is 42 .\n\nDetermine the value of $a$.
find all multiples of 3 and 4, put them into a bracket with the same
name,\n\n<|im_start|>system\nThe first seven multiples are [3,6,9,12,15,18,21]
Let's reason step by step:\n\nThe average of three consecutive multiples of 3 is
a.\nLet's call the three consecutive multiples of 3 as 3x, 3x+3, and 3x+6, where x is an
integer.\nThe average of 3x, 3x+3, and 3x+6 is a.\n(3x + 3x+3 + 3x+6) / 3 = a\n9x + 9 =
3a\n3x + 3 = a\nSo, the three consecutive multiples of 3 are 3x, 3x+3, and 3x+6, where
3x+3 = a.\n\nThe average of four consecutive multiples of 4 is a+27.\nLet's call the four
consecutive multiples of 4 as 4y, 4y+4, 4y+8, and 4y+12, where y is an integer.\nThe
average of 4y, 4y+4, 4y+8, and 4y+12 is a+27.\n(4y + 4y+4 + 4y+8 + 4y+12) / 4 = a+27\n16y
+ 24 = 4(a+27)\n4y + 6 = a+27\n4y = a+21\ny = (a+21)/4\nSo, the four consecutive
multiples of 4 are 4y, 4y+4, 4y+8, and 4y+12, where y = (a+21)/4.\n\nThe average of the
smallest and largest of these seven integers is 42.\nThe smallest integer is 3x, and the
largest integer is 4y+12.\nThe average of 3x and 4y+12 is 42.\n(3x + 4y+12) / 2 = 42\n3x
+ 4y+12 = 84\n3x + 4((a+21)/4) + 12 = 84\n3x + a+21 + 12 = 84\n3x + a+33 = 84\n3x + a =
51\n3x + 3x+3 = 51\n6x + 3 = 51\n6x = 48\nx = 8\nSo, 3x = 24, 3x+3 = 27, and 3x+6 =
30.\n4y = (a+21)/4 = (27+21)/4 = 48/4 = 12\n4y+4 = 12+4 = 16\n4y+8 = 12+8 = 20\n4y+12 =
12+12 = 24\n\nSo, the seven integers are 24, 27, 30, 16, 20, 24, and the average of the
smallest and largest is (24+24)/2 = 48/2 = 24.\n\nThe average of three consecutive
multiples of 3 is a, which is 27.\nThe average of four consecutive multiples of 4 is
a+27, which is 27+27 = 54.\n\nSo, the three consecutive multiples of 3 are 24, 27, and
30, and the four consecutive multiples of 4 are 16, 20, 24, and 28.\n\nThe smallest
integer is 16, and the largest integer is 30.\nThe average of the smallest and largest is
(16+30)/2 = 46/2 = 23.
The average of 24 and 30 is (24+30)/2 = 54/2 = 27.\nSo, the average of the smallest and
largest is 27, which is a.\n\nSo, the value of a is 27.\n\n\\boxed{27}\nQuestion
Base Solution
Zero Solution
Let's check if the average of the smallest and largest is 42:
The smallest integer is 16, and the largest integer is 30.
The average of 16 and 30 is (16+30)/2 = 46/2 = 23.
So, the average of the smallest and largest is not 42.
Let's try again:
The smallest integer is 24, and the largest integer is 30.
Figure 19: A comparison of DeepSeek-Math-7B’s “Backtracking” behavior before and after
zero RL training. Here, “base solution” represents the response of the DeepSeek-Math-7B
base model, while “zero solution” represents the response of the model after training.
24SimpleRL-Zoo
The set of points $(x,y,z)$ that satisfy\n\\[2x = 3y = -z\\]is a line.\n\nThe set of
points $(x,y,z)$ that satisfy\n\\[6x = -y = -4z\\]is another line.\n\nFind the angle
between these lines, in degrees.
I'm not sure what you mean by \""the set of points.\"". A set of points is not a line.\
When you say to \""find the angle,\"" for what purpose? Do you need to understand the
relationship between the two lines, or is it just a math problem?
Let's reason step by step:\n\nThe set of points (x,y,z) that satisfy 2x = 3y = -z is a
line.\n\nLet's find the direction vector of this line.\n\nFrom 2x = 3y, we get x =
3y/2.\n\nFrom 2x = -z, we get z = -2x = -3y.\n\nLet's let y = 2, then x = 3 and z = -
6.\n\nSo a point on this line is (3,2,-6).\n\nThe direction vector of this line is (3-
0,2-0,-6-0) = (3,2,-6).\n\nThe set of points (x,y,z) that satisfy 6x = -y = -4z is
another line.\n\nLet's find the direction vector of this line.\n\nFrom 6x = -y, we get y
= -6x.\n\nFrom 6x = -4z, we get z = -6x/4 = -3x/2.\n\nLet's let x = 2, then y = -12 and
z = -3.\n\nSo a point on this line is (2,-12,-3).\n\nThe direction vector of this line
is (2-0,-12-0,-3-0) = (2,-12,-3).\n\nLet's find the angle between these lines.
The magnitude of the direction vector of the first line is sqrt(3^2 + 2^2 + (-6)^2) =
sqrt(9 + 4 + 36) = sqrt(49) = 7.\n\nThe magnitude of the direction vector of the second
line is sqrt(2^2 + (-12)^2 + (-3)^2) = sqrt(4 + 144 + 9) = sqrt(157).
The cosine of the angle between the lines is the dot product of the direction vectors
divided by the product of the magnitudes of the direction vectors.
The angle between the lines is arccos(0) = 90 degrees.\n\nSo the angle between these
lines is 90 degrees.\n\nLet's put the final answer within \\boxed{90}.\n\nSo the final
answer is \\boxed{90}.\nQuestion
Base Solution
Zero Solution
The dot product of the direction vectors is (3,2,-6) · (2,-12,-3) = 6 - 24 + 18 = 0.
The cosine of the angle between the lines is 0/(7*sqrt(157)) = 0.
Figure 20: A comparison of DeepSeek-Math-7B’s “Verification” behavior before and after
zero RL training. Here, “base solution” represents the response of the DeepSeek-Math-7B
base model, while “zero solution” represents the response of the model after training. Here
involves implicit verification steps, including recalculating intermediate results such as the
dot product and magnitudes before determining the cosine of the angle.
25SimpleRL-Zoo
For a positive integer $a$, define a sequence of integers $x_{1}, x_{2}, \\ldots$ by
letting $x_{1}=a$ and $x_{n+1}=2 x_{n}+1$ for $n \\geq 1$. Let $y_{n}=2^{x_{n}}-1$.
Determine the largest possible $k$ such that, for some positive integer $a$, the numbers
$y_{1}, \\ldots, y_{k}$ are all prime.
If $x_{n+1}=2 x_{n}+1$, then $y_{n+1}=2 x_{n+1}-1=(2^{x_{n+1}-x_{n}}-1)(2^{x_{n}}+1)$.
So, $y_{n+1}<y_{n}$ if and only if $x_{n+1}-x_{n}>1$, which is true if and only if
$x_{n}=2^{i}-1$ for some $i$. Similarly, $y_{n+1}<y_{n}-2$ if and only if $x_{n+1}-
x_{n}>2$, which is true if and only if $x_{n}=2^{i}-2$ for some $i$.
Let's reason step by step.\nLet $a$ be a positive integer.\nDefine a sequence of integers
$x_{1}, x_{2}, \\ldots$ by letting $x_{1}=a$ and $x_{n+1}=2 x_{n}+1$ for $n \\geq
1$.\nLet $y_{n}=2^{x_{n}}-1$.\nWe have $x_{1}=a$ and $x_{n+1}=2 x_{n}+1$ for $n \\geq
1$.\nThen $x_{2}=2 x_{1}+1=2a+1$, $x_{3}=2 x_{2}+1=2(2a+1)+1=4a+3$, and so on.\nThus, the
sequence $x_{n}$ is $a, 2a+1, 4a+3, 8a+7, \\ldots$.\nLet's calculate $y_{n}=2^{x_{n}}-
1$.\nWe have $y_{1}=2^{x_{1}}-1=2^{a}-1$, $y_{2}=2^{x_{2}}-1=2^{2a+1}-1$,
$y_{3}=2^{x_{3}}-1=2^{4a+3}-1$, and so on.\nLet's find the largest possible $k$ such
that, for some positive integer $a$, the numbers $y_{1}, \\ldots, y_{k}$ are all
prime.\nWe have $y_{1}=2^{a}-1$.\nIf $a=1$, then $y_{1}=2^{1}-1=1$, which is not
prime.\nIf $a=2$, then $y_{1}=2^{2}-1=3$, which is prime.\nIf $a=3$, then $y_{1}=2^{3}-
1=7$, which is prime.\nIf $a=4$, then $y_{1}=2^{4}-1=15$, which is not prime.\nThus, the
smallest possible value of $a$ for which $y_{1}$ is prime is $a=2$.
Thus, the largest possible $k$ such that, for some positive integer $a$, the numbers
$y_{1}, \\ldots, y_{k}$ are all prime is $k=2$.
The final answer is \\boxed{2}.Question
Base Solution
Zero Solution
Let's check $y_{2}=2^{x_{2}}-1=2^{2a+1}-1=2^{2*2+1}-1=2^{5}-1=31$, which is prime.
Let's check $y_{3}=2^{x_{3}}-1=2^{4a+3}-1=2^{4*2+3}-1=2^{11}-1=2047=23*89$, which is
not prime.
Figure 21: A comparison of DeepSeek-Math-7B’s “Verification” behavior before and after
zero RL training. Here, “base solution” represents the response of the DeepSeek-Math-7B
base model, while “zero solution” represents the response of the model after training. This
demonstrates more explicit verification, including key phrases like “Let’s check”.
26SimpleRL-Zoo
The expression $10x^2-x-24$ can be written as $(Ax-8)(Bx+3),$ where $A$ and $B$ are
integers. What is $AB + B$?
Let's start by expanding $(Ax-8)(Bx+3)$:
\\begin{align*}\n(Ax-8)(Bx+3) &= ABx^2 + 3Ax - 8Bx - 24\\\\\n&= ABx^2 + (3A-8B)x -
24\n\\end{align*}\nWe can compare this expression to the original expression $10x^2-x-24$
and see that $A = 10$ and $3A - 8B = -1$. Therefore, B must be 4 since 30-8B is -1.\nSo,
the answer is $10\\times4+4 = \\boxed{44}$.
Let's reason step by step:
The expression $10x^2-x-24$ can be written as $(Ax-8)(Bx+3)$, where A and B are
integers.
Expanding $(Ax-8)(Bx+3)$, we get:\n$(Ax-8)(Bx+3) = ABx^2 + 3Ax - 8Bx - 24
= ABx^2 + (3A-8B)x - 24
...
So, the possible values of A and B are:
A = 5, B = 2
A = -20/3, B = -3/2
...
Therefore, AB + B = 12.
The final answer is \\boxed{12}.Question
Base Solution
Zero Solution
Let's check both cases:
Case 1: A = 5, B = 2
(Ax-8)(Bx+3) = (5x-8)(2x+3)
Expanding, we get:
10x^2 + 15x - 16x - 24
= 10x^2 - x - 24
which is the given expression.
Case 2: A = -20/3, B = -3/2
(Ax-8)(Bx+3) = (-20/3 x-8)(-3/2 x+3)
Expanding, we get:
20x^2 - 30x + 24x - 72
= 20x^2 - 6x - 72
which is not the given expression.
Figure 22: A comparison of DeepSeek-Math-7B’s “Enumeration” behavior before and after
zero RL training. Here, “base solution” represents the response of the DeepSeek-Math-7B
base model, while “zero solution” represents the response of the model after training.
27SimpleRL-Zoo
The mean, median, and unique mode of a list of positive integers are three consecutive
integers in some order. Compute the least possible sum of the integers in the original
list.
Step-by-step solution:<|im
Let the list of positive integers be \\( L = \\{x_1, x_2, \\ldots, x_n\\} \\) where \\( n
\\) is the number of elements in the list.\nWe need to find the least possible sum of
these integers given that the mean, median, and unique mode of \\( L \\) are three
consecutive integers.\nLet's denote the mean as \\( \\mu \\), the median as \\( M \\),
and the mode as \\( m \\).
...
To minimize the sum of the elements in the list, we should find the smallest possible
values for \\( \\mu \\), \\( M \\), and \\( m \\) that satisfy the conditions.
Let's start with the simplest case where the list has a small number of elements.
...
...
Since \\( n = 3 \\), each value can only appear at most once, so this case is not valid.
Now, let's try to find the valid cases for \\( n = 3 \\). For \\( n = 3 \\), the three
values can be:\n- \\( x_1 \\), \\( x_2 \\) and \\( x_3 \\)
Let's try the smallest possible values for \\( k \\). Let \\( k = 1 \\), then the three
consecutive integers are 1, 2, and 3.
....
Now, we have found a possible set of values for \\( x_1 \\), \\( x_2 \\), \\( x_3 \\),
and \\( x_4 \\) that satisfy the required conditions. Let's calculate the sum of the
elements.\nThe sum of the elements in the list \\( \\{1, 1, 3, 7\\} \\) is \\( 1 + 1 + 3
+ 7 = 12 \\).\nTherefore, the least possible sum of the integers in the original list is
\\(\\boxed{12}\\).Question
Base Solution
Zero Solution
Case 1: \\( n = 1 \\)\nIn this case, the mean, median, and mode are all the same
number, which contradicts the requirement that they are three consecutive integers.
Case 3: \\( n = 3 \\)\nLet the three elements in the list be \\( x_1 \\), \\( x_2 \\),
and \\( x_3 \\).\nMean \\( \\mu = \\frac{x_1 + x_2 + x_3}{3} \\)\nMedian \\( M = x_2
\\) (since the elements are in ascending order)\nMode: Since \\( n = 3 \\), the mode
can be \\( x_1 \\), \\( x_2 \\), or \\( x_3 \\). It's not guaranteed that the mode will
be unique.\nLet's consider the possible values for \\( x_1 \\), \\( x_2 \\), and \\(
x_3 \\) such that \\( \\mu \\), \\( M \\), and \\( m \\) are three consecutive
integers.\nWithout loss of generality, let's assume \\( x_1 \\leq x_2 \\leq x_3 \\).
Case 3.1: \\( \\mu = k \\), \\( M = k+1 \\), \\( m = k+2 \\)\n\\( M = x_2 = k+1
\\)\n\\( \\mu = \\frac{x_1 + x_2 + x_3}{3} = k \\)\n\\( x_1 + x_2 + x_3 = 3k \\)\n\\(
x_1 + (k+1) + x_3 = 3k \\)\n\\( x_1 + x_3 = 3k - (k+1) \\)\n\\( x_1 + x_3 = 2k - 1
\\)\nMode \\( m = k+2 \\)\nSince the mode is unique, one of the values \\( x_1, x_2,
x_3 \\) must appear exactly once while the other two values appear the same number of
times. Since \\( n = 3 \\), each value can only appear at most once, so this case is
not valid.
Case 3.1: \\( \\mu = 1 \\), \\( M = 2 \\), \\( m = 3 \\)\n\\( \\mu = \\frac{x_1 + x_2 +
x_3}{3} = 1 \\)\n\\( x_1 + x_2 + x_3 = 3 \\)
Figure 23: A comparison of Mistral-Small-24B’s “Enumeration” behavior before and after
zero RL training. Here, “base solution” represents the response of the Mistral-Small-24B
base model, while “zero solution” represents the response of the model after training.
28SimpleRL-Zoo
Compute $a+b+c,$ given that $a,$ $b,$ and $c$ are the roots of \\[\\frac{1}{x} + 5x^2 =
6x - 24.\\]
To find the constant term $c$, what we want is that the polynomial\n\\[\\frac{1}{x} +
5x^2 - 92x + c = 0\\]\nis the solution of the given polynomial\n\\[\\frac{1}{x} + 5x^2 =
6x - 24.\\]\nNow to find $c$, we factor $g(x) = \\frac{1}{x} + 5x^2 + 4x - 24 =
\\frac{5x^3 + 2x^2 - 26x - 24}{x} = 5x^2 + \\frac{2x^2 - 26x - 24}{x}.$
So,\n\\[\\frac{5x^2}{x} + \\frac{2x^2}{x} - \\frac{26x}{x} - \\frac{24}{x} = 6x -
24.\\]\nSimplifying, we have $5x^2 + 2x^2 - 26x - 24 - 2x^2 = 0$\n$\\implies x^4 - 30x -
24 = 0.$\nIf $g_1,$ $g_2,$ and $g_3$ are the roots of $g_1 = g_2$ and $g_1 = g_3$, then
we can conclude that $g_1$ and $g_2$ are roots of $g$.\nSo $g = g_1 \\cdot g_2 =
g_3^2.$\nNow $6g - 24 + c = 0,$ so $c = 24 - 6g.$ We want the quotient, which is the
form\n$$6\\left(x^4 - 30x - 24\\right) = 6x^4 - 180x - 144.$$
To find the roots \\(a\\), \\(b\\), and \\(c\\) of the equation \\(\\frac{1}{x} + 5x^2 =
6x - 24\\), we first need to rewrite the equation in a standard quadratic
form:\n\n\\[\n\\frac{1}{x} + 5x^2 - 6x + 24 = 0.\n\\]\n\nMultiplying through by \\(x\\)
to clear the fraction, we get:\n\n\\[\n1 + 5x^3 - 6x^2 + 24x = 0.\n\\]\n\nRearranging
terms, we obtain the polynomial:\n\n\\[\n5x^3 - 6x^2 + 24x + 1 = 0.\n\\]\n\nWe need to
solve this cubic equation for \\(x\\). By the Rational Root Theorem, the possible
rational roots are \\(\\pm 1, \\pm \\frac{1}{5}\\). 
Testing \\(x = \\frac{1}{5}\\):\n\n\\[\n5\\left(\\frac{1}{5}\\right)^3 -
6\\left(\\frac{1}{5}\\right)^2 + 24\\left(\\frac{1}{5}\\right) + 1 = 5 \\cdot \\frac{1}
{125} - 6 \\cdot \\frac{1}{25} + \\frac{24}{5} + 1 = \\frac{5}{125} - \\frac{6}{25} +
\\frac{24}{5} + 1 = \\frac{1}{25} - \\frac{6}{25} + \\frac{120}{25} + \\frac{25}{25} =
\\frac{1 - 6 + 120 + 25}{25} = \\frac{140}{25} = 0.\n\\]\n\nSo, \\(x = \\frac{1}{5}\\) is
a root. We can factor \\(x - \\frac{1}{5}\\) out of the polynomial \\(5x^3 - 6x^2 + 24x +
1\\). Using synthetic division:\n\n\\[\n\\begin{array}{r|rrrr}\n\\frac{1}{5} & 5 & -6 &
24 & 1 \\\\\n   &   & 1 & -\\frac{1}{5} & \\frac{11}{25} \\\\\n\\hline\n   & 5 & -5 & 23
& 0 \\\\\n\\end{array}\n\\]\n\nThe quotient is \\(5x^2 - 5x + 1\\). So, we
have:\n\n\\[\n5x^3 - 6x^2 + 24x + 1 = (x - \\frac{1}{5})(5x^2 - 5x + 1).\n\\]\n\nNext, we
solve the quadratic equation \\(5x^2 - 5x + 1 = 0\\) using the quadratic formula \\(x =
\\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\):\n\n\\[\nx = \\frac{5 \\pm \\sqrt{25 - 20}}{10}
= \\frac{5 \\pm \\sqrt{5}}{10}.\n\\]\n\nSo, the roots are \\(x = \\frac{1}{5}\\), \\(x =
\\frac{5 + \\sqrt{5}}{10}\\), and \\(x = \\frac{5 - \\sqrt{5}}{10}\\). Therefore, the
roots \\(a\\), \\(b\\), and \\(c\\) are \\(a = \\frac{1}{5}\\), \\(b = \\frac{5 +
\\sqrt{5}}{10}\\), and \\(c = \\frac{5 - \\sqrt{5}}{10}\\).\n\nThe sum of the roots \\(a
+ b + c\\) is:\n\n\\[\na + b + c = \\frac{1}{5} + \\frac{5 + \\sqrt{5}}{10} + \\frac{5 -
\\sqrt{5}}{10} = \\frac{2}{10} + \\frac{5 + \\sqrt{5} + 5 - \\sqrt{5}}{10} = \\frac{2}
{10} + \\frac{10}{10} = \\frac{2 + 10}{10} = \\frac{12}{10} = \\frac{6}{5}.\n\\]\n\nThus,
the value of \\(a + b + c\\) is:\n\n\\[\n\\boxed{\\frac{6}{5}}.\n\\]Question
Base Solution
Zero Solution
Let's test these possible roots.
Testing \\(x = -1\\):\n\n\\[\n5(-1)^3 - 6(-1)^2 + 24(-1) + 1 = -5 - 6 - 24 + 1 = -34
\\neq 0.\n\\]
Figure 24: A comparison of Qwen-2.5-0.5B’s “Verification” behavior before and after zero
RL training. Here, “base solution” represents the response of the Qwen-2.5-0.5B base model,
while “zero solution” represents the response of the model after training.
29SimpleRL-Zoo
The sum of the digits of a two-digit number is $13.$ The difference between the number
and the number with its digits reversed is $27.$ What is the sum of the original number
and the number with its digits reversed?
The tens digit can be any digit from 1 to 9. To get a two-digit number, the tens digit
has to be 8 and the units digit can be 9. The sum of the tens digit and the units digit
is 8 + 9 = 17. From the given information, the difference between the number with digits
reversed and the original number is 27. If we know that the difference is 27, then the
sum of the units digit and the tens digit will give us the difference. Hence, we can form
the following equation 8 + 9 - (17 - 27) = 4 + 18 = 22. Therefore, the sum of the
original number and the number with its digits reversed is 22.
Let the two-digit number be \\(10a + b\\), where \\(a\\) and \\(b\\) are the digits.
According to the problem, we have two equations:\n1. \\(a + b = 13\\)\n2. The difference
between the number and the number with its digits reversed is 27, so \\(10b + a - (10a +
b) = 27\\).\n\nSimplifying the second equation, we get:\n\\[10b + a - 10a - b =
27\\]\n\\[9b - 9a = 27\\]\n\\[b - a = 3\\]\n\nNow we have a system of linear
equations:\n1. \\(a + b = 13\\)\n2. \\(b - a = 3\\)\n\nWe can solve these equations
simultaneously. Adding the two equations, we get:\n\\[a + b + b - a = 13 + 3\\]\n\\[2b =
16\\]\n\\[b = 8\\]\n\nSubstituting \\(b = 8\\) into the first equation, we get:\n\\[a +
8 = 13\\]\n\\[a = 5\\]\n\nSo, the two-digit number is \\(10a + b = 10(5) + 8 =
58\\).\n\nThe number with its digits reversed is \\(85\\). The difference between the
original number and the number with its digits reversed is:\n\\[58 - 85 = -27\\]
Given:\n1. \\(a + b = 13\\)\n2. \\(b - a = 3\\)\n\nWe can solve these equations again.
Adding the two equations, we get:\n\\[a + b + b - a = 13 + 3\\]\n\\[2b = 16\\]\n\\[b =
8\\]\n\nSubstituting \\(b = 8\\) into the first equation, we get:\n\\[a + 8 =
13\\]\n\\[a = 5\\]\n\nSo, the two-digit number is \\(10a + b = 10(5) + 8 = 58\\).\n\nThe
number with its digits reversed is \\(85\\). The difference between the original number
and the number with its digits reversed is:\n\\[58 - 85 = -27\\]\n\nIt seems there was a
misunderstanding. Let's re-evaluate the problem correctly. The correct interpretation
should be:\n1. \\(a + b = 13\\)\n2. \\(b - a = 3\\)\n\nSolving these equations
correctly, we get:\n\\[a = 5\\]\n\\[b = 8\\]\n\nSo, the two-digit number is \\(10a + b =
10(5) + 8 = 58\\).\n\nThe number with its digits reversed is \\(85\\). The difference
between the original number and the number with its digits reversed is:\n\\[58 - 85 = -
27\\]\n\nIt appears there was a miscalculation. Let's recheck the conditions again. The
correct solution should be:\nThe sum of the original number and the number with its
digits reversed is:\n\\[58 + 85 = 143\\]\n\nThus, the sum of the original number and the
number with its digits reversed is:\n\\[\\boxed{143}\\]Question
Base Solution
Zero Solution
However, we are given that the difference is 27, which indicates there might be a
misunderstanding in the problem statement or a need to re-evaluate the conditions.
Let's recheck the conditions and solve again.
Figure 25: A comparison of Qwen-2.5-0.5B’s “Backtracking” behavior before and after zero
RL training. Here, “base solution” represents the response of the Qwen-2.5-0.5B base model,
while “zero solution” represents the response of the model after training.
30SimpleRL-Zoo
Compute the least integer greater than 2023 , the sum of whose digits is 17 .
First, note that, the sum of the digits of 2023 is 17 , so 2023 is 5 less than double of
half of 2023. That is, 2023 is some integer n and 2023 - 5 = n/2 . 2023 is 5 less than
double 2023. Since the difference 5 is odd, it follows that n must be odd, so that
&strong;6 is the least nonnegative integer greater than or equal to 6+5=11. Therefore,
the least integer greater than 2023, whose sum of digits is 17, is 11.\n####\nThe answer
is n.
To find the least integer greater than 2023 whose sum of digits is 17, we need to follow
these steps:\n\n1. Calculate the sum of the digits of 2023.\n2. Find the smallest integer
greater than 2023 whose sum of digits is 17.\n3. Determine the least integer greater than
2023 that meets the criteria.\n\nFirst, let's calculate the sum of the digits of
2023:\n\\[ 2 + 0 + 2 + 3 = 7 \\]\nSo, the sum of the digits of 2023 is 7. We need to find
the smallest integer greater than 2023 whose sum of digits is 17.\n\nLet's denote the
smallest integer greater than 2023 by \\( x \\). We need to find \\( x \\) such
that:\n\\[ x - 2023 < 17 \\]\n\\[ x > 2023 + 17 \\]\n\\[ x > 2040 \\]\nThe smallest
integer greater than 2040 is 2041. Now, we need to check if 2041 has a sum of digits
equal to 17:\n\\[ 2 + 0 + 4 + 1 = 7 \\]Question
Base Solution
Zero Solution
Since 2041 does not have a sum of digits equal to 17, we need to check the next
integer, which is 2042:\n\\[ 2 + 0 + 4 + 2 = 8 \\]
Since 2042 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2043:\n\\[ 2 + 0 + 4 + 3 = 9 \\]
Since 2043 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2044:\n\\[ 2 + 0 + 4 + 4 = 10 \\]
Since 2044 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2045:\n\\[ 2 + 0 + 4 + 5 = 11 \\]
Since 2045 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2046:\n\\[ 2 + 0 + 4 + 6 = 12 \\]
Since 2046 does not have a sum of digits equal to 17, we continue checking the next 
...
Since 2066 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2067:\n\\[ 2 + 0 + 6 + 7 = 15 \\]
Since 2067 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2068:\n\\[ 2 + 0 + 6 + 8 = 15 \\]
Since 2068 does not have a sum of digits equal to 17, we continue checking the next
integer, which is 2069:\n\\[ 2 + 0 + 6 + 9 = 17 \\]
Since 2069 has a sum of digits equal to 17, the least integer greater than 2023 whose
sum of digits is 17 is:\n\\[ \\boxed{2069} \\]
Figure 26: A comparison of Qwen-2.5-0.5B’s “Enumeration” behavior before and after zero
RL training. Here, “base solution” represents the response of the Qwen-2.5-0.5-B base model,
while “zero solution” represents the response of the model after training.
31SimpleRL-Zoo
Let \\[f(n) =\n\\begin{cases}\n4n+3 &\\text{if }n<a, \\\\\n7n-12 &\\text{if
}n\\ge{a}.\n\\end{cases}\n\\]Find $a$ if the graph of $y=f(n)$ is continuous.
To make the graph continuous, the values of $f(n)$ when $n<a$, and when $n\\ge{a}$, must
be equal.\nSubstituting $n=a$ into $7n-12$, we find $7a-12$. Substituting $n$ into
$4n+3$, we find $4a+3$. Setting these equal to each other and solving for $a$, we find
$a=3$.\nThe answer is 3
To determine the value of \\( a \\) that makes the function \\( f(n) \\) continuous, we
need to ensure that the left-hand limit as \\( n \\) approaches \\( a \\) from the left
equals the right-hand limit as \\( n \\) approaches \\( a \\) from the right, and both
equal the value of the function at \\( n = a \\).\n\nThe function \\( f(n) \\) is defined
as:\n\\[\nf(n) =\n\\begin{cases}\n4n+3 & \\text{if } n < a, \\\\\n7n-12 & \\text{if } n
\\ge a.\n\\end{cases}\n\\]\n\nFor the function to be continuous at \\( n = a \\), the
following must be true:\n\\[\n\\lim_{n \\to a^-} f(n) = \\lim_{n \\to a^+} f(n) =
f(a)\n\\]\n\nFirst, let's find the left-hand limit as \\( n \\) approaches \\( a
\\):\n\\[\n\\lim_{n \\to a^-} f(n) = 4a + 3\n\\]\n\nNext, let's find the right-hand limit
as \\( n \\) approaches \\( a \\):\n\\[\n\\lim_{n \\to a^+} f(n) = 7a - 12\n\\]\n\nSince
the function is continuous at \\( n = a \\), we set the left-hand limit equal to the
right-hand limit:\n\\[\n4a + 3 = 7a - 12\n\\]\n\nNow, solve for \\( a \\):\n\\[\n4a + 3 =
7a - 12\n\\]\n\\[\n3 + 12 = 7a - 4a\n\\]\n\\[\n15 = 3a\n\\]\n\\[\na = 5\n\\]\n\nTo ensure
that the function is continuous at \\( n = a \\), 
we also need to check that the value of the function at \\( n = a \\) is the same from
both sides. Substituting \\( a = 5 \\) into the function:\n\\[\nf(5) = 4(5) + 3 = 20 + 3 =
23\n\\]\n\nNow, let's verify the function values:
- For \\( n < 5 \\), \\( f(n) = 4n + 3 \\). At \\( n = 5 \\):\n  \\[\n  f(5) = 4(5) + 3 =
20 + 3 = 23\n  \\]\n\n- For \\( n \\ge 5 \\), \\( f(n) = 7n - 12 \\). At \\( n = 5 \\):\n
\\[\n  f(5) = 7(5) - 12 = 35 - 12 = 23\n  \\]\n\nSince both expressions give \\( f(5) = 23
\\), the function is continuous at \\( n = 5 \\).\n\nTherefore, the value of \\( a \\)
that makes the function \\( f(n) \\) continuous is \\(\\boxed{5}\\).Question
Base Solution
Zero Solution
we also need to check that the value of the function at \\( n = a \\) is the same from
both sides. Substituting \\( a = 5 \\) into the function:\n\\[\nf(5) = 4(5) + 3 = 20 +
3 = 23\n\\]\n\nNow, let's verify the function values:
Figure 27: A comparison of Qwen-2.5-1.5B’s “Verification” behavior before and after zero
RL training. Here, “base solution” represents the response of the Qwen-2.5-1.5B base model,
while “zero solution” represents the response of the model after training.
32SimpleRL-Zoo
Determine all linear functions $f(x)=a x+b$ such that if $g(x)=f^{-1}(x)$ for all values
of $x$, then $f(x)-g(x)=44$ for all values of $x$. (Note: $f^{-1}$ is the inverse
function of $f$.)
The first thought might be to work through the problem algebraically. Note that the
question is really asking for a function with codomain of $-4\\------\\ 44$, in other
words, for any $y$ between $40$ and $-40$, there should be a corresponding $x$ such that
$f(x)=y$. But then, all we need is to reverse the variables, $f(g(x))-g(x)=44$.\nThis
leads us to the idea of trying $f(x)=40+a x$ ($a$ time dilation, so that all such $a$'s
cancel out), which leads\n$$f(x)+g(x)=44+2 a x,$$\nwhich cannot be the untagged error
$44$, $2a$ simply cannot be 1! This has no solution, meaning we iterate our kindest
algorithmical thought.\nSo, back to the first trajectory, $g(x)=2-x$. So $f(g^{-1}
(x))=f(2-x)=a(2-x)+b=2a-x+a+b=2a-x+3-x=40-x=2(x-40)=44$.\nSo, $x-40=22$, which means
$x=62$.\nWe are done!\nLet's implement our solution in Python.
To determine all linear functions \\( f(x) = ax + b \\) such that if \\( g(x) = f^{-1}(x)
\\) for all values of \\( x \\), then \\( f(x) - g(x) = 44 \\) for all values of \\( x
\\), we will follow these steps:\n\n1. **Find the inverse function \\( g(x) \\) of \\(
f(x) \\):**\n\n   Given \\( f(x) = ax + b \\), we find the inverse function \\( g(x) \\)
by solving for \\( x \\) in terms of \\( y \\) where \\( y = f(x) \\):\n   \\[\n   y = ax
+ b\n   \\]\n   Solving for \\( x \\):\n   \\[\n   y - b = ax \\implies x = \\frac{y - b}
{a}\n   \\]\n   Therefore, the inverse function is:\n   \\[\n   g(x) = \\frac{x - b}{a}\n
\\]\n\n2. **Set up the given condition \\( f(x) - g(x) = 44 \\):**\n\n   We know that \\(
f(x) = ax + b \\) and \\( g(x) = \\frac{x - b}{a} \\). Substitute these into the
condition:\n   \\[\n   f(x) - g(x) = (ax + b) - \\frac{x - b}{a}\n   \\]\n   Simplify the
right-hand side:\n   \\[\n   ax + b - \\frac{x - b}{a} = ax + b - \\frac{x}{a} + \\frac{b}
{a}\n   \\]\n   Combine the terms:\n   \\[\n   ax - \\frac{x}{a} + b + \\frac{b}{a} =
\\frac{a^2x}{a} - \\frac{x}{a} + b + \\frac{b}{a} = \\frac{a^2x - x}{a} + b + \\frac{b}{a}
= \\frac{(a^2 - 1)x}{a} + b + \\frac{b}{a}\n   \\]\n   Simplify further:\n   \\[\n
\\frac{(a^2 - 1)x}{a} + \\frac{ab + b}{a} = \\frac{(a^2 - 1)x + ab + b}{a}\n   \\]\n
According to the given condition, this equals 44 for all \\( x \\):\n   \\[\n
\\frac{(a^2 - 1)x + ab + b}{a} = 44\n   \\]\n   For this to hold for all \\( x \\), the
coefficient of \\( x \\) must be zero (since the left-hand side is a linear function in
\\( x \\)):\n   \\[\n   a^2 - 1 = 0 \\implies a^2 = 1 \\implies a = \\pm 1\n   \\]
4. **Conclusion:**\n\n   The only linear function \\( f(x) = ax + b \\) that satisfies the
given condition is when \\( a = 1 \\) and \\( b = 22 \\). Therefore, the linear function
is:\n   \\[\n   \\boxed{f(x) = x + 22}\n   \\]Question
Base Solution
Zero Solution
3. **Consider the two cases for \\( a \\):**\n\n   - **Case 1: \\( a = 1 \\)**\n
\\[\n     f(x) = x + b\n     \\]\n     \\[\n     g(x) = \\frac{x - b}{1} = x - b\n
\\]\n     Substitute into the condition:\n     \\[\n     f(x) - g(x) = (x + b) - (x -
b) = x + b - x + b = 2b\n     \\]\n     Set equal to 44:\n     \\[\n     2b = 44
\\implies b = 22\n     \\]\n     Thus, \\( f(x) = x + 22 \\).\n\n   - **Case 2: \\( a =
-1 \\)**\n     \\[\n     f(x) = -x + b\n     \\]\n     \\[\n     g(x) = \\frac{x - b}{-
1} = -x + b\n     \\]\n     Substitute into the condition:\n     \\[\n     f(x) - g(x)
= (-x + b) - (-x + b) = -x + b + x - b = 0\n     \\]\n     This does not satisfy the
condition \\( f(x) - g(x) = 44 \\).
Figure 28: A comparison of Qwen-2.5-1.5B’s “Enumeration” behavior before and after zero
RL training. Here, “base solution” represents the response of the Qwen-2.5-1.5B base model,
while “zero solution” represents the response of the model after training.
33SimpleRL-Zoo
Find all values of $x$ that satisfy the equation $x = \\!\\sqrt{11-2x} + 4$.
$ x = \\!\\sqrt{11-2x} + 4$\nSubtract 4 on the both sides\n$x-4 = \\!\\sqrt{11-2x}
$\nSquare on both sides$ (x-4)^2 = \\!\\sqrt{11-2x}$\nSimplify $(x-4)^2 = 11-2x$\nExpand
$(x^4 - 3x + 12) = 11-2x$\n$5x^2 - x=13$ Wait. Rewriting that square is not right: $x-4
= 11-2x$ (x-4 + 2x = 11)\n$ 4x + 12$\n$ -3x^2 + x +2x -4x = 13$\n$-3x^2 + -2x =13$\n$-
3x^2 -2x - 13 = 0$\nB is our case : $(-b / 2a)^2.. $\nHere's what we have $b = -2$, and
$-3 / -2$ equals 1.5. Now we had to find the square. So the square is 2.25. But what
about $-3x^2 + -2x =13$? Since our coefficient is -3, we multiply it after we take away
the -2. 2.25 X (-3) = -6.75. And +13 equals 6.25. I don't know if my methods are
correct. I need a one-line solution or a calculus equation so I can solve it.
Given: $x = \\!\\sqrt{11-2x} + 4$\nSubtract 4 from both sides, we get\n$x - 4 =
\\!\\sqrt{11-2x}$\nSquare both sides, we get\n$(x - 4)^2 = 11-2x$\n$x^2 - 8x + 16 = 11-
2x$\n$x^2 - 10x + 5 = 0$\n$x = \\frac{10 \\pm \\sqrt{100 - 20}}{2} = \\frac{10 \\pm
\\sqrt{80}}{2} = \\frac{10 \\pm 4\\sqrt{5}}{2} = 5 \\pm 2\\sqrt{5}$\n$x = 5 +
2\\sqrt{5}$ or $x = 5 - 2\\sqrt{5}$\n$x = 5 + 2\\sqrt{5}$ satisfies the equation.\n$x =
5 + 2\\sqrt{5} = \\!\\sqrt{11-2(5 + 2\\sqrt{5})} + 4$\n$ = \\!\\sqrt{11 - 10 -
4\\sqrt{5}} + 4$\n$ = \\!\\sqrt{1 - 4\\sqrt{5}} + 4$\n$ = \\!\\sqrt{1 - 4\\sqrt{5}} + 4$
$x = 5 - 2\\sqrt{5} = \\!\\sqrt{11-2(5 - 2\\sqrt{5})} + 4$\n$ = \\!\\sqrt{11 - 10 +
4\\sqrt{5}} + 4$\n$ = \\!\\sqrt{1 + 4\\sqrt{5}} + 4$\n$ = \\!\\sqrt{1 + 4\\sqrt{5}} +
4$\n$\\!\\sqrt{1 + 4\\sqrt{5}}$ is a real number. Hence, $x = 5 - 2\\sqrt{5}$ is a
solution.\n$x = 5 - 2\\sqrt{5}$Question
Base Solution
Zero Solution
Since, $\\sqrt{1 - 4\\sqrt{5}}$ is not a real number, $x = 5 + 2\\sqrt{5}$ is not a
solution.
Figure 29: A comparison of Llama-3.1-8B’s “Verification” behavior before and after zero
RL training. Here, “base solution” represents the response of the Llama-3.1-8B base model,
while “zero solution” represents the response of the model after training.
34SimpleRL-Zoo
The sum of the digits of a two-digit number is $13.$ The difference between the number
and the number with its digits reversed is $27.$ What is the sum of the original number
and the number with its digits reversed?
1) In a two digit number. $$L \\cdot Tens + R \\cdot Ones$$ with,\n$$L \\in [\\!
[0,9]\\!]$$ and\n$$R \\in [\\![1,9]\\!]$$\n2) If sum of the digits is $$13$$, then
(hypothesis).\n$$\\Leftrightarrow L+R=13$$\n3) By the hypothesis, number $N$ and it's
reversed number $N'$\nare such that $$N-N'=27$$\nand we have $$L \\cdot Tens + R \\cdot
Ones = L \\cdot Ones + R \\cdot Tens$$ So, $$N-N' = (L-R)(Ten-Ones)-(L-R)(One-
Tens)=180$$ which is equivalent to $$55$$. The sum $N+N'$ of these.\nWe have $$N+N'
=(L+R) \\cdot Ones + (L+R) \\cdot Tens$$ $$+$$ $$+(L+R) \\cdot Ones + (L+R) \\cdot
Tens$$ So, $$2 \\cdot (L+R) \\cdot Ones$$ $$+$$ $$+ 2 \\cdot (L+R) \\cdot Tens $$ which
is equal to $220=2 \\cdot 110=2 \\cdot (10 \\cdot 11) \\quad.$
The sum of the digits of a two-digit number is $13$
Let digit at unit's place = a\nand digit at ten's place = b\na + b = 13
Number = 10*b + a = 10*b + a
Number with digits reversed = 10*a + b
Difference between the number and the number with its digits reversed = 10*b + a - (10*a
+ b) = 10*b + a - 10*a - b = 10*b - 10*a + a - b = 9*b - 9*a = 27
9*b - 9*a = 279*b = 9*a + 27\nb = a + 3
Number = 10*b + a = 10 * 8 + 5 = 80 + 5 = 85
Number with digits reversed = 10*a + b = 10 * 5 + 8 = 50 + 8 = 58
Difference between the number and the number with its digits reversed = 85 - 58 = 27
Given, Difference between the number and the number with its digits reversed = 27
So, 85 - 58 = 27
Thus, 85 + 58 = 143Question
Base Solution
Zero Solution
Next, the difference between the number and the number with its digits reversed is
$27.$
Substituting b = a + 3 in a + b = 13, we get\na + (a + 3) = 13\n2a + 3 = 13\n2a = 10\na
= 5\nb = a + 3 = 5 + 3 = 8
Figure 30: A comparison of Llama-3.1-8B’s “Subgoal Setting” behavior before and after zero
RL training. Here, “base solution” represents the response of the Llama-3.1-8B base model,
while “zero solution” represents the response of the model after training.
35"
11,https://github.com/MilesCranmer/PySR,"






































































GitHub - MilesCranmer/PySR: High-Performance Symbolic Regression in Python and Julia














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        MilesCranmer
 
/

PySR

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    239




 


          Star
 2.7k








        High-Performance Symbolic Regression in Python and Julia
      





ai.damtp.cam.ac.uk/pysr


License





     Apache-2.0 license
    






2.7k
          stars
 



239
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
77






Pull requests
16






Discussions







Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Discussions











          Actions











          Projects











          Security











          Insights






 





MilesCranmer/PySR



 












    masterBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History2,617 Commits.github.github  benchmarksbenchmarks  docsdocs  examplesexamples  pysrpysr  .coveragerc.coveragerc  .gitignore.gitignore  .pre-commit-config.yaml.pre-commit-config.yaml  Apptainer.defApptainer.def  CITATION.mdCITATION.md  CONTRIBUTORS.mdCONTRIBUTORS.md  DockerfileDockerfile  LICENSELICENSE  README.mdREADME.md  environment.ymlenvironment.yml  example.pyexample.py  mkdocs.ymlmkdocs.yml  mypy.inimypy.ini  pyproject.tomlpyproject.toml  setup.pysetup.py  View all filesRepository files navigationREADMEApache-2.0 license
PySR searches for symbolic expressions which optimize a particular objective.





pysr_animation.mp4





PySR: High-Performance Symbolic Regression in Python and Julia



Docs
Forums
Paper
colab demo














pip
conda
Stats






pip: conda: 




If you find PySR useful, please cite the paper arXiv:2305.01582.
If you've finished a project with PySR, please submit a PR to showcase your work on the research showcase page!
Contents:

Why PySR?
Installation
Quickstart
→ Documentation
Contributors


Test status



Linux
Windows
macOS









Docker
Conda
Coverage









Why PySR?
PySR is an open-source tool for Symbolic Regression: a machine learning
task where the goal is to find an interpretable symbolic expression that optimizes some objective.
Over a period of several years, PySR has been engineered from the ground up
to be (1) as high-performance as possible,
(2) as configurable as possible, and (3) easy to use.
PySR is developed alongside the Julia library SymbolicRegression.jl,
which forms the powerful search engine of PySR.
The details of these algorithms are described in the PySR paper.
Symbolic regression works best on low-dimensional datasets, but
one can also extend these approaches to higher-dimensional
spaces by using ""Symbolic Distillation"" of Neural Networks, as explained in
2006.11287, where we apply
it to N-body problems. Here, one essentially uses
symbolic regression to convert a neural net
to an analytic equation. Thus, these tools simultaneously present
an explicit and powerful way to interpret deep neural networks.
Installation
Pip
You can install PySR with pip:
pip install pysr
Julia dependencies will be installed at first import.
Conda
Similarly, with conda:
conda install -c conda-forge pysr


Docker

You can also use the Dockerfile to install PySR in a docker container

Clone this repo.
Within the repo's directory, build the docker container:

docker build -t pysr .

You can then start the container with an IPython execution with:

docker run -it --rm pysr ipython
For more details, see the docker section.



Apptainer

If you are using PySR on a cluster where you do not have root access,
you can use Apptainer to build a container
instead of Docker. The Apptainer.def file is analogous to the Dockerfile,
and can be built with:
apptainer build --notest pysr.sif Apptainer.def
and launched with
apptainer run pysr.sif



Troubleshooting

One issue you might run into can result in a hard crash at import with
a message like ""GLIBCXX_... not found"". This is due to another one of the Python dependencies
loading an incorrect libstdc++ library. To fix this, you should modify your
LD_LIBRARY_PATH variable to reference the Julia libraries. For example, if the Julia
version of libstdc++.so is located in $HOME/.julia/juliaup/julia-1.10.0+0.x64.linux.gnu/lib/julia/
(which likely differs on your system!), you could add:
export LD_LIBRARY_PATH=$HOME/.julia/juliaup/julia-1.10.0+0.x64.linux.gnu/lib/julia/:$LD_LIBRARY_PATH

to your .bashrc or .zshrc file.

Quickstart
You might wish to try the interactive tutorial here, which uses the notebook in examples/pysr_demo.ipynb.
In practice, I highly recommend using IPython rather than Jupyter, as the printing is much nicer.
Below is a quick demo here which you can paste into a Python runtime.
First, let's import numpy to generate some test data:
import numpy as np

X = 2 * np.random.randn(100, 5)
y = 2.5382 * np.cos(X[:, 3]) + X[:, 0] ** 2 - 0.5
We have created a dataset with 100 datapoints, with 5 features each.
The relation we wish to model is $2.5382 \cos(x_3) + x_0^2 - 0.5$.
Now, let's create a PySR model and train it.
PySR's main interface is in the style of scikit-learn:
from pysr import PySRRegressor

model = PySRRegressor(
    maxsize=20,
    niterations=40,  # < Increase me for better results
    binary_operators=[""+"", ""*""],
    unary_operators=[
        ""cos"",
        ""exp"",
        ""sin"",
        ""inv(x) = 1/x"",
        # ^ Custom operator (julia syntax)
    ],
    extra_sympy_mappings={""inv"": lambda x: 1 / x},
    # ^ Define operator for SymPy as well
    elementwise_loss=""loss(prediction, target) = (prediction - target)^2"",
    # ^ Custom loss function (julia syntax)
)
This will set up the model for 40 iterations of the search code, which contains hundreds of thousands of mutations and equation evaluations.
Let's train this model on our dataset:
model.fit(X, y)
Internally, this launches a Julia process which will do a multithreaded search for equations to fit the dataset.
Equations will be printed during training, and once you are satisfied, you may
quit early by hitting 'q' and then <enter>.
After the model has been fit, you can run model.predict(X)
to see the predictions on a given dataset using the automatically-selected expression,
or, for example, model.predict(X, 3) to see the predictions of the 3rd equation.
You may run:
print(model)
to print the learned equations:
PySRRegressor.equations_ = [
	   pick     score                                           equation       loss  complexity
	0        0.000000                                          4.4324794  42.354317           1
	1        1.255691                                          (x0 * x0)   3.437307           3
	2        0.011629                          ((x0 * x0) + -0.28087974)   3.358285           5
	3        0.897855                              ((x0 * x0) + cos(x3))   1.368308           6
	4        0.857018                ((x0 * x0) + (cos(x3) * 2.4566472))   0.246483           8
	5  >>>>       inf  (((cos(x3) + -0.19699033) * 2.5382123) + (x0 *...   0.000000          10
]
This arrow in the pick column indicates which equation is currently selected by your
model_selection strategy for prediction.
(You may change model_selection after .fit(X, y) as well.)
model.equations_ is a pandas DataFrame containing all equations, including callable format
(lambda_format),
SymPy format (sympy_format - which you can also get with model.sympy()), and even JAX and PyTorch format
(both of which are differentiable - which you can get with model.jax() and model.pytorch()).
Note that PySRRegressor stores the state of the last search, and will restart from where you left off the next time you call .fit(), assuming you have set warm_start=True.
This will cause problems if significant changes are made to the search parameters (like changing the operators). You can run model.reset() to reset the state.
You will notice that PySR will save two files:
hall_of_fame...csv and hall_of_fame...pkl.
The csv file is a list of equations and their losses, and the pkl file is a saved state of the model.
You may load the model from the pkl file with:
model = PySRRegressor.from_file(""hall_of_fame.2022-08-10_100832.281.pkl"")
There are several other useful features such as denoising (e.g., denoise=True),
feature selection (e.g., select_k_features=3).
For examples of these and other features, see the examples page.
For a detailed look at more options, see the options page.
You can also see the full API at this page.
There are also tips for tuning PySR on this page.
Detailed Example
The following code makes use of as many PySR features as possible.
Note that is just a demonstration of features and you should not use this example as-is.
For details on what each parameter does, check out the API page.
model = PySRRegressor(
    populations=8,
    # ^ Assuming we have 4 cores, this means 2 populations per core, so one is always running.
    population_size=50,
    # ^ Slightly larger populations, for greater diversity.
    ncycles_per_iteration=500,
    # ^ Generations between migrations.
    niterations=10000000,  # Run forever
    early_stop_condition=(
        ""stop_if(loss, complexity) = loss < 1e-6 && complexity < 10""
        # Stop early if we find a good and simple equation
    ),
    timeout_in_seconds=60 * 60 * 24,
    # ^ Alternatively, stop after 24 hours have passed.
    maxsize=50,
    # ^ Allow greater complexity.
    maxdepth=10,
    # ^ But, avoid deep nesting.
    binary_operators=[""*"", ""+"", ""-"", ""/""],
    unary_operators=[""square"", ""cube"", ""exp"", ""cos2(x)=cos(x)^2""],
    constraints={
        ""/"": (-1, 9),
        ""square"": 9,
        ""cube"": 9,
        ""exp"": 9,
    },
    # ^ Limit the complexity within each argument.
    # ""inv"": (-1, 9) states that the numerator has no constraint,
    # but the denominator has a max complexity of 9.
    # ""exp"": 9 simply states that `exp` can only have
    # an expression of complexity 9 as input.
    nested_constraints={
        ""square"": {""square"": 1, ""cube"": 1, ""exp"": 0},
        ""cube"": {""square"": 1, ""cube"": 1, ""exp"": 0},
        ""exp"": {""square"": 1, ""cube"": 1, ""exp"": 0},
    },
    # ^ Nesting constraints on operators. For example,
    # ""square(exp(x))"" is not allowed, since ""square"": {""exp"": 0}.
    complexity_of_operators={""/"": 2, ""exp"": 3},
    # ^ Custom complexity of particular operators.
    complexity_of_constants=2,
    # ^ Punish constants more than variables
    select_k_features=4,
    # ^ Train on only the 4 most important features
    progress=True,
    # ^ Can set to false if printing to a file.
    weight_randomize=0.1,
    # ^ Randomize the tree much more frequently
    cluster_manager=None,
    # ^ Can be set to, e.g., ""slurm"", to run a slurm
    # cluster. Just launch one script from the head node.
    precision=64,
    # ^ Higher precision calculations.
    warm_start=True,
    # ^ Start from where left off.
    turbo=True,
    # ^ Faster evaluation (experimental)
    extra_sympy_mappings={""cos2"": lambda x: sympy.cos(x)**2},
    # extra_torch_mappings={sympy.cos: torch.cos},
    # ^ Not needed as cos already defined, but this
    # is how you define custom torch operators.
    # extra_jax_mappings={sympy.cos: ""jnp.cos""},
    # ^ For JAX, one passes a string.
)
Docker
You can also test out PySR in Docker, without
installing it locally, by running the following command in
the root directory of this repo:
docker build -t pysr .
This builds an image called pysr for your system's architecture,
which also contains IPython. You can select a specific version
of Python and Julia with:
docker build -t pysr --build-arg JLVERSION=1.10.0 --build-arg PYVERSION=3.11.6 .
You can then run with this dockerfile using:
docker run -it --rm -v ""$PWD:/data"" pysr ipython
which will link the current directory to the container's /data directory
and then launch ipython.
If you have issues building for your system's architecture,
you can emulate another architecture by including --platform linux/amd64,
before the build and run commands.

Contributors ✨

We are eager to welcome new contributors! Check out our contributors guide for tips 🚀.
If you have an idea for a new feature, don't hesitate to share it on the issues or discussions page.



Mark Kittisopikul💻 💡 🚇 📦 📣 👀 🔧 ⚠️
T Coxon🐛 💻 🔌 💡 🚇 🚧 👀 🔧 ⚠️ 📓
Dhananjay Ashok💻 🌍 💡 🚧 ⚠️
Johan Blåbäck🐛 💻 💡 🚧 📣 👀 ⚠️ 📓
JuliusMartensen🐛 💻 📖 🔌 💡 🚇 🚧 📦 📣 👀 🔧 📓
ngam💻 🚇 📦 👀 🔧 ⚠️
Christopher Rowley💻 💡 🚇 📦 👀
Kaze Wong🐛 💻 💡 🚇 🚧 📣 👀 🔬 📓


Christopher Rackauckas🐛 💻 🔌 💡 🚇 📣 👀 🔬 🔧 ⚠️ 📓
Patrick Kidger🐛 💻 📖 🔌 💡 🚧 📣 👀 🔬 🔧 ⚠️ 📓
Okon Samuel🐛 💻 📖 🚧 💡 🚇 👀 ⚠️ 📓
William Booth-Clibborn💻 🌍 📖 📓 🚧 👀 🔧 ⚠️
Pablo Lemos🐛 💡 📣 👀 🔬 📓
Jerry Ling🐛 💻 📖 🌍 💡 📣 👀 📓
Charles Fox🐛 💻 💡 🚧 📣 👀 🔬 📓
Johann Brehmer💻 📖 💡 📣 👀 🔬 ⚠️ 📓


Marius Millea💻 💡 📣 👀 📓
Coba🐛 💻 💡 👀 📓
foxtran💻 💡 🚧 🔧 📓
Shah Mahdi Hasan 🐛 💻 👀 📓
Pietro Monticone🐛 📖 💡
Mateusz Kubica📖 💡
Jay Wadekar🐛 💡 📣 🔬
Anthony Blaom, PhD🚇 💡 👀


Jgmedina95🐛 💡 👀
Michael Abbott💻 💡 👀 🔧
Oscar Smith💻 💡
Eric Hanson💡 📣 📓
Henrique Becker💻 💡 👀
qwertyjl🐛 📖 💡 📓
Rik Huijzer💡 🚇
Hongyu Wang💡 📣 🔬


Zehao Jin🔬 📣
Tanner Mengel🔬 📣
Arthur Grundner🔬 📣
sjwetzel🔬 📣 📓
Saurav Maheshkar🔧



   








About

        High-Performance Symbolic Regression in Python and Julia
      





ai.damtp.cam.ac.uk/pysr


Topics



  python


  distributed-systems


  data-science


  machine-learning


  algorithm


  julia


  genetic-algorithm


  scikit-learn


  symbolic


  symbolic-regression


  evolutionary-algorithms


  automl


  interpretable-ml


  explainable-ai


  equation-discovery



Resources





        Readme
 
License





     Apache-2.0 license
    







Activity 
Stars




2.7k
      stars 
Watchers




31
      watching 
Forks




239
      forks 


          Report repository
 






Releases
      84






v1.5.3

          Latest
 
Mar 28, 2025

 
+ 83 releases






Packages
      0


 



 



 













Contributors
      33









































































+ 19 contributors




Languages












Python
97.4%







Jupyter Notebook
1.1%







Other
1.5%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
12,https://arxiv.org/pdf/2406.00390,"AI- BASED DATA ASSIMILATION :
LEARNING THE FUNCTIONAL OF ANALYSIS ESTIMATION
A P REPRINT
Jan D. Keller∗
Research and Development
Deutscher Wetterdienst
Offenbach, Germany
jan.keller@dwd.de
Roland Potthast
Research and Development
Deutscher Wetterdienst
Offenbach, Germany
roland.potthast@dwd.de
ABSTRACT
The integration of observational data into numerical models, known as data assimilation, is funda-
mental for making Numerical Weather Prediction (NWP) possible, with breathtaking success over
the past 60 years (Bauer et al. [2015]). Traditional data assimilation methods, such as variational
techniques and ensemble Kalman filters, are basic pillars of current NWP by incorporating diverse
observational data. However, the emergence of artificial intelligence (AI) presents new opportunities
for further improvements. AI-based approaches can emulate the complex computations of traditional
NWP models at a reduced computational cost, offering the potential to speed up and improve analyses
and forecasts dramatically (e.g. Pathak et al. [2022], Bi et al. [2023], Lam et al. [2023], Bouallegue
et al. [2023]). AI itself plays a growing role in optimization (e.g. Fan et al. [2024]), which offers new
possibilities also beyond model emulation.
In this paper, we introduce a novel AI-based variational data assimilation approach (AI-Var) designed
to replace classical methods of data assimilation by leveraging deep learning techniques. Unlike
previous hybrid approaches, our method integrates the data assimilation process directly into a neural
network, utilizing the variational data assimilation framework. This innovative AI-based system,
termed AI-Var, employs a neural network trained to minimize the variational cost function, enabling
it to perform data assimilation without relying on pre-existing analysis datasets.
We present a proof-of-concept implementation of this approach, demonstrating its feasibility through
a series of idealized and real-world test cases. Our results indicate that the AI-Var system can
efficiently assimilate observations and produce accurate initial conditions for NWP, highlighting its
potential to carry out the data assimilation process in weather forecasting. This advancement paves
the way for fully data-driven NWP systems, offering a significant leap forward in computational
efficiency and flexibility.
Keywords AI·neural networks ·data assimilation ·variational methods ·reanalysis ·self-supervised learning ·
optimization
1 Introduction
In the dynamic and intricate field of Numerical Weather Prediction (NWP), the integration of observational data into
numerical models stands as a cornerstone for making high forecast accuracy and reliability possible. This process,
known as data assimilation, melds observations with model outputs to furnish refined analyses and initial conditions,
thereby making the predictive prowess of NWP systems with high quality feasible. Traditional methods such as
variational data assimilation techniques, the ensemble Kalman filter and its variants and recent developments on particle
filters are the basis of current systems in this domain. There is a breathtaking improvement of forecast accuracy through
algorithmical improvements and by adeptly incorporating a wide range of diverse observational data, e.g. [Houtekamer
and Mitchell, 1998, 2001, 2005, Anderson, 2001, Lorenc et al., 2000, Lorenc, 2003, Kalnay, 2003, Hunt et al., 2007,
∗www.dwd.dearXiv:2406.00390v1  [physics.ao-ph]  1 Jun 2024Keller and Potthast: AI-based data assimilation A P REPRINT
Evensen, 2009, Anderson and Moore, 2012, van Leeuwen et al., 2015, Reich and Cotter, 2015, Nakamura and Potthast,
2015, Bishop, 2016, Vetra-Carvalho et al., 2018, van Leeuwen et al., 2019, Potthast et al., 2019].
Current developments in artificial intelligence (AI)-based approaches have the potential to considerably enhance NWP
[e.g., Lam et al., 2023, Bi et al., 2023]. These sophisticated tools, leveraging deep learning techniques, are designed to
replicate the complex physics-based calculations of traditional NWP models but at a significantly reduced computational
cost for carrying out the forecasting step (called inference in the framework of machine learning). These NWP emulators
unlock a potential not previously thought possible in terms of speeding up the forecasts generated by weather forecasting
models. Weather predictions with lead times of a week or more normally taking hours to be performed can be calculated
in seconds by AI emulators. This advancement not only expedites the NWP cycle, but also ensures that meteorologists
can deliver timely and reliable weather predictions. On the other hand, classical data assimilation methods can thus
become a bottleneck in the weather forecasting chain - taking up a much larger percentage of time needed to perform
a NWP cycle. As the volume of meteorological data continues to grow, the gap in computing time needed between
AI-based NWP models and the data assimilation step may even further increase.
Therefore, the advent of AI in NWP should also indicate a new era in data assimilation strategies, fostering the
development of systems that intertwine well-tested traditional methodologies with the cutting-edge potential of machine
learning. These innovative models aim to transcend the limitations of conventional techniques, offering a leap forward
in refining initial conditions for NWP through AI-augmented assimilation processes [Gottwald and Reich, 2021, Dong
et al., 2023, Arcucci et al., 2021, Bonavita et al., 2021]. One example is the proposition of merging machine learning
with 4D-Var, suggesting a seamless integration of AI into the fabric of established data assimilation frameworks
integrates deep learning methods into the data assimilation process. Already now, continuous learning of uncertain
components of the forecasting model based on observations have been introduced into operational state-of-the-art
forecasting systems such as the ICON model of DWD [Zängl, 2023], leading to much improved forecasting for surface
variables. An important part of data assimilation systems is the mapping between model fields and the observations,
known as observation operators . Using AI for improving or constructing observation operators has been a topic of
research for many years, leading e.g. to an improved simulation of satellite radiances within RTTOV [Scheck, 2021,
Baur et al., 2023], or for assimilating cloud images [Reinhardt et al., 2023].
AI-VarDA Methods
Variational
Methods
3D-Var 4D-Var EnVarEnsemble
Kalman FiltersParticle Filters
Figure 1: We will approach the task to develop an AI-based data assimilation method based on the 3D-Var functional.
An alternative to hybrid AI approaches, which are currently investigated, is to include observations directly in the AI
emulators for NWP, thus, replacing the data assimilation step altogether [Geer, 2021]. However, current approaches to
apply machine learning techniques in data assimilation aim to either substitute parts of the assimilation process with
AI-based methods to improve performance [Farchi et al., 2021] or to extend the capabilities of current implementations
to enhance the quality of the analysis [Buizza et al., 2022, Chipilski, 2023, Qu et al., 2024].
In this paper, however, we strive to replace the classical data assimilation scheme by training a neural network to
perform the data assimilation task itself. Specifically, we introduce a concept of AI-based data assimilation which avoids
the need of a long time-series of analyses as training set. This approach promises to completely replace a classical data
assimilation systems and, thus, opening the field for fully data driven NWP systems in the future.
Integrating data assimilation into neural networks following variational approaches can build on recent advances in
machine learning that have demonstrated the potential of neural networks to learn the complex functional mappings
required for optimization, bypassing the computational bottlenecks of traditional methods. By leveraging these
capabilities, neural networks can be trained to learn the cost function minimization process inherent in variational data
assimilation, offering significant improvements in computational speed and solution accuracy.
2Keller and Potthast: AI-based data assimilation A P REPRINT
In the broader literature, different approaches for solving this problem have emerged in recent years [Fan et al., 2024].
The relevant approach here is to train neural networks to map input parameters directly to optimal solutions [Liu et al.,
2022]. Solutions are for example presented for integrating optimization for quadratic problems into neural network
architectures [e.g., Effati and Ranjbar, 2011, Amos and Kolter, 2021]. The field of AI-based optimization includes the
use of neural networks for guiding and speeding up the minimization such as reinforcement learning where the neural
network learns a policy for optimization [Deng et al., 2022, Sukhija et al., 2023] and the task of meta-training which
employs trained models to help training or minimizing other models [Wichrowska et al., 2017, Li and Malik, 2016].
One key approach for practical applications is function-based learning [e.g., Briden et al., 2023] that trains neural
networks using decision-focused loss functions. Overall, integrating neural networks into variational data assimilation
leverages recent advances in machine learning to offer a path toward more efficient and accurate state estimation.
Starting with the basic equations of 3D-Var, we present a proof-of-concept for our new AI-based algorithmic data
assimilation approach that enables the utilization of deep learning architectures for the assimilation process, where
the full AI training can be carried out based on observations and first guess fields only. Being based on the concept of
variational data assimilation, we implement the algorithm directly into the training concept of an AI based assimilation
system, thus, effectively embodying an AI-Var .
The remainder of the paper is structured as follows. Section 2 is dedicated to the description of our algorithmic approach,
with Section 3 outlining our experiment framework. Our results are presented in Section 4, followed by the discussion
and conclusions in Section 5.
first guessobservations
analysis model run first guessobservations
analysis
Figure 2: The classical DA cycle, where we replace the step which integrates observations and first guess into an
analysis by a direct AI-based assimilation step.
2 Methodology
Current approaches to apply machine learning techniques in data assimilation aim to either substitute parts of the
assimilation process with AI-based methods to improve performance and / or to extend the capabilities of current
implementations to enhance the quality of the analysis. In this paper, however, we develop a concept to replace the
classical data assimilation scheme by training a neural network to perform the task.
2.1 AI-based Data Assimilation Concepts
While previous approaches to utilize AI in data assimilation focused on either extending or substituting aspects of the
process, we are here striving to fully integrate data assimilation into a neural network. While machine learning is in
general based on the idea of learning relationships from large data sets, we follow a different approach.
A standard approach of many machine learning applications is to use the AI-based emulators to construct fast and
flexible mappings, given input data and the respective desired outcome. For the case of data assimilation, this approach
is shown in Figure 3 as Approach 1 . In this first approach, a training data set of triples is needed which for each time
step consists of observations yξ,first guess xb
ξ, and analysis xa
ξ, such that we would use the set
S1:=
sξ= (yξ, xb
ξ, xa
ξ), ξ = 1, ..., n t	
(1)
with the number ntof training samples. While this approach appears to be straightforward, it will always require a
classical analysis system as basis for the training. Approach 1 is therefore characterized through a strong dependence
on the conventional approaches.
Instead of learning the relationship between input data (i.e., first guess xb, observation y) and the desired outcome, i.e.
the analysis xa, through training the network on the analysis field as a target, we set the AI model to learn the functional
f(xb, y)7→xaitself. Therefore, we will make use of the internal loss function of the neural network model. While the
loss function commonly only measures the difference between the model output and the provided target in the training,
we replace it with a term which penalizes the departure of the outcome (i.e., the analysis) to the first guess plus a term
3Keller and Potthast: AI-based data assimilation A P REPRINT
Classical AnalysisAI Analysis
first guessobservations
analysisApproach 1
minimize difference
to train NNAI analysis first guessobservationsApproach 2
minimize functional
to train NN
12
Figure 3: The conventional approach to training a neural network is to minimize the difference between a prescribed
analysis and the AI analysis, here Approach 1. The alternative is to minimize a functional as in classical variational
minimization, such that the classical analysis is not needed to carry out the minimization.
which measures the difference of the model output to the provided observations with weights given by the background
and observation error covariance, respectively. Therefore, we end up with a loss function which is exactly the cost
function that is commonly used in data assimilation with 3D-Var (compare Figure 1):
l= (ˆx−xb)TB−1(ˆx−xb) + (ˆy−y)TR−1(ˆy−y) (2)
where δˆx=ˆx−xbis the analysis increment as the output of the neural network with ˆxas the analysis state, B
the background error covariance matrix, ythe observations, ˆy=H(ˆx)the model equivalents of ˆx, i.e., the output
transformed into observations, and Rthe observation error covariance matrix. δˆxis obtained as the model output by
minimizing the functional (2).
We make use of the fact that both variational data assimilation algorithms as well as the AI training algorithm minimize
a functional. If we employ the same functional (2) as loss function for training our neural network, we construct the
AI-based emulator for data assimilation such that it solves a particular minimization problem – the data assimilation
problem of 3D-Var.
When we train a neural network with the loss function (2), we do not need to prescribe an analysis xa
ξfor the input
samples xb
ξandyξ. In this case, our training set reduces to
S2:=
sξ= (yξ, xb
ξ), ξ = 1, ..., n t	
(3)
with the number ntof training samples. This means that we do not need to prescribe an analysis for training.
But we need to discuss the role of the first guess fields xbin the whole data assimilation cycle shown in Figure 2.
Figure 4: Examples of highly dynamical observations from
airplanes over central Europe within one hour. Observations
are AIREP upper air temperature in Kelvin.We first note that in classical data assimilation the analy-
sis depends on the observation and the first guess, and of
course the first guess is generated from an earlier analysis
– there is a cyclic dependence of the analysis and the first
guess through the model propagation in the data assim-
ilation cycle. Usually, when starting a data assimilation
cycle, one would try to generate an analysis with a pre-
liminary first guess followed by a spin-up period for the
cycle.
The challenge is even stronger for the AI-based analy-
sis algorithms, since we do not solve the minimization
problem in each step, but we train an emulator to solve
this minimization problem – and the training is carried
out by solving many minimization problems. However,
when a reasonable first guess is available, we can use it
for training. When no first guess is available, we might
work with xb= 0 initially. When a first version of an
analysis algorithm after training with xb= 0, one can
4Keller and Potthast: AI-based data assimilation A P REPRINT
construct a better analysis algorithms based on the available first guess fields calculated from available analyses in an
iterative manner. Here, we will focus on the analysis step itself, showing that indeed the above approach is feasible,
further refinements through iterations will be a topic of future research.
Approach 1 is using the supervised learning technique in the sense that the target solution xais prescribed and the
AI-based analysis is trained to get as close to the target as possible. Unsupervised learning algorithms carry out their
tasks without such prescribed targets or labels, respectively. Our Approach 2 is a self-supervised learning approach that
is a sub-category of unsupervised learning algorithms. For further details on these categorizations we refer to James
et al. [2013], Bishop [2006], Goodfellow et al. [2016], Hastie et al. [2001]. For our conceptional tests we have chosen
three basic configurations:
a) a one-dimensional idealized configuration,
b) a two-dimensional idealized configuration,
c) a real-world test case (2m temperature analysis).
In addition, we will investigate two basic observational setups that are encountered in real world data assimilation
problems:
(1) the observations are available in a fixed configuration - static observation locations,
(2) the places where observations are taken are flexible - dynamic observation locations.
Both observational setups reflect real-world problems of high relevance. For example, our real-world case when
assimilating SYNOP two-meter temperature measured at standard operational weather stations falls into category (1).
When we want to assimilation measurements of commercial airplanes as shown in Figure 4, which are important
observations of toady’s global or regional forecasting systems, the observational setup would be of category (2).
2.2 Assimilation of fixed-position observations
For testing the feasibility of the new Approach 2 we have used PyTorch, the well-known open-source machine learning
library developed by Facebook’s AI Research lab. We employed PyTorch version 2.2.0 for neural network training and
experimentation, see PyTorch [2024]. Pseudo code for the core procedure is given in the Appendix A. Conceptually, we
need to provide (a) input fields , (b) implement our choice of a neural architecture with input and output dimensions and
(c) define a loss function which the minimizer of pytorch can use. Further, we need to provide a training and evaluation
data set for the minimization framework to run.
In the basic configuration a) defined in Section 2.1, where observations are at fixed locations, we can calculate
observation equivalents from model fields based on a fixed set of parameters given by the observation locations. The
observation operators usually carry out an interpolation of model fields to observation locations, often in combination
with further physical processes such as the transmission of radiation. Here, we have chosen to stay with a simple
framework where the model field consists of one variable and we measure the model field in a selection of model grid
locations. In this case, the observational parameters are a list of indices of the model grid points where the values are
measured. The observations are modeled by a simple array of scalar values. In the case of mtemperature observations
at particular locations, this array will consist of mvalues, for which the model equivalents can be obtained taking the m
indices of the model grids where the measurement took place, and evaluating the corresponding field values.
(a) For PyTorch, the input is a combined array of values (xb, y)where xbis the first guess field transformed into the
inherent PyTorch tensor structure, and yis the array of observations. With ngridpoints and a field of one variable only,
the tensor (xb, y)hasn+mvalues.
(b) The neural architecture has been adapted to the three cases a)-c) and will be described in more detail in the sections
below. We basically used dense networks for our test cases as shown in Figure 5.
(c) The cost function can be provided in PyTorch as a function based on its own data structures, the PyTorch tensors.
The tensorial structure allows us define the complex loss function (2) as an implementation of the Mahalanobis distance
(see Mahalanobis [2019]) easily even in the multi-dimensional case.
Finally, we need to define a training data set. For the test configurations a) and b) we have chosen set of prescribed
true functions for simulation, used a random number generator to select a set of indices to fix observation locations,
and calculated artificial observations based on this data set. We have split the data set into a training data set and an
evaluation data set. With these ingredients the setup of the training loop based on a data loader, an optimizer, and the
optimization criterion is straightforward in PyTorch.
5Keller and Potthast: AI-based data assimilation A P REPRINT
2.3 Assimilation of flexible-position observations
For the case of flexible-position observations a simple approach is to add the location of the input fields to the input
vectors given to the AI-based system. This means that we have a parameter vector pξwhich depends on the sample
index ξwhich together with the first guess xb
ξand the observations yξ,ξ= 1, ..., N withNbeing the number of training
samples is given as input to the system. The set of training samples now takes the form
S3:=
sξ= (yξ, pξ, xb
ξ), ξ = 1, ..., N	
, (4)
where in the simplest possible case of linear indices the dimension of yξandpξis identical. Depending on the particular
format of indexing chosen, of course pξcan take tensorial form. The PyTorch system is able to deal with any of these,
as long as the structures are transformed into appropriate PyTorch tensors.
We remark that adding the locations to the system increases the computational complexity of the learning task
considerably. Initially, we naively added the indices, but in these cases our training tasks failed. As described in [Liu
et al., 2022], for the case where the order of the observations does not change the minimization problem, deep sets and
permutation invariant neural architectures can be used to reduce the complexity of the training task. Here, we employed
a simple approach to such methods by ordering the observations based on their location in the grid, which leads to a
uniform and permutation invariant structure for all permutations of observations in the data assimilation task. With this
approach we were successful to achieve meaningful results.
3 Experiment setup
First guess
ObservationsAnalysisHidden
layer 1
(ng+ 2no)Hidden
layer 2
(ng)Hidden
layer 3
(ng)Input
layer
(ng+ 2no)Output
layer
(ng)
Figure 5: Network architecture for the idealized cases. Below the layer names,
the dimension of each layer is provided. Here, ngis size of the grid space
(i.e.,ng=nxfor the 1D case and ng=nx·nyfor the 2D case) and nois
the number of observations.In this section, we describe the data
used in the three test cases for our data
assimilation learning approach. We em-
ploy two idealized cases, one- and two-
dimensional, respectively, as well as a
real world example.
3.1 1D setup
The first case examines our data assim-
ilation learning algorithm using data
from one-dimensional functions. We
use two different basic functions to gen-
erate these data.
In our setup, the x-axis values represent a linearly spaced sequence of nx= 50 values in the interval [0,2π[. With
f∼Uniform (0.5,1.5)a random forcing value and xt=x−t·∆tthe shifted xvalues along the x-axis for ntnumber
of time steps, we define sinusoidal curves aszs
t= sin xtandparabolas using zp
t=f·xt2. The data set is constructed
such that, at each time step, the data is randomly chosen from each of the two types of curves. Examples of the resulting
curves are shown in the results section in Figure 7.
To test the functionality of the data assimilation approach in the 1D idealized case, we apply the following experiment
setup. First, we sample our observations from the training data set of true model states. We choose the first guess state
to be zero and, then force the model to reconstruct the true fields by assimilating the observations. In this case, to give
the observations an appropriate impact reflecting a large uncertainty of the background, we introduce artificial weights
wb= 0.001for the background term and wo= 0.999from the observation term into the loss function.
In order to investigate the performance of our model for the data assimilation purposes, we employ two common
scenarios - a static and a dynamic layout of observation locations. We then investigate the robustness of the model for the
different scenarios with respect to three hyperparameters. First, we train models with different number of observations
no= 5,10,15,20to represent cases from a sparsely to densely observed space. Second, we use different Gaussian
kernel widths sigma ( s= 0.5,1.,2.,4.) for the B-matrix to account for various radii of influence for the observations
on the state space. Last, we train the model with different training sample sizes of nt= 250 ,500,1000,2500 . For all
experiments we use 100independent samples for evaluation. The samples are drawn without replacement using the
different random forcings f.
Our architecture consist of a simple feed forward neural network with three hidden layers as depicted in Figure 5. The
input of the neural network is the first guess field (size nx) as well as the observations (size no) and the observation
indices in the spatial dimension (also size no), made permutation invariant as described in the methodology section. For
6Keller and Potthast: AI-based data assimilation A P REPRINT
0 500 1000 1500 2000 2500 3000
Epoch103
102
101
Validation loss by number of observationsa)05
1015
20best 05
1015
20best
0 500 1000 1500 2000 2500 3000
Epoch103
102
101
Validation loss by B-matrix kernel widthb)0.5
1.02.0
4.0best 0.5
1.02.0
4.0best
0 500 1000 1500 2000 2500 3000
Epoch103
102
101
Validation loss by number of training samplesc)0250
05001000
2500best 0250
05001000
2500best
Figure 6: Validation loss curves for the 1D idealized case for the two scenarios - static (dashed lines) and dynamic
(solid lines) observation locations. The curves represent the mean validation loss over the group of respective training
runs with the same a) number of observations, b) B-matrix kernel width, and c) number of training samples. Therefore,
each line is the average over 16 data sets, respectively.
the implementation of the algorithm, we use the python package PyTorch. The used optimizer is Adam and the learning
rate is set to 0.001.
3.2 2D setup
To systematically investigate the functionality of our approach for a more realistic data assimilation problem, we
employ a 2D setup using trigonometric functions which is designed similar to the 1D case. Here, we use a 2D grid
described by the coordinates xandy. Then, we define the factors fxandfydetermining the different displacement in
xandydirections for the samples through cx=fx·π·t/ntandcy=fy·π·t/nt, respectively. The 2D field zis
then calculated by z= sin [( π/5)·(x−cx[t])]·cos [(π/8)·(y−cy[t])]. Finally, the array zis permutated along the
sample axis. The idealized 2D experiments follow the exact same setup as for the 1D case (cf. section 3.1) including
the model architecture and parameter settings, including the permutation invariance described above. Examples for the
resulting fields are shown in the results section in Figure 10.
3.3 Real case setup
In order to evaluate the potential of our AI-Var approach in a real world setting, we add another experiment setup where
we apply our approach to assimilate 2-meter temperature (T2M) observations from synoptic observation sites into
T2M fields from an NWP model. This setup corresponds to our 2D idealized static observation location experiment.
As gridded data, we choose hourly T2M fields from DWD’s COSMO-REA6 regional reanalysis [Bollmeyer et al.,
2015]. Instead of using the full data set, a subdomain of 20×25grid points (at 6km horizontal resolution) over central
Germany is selected to reduce the complexity. While conventional observations were assimilated in the generation
process of the reanalysis, T2M measurements have only been introduced indirectly via a soil moisture reanalysis
once a day. Therefore, analyses of the reanalysis T2M estimates showed considerable biases, RMSE and correlation
mismatches [Keller and Wahl, 2021].
The observational data comes from DWD’s climatological archive where synoptic measurements are stored for German
stations. The subdomain includes 25 stations with hourly observations. Times where data from any station are missing
have been removed from the whole data set.
Our test period comprises four years (2010-2013) where we only use the summer months to concentrate on Northern
hemisphere summer. The data set comprises 8658 samples which are randomly permutated along the time axis. We
retain 500 data points as validation data set and use the remaining 8158 samples for training with a batch size of 4096.
We employ the same setup as for the 2D case except for a few tuning choices. (1) To better account for the complexity
of the underlying dynamics, we provide the model surface height (which is closely connected to T2M) as a 2D field as
well as time of day as a scalar to the model. (2) We adapt the neural network architect by increasing the number of
neurons in hidden layer 1 and 2 to ng×4andng×2, respectively.
(3) We still use a Gaussian B-matrix which might not be the best choice but should suffice in this proof-of-concept, but
we set the B-matrix kernel width to 0.2and the observation error to 0.1.
7Keller and Potthast: AI-based data assimilation A P REPRINT
1.0
0.5
0.00.51.0inference
staticnobs = 05
nobs = 10
nobs = 15
nobs = 20
truthnobs = 05
nobs = 10
nobs = 15
nobs = 20
truth
0 1 2 3 4 5 61.0
0.5
0.00.51.0inference
dynamic
0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6
Figure 7: Examples of the 1D idealized experiments. The plots depict the 1D fields for four inference samples of the
validation data set (columns) from the static (top row) and the dynamic observation locations (bottom row). The grey
dashed lines denote the respective true state.
In a secondary test setup, we withhold observations to allow for an independent verification data set. In this cross-
validation setup, we perform five model training runs with no= 20 by each time keeping a subset of five observations
from the original data set for evaluation in such a way that we have an independent model for each observation.
4 Results
In this section, we show the results from our proof-of-concept implementation of an AI-based data assimilation
algorithm. We first present the results for the idealized 1D and 2D cases and conclude this section with a simple
real-world 2D example.
4.1 Idealized 1D case
We first look at the loss curves of the training of our data assimilation AI model. Specifically, we are interested in
the validation loss, as the aim of the approach is to be applied to independent data. The three plots in Figure 6 show
the average validation loss for all training runs with a specific parameter setting as described in Section 3.1, i.e. each
colored line represents the average over 16 different models. The dashed lines are determined using a static observation
setup whereas the solid lines indicate the average over models with dynamic observation positions. The grey lines
indicate the best performing model for both cases.
The training loss (not shown) as well as the validation loss converges for all models. The comparison (Fig. 6) further
shows that the models with static observation locations perform better than the ones with dynamic observation locations
(i.e., the former are exhibiting a lower average validation loss). This was expected as the static structure allows for the
neural network to better learn the characteristic of the underlying fields with respect to the provided observations.
Looking at the parameter ""number of observations"" (Fig. 6a), we find a strong deviation in performance between the
models especially for the dynamic setup with 20 observations showing a validation loss nearly one order of magnitude
lower than the models with only 5 observations. Remembering that our 1D space has 50 grid points, the case with 20
observations prescribes already nearly half of the state space, thus, significantly reducing the number of grid points to
be determined compared to the 5 observation case. For the static observation locations, the validation loss varies only
slightly with respect to the number of observations (between 0.002 and 0.004 at the end of the training), again, with 20
observations exhibiting the lowest validation loss.
For the various B-matrix kernel width settings (Fig. 6b), we find that the parameter does only exhibit a very small
impact on the performance of the model with dynamic observation locations. For the static setup however, we find that
while the lower settings have similar validation losses, a value of 4.0seems to imply a too strong smoothing which
increases the validation loss.
The number of training samples seems to be a crucial parameter for the performance of the models with dynamic
observation locations. Figure 6c shows that there is strong variation among the different settings with the largest number
of samples (2500) having the smallest validation loss. This is founded in the ability of the model to generalize from
the changing observation network layout by more samples and, thus, a larger number of different combinations of
8Keller and Potthast: AI-based data assimilation A P REPRINT
0 500 1000 1500 2000 2500 3000
Epoch102
101
100Validation loss by number of observationsa)05
1015
20best 05
1015
20best
0 500 1000 1500 2000 2500 3000
Epoch102
101
100Validation loss by B-matrix kernel widthb)0.5
1.02.0
4.0best 0.5
1.02.0
4.0best
0 500 1000 1500 2000 2500 3000
Epoch102
101
100Validation loss by number of training samplesc)0250
05001000
2500best 0250
05001000
2500best
Figure 8: Validation loss curves for the 2D idealized case for the two scenarios - static (dashed lines) and dynamic
(solid lines) observation locations. The curves represent the mean validation loss over the group of respective training
runs with the same a) number of observations, b) B-matrix kernel width, and c) number of training samples. Therefore,
each line is the average over 16 data sets, respectively.
observation locations. The impact on the static observation location setup is, however, only small, as a limited number
of samples is sufficient for the model to understand the underlying structure of the fields.
05 10 20 40B-matrix kernel width
0.00.20.40.6a) n_obs = 05
0.00.20.40.6b) n_obs = 10
0.00.20.40.6c) n_obs = 15
250 5001000 2500250 5001000 2500250 5001000 2500250 5001000 2500
number of training samples0.00.20.40.6d) n_obs = 20static
dynamic
Figure 9: RMSE for inference against truth over all 100 validation
samples and all grid points for the static (blue) and dynamic (yellow)
observation locations. The four plots represent the results for the models
based on a) 5, b) 10, c) 15 and d) 20 observations.To take a closer look at the generated fields,
Figure 7 shows four exemplary samples from
the validation data set (columns) - two parabo-
las (left) and two sinus curves (right) with the
respective inference results for all four num-
bers of observations nowithns= 2500 and
s= 2.0. In the top row, the curves are recon-
structed with the static observation locations
setup whereas the bottom row depicts the re-
sults from the dynamic observation locations.
The results indicate that our AI-Var approach
is able to very closely reconstruct the true
state for the static case for the given param-
eter settings independent of the number of
observations. For the dynamic case, we find
that for no= 15,20, the model is also nearly
identical to the truth except for some data
points close to the boundaries when there are
no nearby observations. While the estimates
slightly deviate from the truth for no= 10 ,
we find that for no= 5, the inference is not
very smooth anymore and shows larger dis-
crepancies from the original state. This in-
dicates that for a less dense observation net-
work, a larger training data set can compen-
sate this issue for the static case, but it seems
to be much more complicated to achieve good
results for the dynamic case.
4.2 Idealized 2D case
We now anaylze the results with respect to the idealized 2D case. Figure 8 depicts the average validation loss over the
training epochs for all training runs similar to the 1D case (cf. Fig. 6). As expected, we find that independent of the
hyperparameter settings, the static observation locations exhibit lower validation losses compared to the dynamic setup.
This difference is considerably increased in comparison to the 1D case which can be attributed to the more complex 2D
situation.
9Keller and Potthast: AI-based data assimilation A P REPRINT
0246truth
0246inference
static
0.0 2.5 5.00246inference
dynamic
0.0 2.5 5.0
 0.0 2.5 5.0
 0.0 2.5 5.0
 0.0 2.5 5.0
 0.0 2.5 5.0
1.00
0.75
0.50
0.25
0.000.250.500.751.00
value
Figure 10: Examples of the 2D idealized experiments. The plots depict the 2D fields for six samples of the validation
data set (columns) from the truth (top row), the inference (i.e. the AI based analysis) from the static (middle row) and
the dynamic observation locations (bottom row). The grey dots denote the respective observation locations.
In Figure 8a, we find that the impact of the number of observations is far more pronounced for the static case than for
the dynamic observation locations. For the latter, we see that the best performing models are those with the largest
number of observations. However, for the static locations, this effect is reversed with lower number of observations
showing a lower validation loss. For the B-matrix kernel width (Figure 8b), most of the respective models exhibit
a similar performance except for a width of 4 for the static case where the strong smoothing appears to hinder
the ability of the neural network to estimate the observations, thus leading to a considerably higher validation loss.
0 500 1000 1500 2000 2500 3000
Epoch101
100Losstotal training loss
total validation loss
obs training loss
obs validation losstotal training loss
total validation loss
obs training loss
obs validation loss
Figure 11: Loss function for the real test case.
The thick lines depict the total loss whereas the
thin lines are the loss coming from the observa-
tion term. Blue indicates training loss and yellow
denotes validation loss.For the training sample size (Figure 8c), we find that the results are
similar for the static observation locations, indicating that such a
setup is robust also against smaller sample sizes. For the dynamic
locations, we find that larger sample sizes lead to smaller validation
losses. However, especially for 2500 samples, we see that the
average validation loss decreases until a minimum is reached (around
epoch 150) and then increases until convergence is reached. As we
look at the validation loss here, this indicates that while larger sample
sizes can improve the model quality, there is a considerable risk of
overfitting the model towards the training samples.
To further investigate the performance of the AI-based DA approach
in a 2D idealized setting, we perform the inference on the validation
data set with all models and compare the RMSE of the estimated
fields to the truth. Figure 9 shows the average RMSE over all grid
points and all samples for the static (blue) and dynamic (yellow)
observation locations setup. The four plots indicate the different
number of observations as these are usually given in a real world
setting. In general, we find that the model for the static setup is much
less insusceptible towards the B-matrix kernel width whereas the
models for the dynamic locations perform much better with larger
B-matrix kernel widths. For the latter, a setting of 2 seems to be
the best of the choices for this case. In comparison, the number of training samples has a much larger influence on
the performance of the models for static locations than for the dynamic locations. The influence on the former also
depends on the number of observations. With 5 observations, smaller samples produce higher RMSEs whereas for 20
observations, the best results can be achieved with larger number of samples. This clearly indicates that the model’s
tendency for overfitting is dependent on the complexity of the situation (i.e., the number of observations).
Six examples of the reconstruction from the validation data set for both the dynamic and the static case can be found in
Figure 10. The inference is performed for the models with 2500 training samples, 20observations and a B-matrix kernel
width of 2.0. The top row depicts the original fields, wheres the center and bottom row show the reconstruction for the
10Keller and Potthast: AI-based data assimilation A P REPRINT
first guess
 analysis
analysis
increment
791113151719
791113151719
4
2
0241214161820
1214161820
4
2
02417192123
17192123
4
2
0241214161820
1214161820
4
2
024579111315
579111315
4
2
024
Figure 12: Five examples from the validation data of the real case experiment. The contours show the first guess field in
the top row and the AI-Var analysis in the center row. The circles denote the respective T2M observations. The bottom
row depicts the contours of the analysis increments and the deviation of the observations from the first guess in the
circles.
static and dynamic observation locations, respectively. The dots denote the observation location for each example. We
find that the models are able to quite reasonably reproduce the 2D structure of the truth. While in the static case, the
differences between truth and reconstruction are only marginal, some deviations become apparent for the dynamic case.
In summary, the results for 2D idealized experiments are very promising indicating the potential for the application in a
real test case.
4.3 Real test case
Using the experiment setup described in section 3.3, we apply our AI-Var to a real world example for data assimilation.
As usual, the loss is decreasing with increasing epochs as shown in Figure 11. Here, training and validation loss move in
parallel, i.e., an improvement in the model as indicated by a lower training loss also leads to a decrease of the validation
loss. However, with the training loss still trending downward induced by the steep reduction of the observation loss
term, the model is not yet fully trained and may further improve as there is no evidence of overfitting yet, i.e., the
validation loss keeps decreasing, too. Due to the complexity, a larger number of training epochs may be reasonable.
However, as the following results indicate, the model reaches a sufficient level of quality for your proof-of-concept
approach.
Figure 12 shows the application of the trained model to the validation data set. The contour plots depict the first guess
fields from the reanalysis (top row) and the analysis from our AI-Var (center row). The circles denote the observation
locations with the colors indicating the observed value in the same color range as the contour plots. The bottom
row depicts the filled contours of the respective analysis increments with the circles showing the deviation of the
observations from the first guess.
While some observations agree with the first guess fields, there is often a mismatch between the observed and estimated
T2M in the first guess. From the center row, we find that AI-Var is able to locally correct for these deviations such that
the observation match the analysis field very well. This can also be deduced from the bottom row where we find that for
almost all observations, the analysis increment matches the error of the first guess to the observed values.
Another evaluation is given in the left plot in Figure 13 which depicts the diurnal cycle of the mean absolute deviations
of the observations from the first guess (blue) and AI-Var analysis (yellow). The single observations are denoted as thin
lines, whereas the thick lines are the average over all observations. The upper plot shows the result for the validation
period of our real case experiment. We find that there is a clear diurnal cycle of first guess errors with respect to the
observations with larger deviations becoming larger during the night time. This is due to a nightly warm bias in the
COSMO-REA6 reanalysis which is well known. However, with our AI-Var, we are not only able to significantly reduce
the error but also eliminate the diurnal cycle of the T2M errors from the first guess field ( 80%-90% reduction).
11Keller and Potthast: AI-based data assimilation A P REPRINT
0 5 10 15 20
time of day0.00.51.01.52.02.5mean bias from observationsfirst guess
AI-Var analysisfirst guess
AI-Var analysis
0 5 10 15 20
time of day0.00.51.01.52.02.5mean bias from observationsfirst guess
AI-Var analysisfirst guess
AI-Var analysis
Figure 13: Diurnal cycle of first guess (blue) and AI-Var analysis (yellow) deviations from the observations in the
validation data set. Thin lines indicate the individual 25observation sites whereas the thick line denotes the mean over
all stations. The left plot shows the experiment using all observations, the right plot the cross-validation experiment.
In our cross-validation experiment for the real case, we try to evaluate the merit of our AI-Var system using independent
observations. The evaluation of the five training runs withholding five different observations from the full observational
data set in each run, are combined to confirm the validity of our approach. We find a reduction of root mean square
error from first guess to analysis in 20of the 25observations with an average reduction of 26% in these 20observations
and an increase of about 16% in the remaining 5observations. It is important to note that as a proof-of-concept, we only
employed a Gaussian B-matrix which might not be an optimal choice for such heterogeneous fields as T2M. Despite
this strong constraint, the AI-Var is still able to enhance the T2M representation in the cross-validation experiment.
We find further evidence of this in the right hand side plot in Figure 13 which shows the results from the cross-validation
experiments for the diurnal cycle of the deviations form the observations. Here, the differences are calculated from
the independent observations from the five trained models, respectively. While for some observations the errors even
increase in the analysis, on average we still find a reduction of the deviations through data assimilation and an attenuation
of the nightly warm bias. It is important to note that as a proof-of-concept, we only employed a Gaussian B-matrix
which might not be an optimal choice for such heterogeneous fields as T2M. Despite this strong constraint, the AI-Var
is still able to enhance the T2M representation in the cross-validation experiment.
5 Conclusions
In this paper, we have presented a novel AI-based data assimilation approach that has the potential to replace the
classical data assimilation scheme by training a neural network to perform the data assimilation task itself. This
proof-of-concept study has shown promising results across both idealized and real-world scenarios.
Our investigations in one-dimensional (1D) and two-dimensional (2D) idealized cases indicate that the AI-Var approach
is - even with a zero first guess - capable of effectively reconstructing the original state from observations. In particular,
we have noticed that while the reconstruction can be nearly perfect for static observation setups, the performance
decreases only modestly for the more challenging dynamic observation locations case. This indicates that combining a
sufficient number of observations with a large training data set can reasonably compensate for the added complexity
introduced by dynamic observation locations.
Our real-world test case, which involved the assimilation of 2-meter temperature (T2M) observations from synoptic
observation sites, has demonstrated that our AI-Var system can indeed improve estimation accuracy. Specifically, it can
correct for biases in the first guess fields, such as the nocturnal warm bias in the COSMO-REA6 reanalysis, and reduce
errors significantly. These improvements were to a lesser extent also evident in the cross-validation experiment with
independent observations, though the Gaussian B-matrix employed may not be the optimal choice for heterogeneous
fields like T2M.
As with any novel approach, there still remains a large potential for improvement with further research and development
necessary before AI-based data assimilation systems can be fully operational. Future work may focus on: First,
enhanced neural architectures are needed to handle the increased complexity of high-dimensional data assimilation
problems. Second, advanced training strategies including iterative training approaches and meta-learning will be
needed to further reduce computational costs and improve the quality of solutions. Third, realistic 3D applications will
be an important next step extending the approach to three-dimensional as well as multi-variate data sets to better emulate
real-world meteorological scenarios and increase the realism of the results. Fourth, optimized covariance models
have been important to improve quality in traditional algorithms. Investigating alternative B-matrix representations
12Keller and Potthast: AI-based data assimilation A P REPRINT
beyond the Gaussian kernel such as climatological and ensemble-based approaches to better capture the variability
and heterogeneity of different meteorological variables will be an important development step. We note that from a
conceptional viewpoint the use of an ensemble based B-Matrix in the loss functional (2) as in the EnVar [e.g., Buehner
et al., 2013] is straightforward. This needs, however, the generation of an appropriate ensemble and, thus, if one aims to
have a fully data-driven analysis, further progress in AI based ensemble generation. Fifth, it is important to explore the
operational feasibility of AI-based data assimilation, integrating this approach into existing NWP systems, possibly
through hybrid data assimilation strategies that blend traditional and AI-based methods.
In conclusion, our AI-based data assimilation method shows a clear path forward for leveraging machine learning
to handle traditionally complex and computationally expensive tasks. By fully integrating neural networks into the
assimilation process, we open up opportunities for faster, more efficient, and eventually more accurate weather prediction
systems—paving the way for fully data-driven NWP systems in the future.
Disclaimer
This Work has not yet been peer-reviewed and is provided by the contributing Author(s) as a means to ensure timely
dissemination of scholarly and technical Work on a noncommercial basis. Copyright and all rights therein are maintained
by the Author(s) or by other copyright owners. It is understood that all persons copying this information will adhere
to the terms and constraints invoked by each Author’s copyright. This Work may not be reposted without explicit
permission of the copyright owner.
A AI-Var Pseudo Code
1.Set Input Data:
1z := nt x ng array containing the grid input data on the grid
2o := nt x no array containing the observations input data
3i := nt x no array containing the locations of the observations
on the grid
2.Define Input Fields and Vectors for Training:
1sort_indices = sort i in ascending order
2input_field = scale and convert z to tensor
3input_vector = stack sorted o and normalized i into tensor
4b_cov = calculate covariance matrix with Gaussian kernel
width sigma
5regularize b_cov
3.Initialize Training Data and DataLoader:
1train_set = create training dataset with input_field and
input_vector
2train_loader = create DataLoader for training with batch_size and
shuffling based on train_set
4.Define Data Assimilation Neural Network and Loss Function:
1class DataAssimilationNN :
2 initialize with dimensions ng , n_obs , obs_error
3 define three fully connected layers
4 forward pass :
5 concatenate input first guess , observations and their
locations
6 apply relu activation after each fully connected layer
7 reshape and return the output
8
9class DataAssimilationLoss :
10 initialize with ng , b_matrix , obs_err
11 forward pass :
12 calculate background mismatch using Mahalanobis distance
13Keller and Potthast: AI-based data assimilation A P REPRINT
13 sample observations from model output
14 calculate observation mismatch
15 combine losses and return
5.Prepare Training:
1model = initialize DataAssimilationNN with ng , n_obs
2criterion = initialize DataAssimilationLoss with
regularized_b_cov , ng , obs_err
3optimizer = initialize Adam optimizer with learning rate 0.001
6.Training Loop:
1for epoch in range ( num_epochs ):
2 for batch in train_loader :
3 clear optimizer gradients
4 output = model ( batch )
5 loss = criterion (output , batch )
6 backpropagate loss
7 update model parameters with optimizer
8 store training loss
References
B. Amos and J. Z. Kolter. Optnet: Differentiable optimization as a layer in neural networks, 2021. URL https:
//arxiv.org/abs/1703.00443 .
B. D. O. Anderson and J. B. Moore. Optimal Filtering . Dover Books on Electrical Engineering Series. Dover Publica-
tions, Incorporated, 2012. ISBN 9780486136899. URL http://books.google.de/books?id=iYMqLQp49UMC .
J. L. Anderson. An ensemble adjustment Kalman filter for data assimilation. Monthly Weather Review , 129(12):
2884–2903, 2001. doi:10.1175/1520-0493(2001)129<2884:AEAKFF>2.0.CO;2.
R. Arcucci, J. Zhu, S. Hu, and Y .-K. Guo. Deep data assimilation: Integrating deep learning with data assimilation.
Applied Sciences , 11(3), 2021. ISSN 2076-3417. doi:10.3390/app11031114. URL https://www.mdpi.com/
2076-3417/11/3/1114 .
P. Bauer, A. Thorpe, and G. Brunet. The quiet revolution of numerical weather prediction. Nature , 525:47–55, 2015.
doi:10.1038/nature14956.
F. Baur, L. Scheck, C. Stumpf, C. Köpken-Watts, and R. Potthast. A neural-network-based method for generating
synthetic 1.6 µm near-infrared satellite images. Atmospheric Measurement Techniques , 16(21):5305–5326, 2023.
doi:10.5194/amt-16-5305-2023. URL https://amt.copernicus.org/articles/16/5305/2023/ .
K. Bi, L. Xie, H. Zhang, X. Chen, X. Gu, and Q. Tian. Accurate medium-range global weather forecasting with 3d
neural networks. Nature , 619(7970):533–538, July 2023. ISSN 1476-4687. doi:10.1038/s41586-023-06185-3. URL
http://dx.doi.org/10.1038/s41586-023-06185-3 .
C. H. Bishop. The GIGG-EnKF: Ensemble Kalman filtering for highly skewed non-negative uncertainty distributions.
Quart. J. Roy. Meteor. Soc. , 142:1395–1412, 2016. doi:10.1002/qj.2742.
C. M. Bishop. Pattern Recognition and Machine Learning . Springer, New York, 2006. URL https://link.
springer.com/book/10.1007/978-0-387-45528-0 .
C. Bollmeyer, J. D. Keller, C. Ohlwein, S. Wahl, S. Crewell, P. Friederichs, A. Hense, J. Keune, S. Kneifel, I. Pscheidt,
S. Redl, and S. Steinke. Towards a high-resolution regional reanalysis for the European CORDEX domain. Quarterly
Journal of the Royal Meteorological Society , 141(686):1–15, 2015. doi:10.1002/qj.2486.
M. Bonavita, R. Arcucci, A. Carrassi, P. Dueben, A. J. Geer, B. L. Saux, N. Longépé, P.-P. Mathieu, and L. Raynaud.
Machine learning for earth system observation and prediction. Bulletin of the American Meteorological Society ,
102(4):E710 – E716, 2021. doi:10.1175/BAMS-D-20-0307.1. URL https://journals.ametsoc.org/view/
journals/bams/102/4/BAMS-D-20-0307.1.xml .
Z. B. Bouallegue, M. Alexe, M. Chantry, M. Clare, J. Dramsch, S. Lang, C. Lessig, L. Magnusson, A. P. Nemesio,
F. Pinault, B. Raoult, and S. Tietsche). Artificial intelligence for forecasting system (aifs), 2023. URL https:
//www.ecmwf.int/en/about/media-centre/aifs-blog . Accessed: 2024-05-20.
14Keller and Potthast: AI-based data assimilation A P REPRINT
J. Briden, C. Choi, K. Yun, R. Linares, and A. Cauligi. Constraint-informed learning for warm starting trajectory
optimization, 2023. URL https://api.semanticscholar.org/CorpusID:266520898 .
M. Buehner, J. Morneau, and C. Charette. Four-dimensional ensemble-variational data assimilation for global
deterministic weather prediction. Nonlinear Processes in Geophysics , 20(5):669–682, 2013. doi:10.5194/npg-
20-669-2013. URL https://npg.copernicus.org/articles/20/669/2013/ .
C. Buizza, C. Quilodrán Casas, P. Nadler, J. Mack, S. Marrone, Z. Titus, C. Le Cornec, E. Heylen, T. Dur, L. Baca Ruiz,
C. Heaney, J. A. Díaz Lopez, K. S. Kumar, and R. Arcucci. Data learning: Integrating data assimilation and machine
learning. Journal of Computational Science , 58:101525, Feb. 2022. ISSN 1877-7503. doi:10.1016/j.jocs.2021.101525.
URL http://dx.doi.org/10.1016/j.jocs.2021.101525 .
H. G. Chipilski. Exact nonlinear state estimation, 2023. URL https://arxiv.org/abs/2310.10976 .
M. Deng, J. Wang, C.-P. Hsieh, Y . Wang, H. Guo, T. Shu, M. Song, E. Xing, and Z. Hu. RLPrompt: Optimizing discrete
text prompts with reinforcement learning. In Y . Goldberg, Z. Kozareva, and Y . Zhang, editors, Proceedings of the
2022 Conference on Empirical Methods in Natural Language Processing , pages 3369–3391, Abu Dhabi, United
Arab Emirates, Dec. 2022. Association for Computational Linguistics. doi:10.18653/v1/2022.emnlp-main.222. URL
https://aclanthology.org/2022.emnlp-main.222 .
R. Dong, H. Leng, C. Zhao, J. Song, J. Zhao, and X. Cao. A hybrid data assimilation system based on machine
learning. Frontiers in Earth Science , 10:Article 1012165, 2023. doi:10.3389/feart.2022.1012165. URL https:
//doi.org/10.3389/feart.2022.1012165 . Published on 05 January 2023, Section Atmospheric Science.
S. Effati and M. Ranjbar. A novel recurrent nonlinear neural network for solving quadratic programming problems.
Applied Mathematical Modelling , 35(4):1688–1695, 2011. doi:10.1016/j.apm.2010.10.001.
G. Evensen. Data Assimilation: The Ensemble Kalman Filter . Springer, Berlin, Heidelberg, 2 edition, 2009.
doi:10.1007/978-3-642-03711-5.
Z. Fan, B. Ghaddar, X. Wang, L. Xing, Y . Zhang, and Z. Zhou. Artificial intelligence for operations research:
Revolutionizing the operations research process, 2024.
A. Farchi, P. Laloyaux, M. Bonavita, and M. Bocquet. Using machine learning to correct model error in data assimilation
and forecast applications. Quarterly Journal of the Royal Meteorological Society , 147(739):3067–3084, July 2021.
ISSN 1477-870X. doi:10.1002/qj.4116. URL http://dx.doi.org/10.1002/qj.4116 .
A. J. Geer. Learning earth system models from observations: machine learning or data assimilation? Philosophical
Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences , 379(2194), Feb. 2021. ISSN
1471-2962. doi:10.1098/rsta.2020.0089. URL http://dx.doi.org/10.1098/rsta.2020.0089 .
I. Goodfellow, Y . Bengio, and A. Courville. Deep Learning . MIT Press, Cambridge, MA, 2016. URL http:
//www.deeplearningbook.org .
G. A. Gottwald and S. Reich. Combining machine learning and data assimilation to forecast dynamical systems from
noisy partial observations. Chaos: An Interdisciplinary Journal of Nonlinear Science , 31(10), Oct. 2021. ISSN
1089-7682. doi:10.1063/5.0066080. URL http://dx.doi.org/10.1063/5.0066080 .
T. Hastie, J. H. Friedman, and R. Tibshirani. The Elements of Statistical Learning . Springer, New York, 2001.
doi:10.1007/978-0-387-21606-5.
P. L. Houtekamer and H. L. Mitchell. Data assimilation using an ensemble Kalman filter technique. Monthly Weather
Review , 126(3):796–811, 1998. doi:10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2.
P. L. Houtekamer and H. L. Mitchell. A sequential ensemble Kalman filter for atmospheric data assimilation. Monthly
Weather Review , 129(1):123–137, 2001. doi:10.1175/1520-0493(2001)129<0123:ASEKFF>2.0.CO;2.
P. L. Houtekamer and H. L. Mitchell. Ensemble Kalman filtering. Quarterly Journal of the Royal Meteorological
Society , 131(613):3269–3289, 2005. doi:10.1256/qj.05.135.
B. R. Hunt, E. J. Kostelich, and I. Szunyogh. Efficient data assimilation for spatiotemporal chaos: A local ensemble trans-
form Kalman filter. Physica D: Nonlinear Phenomena , 230(1-2):112–126, 2007. doi:10.1016/j.physd.2006.11.008.
G. James, D. Witten, T. Hastie, and R. Tibshirani. An Introduction to Statistical Learning . Springer, New York, 2013.
doi:10.1007/978-1-4614-7138-7.
E. Kalnay. Atmospheric Modeling, Data Assimilation and Predictability . Cambridge University Press, Cambridge,
2003. doi:10.1017/CBO9780511802270.
J. D. Keller and S. Wahl. Representation of climate in reanalyses: An intercomparison for Europe and North America.
Journal of Climate , 34(5):1667–1689, 2021. doi:10.1175/JCLI-D-20-0609.1.
15Keller and Potthast: AI-based data assimilation A P REPRINT
R. Lam, A. Sanchez-Gonzalez, M. Willson, P. Wirnsberger, M. Fortunato, F. Alet, S. Ravuri, T. Ewalds, Z. Eaton-Rosen,
W. Hu, A. Merose, S. Hoyer, G. Holland, O. Vinyals, J. Stott, A. Pritzel, S. Mohamed, and P. Battaglia. Learning skill-
ful medium-range global weather forecasting. Science , 382(6677):1416–1421, 2023. doi:10.1126/science.adi2336.
URL https://www.science.org/doi/abs/10.1126/science.adi2336 .
K. Li and J. Malik. Learning to optimize, 2016. URL https://api.semanticscholar.org/CorpusID:13395552 .
X. Liu, Y . Lu, A. Abbasi, M. Li, J. Mohammadi, and S. Kolouri. Teaching networks to solve optimization problems,
2022. URL https://arxiv.org/abs/2202.04104 .
A. C. Lorenc. The potential of the ensemble Kalman filter for NWP: A comparison with 4D-Var. Quarterly
Journal of the Royal Meteorological Society , 129(595):3183–3203, 2003. doi:10.1256/qj.02.132. URL https:
//doi.org/10.1256/qj.02.132 .
A. C. Lorenc, S. P. Ballard, R. S. Bell, N. B. Ingleby, P. L. F. Andrews, D. M. Barker, J. R. Bray, A. M. Clayton, T. Dalby,
D. Li, T. J. Payne, and F. W. Saunders. The Met. Office global three-dimensional variational data assimilation scheme.
Quarterly Journal of the Royal Meteorological Society , 126(570):2991–3012, 2000. doi:10.1002/qj.49712657002.
URL https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.49712657002 .
P. C. Mahalanobis. Reprint of: On the generalised distance in statistics. Sankhya A , 80(Suppl 1):1–7, 2019.
doi:10.1007/s13171-019-00164-5. Originally published in 1936.
G. Nakamura and R. Potthast. Inverse Modeling: An Introduction to the Theory and Methods of Inverse Problems and
Data Assimilation . G - Reference,Information and Interdisciplinary Subjects Series. IOP Publishing, 2015. ISBN
9780750312196. URL https://books.google.de/books?id=toR_jgEACAAJ .
J. Pathak, S. Subramanian, P. Harrington, S. Raja, A. Chattopadhyay, M. Mardani, T. Kurth, D. Hall, Z. Li, K. Aziz-
zadenesheli, P. Hassanzadeh, K. Kashinath, and A. Anandkumar. FourCastNet: A global data-driven high-resolution
weather model using adaptive Fourier neural operators, 2022. URL https://arxiv.org/abs/2202.11214 .
R. Potthast, A. Walter, and A. Rhodin. A localized adaptive particle filter within an operational nwp framework.
Monthly Weather Review , 147(1):345 – 362, 2019. doi:10.1175/MWR-D-18-0028.1.
PyTorch. Pytorch: An imperative style, high-performance deep learning library. https://pytorch.org/ , 2024.
Accessed: 2024-05-31.
Y . Qu, J. Nathaniel, S. Li, and P. Gentine. Deep generative data assimilation in multimodal setting, 2024. URL
https://arxiv.org/abs/2404.06665 .
S. Reich and C. J. Cotter. Probabilistic Forecasting and Bayesian Data Assimilation . Cambridge University Press,
Cambridge, 2015. doi:10.1017/CBO9781107706804.
M. Reinhardt, S. Y . Schoger, F. Kurzrock, and R. Potthast. Convective-scale assimilation of cloud cover from
photographs using a machine learning forward operator. Artificial Intelligence for the Earth Systems , 2(2):e220025,
2023. doi:10.1175/AIES-D-22-0025.1.
L. Scheck. A neural network based forward operator for visible satellite images and its adjoint.
Journal of Quantitative Spectroscopy and Radiative Transfer , 274:107841, 2021. ISSN 0022-4073.
doi:https://doi.org/10.1016/j.jqsrt.2021.107841.
B. Sukhija, N. Köhler, M. Zamora, S. Zimmermann, S. Curi, A. Krause, and S. Coros. Gradient-based trajectory
optimization with learned dynamics, 2023. URL https://arxiv.org/abs/2204.04558 .
P. J. van Leeuwen, Y . Cheng, and S. Reich. Nonlinear Data Assimilation . Springer, Berlin, Heidelberg, 2015.
doi:10.1007/978-3-319-18347-3.
P. J. van Leeuwen, H. R. Künsch, L. Nerger, R. Potthast, and S. Reich. Particle filters for high-dimensional geoscience
applications: A review. Quarterly Journal of the Royal Meteorological Society , 145(723):2335–2365, 2019.
doi:10.1002/qj.3551. URL https://doi.org/10.1002/qj.3551 .
S. Vetra-Carvalho, P. J. van Leeuwen, L. Nerger, A. Barth, M. U. Altaf, P. Brasseur, P. Kirchgessner, and J.-M. Beckers.
State-of-the-art stochastic data assimilation methods for high-dimensional non-Gaussian problems. Tellus A: Dynamic
Meteorology and Oceanography , 70(1):1–43, 2018. doi:10.1080/16000870.2018.1445364.
O. Wichrowska, N. Maheswaranathan, M. W. Hoffman, S. G. Colmenarejo, M. Denil, N. de Freitas, and J. Sohl-
Dickstein. Learned optimizers that scale and generalize, 2017. URL https://arxiv.org/abs/1703.04813 .
G. Zängl. Adaptive tuning of uncertain parameters in a numerical weather prediction model based upon data assimilation.
Quarterly Journal of the Royal Meteorological Society , 149:2861–2880, 2023. doi:10.1002/qj.4535.
16"
13,https://en.wikipedia.org/wiki/Uncertainty_quantification,"



Uncertainty quantification - Wikipedia



























Jump to content







Main menu





Main menu
move to sidebar
hide



		Navigation
	


Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us





		Contribute
	


HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages



















Search











Search






















Appearance
















Donate

Create account

Log in








Personal tools





Donate Create account Log in





		Pages for logged out editors learn more



ContributionsTalk




























Contents
move to sidebar
hide




(Top)





1
Sources




Toggle Sources subsection





1.1
Aleatoric and epistemic






1.1.1
Mathematical perspective












2
Types of problems




Toggle Types of problems subsection





2.1
Forward








2.2
Inverse






2.2.1
Bias correction only








2.2.2
Parameter calibration only








2.2.3
Bias correction and parameter calibration












3
Selective methodologies




Toggle Selective methodologies subsection





3.1
Forward propagation








3.2
Inverse uncertainty






3.2.1
Frequentist








3.2.2
Bayesian






3.2.2.1
Modular approach








3.2.2.2
Full approach














4
Known issues








5
See also








6
References


















Toggle the table of contents







Uncertainty quantification



Add languages





Add links











ArticleTalk





English

















ReadEditView history







Tools





Tools
move to sidebar
hide



		Actions
	


ReadEditView history





		General
	


What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code





		Print/export
	


Download as PDFPrintable version





		In other projects
	


Wikidata item





















Appearance
move to sidebar
hide










From Wikipedia, the free encyclopedia


Characterization and reduction of uncertainties in both computational and real world applications
Uncertainty quantification (UQ) is the science of quantitative characterization and estimation of uncertainties in both computational and real world applications. It tries to determine how likely certain outcomes are if some aspects of the system are not exactly known. An example would be to predict the acceleration of a human body in a head-on crash with another car: even if the speed was exactly known, small differences in the manufacturing of individual cars, how tightly every bolt has been tightened, etc., will lead to different results that can only be predicted in a statistical sense.
Many problems in the natural sciences and engineering are also rife with sources of uncertainty. Computer experiments on computer simulations are the most common approach to study problems in uncertainty quantification.[1][2][3][4][5][6]


Sources[edit]
Uncertainty can enter mathematical models and experimental measurements in various contexts. One way to categorize the sources of uncertainty is to consider:[7]

Parameter
This comes from the model parameters that are inputs to the computer model (mathematical model) but whose exact values are unknown to experimentalists and cannot be controlled in physical experiments, or whose values cannot be exactly inferred by statistical methods. Some examples of this are the local free-fall acceleration in a falling object experiment, various material properties in a finite element analysis for engineering, and multiplier uncertainty in the context of macroeconomic policy optimization.
Parametric
This comes from the variability of input variables of the model. For example, the dimensions of a work piece in a process of manufacture may not be exactly as designed and instructed, which would cause variability in its performance.
Structural uncertainty
Also known as model inadequacy, model bias, or model discrepancy, this comes from the lack of knowledge of the underlying physics in the problem. It depends on how accurately a mathematical model describes the true system for a real-life situation, considering the fact that models are almost always only approximations to reality. One example is when modeling the process of a falling object using the free-fall model; the model itself is inaccurate since there always exists air friction. In this case, even if there is no unknown parameter in the model, a discrepancy is still expected between the model and true physics.
Algorithmic
Also known as numerical uncertainty, or discrete uncertainty. This type comes from numerical errors and numerical approximations per implementation of the computer model. Most models are too complicated to solve exactly. For example, the finite element method or finite difference method may be used to approximate the solution of a partial differential equation (which introduces numerical errors). Other examples are numerical integration and infinite sum truncation that are necessary approximations in numerical implementation.
Experimental
Also known as observation error, this comes from the variability of experimental measurements. The experimental uncertainty is inevitable and can be noticed by repeating a measurement for many times using exactly the same settings for all inputs/variables.
Interpolation
This comes from a lack of available data collected from computer model simulations and/or experimental measurements. For other input settings that don't have simulation data or experimental measurements, one must interpolate or extrapolate in order to predict the corresponding responses.
Aleatoric and epistemic[edit]
Uncertainty is sometimes classified into two categories,[8][9] prominently seen in medical applications.[10]

Aleatoric
Aleatoric uncertainty is also known as stochastic uncertainty, and is representative of unknowns that differ each time we run the same experiment. For example, a single arrow shot with a mechanical bow that exactly duplicates each launch (the same acceleration, altitude, direction and final velocity) will not all impact the same point on the target due to random and complicated vibrations of the arrow shaft, the knowledge of which cannot be determined sufficiently to eliminate the resulting scatter of impact points.  The argument here is obviously in the definition of ""cannot"".  Just because we cannot measure sufficiently with our currently available measurement devices does not preclude necessarily the existence of such information, which would move this uncertainty into the below category. Aleatoric is derived from the Latin alea or dice, referring to a game of chance.
Epistemic uncertainty
Epistemic uncertainty is also known as systematic uncertainty, and is due to things one could in principle know but does not in practice. This may be because a measurement is not accurate, because the model neglects certain effects, or because particular data have been deliberately hidden. An example of a source of this uncertainty would be the drag in an experiment designed to measure the acceleration of gravity near the earth's surface. The commonly used gravitational acceleration of 9.8 m/s² ignores the effects of air resistance, but the air resistance for the object could be measured and incorporated into the experiment to reduce the resulting uncertainty in the calculation of the gravitational acceleration.
Combined occurrence and interaction of aleatoric and epistemic uncertainty
Aleatoric and epistemic uncertainty can also occur simultaneously in a single term E.g., when experimental parameters show aleatoric uncertainty, and those experimental parameters are input to a computer simulation. If then for the uncertainty quantification a surrogate model, e.g. a Gaussian process or a Polynomial Chaos Expansion, is learnt from computer experiments, this surrogate exhibits epistemic uncertainty that depends on or interacts with the aleatoric uncertainty of the experimental parameters.[4] Such an uncertainty cannot solely be classified as aleatoric or epistemic any more, but is a more general inferential uncertainty.
In real life applications, both kinds of uncertainties are present. Uncertainty quantification intends to explicitly express both types of uncertainty separately. The quantification for the aleatoric uncertainties can be relatively straightforward, where traditional (frequentist) probability is the most basic form. Techniques such as the Monte Carlo method are frequently used. A probability distribution can be represented by its moments (in the Gaussian case, the mean and covariance suffice, although, in general, even knowledge of all moments to arbitrarily high order still does not specify the distribution function uniquely), or more recently, by techniques such as Karhunen–Loève and polynomial chaos expansions. To evaluate epistemic uncertainties, the efforts are made to understand the (lack of) knowledge of the system, process or mechanism. Epistemic uncertainty is generally understood through the lens of Bayesian probability, where probabilities are interpreted as indicating how certain a rational person could be regarding a specific claim.

Mathematical perspective[edit]
In mathematics, uncertainty is often characterized in terms of a probability distribution.  From that perspective, epistemic uncertainty means not being certain what the relevant probability distribution is, and aleatoric uncertainty means not being certain what a random sample drawn from a probability distribution will be.

Types of problems[edit]
There are two major types of problems in uncertainty quantification: one is the forward propagation of uncertainty (where the various sources of uncertainty are propagated through the model to predict the overall uncertainty in the system response) and the other is the inverse assessment of model uncertainty and parameter uncertainty (where the model parameters are calibrated simultaneously using test data). There has been a proliferation of research on the former problem and a majority of uncertainty analysis techniques were developed for it. On the other hand, the latter problem is drawing increasing attention in the engineering design community, since uncertainty quantification of a model and the subsequent predictions of the true system response(s) are of great interest in designing robust systems.

Forward[edit]
See also: Propagation of uncertainty
Uncertainty propagation is the quantification of uncertainties in system output(s) propagated from uncertain inputs. It focuses on the influence on the outputs from the parametric variability listed in the sources of uncertainty. The targets of uncertainty propagation analysis can be:

To evaluate low-order moments of the outputs, i.e. mean and variance.
To evaluate the reliability of the outputs. This is especially useful in reliability engineering where outputs of a system are usually closely related to the performance of the system.
To assess the complete probability distribution of the outputs. This is useful in the scenario of utility optimization where the complete distribution is used to calculate the utility.
Inverse[edit]
See also: Inverse problem
Given some experimental measurements of a system and some computer simulation results from its mathematical model, inverse uncertainty quantification estimates the discrepancy between the experiment and the mathematical model (which is called bias correction), and estimates the values of unknown parameters in the model if there are any (which is called parameter calibration or simply calibration). Generally this is a much more difficult problem than forward uncertainty propagation; however it is of great importance since it is typically implemented in a model updating process. There are several scenarios in inverse uncertainty quantification:

The outcome of bias correction, including an updated model (prediction mean) and prediction confidence interval.
Bias correction only[edit]
Bias correction quantifies the model inadequacy, i.e. the discrepancy between the experiment and the mathematical model. The general model updating formula for bias correction is:






y

e


(

x

)
=

y

m


(

x

)
+
δ
(

x

)
+
ε


{\displaystyle y^{e}(\mathbf {x} )=y^{m}(\mathbf {x} )+\delta (\mathbf {x} )+\varepsilon }


where 




y

e


(

x

)


{\displaystyle y^{e}(\mathbf {x} )}

 denotes the experimental measurements as a function of several input variables 




x



{\displaystyle \mathbf {x} }

, 




y

m


(

x

)


{\displaystyle y^{m}(\mathbf {x} )}

 denotes the computer model (mathematical model) response, 



δ
(

x

)


{\displaystyle \delta (\mathbf {x} )}

 denotes the additive discrepancy function (aka bias function), and 



ε


{\displaystyle \varepsilon }

 denotes the experimental uncertainty. The objective is to estimate the discrepancy function 



δ
(

x

)


{\displaystyle \delta (\mathbf {x} )}

, and as a by-product, the resulting updated model is 




y

m


(

x

)
+
δ
(

x

)


{\displaystyle y^{m}(\mathbf {x} )+\delta (\mathbf {x} )}

. A prediction confidence interval is provided with the updated model as the quantification of the uncertainty.

Parameter calibration only[edit]
Parameter calibration estimates the values of one or more unknown parameters in a mathematical model. The general model updating formulation for calibration is:






y

e


(

x

)
=

y

m


(

x

,


θ


∗


)
+
ε


{\displaystyle y^{e}(\mathbf {x} )=y^{m}(\mathbf {x} ,{\boldsymbol {\theta }}^{*})+\varepsilon }


where 




y

m


(

x

,

θ

)


{\displaystyle y^{m}(\mathbf {x} ,{\boldsymbol {\theta }})}

 denotes the computer model response that depends on several unknown model parameters 




θ



{\displaystyle {\boldsymbol {\theta }}}

, and 





θ


∗




{\displaystyle {\boldsymbol {\theta }}^{*}}

 denotes the true values of the unknown parameters in the course of experiments. The objective is to either estimate 





θ


∗




{\displaystyle {\boldsymbol {\theta }}^{*}}

, or to come up with a probability distribution of 





θ


∗




{\displaystyle {\boldsymbol {\theta }}^{*}}

 that encompasses the best knowledge of the true parameter values.

Bias correction and parameter calibration[edit]
It considers an inaccurate model with one or more unknown parameters, and its model updating formulation combines the two together:






y

e


(

x

)
=

y

m


(

x

,


θ


∗


)
+
δ
(

x

)
+
ε


{\displaystyle y^{e}(\mathbf {x} )=y^{m}(\mathbf {x} ,{\boldsymbol {\theta }}^{*})+\delta (\mathbf {x} )+\varepsilon }


It is the most comprehensive model updating formulation that includes all possible sources of uncertainty, and it requires the most effort to solve.

Selective methodologies[edit]
Much research has been done to solve uncertainty quantification problems, though a majority of them deal with uncertainty propagation. During the past one to two decades, a number of approaches for inverse uncertainty quantification problems have also been developed and have proved to be useful for most small- to medium-scale problems.

Forward propagation[edit]
Existing uncertainty propagation approaches include probabilistic approaches and non-probabilistic approaches. There are basically six categories of probabilistic approaches for uncertainty propagation:[11]

Simulation-based methods: Monte Carlo simulations, importance sampling, adaptive sampling, etc.
General surrogate-based methods: In a non-instrusive approach, a surrogate model is learnt in order to replace the experiment or the simulation with a cheap and fast approximation. Surrogate-based methods can also be employed in a fully Bayesian fashion. [12][4][13][14] This approach has proven particularly powerful when the cost of sampling, e.g. computationally expensive simulations, is prohibitively high.
Local expansion-based methods: Taylor series, perturbation method, etc. These methods have advantages when dealing with relatively small input variability and outputs that don't express high nonlinearity. These linear or linearized methods are detailed in the article Uncertainty propagation.
Functional expansion-based methods: Neumann expansion, orthogonal or Karhunen–Loeve expansions (KLE), with polynomial chaos expansion (PCE) and wavelet expansions as special cases.
Most probable point (MPP)-based methods: first-order reliability method (FORM) and second-order reliability method (SORM).
Numerical integration-based methods: Full factorial numerical integration (FFNI) and dimension reduction (DR).
For non-probabilistic approaches, interval analysis,[15] Fuzzy theory, Possibility theory and evidence theory are among the most widely used.
The probabilistic approach is considered as the most rigorous approach to uncertainty analysis in engineering design due to its consistency with the theory of decision analysis. Its cornerstone is the calculation of probability density functions for sampling statistics.[16] This can be performed rigorously for random variables that are obtainable as transformations of Gaussian variables, leading to exact confidence intervals.

Inverse uncertainty[edit]
Frequentist[edit]
In regression analysis and least squares problems, the standard error of parameter estimates is readily available, which can be expanded into a confidence interval.

Bayesian[edit]
Several methodologies for inverse uncertainty quantification exist under the Bayesian framework. The most complicated direction is to aim at solving problems with both bias correction and parameter calibration. The challenges of such problems include not only the influences from model inadequacy and parameter uncertainty, but also the lack of data from both computer simulations and experiments. A common situation is that the input settings are not the same over experiments and simulations. Another common situation is that parameters derived from experiments are input to simulations. For computationally expensive simulations, then often a surrogate model, e.g. a Gaussian process or a Polynomial Chaos Expansion, is necessary, defining an inverse problem for finding the surrogate model that best approximates the simulations.[4]

Modular approach[edit]
An approach to inverse uncertainty quantification is the modular Bayesian approach.[7][17] The modular Bayesian approach derives its name from its four-module procedure. Apart from the current available data, a prior distribution of unknown parameters should be assigned.

Module 1: Gaussian process modeling for the computer model
To address the issue from lack of simulation results, the computer model is replaced with a Gaussian process (GP) model






y

m


(

x

,

θ

)
∼


G
P




(




h


m


(
⋅

)

T




β


m


,

σ

m


2



R

m


(
⋅
,
⋅
)


)




{\displaystyle y^{m}(\mathbf {x} ,{\boldsymbol {\theta }})\sim {\mathcal {GP}}{\big (}\mathbf {h} ^{m}(\cdot )^{T}{\boldsymbol {\beta }}^{m},\sigma _{m}^{2}R^{m}(\cdot ,\cdot ){\big )}}


where






R

m




(


(

x

,

θ

)
,
(


x

′

,


θ

′

)


)


=
exp
⁡

{

−

∑

k
=
1


d



ω

k


m


(

x

k


−

x

k

′


)

2



}

exp
⁡

{

−

∑

k
=
1


r



ω

d
+
k


m


(

θ

k


−

θ

k

′


)

2



}

.


{\displaystyle R^{m}{\big (}(\mathbf {x} ,{\boldsymbol {\theta }}),(\mathbf {x} ',{\boldsymbol {\theta }}'){\big )}=\exp \left\{-\sum _{k=1}^{d}\omega _{k}^{m}(x_{k}-x_{k}')^{2}\right\}\exp \left\{-\sum _{k=1}^{r}\omega _{d+k}^{m}(\theta _{k}-\theta _{k}')^{2}\right\}.}






d


{\displaystyle d}

 is the dimension of input variables, and 



r


{\displaystyle r}

 is the dimension of unknown parameters. While 





h


m


(
⋅
)


{\displaystyle \mathbf {h} ^{m}(\cdot )}

 is pre-defined, 




{



β


m


,

σ

m


,

ω

k


m


,
k
=
1
,
…
,
d
+
r

}



{\displaystyle \left\{{\boldsymbol {\beta }}^{m},\sigma _{m},\omega _{k}^{m},k=1,\ldots ,d+r\right\}}

, known as hyperparameters of the GP model, need to be estimated via maximum likelihood estimation (MLE). This module can be considered as a generalized kriging method.

Module 2: Gaussian process modeling for the discrepancy function
Similarly with the first module, the discrepancy function is replaced with a GP model





δ
(

x

)
∼


G
P




(




h


δ


(
⋅

)

T




β


δ


,

σ

δ


2



R

δ


(
⋅
,
⋅
)


)




{\displaystyle \delta (\mathbf {x} )\sim {\mathcal {GP}}{\big (}\mathbf {h} ^{\delta }(\cdot )^{T}{\boldsymbol {\beta }}^{\delta },\sigma _{\delta }^{2}R^{\delta }(\cdot ,\cdot ){\big )}}


where






R

δ


(

x

,


x

′

)
=
exp
⁡

{

−

∑

k
=
1


d



ω

k


δ


(

x

k


−

x

k

′


)

2



}

.


{\displaystyle R^{\delta }(\mathbf {x} ,\mathbf {x} ')=\exp \left\{-\sum _{k=1}^{d}\omega _{k}^{\delta }(x_{k}-x_{k}')^{2}\right\}.}


Together with the prior distribution of unknown parameters, and data from both computer models and experiments, one can derive the maximum likelihood estimates for 




{



β


δ


,

σ

δ


,

ω

k


δ


,
k
=
1
,
…
,
d

}



{\displaystyle \left\{{\boldsymbol {\beta }}^{\delta },\sigma _{\delta },\omega _{k}^{\delta },k=1,\ldots ,d\right\}}

. At the same time, 





β


m




{\displaystyle {\boldsymbol {\beta }}^{m}}

 from Module 1 gets updated as well.

Module 3: Posterior distribution of unknown parameters
Bayes' theorem is applied to calculate the posterior distribution of the unknown parameters:





p
(

θ

∣

data

,

φ

)
∝
p
(



d
a
t
a

∣

θ

,

φ

)
p
(

θ

)




{\displaystyle p({\boldsymbol {\theta }}\mid {\text{data}},{\boldsymbol {\varphi }})\propto p({\rm {{data}\mid {\boldsymbol {\theta }},{\boldsymbol {\varphi }})p({\boldsymbol {\theta }})}}}


where 




φ



{\displaystyle {\boldsymbol {\varphi }}}

 includes all the fixed hyperparameters in previous modules.

Module 4: Prediction of the experimental response and discrepancy function
Full approach[edit]
Fully Bayesian approach requires that not only the priors for unknown parameters 




θ



{\displaystyle {\boldsymbol {\theta }}}

 but also the priors for the other hyperparameters 




φ



{\displaystyle {\boldsymbol {\varphi }}}

 should be assigned. It follows the following steps:[18]

Derive the posterior distribution 



p
(

θ

,

φ

∣

data

)


{\displaystyle p({\boldsymbol {\theta }},{\boldsymbol {\varphi }}\mid {\text{data}})}

;
Integrate 




φ



{\displaystyle {\boldsymbol {\varphi }}}

 out and obtain 



p
(

θ

∣

data

)


{\displaystyle p({\boldsymbol {\theta }}\mid {\text{data}})}

. This single step accomplishes the calibration;
Prediction of the experimental response and discrepancy function.
However, the approach has significant drawbacks:

For most cases, 



p
(

θ

,

φ

∣

data

)


{\displaystyle p({\boldsymbol {\theta }},{\boldsymbol {\varphi }}\mid {\text{data}})}

 is a highly intractable function of 




φ



{\displaystyle {\boldsymbol {\varphi }}}

. Hence the integration becomes very troublesome. Moreover, if priors for the other hyperparameters 




φ



{\displaystyle {\boldsymbol {\varphi }}}

 are not carefully chosen, the complexity in numerical integration increases even more.
In the prediction stage, the prediction (which should at least include the expected value of system responses) also requires numerical integration. Markov chain Monte Carlo (MCMC) is often used for integration; however it is computationally expensive.
The fully Bayesian approach requires a huge amount of calculations and may not yet be practical for dealing with the most complicated modelling situations.[18]

Known issues[edit]
The theories and methodologies for uncertainty propagation are much better established, compared with inverse uncertainty quantification. For the latter, several difficulties remain unsolved:

Dimensionality issue: The computational cost increases dramatically with the dimensionality of the problem, i.e. the number of input variables and/or the number of unknown parameters.
Identifiability issue:[19] Multiple combinations of unknown parameters and discrepancy function can yield the same experimental prediction. Hence different values of parameters cannot be distinguished/identified. This issue is circumvented in a Bayesian approach, where such combinations are averaged over.[4]
Incomplete model response: Refers to a model not having a solution for some combinations of the input variables.[20][21]
Quantifying uncertainty in the input quantities: Crucial events missing in the available data or critical quantities unidentified to analysts due to, e.g., limitations in existing models.[22]
Little consideration of the impact of choices made by analysts.[23]
See also[edit]
Computer experiment
Further research is needed
Quantification of margins and uncertainties
Probabilistic numerics
Bayesian regression
Bayesian probability
References[edit]


^ Sacks, Jerome; Welch, William J.; Mitchell, Toby J.; Wynn, Henry P. (1989). ""Design and Analysis of Computer Experiments"". Statistical Science. 4 (4): 409–423. doi:10.1214/ss/1177012413. JSTOR 2245858.

^ Iman, Ronald L.; Helton, Jon C. (1988). ""An Investigation of Uncertainty and Sensitivity Analysis Techniques for Computer Models"". Risk Analysis. 8 (1). Wiley: 71–90. Bibcode:1988RiskA...8...71I. doi:10.1111/j.1539-6924.1988.tb01155.x. ISSN 0272-4332.

^ Walker, W.E.; Harremoës, P.; Rotmans, J.; van der Sluijs, J.P.; van Asselt, M.B.A.; Janssen, P.; Krayer von Krauss, M.P. (2003). ""Defining Uncertainty: A Conceptual Basis for Uncertainty Management in Model-Based Decision Support"". Integrated Assessment. 4 (1). Swets & Zeitlinger Publishers: 5–17. Bibcode:2003IntAs...4....5W. doi:10.1076/iaij.4.1.5.16466. hdl:1874/386032. ISSN 1389-5176.

^ a b c d e Ranftl, Sascha; von der Linden, Wolfgang (2021-11-13). ""Bayesian Surrogate Analysis and Uncertainty Propagation"". Physical Sciences Forum. 3 (1): 6. arXiv:2101.04038. doi:10.3390/psf2021003006. ISSN 2673-9984.

^ Ralph C. Smith(Ed.): ""Uncertainty Quantification: Theory, Implementation, and Applications"", 2nd Ed., SIAM, ISBN 978-1-61197-783-7 (2024).

^ T.J. Sullivan:""Introduction to Uncertainty Quantification"", Springer, ISBN 978-3319233949 (Dec, 21st, 2015). 

^ a b Kennedy, Marc C.; O'Hagan, Anthony (2001). ""Bayesian calibration of computer models"". Journal of the Royal Statistical Society, Series B (Statistical Methodology). 63 (3): 425–464. doi:10.1111/1467-9868.00294.

^ Der Kiureghian, Armen; Ditlevsen, Ove (2009). ""Aleatory or epistemic? Does it matter?"". Structural Safety. 31 (2): 105–112. doi:10.1016/j.strusafe.2008.06.020.

^ Matthies, Hermann G. (2007). ""Quantifying Uncertainty: Modern Computational Representation of Probability and Applications"". Extreme Man-Made and Natural Hazards in Dynamics of Structures. NATO Security through Science Series. pp. 105–135. doi:10.1007/978-1-4020-5656-7_4. ISBN 978-1-4020-5654-3.

^ Abhaya Indrayan, Medical Biostatistics, Second Edition, Chapman & Hall/CRC Press, 2008, pages 8, 673

^ Lee, S. H.; Chen, W. (2008-05-09). ""A comparative study of uncertainty propagation methods for black-box-type problems"". Structural and Multidisciplinary Optimization. 37 (3). Springer Science and Business Media LLC: 239–253. doi:10.1007/s00158-008-0234-7. ISSN 1615-147X. S2CID 119988015.

^ Cardenas, IC (2019). ""On the use of Bayesian networks as a meta-modeling approach to analyse uncertainties in slope stability analysis"". Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 13 (1): 53–65. Bibcode:2019GAMRE..13...53C. doi:10.1080/17499518.2018.1498524. S2CID 216590427.

^ Ranftl, Sascha; Melito, Gian Marco; Badeli, Vahid; Reinbacher-Köstinger, Alice; Ellermann, Katrin; von der Linden, Wolfgang (2019-12-31). ""Bayesian Uncertainty Quantification with Multi-Fidelity Data and Gaussian Processes for Impedance Cardiography of Aortic Dissection"". Entropy. 22 (1): 58. Bibcode:2019Entrp..22...58R. doi:10.3390/e22010058. ISSN 1099-4300. PMC 7516489. PMID 33285833.

^ Ranftl, Sascha; Müller, Thomas Stephan; Windberger, Ursula; von der Linden, Wolfgang; Brenn, Günter (2021-05-03), Data and codes for 'A Bayesian Approach to Blood Rheological Uncertainties in Aortic Hemodynamics', doi:10.5281/zenodo.5237189, retrieved 2022-01-12

^ Jaulin, L.; Kieffer, M.; Didrit, O.; Walter, E. (2001). Applied Interval Analysis. Springer. ISBN 1-85233-219-0.

^ Arnaut, L. R. Measurement uncertainty in reverberation chambers - I. Sample statistics. Technical report TQE 2, 2nd. ed., sec. 3.1, National Physical Laboratory, 2008.

^ Marc C. Kennedy, Anthony O'Hagan, Supplementary Details on Bayesian Calibration of Computer Models, Sheffield, University of Sheffield: 1–13, 2000

^ a b Bayarri, M. J.; Berger, J. O.; Liu, F. (2009-03-01). ""Modularization in Bayesian analysis, with emphasis on analysis of computer models"". Bayesian Analysis. 4 (1). Institute of Mathematical Statistics: 119–150. doi:10.1214/09-ba404. ISSN 1936-0975.

^ Arendt, Paul D.; Apley, Daniel W.; Chen, Wei; Lamb, David; Gorsich, David (2012-09-28). ""Improving Identifiability in Model Calibration Using Multiple Responses"". Journal of Mechanical Design. 134 (10). ASME International: 100909. doi:10.1115/1.4007573. ISSN 1050-0472.

^ Cardenas, IC (2019). ""On the use of Bayesian networks as a meta-modeling approach to analyse uncertainties in slope stability analysis"". Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 13 (1): 53–65. Bibcode:2019GAMRE..13...53C. doi:10.1080/17499518.2018.1498524. S2CID 216590427.

^ van den Eijnden, AP; Schweckendiek, T; Hicks, MA (2021). ""Metamodelling for geotechnical reliability analysis with noisy and incomplete models"". Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards. 16 (3): 518–535. doi:10.1080/17499518.2021.1952611. S2CID 238819106.

^ Cardenas, I.; Aven, T.; Flage, R. (2022). ""Addressing challenges in uncertainty quantification. The case of geohazard assessments"". Geosci. Model Dev. Discuss. 16 (6): 1601–1615. doi:10.5194/gmd-16-1601-2023. hdl:11250/3105739.

^ Cardenas, I.; Aven, T.; Flage, R. (2022). ""Addressing challenges in uncertainty quantification. The case of geohazard assessments"". Geosci. Model Dev. Discuss. 16 (6): 1601–1615. doi:10.5194/gmd-16-1601-2023. hdl:11250/3105739.






Retrieved from ""https://en.wikipedia.org/w/index.php?title=Uncertainty_quantification&oldid=1280053307""
Categories: Applied mathematicsMathematical modelingOperations researchStatistical theoryHidden categories: Articles with short descriptionShort description matches Wikidata






 This page was last edited on 12 March 2025, at 05:32 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike 4.0 License;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Code of Conduct
Developers
Statistics
Cookie statement
Mobile view














Search













Search









Toggle the table of contents







Uncertainty quantification




























Add languages


Add topic
















"
14,https://github.com/lululxvi/deepxde,"






































































GitHub - lululxvi/deepxde: A library for scientific machine learning and physics-informed learning














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        lululxvi
 
/

deepxde

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    803




 


          Star
 3.1k








        A library for scientific machine learning and physics-informed learning
      





deepxde.readthedocs.io


License





     LGPL-2.1 license
    






3.1k
          stars
 



803
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
265






Pull requests
14






Discussions







Actions







Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Discussions











          Actions











          Security











          Insights






 





lululxvi/deepxde



 












    masterBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History1,236 Commits.github.github  deepxdedeepxde  dockerdocker  docsdocs  examplesexamples  .codacy.yml.codacy.yml  .gitignore.gitignore  .prospector.yaml.prospector.yaml  .readthedocs.yaml.readthedocs.yaml  CITATION.cffCITATION.cff  LICENSELICENSE  README.mdREADME.md  pyproject.tomlpyproject.toml  requirements.txtrequirements.txt  View all filesRepository files navigationREADMELGPL-2.1 licenseDeepXDE








DeepXDE is a library for scientific machine learning and physics-informed learning. DeepXDE includes the following algorithms:

physics-informed neural network (PINN)

solving different problems

solving forward/inverse ordinary/partial differential equations (ODEs/PDEs) [SIAM Rev.]
solving forward/inverse integro-differential equations (IDEs) [SIAM Rev.]
fPINN: solving forward/inverse fractional PDEs (fPDEs) [SIAM J. Sci. Comput.]
NN-arbitrary polynomial chaos (NN-aPC): solving forward/inverse stochastic PDEs (sPDEs) [J. Comput. Phys.]
PINN with hard constraints (hPINN): solving inverse design/topology optimization [SIAM J. Sci. Comput.]


improving PINN accuracy

residual-based adaptive sampling [SIAM Rev., Comput. Methods Appl. Mech. Eng.]
gradient-enhanced PINN (gPINN) [Comput. Methods Appl. Mech. Eng.]
PINN with multi-scale Fourier features [Comput. Methods Appl. Mech. Eng.]


Slides, Video, Video in Chinese


(physics-informed) deep operator network (DeepONet)

DeepONet: learning operators [Nat. Mach. Intell.]
DeepONet extensions, e.g., POD-DeepONet [Comput. Methods Appl. Mech. Eng.]
MIONet: learning multiple-input operators [SIAM J. Sci. Comput.]
Fourier-DeepONet [Comput. Methods Appl. Mech. Eng.], Fourier-MIONet [arXiv]
physics-informed DeepONet [Sci. Adv.]
multifidelity DeepONet [Phys. Rev. Research]
DeepM&Mnet: solving multiphysics and multiscale problems [J. Comput. Phys., J. Comput. Phys.]
Reliable extrapolation [Comput. Methods Appl. Mech. Eng.]


multifidelity neural network (MFNN)

learning from multifidelity data [J. Comput. Phys., PNAS]



DeepXDE supports five tensor libraries as backends: TensorFlow 1.x (tensorflow.compat.v1 in TensorFlow 2.x), TensorFlow 2.x, PyTorch, JAX, and PaddlePaddle. For how to select one, see Working with different backends.
Documentation: ReadTheDocs




Features
DeepXDE has implemented many algorithms as shown above and supports many features:

enables the user code to be compact, resembling closely the mathematical formulation.
complex domain geometries without tyranny mesh generation. The primitive geometries are interval, triangle, rectangle, polygon, disk, ellipse, star-shaped, cuboid, sphere, hypercube, and hypersphere. Other geometries can be constructed as constructive solid geometry (CSG) using three boolean operations: union, difference, and intersection. DeepXDE also supports a geometry represented by a point cloud.
5 types of boundary conditions (BCs): Dirichlet, Neumann, Robin, periodic, and a general BC, which can be defined on an arbitrary domain or on a point set; and approximate distance functions for hard constraints.
3 automatic differentiation (AD) methods to compute derivatives: reverse mode (i.e., backpropagation), forward mode, and zero coordinate shift (ZCS).
different neural networks: fully connected neural network (FNN), stacked FNN, residual neural network, (spatio-temporal) multi-scale Fourier feature networks, etc.
many sampling methods: uniform, pseudorandom, Latin hypercube sampling, Halton sequence, Hammersley sequence, and Sobol sequence. The training points can keep the same during training or be resampled (adaptively) every certain iterations.
4 function spaces: power series, Chebyshev polynomial, Gaussian random field (1D/2D).
data-parallel training on multiple GPUs.
different optimizers: Adam, L-BFGS, etc.
conveniently save the model during training, and load a trained model.
callbacks to monitor the internal states and statistics of the model during training: early stopping, etc.
uncertainty quantification using dropout.
float16, float32, and float64.
many other useful features: different (weighted) losses, learning rate schedules, metrics, etc.

All the components of DeepXDE are loosely coupled, and thus DeepXDE is well-structured and highly configurable. It is easy to customize DeepXDE to meet new demands.
Installation
DeepXDE requires one of the following backend-specific dependencies to be installed:

TensorFlow 1.x: TensorFlow>=2.7.0
TensorFlow 2.x: TensorFlow>=2.3.0, TensorFlow Probability>=0.11.0
PyTorch: PyTorch>=2.0.0
JAX: JAX, Flax, Optax
PaddlePaddle: PaddlePaddle>=2.6.0

Then, you can install DeepXDE itself.

Install the stable version with pip:

$ pip install deepxde

Install the stable version with conda:

$ conda install -c conda-forge deepxde

For developers, you should clone the folder to your local machine and put it along with your project scripts.

$ git clone https://github.com/lululxvi/deepxde.git
Explore more

Install and Setup
Demos of function approximation
Demos of forward problems
Demos of inverse problems
Demos of operator learning
FAQ
Research papers used DeepXDE
API

Cite DeepXDE
If you use DeepXDE for academic research, you are encouraged to cite the following paper:
@article{lu2021deepxde,
  author  = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
  title   = {{DeepXDE}: A deep learning library for solving differential equations},
  journal = {SIAM Review},
  volume  = {63},
  number  = {1},
  pages   = {208-228},
  year    = {2021},
  doi     = {10.1137/19M1274067}
}

Contributing to DeepXDE
First off, thanks for taking the time to contribute!

Reporting bugs. To report a bug, simply open an issue in the GitHub Issues.
Suggesting enhancements. To submit an enhancement suggestion for DeepXDE, including completely new features and minor improvements to existing functionality, let us know by opening an issue in the GitHub Issues.
Pull requests. If you made improvements to DeepXDE, fixed a bug, or had a new example, feel free to send us a pull-request.
Asking questions. To get help on how to use DeepXDE or its functionalities, you can open a discussion in the GitHub Discussions.
Answering questions. If you know the answer to any question in the Discussions, you are welcomed to answer.

Slack. The DeepXDE Slack hosts a primary audience of moderate to experienced DeepXDE users and developers for general chat, online discussions, collaboration, etc. If you need a slack invite, please send me an email.
The Team
DeepXDE was developed by Lu Lu under the supervision of Prof. George Karniadakis at Brown University from the summer of 2018 to 2020. DeepXDE was originally self-hosted in Subversion at Brown University, under the name SciCoNet (Scientific Computing Neural Networks). On Feb 7, 2019, SciCoNet was moved from Subversion to GitHub, renamed to DeepXDE.
DeepXDE is currently maintained by Lu Lu at Yale University with major contributions coming from many talented individuals in various forms and means. A non-exhaustive but growing list needs to mention: Paul Escapil-Inchauspé, Zongren Zou, Jialin Li, Saransh Chopra, Sensen He, Vladimir Dudenkov, Anran Jiao, Zhongyi Jiang, Shunyuan Mao.
License
LGPL-2.1 License
   








About

        A library for scientific machine learning and physics-informed learning
      





deepxde.readthedocs.io


Topics



  deep-learning


  neural-network


  tensorflow


  pytorch


  operator


  pde


  paddle


  pinn


  jax


  scientific-machine-learning


  multi-fidelity-data


  physics-informed-learning


  deeponet



Resources





        Readme
 
License





     LGPL-2.1 license
    







Activity 
Stars




3.1k
      stars 
Watchers




59
      watching 
Forks




803
      forks 


          Report repository
 






Releases
      70






DeepXDE v1.13.2

          Latest
 
Mar 3, 2025

 
+ 69 releases





Packages
      0

        No packages published 






Used by 198 




























        + 190
      






Contributors
      75









































































+ 61 contributors




Languages











Python
99.9%







Dockerfile
0.1%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
15,https://smt.readthedocs.io/en/latest/index.html,"





SMT: Surrogate Modeling Toolbox — SMT 2.9.2 documentation















Navigation


index

next |
SMT 2.9.2 documentation »
SMT: Surrogate Modeling Toolbox









SMT: Surrogate Modeling Toolbox¶
The surrogate modeling toolbox (SMT) is an open-source Python package consisting of libraries of surrogate modeling methods (e.g., radial basis functions, kriging), sampling methods, and benchmarking problems.
SMT is designed to make it easy for developers to implement new surrogate models in a well-tested and well-document platform, and for users to have a library of surrogate modeling methods with which to use and compare methods.
The code is available open-source on GitHub together with introducing tutorials.


Cite us¶
To cite SMT 2.0: P. Saves and R. Lafage and N. Bartoli and Y. Diouane and J. H. Bussemaker and T. Lefebvre and J. T. Hwang and J. Morlier and J. R. R. A. Martins.
SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and Mixed Variables Gaussian Processes, Advances in Engineering Software, 2024.
@article{saves2024smt,
        author = {P. Saves and R. Lafage and N. Bartoli and Y. Diouane and J. Bussemaker and T. Lefebvre and J. T. Hwang and J. Morlier and J. R. R. A. Martins},
        title = {{SMT 2.0: A} Surrogate Modeling Toolbox with a focus on Hierarchical and Mixed Variables Gaussian Processes},
        journal = {Advances in Engineering Sofware},
        year = {2024},
        volume = {188},
        pages = {103571},
        doi = {https://doi.org/10.1016/j.advengsoft.2023.103571}}


To cite SMT legacy: M. A. Bouhlel and J. T. Hwang and N. Bartoli and R. Lafage and J. Morlier and J. R. R. A. Martins.
A Python surrogate modeling framework with derivatives. Advances in Engineering Software, 2019.
@article{SMT2019,
        Author = {Mohamed Amine Bouhlel and John T. Hwang and Nathalie Bartoli and Rémi Lafage and Joseph Morlier and Joaquim R. R. A. Martins},
        Journal = {Advances in Engineering Software},
        Title = {A Python surrogate modeling framework with derivatives},
        pages = {102662},
        issn = {0965-9978},
        doi = {https://doi.org/10.1016/j.advengsoft.2019.03.005},
        Year = {2019}}




Focus on derivatives¶
SMT is meant to be a general library for surrogate modeling (also known as metamodeling, interpolation, and regression), but its distinguishing characteristic is its focus on derivatives, e.g., to be used for gradient-based optimization.
A surrogate model can be represented mathematically as

\[y = f(\mathbf{x}, \mathbf{xt}, \mathbf{yt}),\]
where
\(\mathbf{xt} \in \mathbb{R}^{nt \times nx}\) contains the training inputs,
\(\mathbf{yt} \in \mathbb{R}^{nt}\) contains the training outputs,
\(\mathbf{x} \in \mathbb{R}^{nx}\) contains the prediction inputs,
and
\(y \in \mathbb{R}\) contains the prediction outputs.
There are three types of derivatives of interest in SMT:

Derivatives (\({dy}/{dx}\)): derivatives of predicted outputs with respect to the inputs at which the model is evaluated.
Training derivatives (\({dyt}/{dxt}\)): derivatives of training outputs, given as part of the training data set, e.g., for gradient-enhanced kriging.
Output derivatives (\({dy}/{dyt}\)): derivatives of predicted outputs with respect to training outputs, representing how the prediction changes if the training outputs change and the surrogate model is re-trained.

Not all surrogate modeling methods support or are required to support all three types of derivatives; all are optional.


Documentation contents¶


Getting started
Surrogate modeling methods
Least-squares approximation
Second-order polynomial approximation
Gaussian process regression
Kriging (KRG)
KPLS
KPLSK
GPX
GEKPLS
Marginal Gaussian Process (MGP)
Sparse Gaussian Process (SGP)


Radial basis functions
Inverse-distance weighting
Regularized minimal-energy tensor-product splines
GENN


Benchmarking problems
Sphere function
Branin function
Lp norm function
Rosenbrock function
Tensor-product function
Cantilever beam function
Mixed cantilever beam function
Multi-layer perceptron
Robot arm function
Torsion vibration function
Water flow function
Welded beam function
Wing weight function


Sampling methods
Random sampling
Latin Hypercube sampling
Full-factorial sampling
pyDOE sampling methods


Examples
1-D step-like data set
RANS CRM wing 2-D data set
Boeing 777 engine data set
Learning Airfoil Parameters


Applications
Mixed Integer and Hierarchical Design Spaces (Variables, Sampling and Context)
Mixed Integer and hierarchical Surrogates
Mixture of experts (MOE)
Variable-fidelity modeling (VFM)
Multi-Fidelity Kriging (MFK)
Multi-Fidelity Co-Kriging (MFCK)
Multi-Fidelity Kriging KPLS (MFKPLS)
Multi-Fidelity Kriging KPLSK (MFKPLSK)
Efficient Global Optimization (EGO)
Proper Orthogonal Decomposition + Interpolation (PODI)
Cooperative Components Kriging (CoopCompKRG)


Contributing to SMT
Developer API for surrogate models
Developer API for benchmarking problems
Developer API for design spaces
Developer API for sampling methods





Indices and tables¶

Index
Search Page













Table of Contents

SMT: Surrogate Modeling Toolbox
Cite us
Focus on derivatives
Documentation contents
Indices and tables





Next topic
Getting started


This Page

Show Source



Quick search













Navigation


index

next |
SMT 2.9.2 documentation »
SMT: Surrogate Modeling Toolbox



    © Copyright 2017, John Hwang.
      Created using Sphinx 8.2.3.
    

"
16,https://neuraloperator.github.io/dev/user_guide/neural_operators.html,"




Neural Operators: an Introduction — neuraloperator 1.0.2 documentation












































              Install
            

              User Guide
            

              API
            

              Examples
            

              Developer's Guide
            








Github




























Installing NeuralOperator
User Guide
API reference
Examples
NeuralOperator Developer’s Guide









menu




Neural Operators: an Introduction
Here, we introduce neural operators, a class of models that learn
mappings between function spaces and solve partial differential equations.
You can also check out the papers [1] and [2] for more formal derivations,
as well as the blog post [3].

Introduction
Scientific computations are expensive.
It could take days and months for numerical solvers to simulate fluid dynamics and many-body motions.
Because to achieve good accuracy,
the numerical solvers need to discretize the space and time into very fine grids
and solve a great number of equations on the grids.
Recently, people are developing data-driven methods based on machine learning techniques such as deep learning.
Instead of directly solving the problems, data-driven solvers learn from the data of the problems and solutions.
When querying new problems, data-driven solvers can directly give predictions based on the data.
Since they don’t need to discretize the space into very small pieces and solve all these equations,
these data-driven solvers are usually much faster compared to traditional numerical solvers.
However, data-driven solvers are subject to the quality of the data given.
If the training data is not good enough, they can’t make good predictions.
In scientific computing, usually, the training data are generated by the traditional numerical solvers.
And to generate good enough data, it still takes days and months for these numerical solvers.
Sometime, data are observed from experiments and there are just no good training data.
Especially, people consider neural networks as interpolators which may not be able to extrapolate.
It is unclear whether neural networks can generalize to unseen data.
So if the training data are of one resolution,
the learned solvers can only solve the problem in this specific resolution.
In general, generalization is a crucial problem in machine learning.
It becomes a trade-off: these machine learning based methods make evaluation easier,
but the training process could be even more painful.
To dealing with this problem, we purpose operator learning. By encoding certain structures,
we let the neural network learn the mapping of functions and generalize among different resolutions.
As a result, we can first use a numerical method generated some less-accurate, low-resolution data,
but the learned solver is still able to give reasonable, high-resolution predictions.
In some sense, both training and evaluation can be pain-free.


Operator Learning
In mathematics, operators are usually referring to the mappings between function spaces.
You most likely have already encountered some operators.
For example, the differentiation and integration are operators.
When we take the derivative  or do an indefinite integration of a function,
we will get another function.
In other words, the differentiation and integration are mappings from function space to function space.
In scientific computing, usually the problem is to solve some form of differential equations. Consider a general differential equation of the form:

\[\mathcal{L}u = f\]
where  \(u\) and \(f\) are some functions on the physical domain, and
\(\mathcal{L}\) is some differential operator that maps
the function \(u\) to the function \(f\).
Usually, \(\mathcal{L}\) and \(f\) are given. The task is to solve for \(u\).
That is, we want to learn an operator like the inverse of \(\mathcal{L}\) that
maps the function \(f\) to the function \(u\).
So the problem of PDE is indeed an operator learning problem.
The classical development of neural networks has been primarily
for mappings between a finite-dimensional Euclidean space and a set of classes
(e.g. an image vector to a label),
or between two finite-dimensional Euclidean spaces (e.g. an image vector to another image vector).
However, many problems in physics and math involve learning the mapping between function spaces,
which poses a limitation on the classical neural network based methods.
Besides all these problem governed by differential equations,
we are learning operators in many common machine learning setting.
For a bold example, images should be considered as functions of light defined on a continuous region,
instead of as \(32 \times 32\) pixel vectors.
In this work, we aim to generalize neural networks so that they can learn operators,
the mappings between infinite-dimensional spaces, with a special focus on PDEs.


Limitation of Fixed Discretization
PDEs are, unfortunately, hard.
Instead of learning the operator, people usually discretize the physical domain
and cast the problem in finite-dimensional Euclidean space.
Indeed, hundred years of effort has been made to develop numerical solvers
such as the finite element method and finite difference method.


Three examples of discretization.
The left one is a regular grid used in the finite difference method;
the middle one is a triangulated grid used in the finite element method;
the right one is a cylinder mesh for real-world airfoil problem.
Just like how we store images by pixels in .PNG and .JPG formats,
we need to discretize the domain of PDEs into some grid and solve the equation on the grid.
It really makes the thing easier.
These traditional numerical solvers are awesome, but they have some drawbacks:

The error scales steeply with the resolution. We need a high resolution to get good approximations.
The computation and storage steeply scale with the resolution (i.e. the size of the grid).
When the equation is solved on one discretization, we cannot change the discretization anymore.

.PNG and .JPG formats are good.
But sometimes maybe we want to save the images as vector images in .EPS or .SVG formats,
so that it can be used and displayed in any context.
And for some images, the vector image format is more convenient and efficient.
Similarly, we want to find the continuous version for PDEs, an operator that is invariant of discretization.
Furthermore, mathematically speaking, such continuous,
discretization-invariant format is in some sense, closer to the real, analytic solution.
It has an important mathematical meaning.
Bear the motivation in mind. Let’s develop a rigorous formulation.


Problem Setting
Let’s be more concrete. Consider the standard second order elliptic PDE

\[- \nabla \cdot (a(x) \nabla u(x))  = f(x), \quad  x \in D\]

\[u(x) = 0, \quad x \in \partial D\]
for some bounded, open domain \(D \subset \mathbb{R}^d\) and a fixed source function
\(f\). This equation is prototypical of PDEs arising in
numerous applications including hydrology  and elasticity.
For a given function \(a\),
the equation has a unique weak solution \(u\)
and therefore we can define the solution operator \(\mathcal{F}_{true}\)
as the map from function to function \(a \mapsto u\).
Our goal is to learn a operator \(\mathcal{F}\) approximating \(\mathcal{F}_{true}\),
by using a finite collection of observations of input-output pairs
\(\{a_j, u_j\}_{j=1}^N\), where each \(a_j\) and \(u_j\) are functions on \(D\).
In practice, the training data is solved numerically or observed in experiments.
In other words, functions \(a_j\) and \(u_j\) come with discretization.
Let \(P_K = \{x_1,\dots,x_K\} \subset D\) be a \(K\)-point discretization of the domain
\(D\) and assume we have observations \(a_j|_{P_K}, u_j|_{P_K}\), for a finite
collection  of input-output pairs indexed by \(j\).
We will show how to learn a discretization-invariant mapping based on discretized data.


Kernel Formulation
For a general PDE of the form:

\[(\mathcal{L}_a u)(x)= f(x), \quad x \in D\]

\[u(x) = 0, \quad x \in \partial D\]
Under fairly general conditions on \(\mathcal{L}_a\),
we may define the Green’s function \(G : D \times D \to \mathbb{R}\) as the
unique solution to the problem

\[\mathcal{L}_a G(x, \cdot) = \delta_x\]
where \(\delta_x\) is the delta measure on \(\mathbb{R}^d\) centered at \(x\).
Note that \(G\) will depend on the coefficient \(a\) thus we will henceforth denote it as \(G_a\).
Then operator \(\mathcal{F}_{true}\) can be written as an integral operator of green function:

\[u(x) = \int_D G_a(x,y)f(y) \: dy\]
Generally the Green’s function is continuous at points \(x \neq y\),
for example, when \(\mathcal{L}_a\) is uniformly elliptic.
Hence it is natural to model the kernel via a neural network \(\kappa\).
Just as the Green function, the kernel network \(\kappa\) takes input \((x,y)\).
Since the kernel depends on \(a\), we let \(\kappa\) also take input \((a(x),a(y))\).

\[u(x) = \int_D \kappa(x,y,a(x),a(y))f(y) \: dy\]


As an Iterative Solver
In our setting, \(f\) is an unknown but fixed function.
Instead of doing the kernel convolution with \(f\),
we will formulate it as an iterative solver
that approximated \(u\) by \(u_t\),
where \(t = 0,\ldots,T\) is the time step.
The algorithm starts from an initialization \(u_0\),
for which we use \(u_0(x) = (x, a(x))\).
At each time step \(t\), it updates \(u_{t+1}\) by an kernel convolution of \(u_{t}\).

\[u_{t+1}(x) = \int_D \kappa(x,y,a(x),a(y))u_{t}(x) \: dy\]
It works like an implicit iteration.
At each iteration the algorithm solves an equation of \(u_{t}(x)\) and \(u_{t+1}(x)\)
by the kernel integral. \(u_T\) will be output as the final prediction.
To further take the advantage of neural networks,
we will lift \(u(x) \in \mathbb{R}^d\)
to a high dimensional representation \(v(x) \in \mathbb{R}^n\),
with \(n\) the dimension of the hidden representation.
The overall algorithmic framework follow:

\[v_0(x) = NN_1 (x, a(x))\]

\[v_{t+1}(x) = \sigma\Big( W v_t(x) + \int_{B(x,r)} \kappa_{\phi}\big(x,y,a(x),a(y)\big) v_t(y)\: \mathrm{d}y \Big) \quad \text{for } \ t=1,\ldots,T\]

\[u(x) = NN_2 (v_T (x))\]
where \(NN_1\) and \(NN_2\) are two feed-forward neural networks
that lifts the initialization to hidden representation \(v\)
and projects the representation back to the solution \(u\), respective.
\(\sigma\) is an activation function such as ReLU.
the additional term \(W \in \mathbb{R}^{n \times n}\) is a linear transformation
that acts on $v$.
Notice, since the kernel integration happens in the high dimensional representation,
the output of \(\kappa_{\phi}\) is not a scalar,
but a linear transformation \(\kappa_{\phi}\big(x,y,a(x),a(y)\big)\in \mathbb{R}^{n \times n}\).


Graph Neural Networks
To do the integration, we again need some discretization.
Assuming a uniform distribution of \(y\),
the integral \(\int_{B(x,r)} \kappa_{\phi}\big(x,y,a(x),a(y)\big)
v_t(y)\: \mathrm{d}y\) can be approximated by a sum:

\[\frac{1}{|N|}\sum_{y \in N(x)} \kappa(x,y,a(x),a(y))v_t(y)\]
Observation: the kernel integral is equivalent to the message passing on graphs
If you are similar with graph neural network,
you may have already realized this formulation is the same as
the aggregation of messages in graph network.
Message passing graph networks comprise a standard architecture employing edge features
(gilmer et al, 2017).
If we properly construct graphs on the spatial domain \(D\) of the PDE,
the kernel integration can be viewed as an aggregation of messages.
Given node features \(v_t(x) \in \mathbb{R}^{n}\),
edge features \(e(x,y) \in \mathbb{R}^{n_e}\),
and a graph \(G\), the message passing neural network with averaging aggregation is

\[v_{t+1}(x) =  \sigma\Big(W v_t(x) + \frac{1}{|N(x)|} \sum_{y \in N(x)} \kappa_{\phi}\big(e(x,y)\big) v_t(y)\Big)\]
where \(W \in \mathbb{R}^{n \times n}\),
\(N(x)\) is the neighborhood of \(x\) according to the graph,
\(\kappa_{\phi}\big(e(x,y)\big)\) is a neural network
taking as input edge features and as output
a matrix in \(\mathbb{R}^{n \times n}\).
Relating to our kernel formulation, \(e(x,y) = (x,y,a(x),a(y))\).




Nystrom Approximation
Ideally, to use all the information available,
we should construct \(K\) nodes in the graph for all the points in the discretization
\(P_k = \{x_1,\ldots, x_K\}\), which will create \(O(K^2)\) edges.
It is quite expensive.
Thankfully, we don’t need all the points to get an accurate approximation.
For each graph, the error of Monte Carlo approximation of the kernel integral
\(\int_{B(x,r)} \kappa_{\phi}(x,y) v_t(y)\: \mathrm{d}y\) scales with \(m^{-1/2}\),
where \(m\) is the number of nodes sampled.
Since we will sample \(N\) graphs in total for all \(N\) training examples \(\{a_j, u_j\}^N\),
the overall error of the kernel is much smaller than \(m^{-1/2}\).
In practice, sampling \(m \sim 200\) nodes is sufficient for \(K \sim 100000\) points.
It is possible to further improve the approximation
using more sophisticated Nystrom Approximation methods.
For example, we can estimate the importance of each points,
and add more nodes to the difficult and singularity areas in the PDEs.


Experiments: Poisson Equations
First let’s do a sanity check. Consider a simple poisson equation:

\[-\Delta u = f\]
We set \(v_0 = f\) and \(T=1\), using one iteration of the graph kernel network
to learn the operator \(\mathcal{F}: f \mapsto u\).

poisson equation


As shown in the figure above, we compare the true analytic Green function \(G(x,y)\) (left)
with the learned kernel \(\kappa_{\phi}(x,y)\)  (right).
The learned kernel is almost the same as the true kernel,
which means are neural network formulation does match the Green function expression.


2D poisson equation


By assuming the kernel structure,
graph kernel networks need only a few training examples to learn the shape of solution \(u\).
As shown in the figure above, the graph kernel network can roughly learn \(u\) with \(5\) training pairs,
which a feedforward neural network need at least \(100\) training examples.



Experiments: generalization of resolution
For the large scale experiments, we use Darcy equation of the form

\[- \nabla \cdot (a(x) \nabla u(x))  = f(x), \quad  x \in D\]

\[u(x) = 0, \quad x \in \partial D\]
and learn the operator \(\mathcal{F}: a \mapsto u\).
To show the generalization property, we train the graph kernel network
with nodes sampled from the resolution \(s \times s\)
and test on another resolution \(s' \times s'\) .
As shown in the table above for each row,
the test errors on different resolutions are about the same,
which means the graph kernel network can
also generalize in the semi-supervised setting.
An figure for \(s=16, s'=241\) is following (where error is absolute squared error):




Conclusion
In the work we purposed to use graph networks for operator learning in PDE problems.
By varying the underlying graph and discretization,
the learned kernel is invariant of the discretization.
Experiments confirm the graph kernel networks are able to generalize among different discretization.
And in the fixed discretization setting, the graph kernel networks also have good performances compared to several benchmark.


References


[1]
Neural operator: Graph kernel network for partial differential equations,
Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar


[2]
Neural operator: Learning maps between function spaces,
Nikola Kovachki, Zongyi Li, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar


[3]
Blog post by Zongyi Li, https://zongyi-li.github.io/blog/2020/graph-pde/










          © Copyright 2025, Jean Kossaifi, David Pitt, Nikola Kovachki, Zongyi Li and Anima Anandkumar.










 On this page 




Neural Operators: an Introduction
Introduction
Operator Learning
Limitation of Fixed Discretization
Problem Setting
Kernel Formulation
As an Iterative Solver
Graph Neural Networks
Nystrom Approximation
Experiments: Poisson Equations
poisson equation
2D poisson equation


Experiments: generalization of resolution
Conclusion
References










"
17,https://github.com/pnnl/neuromancer,"






































































GitHub - pnnl/neuromancer: Pytorch-based framework for solving parametric constrained optimization problems, physics-informed system identification, and parametric model predictive control.














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        pnnl
 
/

neuromancer

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    143




 


          Star
 1.1k








        Pytorch-based framework for solving parametric constrained optimization problems, physics-informed system identification, and parametric model predictive control. 
      





pnnl.github.io/neuromancer/


License





     View license
    






1.1k
          stars
 



143
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
6






Pull requests
6






Discussions







Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Discussions











          Actions











          Projects











          Security











          Insights






 





pnnl/neuromancer



 












    masterBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History705 Commits.github/workflows.github/workflows  assistantassistant  docsdocs  examplesexamples  figsfigs  src/neuromancersrc/neuromancer  teststests  .gitignore.gitignore  CONTRIBUTING.mdCONTRIBUTING.md  INSTALLATION.mdINSTALLATION.md  LICENSE.mdLICENSE.md  README.mdREADME.md  README_old.mdREADME_old.md  RELEASE_NOTES.mdRELEASE_NOTES.md  USER_GUIDE.mdUSER_GUIDE.md  linux_env.ymllinux_env.yml  osxarm64_env.ymlosxarm64_env.yml  pyproject.tomlpyproject.toml  windows_env.ymlwindows_env.yml  View all filesRepository files navigationREADMELicense


NeuroMANCER v1.5.3




Neural Modules with Adaptive Nonlinear Constraints and Efficient Regularizations (NeuroMANCER)
is an open-source differentiable programming (DP) library for solving parametric constrained optimization problems,
physics-informed system identification, and parametric model-based optimal control.
NeuroMANCER is written in PyTorch and allows for systematic
integration of machine learning with scientific computing for creating end-to-end
differentiable models and algorithms embedded with prior knowledge and physics.

Table of Contents

Overview
Key Features
What's New in v1.5.3
Installation
Getting Started
Tutorials
Documentation and User Guides


Key Features

Learn To Model, Learn To Control, Learn To Optimize: Our library is built to provide end users a multitude of tools to solve Learning To Optimize (L2O), Learning To Model (L2M), and Learning To Control (L2C) tasks. Tackle advanced constrained parametric optimization, model fluid dynamics using physics-informed neural networks, or learn how to control indoor air temperature in buildings to maximize building efficiency.
Symbolic programming interface makes it very easy to define embed prior knowledge of physics, domain knowledge, and constraints into those learning paradigms.
Comprehensive Learning Tools: Access a wide array of tutorials and example applications—from basic system identification to advanced predictive control—making it easy for users to learn and apply NeuroMANCER to real-world problems.
State-of-the-art methods: NeuroMANCER is up-to-date with SOTA methods such as Kolgomorov-Arnold Networks (KANs) for function approximation, neural ordinary differential equations (NODEs) and sparse identification of non-linear dynamics (SINDy) for learning to model dynamical systems, and differentiable convex optimization layers for safety constraints in learning to optimize and learning to control.

What's New in v1.5.3
The NeuroMANCER-GPT Assistant
We provide the easy-to-use scripts to convert the contents of the NeuroMANCER library in a way that is suitable for ingestion in RAG-based ""LLM-assistant"" pipelines. Please see Assistant to read more about how one can quickly spin-up an LLM model to help understand and code in NeuroMANCER.
Building Control Comparison: Reinforcement Learning vs Differential Predictive Control Example
We add to our growing library of building modeling and control tutorials a highly education and in-depth walkthrough of reinforcement learning (RL) methods and compare them to differential predictive control (DPC) in NeuroMANCER. This notebook shows that the while the RL solution is more adaptive, the DPC solution in NeuroMANCER is more energy-efficien, has smoother control actions, trains faster and is easier constraint enforcement.
Python 3.11 Version Support
NeuroMANCER has been updated to support Python 3.11.
New Feature: Improved Node Class
The Node class has been updated to accept instantiated Variable objects as well. The change is backwards-compatible and simplifies house-keeping for the user.
New Colab Examples:

⭐ Building Energy Systems Modeling and Control

Installation
Simply run
pip install neuromancer

For manual installation, please refer to  Installation Instructions
Getting Started
An extensive set of tutorials can be found in the
examples folder and the Tutorials below.
Interactive notebook versions of examples are available on Google Colab!
Test out NeuroMANCER functionality before cloning the repository and setting up an
environment.
The notebooks below introduce the core abstractions of the NeuroMANCER library, in particular, our symbolic programming interface and Node classes.
Symbolic Variables, Nodes, Constraints, Objectives, and Systems Classes



Part 1: Linear regression in PyTorch vs NeuroMANCER.



Part 2: NeuroMANCER syntax tutorial: variables, constraints, and objectives.



Part 3: NeuroMANCER syntax tutorial: modules, Node, and System class.


Example
Quick example for how to solve parametric constrained optimization problem using NeuroMANCER, leveraging our symbolic programming interface, Node and Variable, Blocks, SLiM library, and PenaltyLoss classes.
# Neuromancer syntax example for constrained optimization
import neuromancer as nm
import torch 

# define neural architecture 
func = nm.modules.blocks.MLP(insize=1, outsize=2, 
                             linear_map=nm.slim.maps['linear'], 
                             nonlin=torch.nn.ReLU, hsizes=[80] * 4)
# wrap neural net into symbolic representation via the Node class: map(p) -> x
map = nm.system.Node(func, ['p'], ['x'], name='map')
    
# define decision variables
x = nm.constraint.variable(""x"")[:, [0]]
y = nm.constraint.variable(""x"")[:, [1]]
# problem parameters sampled in the dataset
p = nm.constraint.variable('p')

# define objective function
f = (1-x)**2 + (y-x**2)**2
obj = f.minimize(weight=1.0)

# define constraints
con_1 = 100.*(x >= y)
con_2 = 100.*(x**2+y**2 <= p**2)

# create penalty method-based loss function
loss = nm.loss.PenaltyLoss(objectives=[obj], constraints=[con_1, con_2])
# construct differentiable constrained optimization problem
problem = nm.problem.Problem(nodes=[map], loss=loss)
Domain Examples
NeuroMANCER is built to tackle a variety of domain-specific modeling and control problems using its array of methods. Here we show how to model and control building energy systems, as well as apply load forecasting techniques.
For more in-depth coverage of our methods, please see our general Tutorials section below.
Energy Systems



 Learning Building Thermal Dynamics using Neural ODEs 



 Multi-zone Building Thermal Dynamics Resistance-Capacitance network with Neural ODEs



 Learning Swing Equation Dynamics using Neural ODEs



 Learning to Control Indoor Air Temperature in Buildings



 Energy Load Forecasting for the Air Handling System of an Office Building with MLP and CNN models



  Energy Load Forecasting for Building with Transformers Model



 Learning to Control Pumped-storage Hyrdoelectricity System



 Learning to Control Indoor Air Temperature in Buildings With Safe Reinforcement Learning and Differentiable Predictive Control


Tutorials on Methods for Modeling, Optimization, and Control
Learning to Optimize (L2O) Parametric Programming
Neuromancer allows you to formulate and solve a broad class of parametric optimization problems leveraging machine learning to learn the solutions to such problems. More information on Parametric programming



Part 1: Learning to solve a constrained optimization problem.



Part 2: Learning to solve a quadratically-constrained optimization problem.



Part 3: Learning to solve a set of 2D constrained optimization problems.



Part 4: Learning to solve a constrained optimization problem with the projected gradient.



Part 5: Using Cvxpylayers for differentiable projection onto the polytopic feasible set.



Part 6: Learning to optimize with metric learning for Operator Splitting layers.


Learning to Control (L2C)
Neuromancer allows you to learn control policies for full spectrum of white/grey/black-box dynamical systems, subject to choice constraints and objective functions.
More information on Differential Predictive Control



 Part 1: Learning to stabilize a linear dynamical system.



 Part 2: Learning to stabilize a nonlinear differential equation.



 Part 3: Learning to control a nonlinear differential equation.



 Part 4: Learning neural ODE model and control policy for an unknown dynamical system.



 Part 5: Learning neural Lyapunov function for a nonlinear dynamical system.


Function Approximation
Neuromancer is up-to-date with state-of-the-art methods. Here we showcase the powerful Kolgomorov-Arnold networks More information on Kolgomorov-Arnold Networks

 Part 1: A comparison of KANs and FBKANs in learning a 1D multiscale function with noise
 Part 2: A comparison of KANs and FBKANs in learning a 2D multiscale function with noise

Neural Operators
Neuromancer allows one to use machine learning, prior physics and domain knowledge, to construct mathematical and differentiabl models of dynamical systems given the measured observations of the system behavior.
More information on System ID via Neural State Space Models and ODEs



 Part 1: Neural Ordinary Differential Equations (NODEs)



 Part 2: Parameter estimation of ODE system



 Part 3: Universal Differential Equations (UDEs)



 Part 4: NODEs with exogenous inputs



 Part 5: Neural State Space Models (NSSMs) with exogenous inputs



 Part 6: Data-driven modeling of resistance-capacitance (RC) network ODEs



 Part 7: Deep Koopman operator



 Part 8: control-oriented Deep Koopman operator



 Part 9: Sparse Identification of Nonlinear Dynamics (SINDy)


Physics-Informed Neural Networks (PINNs)
Neuromancer's symbolic programming design is perfectly suited for solving PINNs. More information on PINNs

 Part 1: Diffusion Equation
 Part 2: Burgers' Equation
 Part 3: Burgers' Equation w/ Parameter Estimation (Inverse Problem)
 Part 4: Laplace's Equation (steady-state)
 Part 5: Damped Pendulum (stacked PINN)
 Part 6: Navier-Stokes equation (lid-driven cavity flow, steady-state, KAN)

Stochastic Differential Equations (SDEs)
Neuromancer has been integrated with TorchSDE to handle stochastic dynamical systems. More information on SDEs



 LatentSDEs: ""System Identification"" of Stochastic Processes using Neuromancer x TorchSDE


Scalability and Customization
PyTorch Lightning Integration
We have integrated PyTorch Lightning to streamline code, enable custom training logic, support GPU and multi-GPU setups, and handle large-scale, memory-intensive learning tasks.



 Part 1: Lightning Integration Basics.



 Part 2: Lightning Advanced Features and Automatic GPU Support.



 Part 4: Defining Custom Training Logic via Lightning Modularized Code.


Documentation and User Guides
The documentation for the library can be found online.
There is also an introduction video covering
the core features of the library.
For more information, including those for developers, please go to our Developer and User Guide
Community Information
We welcome contributions and feedback from the open-source community!
Contributions, Discussions, and Issues
Please read the Community Development Guidelines
for further information on contributions, discussions, and Issues.
Release notes
See the Release notes documenting new features.
License
NeuroMANCER comes with BSD license.
See the license for further details.
Publications

Bo Tang, Elias B. Khalil, Ján Drgoňa, Learning to Optimize for Mixed-Integer Non-linear Programming, arXiv:2410.11061, 2024
John Viljoen, Wenceslao Shaw Cortez, Jan Drgona, Sebastian East, Masayoshi Tomizuka, Draguna Vrabie, Differentiable Predictive Control for Robotics: A Data-Driven Predictive Safety Filter Approach, arXiv:2409.13817, 2024
Jan Drgona, Aaron Tuor, Draguna Vrabie, Learning Constrained Parametric Differentiable Predictive Control Policies With Guarantees, IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2024
Renukanandan Tumu, Wenceslao Shaw Cortez, Ján Drgoňa, Draguna L. Vrabie, Sonja Glavaski, Differentiable Predictive Control for Large-Scale Urban Road Networks, 	arXiv:2406.10433, 2024
Ethan King, James Kotary, Ferdinando Fioretto, Jan Drgona, Metric Learning to Accelerate Convergence of Operator Splitting Methods for Differentiable Parametric Programming, arXiv:2404.00882, 2024
James Koch, Madelyn Shapiro, Himanshu Sharma, Draguna Vrabie, Jan Drgona, Neural Differential Algebraic Equations, arXiv:2403.12938, 2024
Wenceslao Shaw Cortez, Jan Drgona, Draguna Vrabie, Mahantesh Halappanavar, A Robust, Efficient Predictive Safety Filter, arXiv:2311.08496, 2024
Shrirang Abhyankar, Jan Drgona, Andrew August, Elliott Skomski, Aaron Tuor, Neuro-physical dynamic load modeling using differentiable parametric optimization, 2023 IEEE Power & Energy Society General Meeting (PESGM), 2023
James Koch, Zhao Chen, Aaron Tuor, Jan Drgona, Draguna Vrabie, Structural Inference of Networked Dynamical Systems with Universal Differential Equations, arXiv:2207.04962, (2022)
Ján Drgoňa, Sayak Mukherjee, Aaron Tuor, Mahantesh Halappanavar, Draguna Vrabie, Learning Stochastic Parametric Differentiable Predictive Control Policies, IFAC ROCOND conference (2022)
Sayak Mukherjee, Ján Drgoňa, Aaron Tuor, Mahantesh Halappanavar, Draguna Vrabie, Neural Lyapunov Differentiable Predictive Control, IEEE Conference on Decision and Control Conference 2022
Wenceslao Shaw Cortez, Jan Drgona, Aaron Tuor, Mahantesh Halappanavar, Draguna Vrabie, Differentiable Predictive Control with Safety Guarantees: A Control Barrier Function Approach, IEEE Conference on Decision and Control Conference 2022
Ethan King, Jan Drgona, Aaron Tuor, Shrirang Abhyankar, Craig Bakker, Arnab Bhattacharya, Draguna Vrabie, Koopman-based Differentiable Predictive Control for the Dynamics-Aware Economic Dispatch Problem, 2022 American Control Conference (ACC)
Drgoňa, J., Tuor, A. R., Chandan, V., & Vrabie, D. L., Physics-constrained deep learning of multi-zone building thermal dynamics. Energy and Buildings, 243, 110992, (2021)
E. Skomski, S. Vasisht, C. Wight, A. Tuor, J. Drgoňa and D. Vrabie, ""Constrained Block Nonlinear Neural Dynamical Models,"" 2021 American Control Conference (ACC), 2021, pp. 3993-4000, doi: 10.23919/ACC50511.2021.9482930.
Skomski, E., Drgoňa, J., & Tuor, A. (2021, May). Automating Discovery of Physics-Informed Neural State Space Models via Learning and Evolution. In Learning for Dynamics and Control (pp. 980-991). PMLR.
Drgoňa, J., Tuor, A., Skomski, E., Vasisht, S., & Vrabie, D. (2021). Deep Learning Explicit Differentiable Predictive Control Laws for Buildings. IFAC-PapersOnLine, 54(6), 14-19.
Tuor, A., Drgona, J., & Vrabie, D. (2020). Constrained neural ordinary differential equations with stability guarantees. arXiv preprint arXiv:2004.10883.
Drgona, Jan, et al. ""Differentiable Predictive Control: An MPC Alternative for Unknown Nonlinear Systems using Constrained Deep Learning."" Journal of Process Control Volume 116, August 2022, Pages 80-92
Drgona, J., Skomski, E., Vasisht, S., Tuor, A., & Vrabie, D. (2020). Dissipative Deep Neural Dynamical Systems, in IEEE Open Journal of Control Systems, vol. 1, pp. 100-112, 2022
Drgona, J., Tuor, A., & Vrabie, D., Learning Constrained Adaptive Differentiable Predictive Control Policies With Guarantees, arXiv preprint arXiv:2004.11184, (2020)

Cite as
@article{Neuromancer2023,
  title={{NeuroMANCER: Neural Modules with Adaptive Nonlinear Constraints and Efficient Regularizations}},
  author={Drgona, Jan and Tuor, Aaron and Koch, James and Shapiro, Madelyn and Jacob, Bruno and Vrabie, Draguna},
  Url= {https://github.com/pnnl/neuromancer}, 
  year={2023}
}
Development team
Active core developers: Jan Drgona, Rahul Birmiwal, Bruno Jacob, Reilly Raab
Notable contributors: Aaron Tuor, Madelyn Shapiro, James Koch, Seth Briney, Bo Tang, Ethan King, Elliot Skomski, Zhao Chen, Christian Møldrup Legaard
Scientific advisors: Draguna Vrabie, Panos Stinis
Open-source contributions made by:



Made with contrib.rocks.
Acknowledgments
This research was partially supported by the Mathematics for Artificial Reasoning in Science (MARS) and Data Model Convergence (DMC) initiatives via the Laboratory Directed Research and Development (LDRD) investments at Pacific Northwest National Laboratory (PNNL), by the U.S. Department of Energy, through the Office of Advanced Scientific Computing Research's “Data-Driven Decision Control for Complex Systems (DnC2S)” project, and through the Energy Efficiency and Renewable Energy, Building Technologies Office under the “Dynamic decarbonization through autonomous physics-centric deep learning and optimization of building operations” and the “Advancing Market-Ready Building Energy Management by Cost-Effective Differentiable Predictive Control” projects. This project was also supported from the U.S. Department of Energy, Advanced Scientific Computing Research program, under the Uncertainty Quantification for Multifidelity Operator Learning (MOLUcQ) project (Project No. 81739). PNNL is a multi-program national laboratory operated for the U.S. Department of Energy (DOE) by Battelle Memorial Institute under Contract No. DE-AC05-76RL0-1830.
   








About

        Pytorch-based framework for solving parametric constrained optimization problems, physics-informed system identification, and parametric model predictive control. 
      





pnnl.github.io/neuromancer/


Topics



  deep-learning


  pytorch


  constrained-optimization


  dynamical-systems


  control-systems


  nonlinear-dynamics


  nonlinear-optimization


  differentiable-programming


  physics-informed-ml


  differentiable-optimization


  differentiable-control



Resources





        Readme
 
License





     View license
    







Activity 




Custom properties 
Stars




1.1k
      stars 
Watchers




26
      watching 
Forks




143
      forks 


          Report repository
 






Releases
      5






v1.5.3

          Latest
 
Feb 26, 2025

 
+ 4 releases





Packages
      0

        No packages published 












Contributors
      23















































+ 9 contributors




Languages












Python
78.4%







Cuda
13.8%







C++
7.8%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
18,https://github.com/IBM/simulai/,"






































































GitHub - IBM/simulai: A toolkit with data-driven pipelines for physics-informed machine learning.














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        IBM
 
/

simulai

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    24




 


          Star
 175








        A toolkit with data-driven pipelines for physics-informed machine learning.
      





ibm.github.io/simulai/


License





     Apache-2.0 license
    






175
          stars
 



24
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
8






Pull requests
0






Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Actions











          Projects











          Security











          Insights






 





IBM/simulai



 












    mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History1,040 Commits.github/workflows.github/workflows  assetsassets  docsdocs  examplesexamples  mkdocsmkdocs  scalability_testsscalability_tests  scriptsscripts  simulaisimulai  teststests  .coveragerc.coveragerc  .gitignore.gitignore  .readthedocs.yaml.readthedocs.yaml  AUTHORS.rstAUTHORS.rst  CODE_OF_CONDUCT.rstCODE_OF_CONDUCT.rst  CONTRIBUTING.rstCONTRIBUTING.rst  DESCRIPTION.mdDESCRIPTION.md  DISCLAIMERDISCLAIMER  HISTORY.rstHISTORY.rst  LICENSELICENSE  MANIFEST.inMANIFEST.in  MakefileMakefile  README.rstREADME.rst  pyproject.tomlpyproject.toml  requirements.txtrequirements.txt  setup.pysetup.py  simulai_models_autoencoder.mdsimulai_models_autoencoder.md  simulai_models_deeponet.mdsimulai_models_deeponet.md  tox.initox.ini  View all filesRepository files navigationREADMEApache-2.0 license
SimulAI
NOTICE: This package is being maintained and bug-fixed. New features will be added, but with no planned timeline.
Contributions from external developers via pull requests are welcome though.






An extensible Python package with data-driven pipelines for physics-informed machine learning.
Call for contributions:
If you have developed and/or published new architectures using PyTorch and intend to make them opensource,
consider include them as part of SimulAI, which works as an unified repository for scientific machine learning models, continuously tested and maintained.
SimulAI was already packaged under a friendly license (Apache) and it can be used to more easily share state of the art models whithin the scientific community.

The SimulAI toolkit provides easy access to state-of-the-art models and algorithms for physics-informed machine learning. Currently, it includes the following methods described in the literature:

Physics-Informed Neural Networks (PINNs)
Deep Operator Networks (DeepONets)
Variational Encoder-Decoders (VED)
Operator Inference (OpInf)
Koopman Autoencoders (experimental)
Echo State Networks (experimental GPU support)
Transformers
U-Nets

In addition to the methods above, many more techniques for model reduction and regularization are included in SimulAI. See documentation.

Installing
Python version requirements: 3.9 <= python <= 3.12

Using pip
For installing the most recent stable version from PyPI:
pip install simulai-toolkit
For installing from the latest commit sent to GitHub (just for testing and developing purposes):
pip uninstall simulai-toolkit
pip install -U git+https://github.com/IBM/simulai#egg=simulai-toolkit

Contributing code to SimulAI
If you are interested in directly contributing to this project, please see CONTRIBUTING.

Using MPI
Some methods implemented on SimulAI support multiprocessing with MPI.
In order to use it, you will need a valid MPI distribution, e.g. MPICH, OpenMPI. As an example, you can use conda to install MPICH as follows:
conda install -c conda-forge mpich gcc

Issues with macOS
If you have problems installing gcc using the command above, we recommend you to install it using Homebrew.

Using Tensorboard
Tensorboard is supported for monitoring neural network training tasks. For a tutorial about how to set it see this example.

Documentation
Please, refer to the SimulAI API documentation before using the toolkit.

Examples
Additionally, you can refer to examples in the respective folder.

License
This software is licensed under Apache license 2.0. See LICENSE.

Contributing code to SimulAI
If you are interested in directly contributing to this project, please see CONTRIBUTING.

How to cite SimulAI in your publications
If you find SimulAI to be useful, please consider citing it in your published work:
@misc{simulai,
  author = {IBM},
  title = {SimulAI Toolkit},
  subtitle = {A Python package with data-driven pipelines for physics-informed machine learning},
  note = ""https://github.com/IBM/simulai"",
  doi = {10.5281/zenodo.7351516},
  year = {2022},
}
or, via Zenodo:
@software{joao_lucas_de_sousa_almeida_2023_7566603,
      author       = {João Lucas de Sousa Almeida and
                      Leonardo Martins and
                      Tarık Kaan Koç},
      title        = {IBM/simulai: 0.99.13},
      month        = jan,
      year         = 2023,
      publisher    = {Zenodo},
      version      = {0.99.25},
      doi          = {10.5281/zenodo.7566603},
      url          = {https://doi.org/10.5281/zenodo.7566603}
    }

Publications
João Lucas de Sousa Almeida, Pedro Roberto Barbosa Rocha, Allan Moreira de Carvalho and Alberto Costa Nogueira Jr. A coupled Variational
Encoder-Decoder - DeepONet surrogate model for the Rayleigh-Bénard convection problem. In When Machine Learning meets Dynamical Systems:
Theory and Applications, AAAI, 2023.
João Lucas S. Almeida, Arthur C. Pires, Klaus F. V. Cid, and Alberto C.
Nogueira Jr. Non-intrusive operator inference for chaotic systems. IEEE Transactions on Artificial Intelligence, pages 1–14, 2022.
Pedro Roberto Barbosa Rocha, Marcos Sebastião de Paula Gomes,
Allan Moreira de Carvalho, João Lucas de Sousa Almeida and Alberto Costa
Nogueira Jr. Data-driven reduced-order model for atmospheric CO2 dispersion. In AAAI 2022 Fall Symposium: The Role of AI in Responding to
Climate Challenges, 2022.
Pedro Roberto Barbosa Rocha, João Lucas de Sousa Almeida, Marcos Sebastião de Paula Gomes, Alberto Costa Nogueira,
Reduced-order modeling of the two-dimensional Rayleigh–Bénard convection flow through a non-intrusive operator inference,
Engineering Applications of Artificial Intelligence, Volume 126, Part B, 2023, 106923,
ISSN 0952-1976, https://doi.org/10.1016/j.engappai.2023.106923. (https://www.sciencedirect.com/science/article/pii/S0952197623011077)

References
Jaeger, H., Haas, H. (2004).
""Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication,""
Science, 304 (5667): 78–80.
DOI:10.1126/science.1091277.
Lu, L., Jin, P., Pang, G., Zhang, Z., Karniadakis, G. E. (2021).
""Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators,""
Nature Machine Intelligence, 3 (1): 218–229.
ISSN: 2522-5839.
DOI:10.1038/s42256-021-00302-5.
Eivazi, H., Le Clainche, S., Hoyas, S., Vinuesa, R. (2022)
""Towards extraction of orthogonal and parsimonious non-linear modes from
turbulent flows""
Expert Systems with Applications, 202.
ISSN: 0957-4174.
DOI:10.1016/j.eswa.2022.117038.
Raissi, M., Perdikaris, P., Karniadakis, G. E. (2019).
""Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations,""
Journal of Computational Physics, 378 (1): 686-707.
ISSN: 0021-9991.
DOI:10.1016/j.jcp.2018.10.045.
Lusch, B., Kutz, J. N., Brunton, S.L. (2018).
""Deep learning for universal linear embeddings of nonlinear dynamics,""
Nature Communications, 9: 4950.
ISSN: 2041-1723.
DOI:10.1038/s41467-018-07210-0.
McQuarrie, S., Huang, C. and Willcox, K. (2021).
""Data-driven reduced-order models via regularized operator inference for a single-injector combustion process,""
Journal of the Royal Society of New Zealand, **51**(2): 194-211.
ISSN: 0303-6758.
DOI:10.1080/03036758.2020.1863237.
   








About

        A toolkit with data-driven pipelines for physics-informed machine learning.
      





ibm.github.io/simulai/


Topics



  machine-learning


  simulation


  neural-networks


  physics-informed-neural-networks



Resources





        Readme
 
License





     Apache-2.0 license
    







Activity 




Custom properties 
Stars




175
      stars 
Watchers




12
      watching 
Forks




24
      forks 


          Report repository
 






Releases
      19






0.99.28

          Latest
 
Feb 13, 2024

 
+ 18 releases











Contributors
      9



































Languages











Python
99.3%







Other
0.7%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
19,https://github.com/leakec/tfc,"






































































GitHub - leakec/tfc: The Theory of Functional Connections: A functional interpolation method with applications in solving differential equations.














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        leakec
 
/

tfc

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    10




 


          Star
 39








        The Theory of Functional Connections: A functional interpolation method with applications in solving differential equations.
      





tfc-documentation.readthedocs.io/en/latest/


License





     MIT license
    






39
          stars
 



10
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
0






Pull requests
0






Discussions







Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Discussions











          Actions











          Projects











          Security











          Insights






 





leakec/tfc



 












    mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History695 Commits.github.github  docsdocs  examplesexamples  src/tfcsrc/tfc  teststests  utilsutils  .gitignore.gitignore  .readthedocs.yml.readthedocs.yml  CONTRIBUTING.mdCONTRIBUTING.md  LICENSELICENSE  MANIFEST.inMANIFEST.in  README.mdREADME.md  pyproject.tomlpyproject.toml  requirements.txtrequirements.txt  setup.pysetup.py  View all filesRepository files navigationREADMEMIT licenseTheory of Functional Connections (TFC)
A functional interpolation framework with applications in solving differential equations.



Installation guide
| Reference documentation
| Mathematical documentation

Summary:
The tfc Python module is designed to help you quickly and easily apply the Theory of Functional Connections (TFC) to optimization problems. For more information on the code itself and code-based tutorials, see the Reference documentation. What follows is a brief description of TFC.
TFC is a functional interpolation framework centered around the concept of the constrained expression. A constrained expression is a mathematical functional that expresses all possible functions that satisfy a set of user-defined constraints. For example, suppose you are interested in all possible functions that satisfy the constraint y(0) = 3. The TFC constrained expression for this constraint is,

y(x,g(x)) = g(x) + 3 - g(0),

where g(x) is any function defined at the constraint point; by changing g(x) you get different outputs, but all of these outputs satisfy the constraint regardless of how you choose g(x). In this way, you maintain a completly unrestricted functiton, g(x), which we will call the free function, but always satsify the constraint. Neat, huh?
While developing the constrained expression for our example above was trivial, as you introduce more complex constraints in n-dimensions, trying to derive these constrained expression by-eye, i.e., without a step-by-step framework, becomes extremely difficult. Luckily, TFC comes equiped with a straightfowrward, step-by-step process for developing constrained expressions. For more information on this process, see the Mathematical documentation.
Since the constrained expressions effectively translate the set of all functions defined at the constraints—this set is represented by g(x), the domain of the functional—to the set of all functions that satisfy the constraints—this is the output or co-domain of the constrained exppression—the constrained expresssion can be used to transform constrained optimization problems into unconstrained optimization problems. For example, consider the following differential equation,

yx = 2y,    where    y(0) = 3.

This differential equation can be viewed as an optimization problem where we seek to minimize the residual of the differential equation, i.e., minimize J where J = yx - 2y. Classicly, we would have to minimize J using y(x) subject to the constraint y(0) = 3. However, with TFC we can minimize J using g(x) where y(x,g(x)) = g(x) + 3 - 0, and g(x) is not subject to any constraints. Thus, TFC has translated our differential equation from a constrained optimization problem to an unconstrained optimization problem! The benefits of doing so include:

More accurate solutions
Faster solutions
Robustness to initial guess

For more information on the appliation of TFC to differential equations and its benefits see the Mathematical documentation.
Installation:
The following instructions can be used to install a source distribution via pip or build TFC directly from source.
To install via pip run:
pip install --upgrade pip setuptools wheel numpy
pip install --upgrade tfc
The above will install a binary TFC wheel. The developers have found that installing a source distribution leads to code that is slightly faster on some machines, as the code is compiled using potentially newer versions of compilers and swig. If you would like the source distribution, then you can use the following:
pip install tfc --no-binary tfc
Note that you may need to first install the system package dependencies listed in the Building from source section if they are not already installed.
Reference Documentation:
For tutorials on how to use this package as well as information about the tfc API, see the reference documentation.
Mathematical Documentation:
Any users interested in the process for developing constrained expressions, the mathematical theory behind TFC, and the application of TFC to differential equations should start with this journal article; note that the article is open access, so you can download it for free. The curious user can continue their study of the mathematical theory by visiting the TFC article repository on ResearchGate for a complete list of TFC publications with free downloadable PDFs. Furthermore, links to free downloadable versions of Hunter's and Carl's dissertations can be found in the READMEs of their respective folders in the examples directory. Finally, the TFC textbook is available for purchase.
Citing this repository:
The authors of this repsitory and the associated theory have gone to lengths to ensure that both are publicy available at no cost to the user. All that we ask in return is that if you use them, please add a reference to this GitHub and following journal article. Thank you.
@misc{tfc2023github,
    author = {Carl Leake and Hunter Johnston},
    title = {{TFC: A Functional Interpolation Framework}},
    url = {https://github.com/leakec/tfc},
    version = {1.1.0},
    year = {2024},
}
@article{TFC, 
    title={The Multivariate Theory of Functional Connections: Theory, Proofs, and Application in Partial Differential Equations}, 
    volume={8}, 
    ISSN={2227-7390}, 
    url={http://dx.doi.org/10.3390/math8081303}, 
    DOI={10.3390/math8081303},
    number={8}, 
    journal={Mathematics},
    publisher={MDPI AG},
    author={Leake, Carl and Johnston, Hunter and Mortari, Daniele}, 
    year={2020}, 
    month={Aug}, 
    pages={1303}
}

For developers:
Building from source:

Create a dist directory in the main directory.
Run python setup.py bdist_wheel from the main directory.
Navigate to dist, and run pip3 install ""wheel"" where ""wheel"" is the name of the wheel created in the previous step.

Dependencies:

System Packages:

swig
graphviz


Python Packages:

matplotlib
jax
jaxlib
colorama
graphviz
yattag



Testing instructions:

Navigate to the tests directory.
Run py.test or python -m pytest.
These serve as simple unit tests that test basic functionality of the code. These include tests for individual TFC functions, as well as full ODE and PDE tests.

Building Reference Documentation from Source:
If for some reason you want to build the reference documentation from source, you can do so using these two steps:

Change into the docs directory.
Run:

sphinx-build . _build/html
The code documentation will appear under _build/html and the main file is index.html. This file can also be accessed using the SphinxDocumentation.html symbolic link in the docs directory.
Dependencies:

System Packages:

graphviz
doxygen
python3-sphinx


Python Packages: see requirements.txt file in the docs directory.

   








About

        The Theory of Functional Connections: A functional interpolation method with applications in solving differential equations.
      





tfc-documentation.readthedocs.io/en/latest/


Resources





        Readme
 
License





     MIT license
    







Activity 
Stars




39
      stars 
Watchers




4
      watching 
Forks




10
      forks 


          Report repository
 






Releases
      28






tfc-v1.1.0

          Latest
 
Jan 22, 2025

 
+ 27 releases










Languages













Python
60.2%







C
22.7%







C++
16.2%







Other
0.9%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
20,https://www.machinedesign.com/additive-3d-printing/fea-and-simulation/article/21832072/whats-the-difference-between-fem-fdm-and-fvm,"

Understanding the Differences Between FEM, FDM, and FVM in Engineering Simulations  | Machine Design


























































































































































































































































































  ResourcesMembersDirectoryWebinarsVideoWISECAD ModelsEDGE AwardsSearchSearchAdditive/3D PrintingAUTOMATION & IIOTCAD/CAM Software++MaterialsMedical DevicesMotion SystemsRoboticsAdditive/3D Printing FEA and SimulationWhat’s The Difference Between FEM, FDM and FVM?May 31, 2024Explore the methodologies of the finite element method (FEM), finite difference method (FDM) and finite volume method (FVM) to grasp their computational intricacies and application-specific advantages for additive manufacturing.Bjorn Sjodin      This article originally posted on May 18, 2016. It was updated on May 31, 2024.
The finite-element, finite-difference and finite-volume methods—FEM, FDM and FVM, respectively—are numerical techniques used in engineering and machine design for solving partial differential equations (PDEs) that govern the behavior of physical systems. They are used for analyzing structural integrity, heat transfer, fluid dynamics and other physical phenomena, with specific usage based on the complexity of geometry, type of analysis required and nature of the system under study.
This article will answer the following frequently asked questions:

What is the finite-element method?
What is the finite-diference method?
What is the finite-volume method?
What are the advantages and disadvantages of each?

 
What Are FEM, FDM and FVM?
FEM, FDM and FVM differ from one another in important ways. Understanding these distinctions is key to selecting the method most appropriate for your purposes.
The Finite-Element Method (FEM) Explained
The finite-element method is a computational method that subdivides a CAD model into very small but finite-sized elements of geometrically simple shapes. The collection of all these simple shapes constitutes the so-called finite-element mesh.
LEARN MORE: Register for a simulation software webinar
The next step is to take a system of field equations, mathematically represented by PDEs that describe the physics you are interested in, and formulate these equations for each element. This is handled by approximating the fields within each element as a simple function, such as a linear or quadratic polynomial, with a finite number of degrees of freedom (DOFs). This gives an approximate local description of the physics by a set of simple linear (but sometimes nonlinear) equations. When the contributions from all elements are assembled you end up with a large sparse matrix equation system that can be solved by any of a number of well-known sparse matrix solvers.
READ MORE: Buckling Analysis with FEA
The type of solver used depends on the original physics, since each type of physics gives its unique imprint on the structure of the matrix. To speed things up, this structure is exploited by using a tailored numerical method. A method may be suitable for structural mechanics but not for electromagnetics, and vice versa. Historically, the method was first applied to structural analysis. Since roughly 2006, it has been realized that the finite element method is also suitable for a large class of multi-physics problems.
Understanding the Finite-Difference Method (FDM)
The finite-difference method is the most direct approach to discretizing partial differential equations. You consider a point in space where you take the continuum representation of the equations and replace it with a set of discrete equations, called finite-difference equations. The finite-difference method is typically defined on a regular grid and this fact can be used for very efficient solution methods. The method is therefore not usually used for irregular CAD geometries, but more often for rectangular or block-shaped models.
There is a connection with the finite-element method: Certain formulations of the finite-element method defined on a regular grid are identical to a finite-difference method on the same grid. Regular grids can often be used in meteorological, seismological, and astrophysical simulations, for example.Delaunay triangulations are used to build meshes for space-discretized solvers for the finite-element and finite-volume methods.
An Overview of the Finite-Volume Method (FVM)
The finite-volume method is similar to the finite-element method in that the CAD model is first divided into very small but finite-sized elements of geometrically simple shapes. Apart from this, the finite-volume method is very different from the finite-element method, beginning with the concept of elements, which are instead referred to as cells.
The finite-volume method is based on the fact that many physical laws are conservation laws—what goes into one cell on one side needs to leave the same cell on another side. Following this idea, you end up with a formulation that consists of flux conservation equations defined in an averaged sense over the cells. Historically, this method has been very successful in solving fluid flow problems.
READ MORE: AM Heralds a New Chapter for Fluid Flow Applications | Machine Design
Key Differences Among FEM, FDM and FVM
Each method is quite similar in that it represents a systematic numerical method for solving PDEs. One important difference is the ease of implementation. A common opinion is that the finite-difference method is the easiest to implement and the finite-element method the most difficult. One reason for this may be that the finite-element method requires quite sophisticated mathematics for its formulation.Finite-element analysis of an air-filled shell and tube heat exchanger with water flowing in the inner tubes. Simulation results available from COMSOL Multiphysics software reveal flow velocity, temperature distribution, and pressure within the vessel.
Advantages and Disadvantages
FEM: Benefits and Drawbacks
One reason for the finite element method’s success in multi-physics analysis is that it is a very general method. Solving the resulting equation systems are the same or very similar to well-known and efficient methods used for structural and electromagnetics analysis. Another reason for the method’s success is that it makes it easy to “increase the order of the elements” so that the physics fields can be approximated very accurately. This typically corresponds to locally approximating the physics fields with polynomials of “higher order,” such as second- and third-degree polynomials, or higher. This technique is often critical, for example, in the case of accurate stress analysis.
READ MORE: Spend Your Time Engineering, Not on Differential Equations
If we consider the example of stress analysis, it is quite common that there are important stress concentrations close to some of the corners of a mechanical part. In this case, the finite-element method allows for two different ways of increasing the accuracy of the solution around this corner. One way is to increase the order of the elements, as described earlier. Another method is to locally refine the mesh close to that corner; the element density increases locally. The finer the mesh (i.e., more elements), the more accurate approximation one gets for the stress field around the corner of interest. Both techniques are used in finite-element software and are frequently made automatic from the user’s perspective. This is known as “adaptive mesh refinement.”
Another advantage with the finite-element method, which is particularly important for multi-physics analysis, is that you can combine different kinds of functions that approximate the solution within each element. This is called mixed formulations. This is important, for example, in the case of electromagnetic heating. The physics and mathematics require one type of function for the electromagnetic field and another type of function for heat transfer; they both need to be tightly coupled to get an accurate solution and for the solution to converge. Mixed formulations are straightforward to handle the finite-element method, but difficult or impossible with other methods.
The benefits with both the finite-element method and the finite-volume method are that curved and irregular CAD geometries are handled in a natural way.
However, the mathematics behind the finite-element method is quite advanced and thus the method requires mathematical expertise for its implementation. Implementations of finite-difference and finite-volume methods are comparatively straightforward.
For certain time-dependent simulations, one needs to use so-called explicit solvers for reasons of efficiency. Implementing such solver techniques is more difficult for the finite-element method than for the finite-difference and finite-volume methods. However, this has successfully been commercialized in some cases, such as in crash simulations.
FDM: Pros and Cons
The finite-difference method is defined dimension per dimension; this makes it easy to increase the “element order” to get higher-order accuracy. If you can fit the simulation in a rectangular or box-shaped geometry using a regular grid, efficient implementations are much easier than for finite-element and finite-volume methods. Regular grids are useful for very-large-scale simulations on supercomputers often used in, as mentioned before, meteorological, seismological, and astrophysical simulations.
READ MORE: Math, Models, Motion and More
With the finite-difference method, you may easily run into problems handling curved boundaries for the purpose of defining the boundary conditions. Boundary conditions are needed to truncate the computational domain. They represent communication with the surrounding world, which is the part that you do not want included in your simulation. If one can overcome the boundary-condition problem on curved boundaries, the method gives very efficient and high quality results.
For computations that need high accuracy, the extra effort in making boundary-fitted meshes and the associated complications of such meshes for the implementation may be worth it. Examples include Formula 1 car computational-fluid-dynamic (CFD) simulations and space-shuttle CFD simulations. The finite-difference method is more difficult to use for handling material discontinuities. In addition, it does not lend itself for local grid refinement or anything similar to “adaptive mesh refinement.” This may be needed to resolve local rapid variations in solutions such as around a corner of a complex shape, as described earlier.
FVM: Strengths and Weaknesses
The finite-volume method is a natural choice for CFD problems, since the partial differential equations you have to solve for CFD are conservation laws. However, both finite differences and finite elements can also be used for CFD. Efficient technology for CFD with the finite-element method has become increasingly popular over the last 10 to 15 years. Techniques for CFD with the finite-difference and finite-volume method have been known and used much longer.
The finite-volume method’s strength is that it only needs to do flux evaluation for the cell boundaries. This also holds for nonlinear problems, which makes it extra powerful for robust handling of (nonlinear) conservation laws appearing in transport problems.
The local accuracy of the finite-volume method, such as close to a corner of interest, can be increased by refining the mesh around that corner, similar to the finite-element method. However, the functions that approximate the solution when using the finite-volume method cannot be easily made of higher order. This is a disadvantage of the finite-volume method compared to the finite-element and finite-difference methods.
Applications of Each Method
Practical Applications of FEM
All kinds of structural analysis, heat transfer, chemical engineering, electromagnetics (including electrostatics, magnetostatics, low-frequency electromagnetics, and frequency-domain high-frequency electromagnetic waves), multi-physics, and CFD.
Use Cases for FDM
Weather calculations, astrophysics, seismology, physical realism in computer graphics, and special effects.
FVM in Real-World Scenarios
CFD, heat transfer, and chemical engineering.
Choosing the Right Method
All of these methods are frequently used today in commercial software, as well as in academic environments. The finite-element method is usually most taxing on a computer system, but it depends on the type of analysis. 
Bjorn Sjodin is VP of Product Management for COMSOL Inc.
Download this article in .PDF format
			This file type includes high-resolution graphics and schematics when applicable.Continue ReadingAccelerate Virtual Prototyping and Design Processes with Finite Element AnalysisIntegrating Advanced Technology, Additive Manufacturing for Better AccessibilitySponsored RecommendationsRevolution for bionic prosthesesMarch 31, 2025 Unlike passive products - made of simple carbon springs - the bionic prostheses developed by Revival Bionics are propulsive, equipped with a motor and an artificial Achilles tendon...State-of-the-art Drive Technology in Industrial Automation and RoboticsMarch 31, 2025 Electric drives are a key technology for the performance of machines, robots, and power tools. Download this guide for an introduction to high-quality mechatronic drive systems...The perfect drive solution is just a few clicks awayMarch 31, 2025 Discover the world of maxon drive technology: motors, gearheads, sensors, controllers, and accessories. Configure your drive system online, including all relevant product and ...Drone powered by solar energyMarch 31, 2025 Share current page XSun designs and manufactures a drone that is both energy-independent and can make its own decisions, for fully-automated missions. The company needed reliable...Voice your opinion! To join the conversation, and become an exclusive member of Machine Design, create an account today! Join today! I already have an account NewPhase Noise Impact on Satellite Uplink and Downlink Channel CapacityJust-in-Time Insights: The Factory Reset that Global Manufacturing NeedsIs the Next Big Leap in Additive Manufacturing Fueled by Metrology?Most ReadMeet Five Women Shaping Engineering CareersWhat’s the Difference Between Bearing, Shear and Tear-Out Stress?Planetary Gears: The BasicsSponsoredGuide to Drive Technology in Wastewater Treatment PlantsAdvancing Automation with Linear Motors and Electric CylindersSpiral Freezers: Reliably Driven Load More Content https://www.facebook.com/MachineDesignMagazine/ https://www.linkedin.com/company/10998894 https://twitter.com/MachineDesign https://www.youtube.com/channel/UCntE9Y_EMGAKpIJQECNHsGw About UsContact UsAdvertiseDo Not Sell or SharePrivacy & Cookie PolicyTerms of Service © 2025 Endeavor Business Media, LLC. All rights reserved. 
"
21,https://arxiv.org/pdf/1907.03507,"PHYSICS INFORMED EXTREME LEARNING MACHINE (PIELM)–
ARAPID METHOD FOR THE NUMERICAL SOLUTION OF PARTIAL
DIFFERENTIAL EQUATIONS
A P REPRINT
Vikas Dwivedi
Department of Mechanical Engineering
Indian Institute of Technology, Madras
Chennai-600036, India
me15d080@smail.iitm.ac.inBalaji Srinivasan
Department of Mechanical Engineering
Indian Institute of Technology, Madras
Chennai-600036, India
sbalaji@iitm.ac.in
July 9, 2019
ABSTRACT
There has been rapid progress recently on the application of deep networks to solution of partial
differential equations, collectively labelled as Physics Informed Neural Networks (PINNs). In this
paper, we develop Physics Informed Extreme Learning Machine (PIELM), a rapid version of PINNs
which can be applied to stationary and time dependent linear partial differential equations. We
demonstrate that PIELM matches or exceeds the accuracy of PINNs on a range of problems. We also
discuss the limitations of neural network based approaches, including our PIELM, in the solution of
PDEs on large domains and suggest an extension, a distributed version of our algorithm -- DPIELM.
We show that DPIELM produces excellent results comparable to conventional numerical techniques
in the solution of time-dependent problems. Collectively, this work contributes towards making
the use of neural networks in the solution of partial differential equations in complex domains as a
competitive alternative to conventional discretization techniques.
Keywords Partial differential equations Physics informed neural networks Extreme learning machine 
Advection-diffusion equation
1 Introduction
Partial differential equations (PDEs) are extensively used in the mathematical modelling of various problems in physics,
engineering and ﬁnance. In practical situations, these equations typically lack analytical solutions and are solved
numerically. In current practice, most numerical approaches to solve PDEs like ﬁnite element method (FEM), ﬁnite
difference method (FDM) and ﬁnite volume method (FVM) are mesh based. A typical implementation of a mesh based
approach involves three steps: (1) Grid generation, (2) Discretization of governing equation and (3) Solution of the
discretized equations with some iterative method.
However, there are limitations to these approaches. Some of the limitations of these methods are as follows:
1.They cannot be used to solve PDEs in complex computational domains because grid generation (step 1) itself
becomes infeasible.
2.The process of discretization (step 2) creates a discrepancy between the mathematical nature of actual PDE
and its approximate difference equation [1]. Sometimes this can lead to quite serious problems [2].
Use footnote for providing further information about author (webpage, alternative address)— notfor acknowledging funding
agencies.arXiv:1907.03507v1  [cs.LG]  8 Jul 2019Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
One of the options to ﬁx these issues is to use neural networks. In this approach, the data set consists of some randomly
selected points in the domain and on the boundary. The governing equations and the boundary conditions are ﬁtted
using neural network. There are two main motivations for this approach. First, being universal approximators, neural
networks can potentially represent any PDE. So this avoids the discretization step and thus discretization based physics
errors too. Second, it is meshfree and therefore complex geometries can be easily handled [ 3]. Initial work in this
direction can be credited to Lagaris et al. [ 4,5]. Firstly, they solved the initial boundary value problem using neural
networks and later they extended their work to handle irregular boundaries. Since then, a lot of work has been done in
this ﬁeld [ 6,7,8,9,10,11,12,13]. In particular, we refer to the physics-informed neural networks (PINN) approach by
Raissi and Karniadakis [ 11] and Raissi et. al [ 12,13]. This approach has produced promising results for a series of
benchmark nonlinear problems.
Recently, Berg et al. [ 3] have developed a PINN based method to solve PDEs on complex domains and produced
several results. However, in spite of various advantages of using deep networks for solving PDEs, PINNs have several
problems [ 13]. Firstly, there is no theoretical basis to know the size of neural network architecture and the amount of
data needed. Then, there is no guarantee that the algorithm will not hit upon a local minima. Finally, their learning time
is slower than the traditional numerical methods making them very expensive for practical problems.
We show that some of the problems mentioned above can be easily handled by using an alternative network called the
extreme learning machine (ELM). The basic ELM was proposed by Huang et al. [ 14] for a single hidden layer feed
forward networks (SLFNs) and later it was extended to generalized SLFNs. The essence of ELM is that the weights
of the hidden layer of SLFNs need not to be learnt. It is much faster than the traditional gradient based optimization
methods alleviating the learning time problem. Previously, ELMs have been used in approximating functions [ 15] and
solving ordinary differential equations (ODEs) and stationary PDEs [ 16,17] using Legendre and Bernstein polynomial
basis functions respectively.
In this paper, we propose a new machine learning algorithm to solve stationary and time dependent PDEs in complex
geometries. We have named it physics informed extreme learning machine (PIELM) because it is a combination of
two algorithms namely ELM and PINN. Theoretically, there is no question over the employment of ELM as a PDE
solver because it is a universal approximator [ 18] and therefore it can approximate any PDE. We have made our ELM
“physics informed” by incorporating the information about the physics of PDE as the cost function. In addition to this,
we have also proposed an extension to original PIELM called distributed PIELM that enhances the representation power
of PIELM without adding any extra hidden layers. We demonstrate that both PIELM and DPIELM exibit superior
performance on a range of stationary and time-dependent problems in comparison to existing methods.
This paper proceeds as follows. We give a brief review of PINN and ELM in Section 2. The proposed PIELM is
described in Section 3.In Section 4, we evaluate the performance of PIELM in solving various stationary and time-
dependent PDEs. To our knowledge, this is the ﬁrst application of an ELM based algorithm to solve a 2D unsteady PDE.
In Section 5, we discuss the limitation of PIELM to represent discontinuous functions and the functions with sharp
gradient. We also illustrate a test case where even a deep PINN fails to represent a complicated function. In Section
6, DPIELM, the distributed version of PIELM for enhanced representation is described. In Section 7, the results of
implementation of DPIELM algorithm in test cases involving representation of functions with sharp gradients have been
presented. We have also shown that DPIELM outperforms the deep PINN in representing the complicated function
described earlier. Finally, conclusion and future work are given in Section 8.
2 Brief review of ELM and PINN
The PIELM is combination of two learning algorithms: ELM and PINN. In this section, we review these two algorithms
in brief.
2.1 Extreme learning machine
Traditional gradient-based learning algorithms [ 19] have prohibitively slow learning speed and they suffer from various
problems like improper learning rate, local minima etc. Huang et al. [ 14] originally proposed a novel learning algorithm
called ELM to ﬁx these issues. ELM is extremely fast and mostly it shows better generalization performance than
gradient-based learning approaches like back-propagation. A typical implementation of the algorithm involves the
following steps:
1. Select a shallow neural network.
2.Fix the hidden layer weights and biases randomly. These parameters will not be learned and therefore no
iterative optimization is required for them.
2Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
3. Apply a nonlinear transformation to the input data set. This gives the input to the ﬁnal layer.
4. Take the linear combination of all the inputs of the ﬁnal layer. This is the output of ELM.
5. Learn the output layer weights using the least squares method.
x2+x1+
+
+ yi
xnRandomly generated
weights in first layer:
(Wi, bi)     
 Optimized weights in 
last layer : c 
(nx1) input vector N* hidden neuronsith component of (mx1) 
output neuron vector c1
c2
c3
cN*
Figure 1: Basic structure of ELM
Mathematical formulation
Consider the basic ELM shown in Fig (1). It is a single layer feed forward neural network with Nneurons in the
hidden layer. Input is a vector of size nand output is the ithcomponent of the output vector of size m. We denote the
non-linear activation by 'and the weights and biases of jthnode of hidden layer by  !a(i)
jandb(i)
jrespectively. The
output of the hidden node jis'(  !x;  !a(i)
j;b(i)
j). For a given data set f(xk;yk)gN
k=1<nx<mwithNdistinct samples,
the ELM output is given by
  !y(i)
ELM =H(i)(  !x)  !c (1)
where,
H(i)= [  !h(i)(  !x1);  !h(i)(  !x2);:::;  !h(i)(  !xN)]T;
  !h(i)(  !xk) = ['(  !xk;  !a(i)
1;b(i)
1);'(  !x;  !a(i)
2;b(i)
2);:::;' (  !x;  !a(i)
N;b(i)
N)];
and  !c= [c1;c2;:::;cN]Tis vector of output layer weights.
On writing the Eq. (1) for all the mcomponents, the resulting ELM is given by
H(i)  !c=  !y(i)   !(i); i= 1;2;:::m; (2)
where  !is the training error vector. The ELM tends to reach the smallest training error together with the smallest
norm of the output weights. Mathematically saying, the loss function to be minimized for the ELM is given by
J=1
2jj  !cjj2+1
2NmX
i=1  !(i)T  !(i); (3)
whereis the regularization parameter. The correct weights that minimize Jcan be calculated by solving the normal
equations as given below.
@J
@ck= 0; k= 1;2;:::;N(4)
3Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
2.2 Physics informed neural network
Raissi et al. [ 13] proposed a data efﬁcient PINN for approximating solutions to general non-linear PDEs and validated
it with a series of benchmark test cases. The main feature of the PINN is the inclusion of the prior knowledge of physics
in the learning algorithm as cost function. As a result, the algorithm imposes penalty for any non-physical solution and
quickly directs it towards the correct solution. This physics informed approach enhances the information content of the
data. As a result, the algorithm has good generalization property even in the small data set regime.
Mathematical formulation
Consider a PDE of the following form
@
@tu(  !x;t) +Nu(  !x;t) =R(  !x;t);(  !x;t)
x[0;T]; (5)
u(  !x;t) =B(  !x;t);(  !x;t)@
x[0;T]; (6)
u(  !x;0) =F(  !x);  !x
; (7)
whereNmay be a linear or nonlinear differential operator and @
is the boundary of computational domain 
. We
approximate u(  !x;t)with the output f(  !x;t)of PINN. The network architecture may be shallow or deep depending
upon the non-linearity N. The essence of PINN lies in the deﬁnition of its loss function. In order to make the neural
network “physics informed”, the loss function is deﬁned such that a penalty is imposed whenever the network output
doesn’t respect the physics of the problem. If we denote the training errors in approximating the PDE, BCs and IC by  !f,  !bcand  !icrespectively. Then, the expressions for these errors are as follows:
  !f=@  !f
@t+N  !f   !R;(  !x;t)
x[0;T]; (8)
  !bc=  !f   !B;(  !x;t)@
x[0;T]; (9)
  !ic=  !f(:;0)   !F;  !x
: (10)
For shallow networks,@  !f
@tandN  !fcan be determined using hand calculations. However, for deep networks, we have
to use automatic differentiation [20]. The loss function Jto be minimized for a PINN is given by
J=  !T
f  !f
2Nf+  !T
bc  !bc
2Nbc+  !T
ic  !ic
2Nic; (11)
whereNf,NbcandNicrefer to number of collocation points, boundary condition points and initial condition points
respectively. Finally, any gradient based optimization routine may be used to minimize J.
This completes the mathematical formulation of PINN. The key steps in its implementation are as follows:
1. Identify the PDE to be solved along with the initial and boundary conditions.
2. Decide the architecture of PINN.
3. Approximate the correct solution with PINN.
4. Find expressions for the PDE, BCs and IC in terms of PINN and its derivatives.
5. Deﬁne a loss function which penalizes for error in PDE, BCs and IC.
6. Minimize the loss with gradient based algorithms.
3 Proposed PIELM
Consider the following unsteady linear PDE
@
@tu(  !x;t) +Lu(  !x;t) =R(  !x;t);(  !x;t)
x[0;T]; (12)
4Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
x+1+
+
+ub1
b2
bN*b3
mN*m3m2m1
cN*c1
c3c2
tn1
n2
n3
nN*Randomly generated
weights in first layer Optimized weights in 
last layer 
3 input neurons N* hidden neurons 1 output neuron
Figure 2: PIELM for 1D unsteady problems
u(  !x;t) =B(  !x;t);(  !x;t)@
x[0;T]; (13)
u(  !x;0) =F(  !x);  !x
; (14)
whereLis a linear differential operator and @
is the boundary of computational domain 
. We approximate
u(  !x;t)with the output f(  !x;t)of PIELM. For simplicity, we consider the 1D unsteady version of Eqns (12, 13,
14). The extension to higher dimensional problems is straightforward. The PIELM for 1D unsteady problem is
schematically shown in Fig (2). The number of neurons in the hidden layers is N. If we deﬁne  != [x;t;1]T,
  !m= [m1;m2;:::;mN]T,  !n= [n1;n2;:::;nN]T,  !b= [b1;b2;:::;bN]Tand  !c= [c1;c2;:::;cN]Tthen, the
output of the kthhidden neuron is
hk='(zk);
wherezk= [mk;nk;bk]  !and'=tanh is the nonlinear activation function. The PIELM output is given by
f(  !) =  !h  !c: (15)
Similarly, the formulae for@pf
@xpand@f
@tare given by
@pfk
@xp=mp
k@p'
@zp; (16)
@fk
@t=nk@'
@z: (17)
We denote the training errors in approximating the PDE, BCs and IC by  !f,  !bcand  !icrespectively. The
expressions for these errors are as follows:
  !f=@  !f
@t+L  !f   !R;(  !x;t)
x[0;T]; (18)
  !bc=  !f   !B;(  !x;t)@
x[0;T]; (19)
  !ic=  !f(:;0)   !F;  !x
: (20)
5Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
Next, we put a hard constraint on  !cto solve the PDE exactly with zero error by setting
  !f=  !0; (21)
  !bc=  !0; (22)
  !ic=  !0: (23)
Eqns (21 to 23) lead to the a system of linear equations which can be represented as
H  !c=  !K: (24)
The form of Hand  !Kdepends on theL,BandFi.e. on the type of PDE, boundary condition and initial condition. In
order to ﬁnd  !c, Moore–Penrose generalized inverse [ 21] (also called pseudo-inverse) should be used as it works well
for singular and non square Htoo. An additional advantage with this formulation is that we have a basis to guess the
scale of the PIELM architecture. When we are solving Eqns (21 to 23) simultaneously, we know that a unique solution
will exist when number of unknowns are equal to number of equations which means that N=Nf+Nbc+Nic. This
gives us an idea of the size of the hidden layer. However, in practice we get the correct solution even with lesser number
of neurons. For example, if we supply a large number of points to approximate a linear function, the PIELM would not
require the same number of neurons for learning.
This completes the mathematical formulation of PIELM. The key steps in its implementation are as follows:
1. Assign the input layer weights randomly.
2. Depending on the PDE and the initial and boundary conditions, ﬁnd the expressions for  !f,  !bcand  !ic.
3. Assemble the three sets of equations in the form of H  !c=  !K:
4. Output layer weight vector is given by pinv(H)  !K;wherepinv refers to pseudo-inverse.
It is to be noted that unlike conventional ELMs , we are not solving an optimization problem. The loss function Jto be
minimized for a conventional physics informed ELM would be given by
J=1
2jj  !cjj2+1
2   !T
f  !f
2Nf+  !T
bc  !bc
2Nbc+  !T
ic  !ic
2Nic!
; (25)
whereis a regularization parameter and Nf,NbcandNicrefer to number of collocation points, boundary condition
points and initial condition points respectively. The correct ELM weights that minimize Jcan be calculated by solving
the normal equations which is given below.
@J
@ck= 0; k= 1;2;:::;N(26)
Although a PIELM can be made with this minimization approach, we have opted for the direct approach due to the
following reasons:
1.The direct approach is straightforward to formulate and code. It saves the effort of calculating loss function
and setting the derivatives equal to zero.
2.The learning of the minimization approach is comparatively less “physics informed” because physics is not
being imposed in an exact sense.
6Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
Steady/
Unsteady1D/2D Test
case
IDDescription
Steady1DTC-1 Linear advection
TC-2 Linear diffusion
TC-3 Linear advection-diffusion
2DTC-4 Linear advection in a star shaped
computational domain
TC-5 Linear diffusion in a star shaped
computational domain
TC-6 Linear diffusion in a complex
computational domain
Unsteady1DTC-7 Linear advection
TC-8 Quasi-linear advection
TC-9 Linear advection-diffusion
2D TC-10 Linear advection-diffusion
Table 1: List of test cases for PIELM.
4 Performance evaluation of PIELM
(a) For 1D steady problems
 (b) For 2D unsteady problems
Figure 3: PIELMs for steady 1D and unsteady 2D problems
To evaluate the performance of PIELM, we rigorously test it on various linear and quasi-linear PDEs described in
Table(1). TC-1, TC-2, TC-4, TC-5, TC-6 are taken from Berg et al. [ 3]. TC-8 is taken from Kopriva et al. [ 22]. TC-9
and TC-10 are taken from Borker et al. [ 23]. All the experiments are conducted in Matlab 2017b environment running
in an Intel Core i5 2.20GHz CPU and 8GB RAM Dell laptop. The error is deﬁned as the difference between the PIELM
prediction and the exact solution.
7Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
4.1 1D steady cases [ TC-1, TC-2, TC-3 ]
0 0.2 0.4 0.6 0.8 100.20.40.60.811.21.41.61.82
(a) PIELM solution.
0 0.2 0.4 0.6 0.8 1-6-5-4-3-2-10110-4 (b) Error plot.
Figure 4: Solution and error for steady 1D advection. Red: PIELM, Blue: Exact.
0 0.2 0.4 0.6 0.8 10.40.60.811.21.41.61.82
(a) PIELM solution.
0 0.2 0.4 0.6 0.8 1-2-1.5-1-0.500.511.5210-4 (b) Error plot.
Figure 5: Solution and error for steady 1D diffusion. Red: PIELM, Blue: Exact.
8Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
0 0.2 0.4 0.6 0.8 100.20.40.60.81
(a) PIELM solution.
0 0.2 0.4 0.6 0.8 1-2-1.5-1-0.500.511.522.510-8 (b) Error plot.
Figure 6: Solution and error for 1D steady advection diffusion at = 0:2. Red: PIELM, Blue: Exact.
The 1D stationary advection, diffusion and advection-diffusion equations are given by
ux=R;0<x1; (27)
uxx=R;0<x1; (28)
ux uxx=R;0<x< 1 (29)
respectively. The expressions for Rand the Dirichlet boundary conditions for these cases are calculated by assuming
the following exact solutions
bu=sin(2x)cos(4x) + 1; (30)
bu=sin(x
2)cos(2x) + 1; (31)
bu=ex
 1
e1
 1(32)
respectively. In order to solve these equations in PIELM framework, we have to solve Eqn(21 to 23). The expression
for  !fdepends on the linear differential operator L. The deﬁnitions of Lin these cases are@
@x,@2
@x2and@
@x @2
@x2
respectively. When Lacts onu, the corresponding expressions for  !f=  !0may be written as follows:
'0(XfWT)  !c  !m=R(  !xf); (33)
'00(XfWT)  !c  !m  !m=R(  !xf); (34)
'0(XfWT)  !c  !m '00(XfWT)  !c  !m  !m=  !0: (35)
where  !xfis collocation points vector,  !Iis bias vector, Xf= [  !xf;  !I]and ’’ refers to Hadamardt product. Referring
to Fig (3a), W= [  !m;  !b]. Similarly, expression for  !bc=  !0is given by
'(XbcWT)  !c=B(  !xbc) (36)
where  !xbcis boundary points vector, Xbc= [  !xbc;  !I]andBis the boundary condition.
The results for these test cases are given in Fig(4), Fig(5) and Fig (6) respectively and the summary of the experiments
is given in Tab(2).
9Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
TC [Nf;Nbc;N]O(Error )
TC-1 [40;2;42] 10 4
TC-2 [40;2;42] 10 4
TC-3 [20;2;22] 10 6
Table 2: Summary of experiments for 1D steady test cases.
Remark
1.It should be noted that the uniﬁed deep ANN algorithm [ 3] took 100 points to achieve an order of accuracy of
10 5and10 3in TC-1 and TC-2 respectively. In comparison, PIELM took less than half of the points and
still achieved an order of accuracy of 10 4in both the cases.
4.2 2D steady cases [ TC-4, TC-5, TC-6 ]
-1 -0.5 0 0.5 1-1-0.8-0.6-0.4-0.200.20.40.60.81
(a)
1
0 0.2 0.4 0.6 0.8 100.10.20.30.40.50.60.70.80.91 (b)
2
Figure 7: Computational domains for 2D steady problems
(a) PIELM solution.
 (b) Error plot.
Figure 8: Solution and error for 2D steady advection equation on 
1.
10Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
(a) PIELM solution.
 (b) Error plot.
Figure 9: Solution and error for 2D steady diffusion equation on 
1.
(a) PIELM solution.
 (b) Error plot.
Figure 10: Solution and error for 2D diffusion equation in a complex 2D geometry.
The stationary 2D advection and diffusion equations for the three cases are given by
aux+buy=R;(x;y)
1 (37)
uxx+uyy=R;(x;y)
1 (38)
uxx+uyy=R;(x;y)
2 (39)
wherea= 1andb=1
2are advection coefﬁcients. The computational domains 
1and
2are shown in respectively.
The expressions for Rand theBfor these cases are constructed by choosing the following exact solutions
bu=1
2cos(x)sin(y); (40)
bu=1
2+e (2x2+4y2); (41)
bu=1
2+e ((x 0:6)2+(y 0:6)2)(42)
respectively. PIELM equations for these problems are as follows:
11Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
1.  !f=  !0
Case 1: Advection
'0(XfWT)  !c(a  !m+b  !n) =R(  !xf;  !yf) (43)
Case 2: Diffusion
'00(XfWT)  !c(  !m  !m+  !n  !n) =R(  !xf;  !yf) (44)
whereXf= [  !xf;  !yf;  !I]andW= [  !m;  !n;  !b](refer Fig (2)).
2.  !bc=  !0
'(XbcWT)  !c=B(  !xbc;  !ybc) (45)
whereXbc= [  !xbc;  !ybc;  !I].
The results for the advection and diffusion cases on 
1are shown in Fig (8) and Fig (9) respectively. The result for
diffusion case on 
2is given in Fig (10). Summary of the experiments is given in
TC [Nf;NBC;N]O(Error )
TC-4 [921;240;2000] 10 6
TC-5 [921;240;2000] 10 4
TC-6 [1489;881;5000] 10 7
Table 3: Summary of experiments for 2D steady test cases.
Remarks
1.The uniﬁed deep ANN algorithm [ 3] took 5500 points to achieve an order of accuracy of 10 3in TC-4 and
TC-5. In comparison, PIELM solved these cases with merely 1161 points and still achieved an order of
accuracy of 10 6and10 4respectively.
2.False diffusion is an error which gives diffusion like appearance to solution of pure advection equation when it
is solved using upwind discretization. In Fig (8) these errors can be seen ﬂowing along streamlines. However,
PIELM reduces the order of these errors to an insigniﬁcant level.
3.Computational domain 
2is the map of state of Illinois in USA. This is an example of a complicated polygon
which has very short line segments and ﬁne grained details in various regions. Conventional mesh based
methods are not feasible for these kind of geometries. The latitudes and longitudes of the boundary are
available in MATLAB’s in-built function “usamap”. We have re-scaled the data in the range 0 1. PIELM
solved this case with just 2370 points to an accuracy level of 10 7in just 10seconds.
12Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
4.3 1D unsteady advection cases [ TC-7, TC-8 ]
-1 0 1-1-0.500.51t=0
-1 0 1-1-0.500.51t=0.25
-1 0 1-1-0.500.51t=0.5
(a) Constant coefﬁcient unsteady advection.
-1 0 1-1-0.500.51t=0
-1 0 1-1-0.500.51t=0.25
-1 0 1-1-0.500.51t=0.5
(b) Variable coefﬁcient unsteady advection.
Figure 11: Exact and PIELM solution for 1D unsteady advection with constant and variable coefﬁcients. Red: PIELM,
Blue: Exact.
The unsteady 1D advection equation is given by
ut+a(x)ux= 0;(x;t)[ 1;1]x[0;0:5]; (46)
u(x;0) =F(x);x[ 1;1]; (47)
wherea(x;t)is the advection coefﬁcient. In this problem, we consider two cases: (1) constant coefﬁcient case with
a(x;t) = 1 and (2) variable coefﬁcient case [ 22] witha(x;t) = 1+x. The two cases have periodic and inﬂow boundary
conditions respectively. The value of Fissin(x). The exact solutions to the 1D unsteady advection problems with
constant and variable coefﬁcient are respectively given by
bu=F(x t); (48)
bu=F((1 +x)e t 1): (49)
PIELM equations
1.  !f=  !0
TC-7: Linear case
'0(XfWT)  !c(  !m+  !n) =  !0 (50)
13Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
TC-8: Quasi-linear case
'0(XfWT)  !c  !n+ ('0(XfWT)Af)  !c  !m=  !0 (51)
where  !xf;  !tfare collocation point vectors, Xf= [  !xf;  !tf;  !I],W= [  !m;  !n;  !b]andAf=
[a  !xf;  !tf
; ::: ; a  !xf;  !tf
]NxN.
2.  !bc=  !0
'(XlbcWT)  !c='(XrbcWT)  !c (52)
where  !xlbc,  !tlbcare left boundary points vectors,  !xrbc,  !trbcare right boundary points vectors, Xlbc=
[  !xlbc;  !tlbc;  !I]andXrbc= [  !xrbc;  !trbc;  !I].
3.  !ic=  !0
'(XicWT)  !c=F(  !xic;  !tic) (53)
where  !xic;  !ticare initial condition vectors, Xic= [  !xic;  !tic;  !I]andFis initial condition.
The results are shown in Fig (11). PIELM predicts the exact solution correctly for both linear and quasi-linear advection.
In this case, we took Nf= 420 ,Nbc= 21 ,Nic= 20 andN= 440 . The total learning time is within 2-3 seconds.
Remark
1.For advection problems, the time step of the traditional numerical schemes like upwinding can not exceed the
mesh size due to stability issues. However, PIELM doesn’t impose any such restriction and we can take larger
time steps.
4.3.1 1D unsteady advection-diffusion [ TC-9 ]
0 0.5 1-0.200.20.40.60.811.2t=0
0 0.5 1-0.200.20.40.60.811.2t=0.25
0 0.5 1-0.200.20.40.60.811.2t=0.5
Figure 12: Exact and PIELM solution for unsteady 1D convection diffusion at = 0:005. Red: PIELM, Blue: Exact.
The 1D equivalent of the unsteady 2D advection-diffusion equation solved by Borker et al. [23] is given by
ut+aux=uxx;(x;t)[0;1]x[0;0:5]; (54)
whereais the advection coefﬁcient. The expressions for the initial condition Fand the boundary condition Bare
constructed on the basis of the following exact solution
bu=1p4t+ 1e 1
(4t+1)(x 0:2 at)2(55)
The PIELM equations are as follows:
1.  !f=  !0
'0(XfWT)  !c  !n+a'0(XfWT)  !c  !m='00(XfWT)  !c  !m  !m (56)
where  !xf;  !tfare collocation point vectors, Xf= [  !xf;  !tf;  !I]andW= [  !m;  !n;  !b].
14Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
2.  !bc=  !0
'(XbcWT)  !c=B(  !xbc;  !tbc) (57)
where  !xbc,  !tbcare boundary points vectors, Xbc= [  !xbc;  !tbc;  !I]andBis the boundary condition.
3.  !ic=  !0
'(XicWT)  !c=F(  !xic;  !tic) (58)
where  !xic;  !ticare initial condition vectors, Xic= [  !xic;  !tic;  !I]andFis initial condition.
The results are shown in Fig (12). In this case, PIELM prediction clearly goes wrong in the following grounds:
1. Initial and boundary conditions aren’t captured correctly.
2. Solution has unphysical oscillations throughout the domain.
3. The hump of the Gaussian decays a lot slower than the correct rate.
We increased the size of hidden layer but didn’t see any improvement in results. For example, we took 250x30points in
the computational domain and put as many as 7780 neurons in the hidden layer. Still the PIELM predictions were poor.
4.3.2 2D unsteady advection-diffusion [ TC-10 ]
Figure 13: PIELM solution for 2D unsteady advection diffusion
Figure 14: Error for 2D unsteady advection diffusion
We solve the following unsteady 2D advection-diffusion equation[23]
ut+aux+buy=(uxx+uyy);(x;y;t )
xyx[0;0:2]; (59)
u(x;y;0) =F(x;y);(x;y)
xy; (60)
u(x;y;t ) =B(x;y;t );(x;y;t )@
xyx[0;0:5]; (61)
where 
xy= [0;1]x[0;1].a=cos(22:5)andb=sin(22:5)are advection coefﬁcients in xandydirections and
= 0:005is the diffusion coefﬁcient. The expressions for the initial and the boundary conditions are constructed by
choosing the following exact solution:
bu=1
(4t+ 1)e (x at)2+(y bt)2
(4t+1) (62)
15Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
PIELM equations to be solved are as follows:
1.  !f=  !0
'0(XfWT)  !c  !r+'0(XfWT)  !c(a  !p+b  !q) ='00(XfWT)  !c(  !p  !p+  !q  !q) (63)
where  !xf;  !yf;  !tfare collocation point vectors, Xf= [  !xf;  !yf;  !tf;  !I]. Referring to Fig (3b), W=
[  !p;  !q;  !r;  !s].
2.  !bc=  !0
'(XbcWT)  !c=B(  !xbc;  !ybc;  !tbc) (64)
where  !xbc,  !ybc,  !tbcare boundary points vectors and Xbc= [  !xbc;  !ybc;  !tbc;  !I].
3.  !ic=  !0
'(XicWT)  !c=F(  !xic;  !yic;  !tic) (65)
where  !xic;  !yic;  !ticare initial condition vectors and Xic= [  !xic;  !yic;  !tic;  !I].
The results are shown in Fig (13-14). They are 2D equivalents of 1D results. The solution is diffusive and contains
unphysical oscillations throughout the domain. In spite of all these issues, it should be noted that:
1.The advection component of the equation is captured correctly. The two humps are moving at the same speed.
2. The non-physical oscillations don’t grow with time.
For this case, we have taken a total of 125000 data points and 1000 neurons in the hidden layer. The results show signs
of improvement if we keep increasing the number of points. However, that takes a lot of time which makes the option
impractical. The limitations of the PIELM will be further investigated in the next section. We close this section by
summarizing the advantages of the PIELM which are as follows:
1. It is extremely fast as well as data efﬁcient.(TC-1 to TC-6)
2. It can be seamlessly extended to higher dimensions. (TC-10)
3. It reduces numerical artefacts like false diffusion.(TC-4)
4. It is meshfree method and can handle the complex geometries.(TC-6)
5. It reduces the arbitrariness of the number of neurons in the hidden layer.
5 Limitations of PIELM
Test case ID Description
Representation of functions
with PIELMTC-11 Representation of sharp and
discontinuous functions in 1D
TC-12 Representation of a sharp peaked
2D Gaussian
Solution of PDEs with
PIELMTC-13 TC-7 withF=e 100x2
TC-14 TC-3 with= 0:02
Solution of PDEs with PINN TC-15 TC-7 withF=e 5x2sin(10x)
Table 4: List of numerical experiments that show limitations of PIELM and PINN
A potential reason for the failure of PIELM in solving advection-diffusion equation [ 23] could be the limited representa-
tion capacity of PIELM to represent a complex function. A PDE consists of function and its derivatives. If a neural
network cannot represent the function itself, then calculation of derivatives only adds to the error.
16Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
Representation of functions with sharp gradients [ TC-11, TC-12 ]
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1-0.200.20.40.60.811.21.4
Figure 15: Representation of 1D non smooth functions with PIELM. Red: PIELM solution, Blue: exact solution.
-0.20
10.20.4
0.5 10.60.8
0.5011.2
0
-0.5
-0.5
-1 -1
-0.100.10.20.30.40.50.60.70.8
-0.20
10.20.4
0.5 10.60.8
0.5011.2
0
-0.5
-0.5
-1 -1
0.10.20.30.40.50.60.70.80.9
Figure 16: Representation of a sharp peaked 2D Gaussian with PIELM
To put the representation power of PIELM to test we choose the following two functions: (1) A 1D composite
function that contains both discontinuous functions and functions with sharp gradients and (2) A 2D Gaussian
function with a sharp peak. The expressions for 2D Gaussian function and 1D composite function are f(x;y;t ) =
e 20f(x 0:25)2+(y 0:25)2gand
f(x) =8
>>>>><
>>>>>:1
2fsgn(x+ 0:8) sgn(x+ 0:5)gx 1
2
e 100x2 1
2<x1
2
20
3x 10
31
2<x13
20
 20
3x+16
313
20<x4
5
0 x>4
5(66)
respectively. The results are shown in ﬁgure (15)and Fig (16) respectively. These cases clearly expose the limitation of
PIELM in representing proﬁles with sharp gradients and corners.
17Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
PDEs with sharp solutions [ TC-13, TC-14 ]
-1 0 1-0.200.20.40.60.811.2t=0
-1 0 1-0.200.20.40.60.811.2t=0.1
-1 0 1-0.200.20.40.60.811.2t=0.2
Figure 17: Exact and PIELM solution of 1D advection of a sharp peaked Gaussian with PIELM. Red: PIELM, Blue:
exact.
0 0.2 0.4 0.6 0.8 100.20.40.60.81
Figure 18: Steady 1D convection diffusion at = 0:02. Red: PIELM, Blue: Exact.
Due to this limitation, PIELM fails to solve any PDE which admits functions with sharp gradients. For example, we
have already seen the failure of our algorithm in solving 1D and 2D advection-diffusion equation. We further illustrate
the impact of this limitation on two simpler equations. Firstly, we consider pure advection of a sharp peaked Gaussian.
This equation has been solved in TC-7 for a smooth sine function. Next , we take steady advection-diffusion equation
(TC-3) with a low value of diffusion coefﬁcient.
The exact and PIELM solutions for these problems are shown in Fig (17) and Fig (18) respectively.
18Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
Representation of a high frequency wavelet with PINN [TC-15]
Figure 19: Deep PINN architecture
-1 0 1-5-4-3-2-101t=0
-1 0 1-5-4-3-2-101t=0.1
-1 0 1-5-4-3-2-101t=0.2
Figure 20: Exact and PINN solution of pure advection of a high frequency wave packet. Red: PINN, Blue: exact
An obvious idea to improve the representation capacity of a neural network is to make it deep. Therefore, we test
the performance of PINN in TC-7 with F=e 5x2sin(10x)i.e. pure advection of a high frequency wavelet. The
PINN code is freely available at https://github.com/maziarraissi/PINNs. We modiﬁed the original code by replacing the
Burgers equation with pure linear advection equation. Fig(19) shows the architecture of PINN. It consists of 9 hidden
layers with 20 neurons each. Each layer is activated by tanh functions.
The exact and the PINN solutions are shown in Fig (20). We can see that even a deep network is unable to capture the
sharp gradients of this wavelet.
List of the experiments conducted in this section are given in Tab 4. We summarize this section as follows:
1. The main limitation of a PIELM is its inability to represent complex functions.
2. This limitation restricts the PIELM to solve the PDEs with sharp exact solutions.
3. Adding extra layers is not the practical solution to this problem. (TC-15)
19Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
6 Distributed PIELM
In this section, we propose a distributed version of PIELM called DPIELM. This algorithm takes motivation from ﬁnite
volume methods in which the whole computational domain is partitioned into multiple cells and governing equations are
solved at each cell. The solutions of these individual cells are stitched together with additional convective and diffusive
ﬂuxes conditions at the cell interfaces. We adopt a similar strategy in DPIELM. As representation of a complex function
is very hard for a single PIELM or PINN in the whole domain, we divide the domain into multiple cells and install
a PIELM in each cell. Therefore, each PIELM uses different representations in different portions of domain while
satisfying some additional constraints of continuity and differentiability.
6.1 Mathematical formulation
(a) Distributed PIELMs in 
 (b) A PIELM in 
i. Red triangles: boundary points, green
rectangles: collocation points
Figure 21: DPIELM architecture for full domain and an individual cell.
Consider the following 1D unsteady problem
@
@tu(x;t) +Lu(x;t) =R(x;t);(x;t)
 (67)
u(x;t) =B(x;t);(x;t)@
; (68)
u(x;0) =F(x);x[xL;xR]; (69)
whereLis a linear differential operator and @
is the boundary of computational domain 
. In this problem, the
rectangular domain 
is given by 
 = [xL;xR]x[0;T]. On uniformly dividing 
intoNcnon-overlapping rectangular
cells, 
may be written as

 =Nc[
i=1
i: (70)
The boundary of the cell 
iis denoted by @
i. For rectangular cells,
@
i=4[
m=1I(i)
m (71)
whereI(i)
mrepresents the mthinterface of 
i.
Fig (21a) shows the distribution of PIELMs in a rectangular computational domain with NBxxNBtcells (i.e.Nc=
NBxxNBt). We denote the PIELM on the ithcell byM(i). Fig (21b) shows a PIELM with collocation points at
20Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
the interior and the boundary points at the four interfaces. The weights and output corresponding to a given M(i)are
denoted by [  !m(i);  !n(i);  !b(i)
;  !c(i)]andf(i)respectively.
At eachM(i), we enforce additional constraints of continuity (or smoothness) of solution at the cell interfaces depending
on the differential operator L. For example, continuity of solution is sufﬁcient for advection problems. For diffusion
problem, the solution should be continuously differentiable. For the computational domain shown in the Fig (21), the
system of equations to be solved in the DPIELM framework are given below.
6.1.1 Regular PIELM equations
1.  !(i)
f=  !0 
@  !f(i)
@t+L  !f(i)   !R(i)!

i=  !0;i= 1;2;:::;Nc (72)
2.  !(i)
bc=  !0
(  !f(i)   !B(i))I4=  !0;i= 1;(1 +NBx);:::;(1 + (NBt 1)NBx) (73)
(  !f(i)   !B(i))I2=  !0;i=NBx;2NBx;:::;NBtxNBx (74)
3.  !(i)
ic=  !0
(  !f(i)   !F(i))I1=  !0;i= 1;2;:::;NBx (75)
6.1.2 Additional interface equations
1. Constraints for C0solutions i.e.  !(i)
C0=  !0.
Continuity along xdirection
8
>><
>>:  !f((1)+i 1)
  !f((2)+i 1)
:::  !f((NBt)+i 1)9
>>=
>>;
I2=8
>><
>>:  !f((1)+i)
  !f((2)+i)
:::  !f((NBt)+i)9
>>=
>>;
I4;i= 1;2;:::;NBx 1 (76)
where= [1;(1 +NBx);:::;1 + (NBt 1)NBx]T.
Continuity along tdirection
8
>><
>>:  !f((1)+(i 1)NBx)
  !f((2)+(i 1)NBx)
:::  !f((NBx)+(i 1)NBx)9
>>=
>>;
I3=8
>><
>>:  !f((1)+iNBx)
  !f((2)+iNBx)
:::  !f((NBx)+iNBx)9
>>=
>>;
I1;i= 1;2;:::;NBt 1 (77)
where= [1;2;:::;NBx]T.
2. Constraints for C1solutions i.e.  !(i)
C1=  !0.
Smooth solutions along xdirection
@
@x8
>><
>>:  !f((1)+i 1)
  !f((2)+i 1)
:::  !f((NBt)+i 1)9
>>=
>>;
I2=@
@x8
>><
>>:  !f((1)+i)
  !f((2)+i)
:::  !f((NBt)+i)9
>>=
>>;
I4;i= 1;2;:::;NBx 1 (78)
where= [1;(1 +NBx);:::;1 + (NBt 1)NBx]T.
Assembly of Eqns (72 to 78) leads to a system of linear equations which can be represented as
H  !c=  !K; (79)
where  !c= [  !c(1);  !c(2);:::;  !c(Nc)]T:The form of Hand  !Kdepends on theL,BandF. Finally  !ccan be found
using pseudo inverse. It is to be noted that although we have shown the formulation for 1D unsteady problems, no
special adjustment is needed to extend the formulation to higher dimensional problems.
This completes the mathematical formulation of DPIELM. The main steps in its implementation are as follows:
21Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
1.Divide the computational domain into uniformly distributed non overlapping cells and install a PIELM in each
cell.
2.Depending on the cell location, PDE and the initial and boundary conditions, ﬁnd the expressions for  !(i)
f,
  !(i)
bcand  !(i)
icat each cell.
3. Depending on the PDE, ﬁnd the expressions for  !(i)
C0and  !(i)
C1at each cell interface.
4. Assemble these equations in the form of H  !c=  !K;where  !c= [  !c(1);  !c(2);:::;  !c(Nc)]T:
5. Find the value of  !cusing pseudo inverse.
7 Performance evaluation of DPIELM
Test Case ID Description Architecture
TC-9 1D unsteady linear advection-diffusion [10;10;5;5;30]
TC-10 2D unsteady linear advection-diffusion
equation[20;20;50;3;3;3;30]
TC-11 Representation of 1D sharp and
discontinuous functions[50;5;5]
TC-12 Representation of a sharp peaked 2D
Gaussian with DPIELM[15;15;5;5;15]
TC-13 Advection of a sharp peaked Gaussian [15;10;5;5;30]
TC-14 1D steady advection-diffusion [20;5;20]
TC-15 Advection of a high frequency wave
packet[15;10;5;5;30]
Table 5: Details of DPIELM architecture for the test cases. For 1D steady problems, architecture is given by
[NBx;nbx;N
cell], whereNBx,nbxandN
cellrefer to number of cells, number of points in the cell and size of hidden
layer of the PIELM. Similarly, for 1D and 2D unsteady problems, it is given by [NBx;NBt;nbx;nbt;N
cell]and
[NBx;NBy;NBt;nbx;nby;nbt;N
cell]respectively.
In this section, we evaluate the performance of DPIELMs by testing it on all the cases in which regular PIELM and
PINN failed to perform. The details of the architecture is given in Tab(5).
Representation of functions with sharp gradient [ TC-11, TC-12]
-1 -0.5 0 0.5 1-0.200.20.40.60.811.21.4
Figure 22: Representation of 1D non smooth functions with DPIELM. Red: DPIELM, Blue: Exact.
22Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
10
10.5
0.501
0
-0.5
-1 -1
00.10.20.30.40.50.60.70.80.9
Figure 23: Representation of a sharp peaked 2D Gaussian with DPIELM
The mathematical formulation of DPIELM equations for 1D case are as follows:
1.  !(i)
f=  !0
'(Xf(i)W(i)T)  !c(i)=f(  !x(i)
f);i= 1;2;:::;NBx (80)
2.  !(i)
bc=  !0(
'(Xbc;I 1(1)W(1)T)  !c(1)
'(Xbc;I 2(NBx)W(NBx)T)  !c(NBx))
=(
f(  !x(1)
bc;I 1)
f(  !x(NBx)
bc;I 2))
(81)
whereI1;I2refer to left and right cell interfaces respectively.
3.  !(i)
C0=  !0
'(Xbc;I 2(i)W(i)T)  !c(i)='(Xbc;I 1(i+1)W(i+1)T)  !c(i+1);i= 1;2;:::;NBx 1 (82)
The equations for the 3D case can be written in a similar fashion. The exact and DPIELM solutions for these cases are
shown in Figs (22) and (23) respectively.
1D steady advection-diffusion equation with low value of diffusion constant [TC-14]
0 0.2 0.4 0.6 0.8 100.20.40.60.81
Figure 24: Exact and DPIELM solution of unsteady 1D convection diffusion. Red: DPIELM, Blue: exact
23Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
The DPIELM equations are as follows:
1.  !(i)
f=  !0
'0(Xf(i)W(i)T)  !c(i)  !m '00(Xf(i)W(i)T)  !c  !m  !m=  !0;i= 1;2;:::;NBx (83)
2.  !(i)
bc=  !0(
'(Xbc;I 1(1)W(1)T)  !c(1)
'(Xbc;I 2(NBx)W(NBx)T)  !c(NBx))
=(
B(  !x(1)
bc;I 1)
B(  !x(NBx)
bc;I 2))
(84)
3.  !(i)
C0=  !0
'(Xbc;I 2(i)W(i)T)  !c(i)='(Xbc;I 1(i+1)W(i+1)T)  !c(i+1);i= 1;2;:::;NBx 1 (85)
4.  !(i)
C1=  !0
'0(Xbc;I 2(i)W(i)T)  !c(i)  !m(i)='0(Xbc;I 1(i+1)W(i+1)T)  !c(i+1)  !m(i+1);i= 1;2;:::;NBx 1(86)
The results of the exact and DPIELM solution is given in Fig(24).
7.1 1D unsteady advection of a sharp peaked Gaussian and a high frequency wavelet and [ TC-13, TC-15 ]
-1 0 1-0.200.20.40.60.811.2t=0
-1 0 1-0.200.20.40.60.811.2t=0.1
-1 0 1-0.200.20.40.60.811.2t=0.2
Figure 25: Exact and DPIELM solution advection of a sharp peaked Gaussian with DPIELM. Red: DPIELM, Blue:
Exact.
-1 0 1-1-0.500.51t=0
-1 0 1-1-0.500.51t=0.1
-1 0 1-1-0.500.51t=0.2
Figure 26: Exact and DPIELM solution of pure advection of a high frequency wave packet. Red: DPIELM, Blue: exact
24Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
The DPIELM equation to be solved are as follows:
1.  !(i)
f=  !0
'0(Xf(i)W(i)T)  !c(i)(  !m(i)+  !n(i)) =  !0;i= 1;2;:::;Nc (87)
2.  !(i)
bc=  !0
'(Xbc;I 4(i)W(i)T)  !c(i)=  !0;i= 1;(1 +NBx);:::;(1 + (NBt 1)NBx) (88)
'(Xbc;I 2(i)W(i)T)  !c(i)=  !0;i=NBx;2NBx;:::;NBtxNBx (89)
3.  !(i)
ic=  !0
'(Xbc;I 1(i)W(i)T)  !c(i)=  !F(  !x(i)
bc;I 1);i= 1;2;:::;NBx (90)
4.  !(i)
C0=  !0
Continuity along xdirection
8
>>><
>>>:'(Xbc;I 2(j(1;i) 1)W(j(1;i) 1)T)  !c(j(1;i) 1)
'(Xbc;I 2(j(2;i) 1)W(j(2;i) 1)T)  !c(j(2;i) 1)
:::
'(Xbc;I 2(j(NBt;i) 1)W(j(NBt;i) 1)T)  !c(j(NBt;i) 1)9
>>>=
>>>;=
8
>>><
>>>:'(Xbc;I 4(j(1;i))W(j(1;i))T)  !c(j(1;i))
'(Xbc;I 4(j(2;i))W(j(2;i))T)  !c(j(2;i))
:::
'(Xbc;I I4(j(NBt;i))W(j(NBt;i))T)  !c(j(NBt;i))9
>>>=
>>>;(91)
where= 1;2:::;NBt,j(;i) =() +i; i= 1;2;:::;NBx 1and= [1;(1 +NBx);:::;1 +
(NBt 1)NBx]T.
Continuity along tdirection
8
>>><
>>>:'(Xbc;I 3(j(1;i 1)W(j(1;i 1)T)  !c(j(1;i 1)
'(Xbc;I 3(j(2;i 1)W(j(2;i 1)T)  !c(j(2;i 1)
:::
'(Xbc;I 3(j(NBt;i 1)W(j(NBt;i 1)T)  !c(j(NBt;i 1)9
>>>=
>>>;=
8
>>><
>>>:'(Xbc;I 1(j(1;i))W(j(1;i))T)  !c(j(1;i))
'(Xbc;1(j(2;i))W(j(2;i))T)  !c(j(2;i))
:::
'(Xbc;I I1(j(NBt;i))W(j(NBt;i))T)  !c(j(NBt;i))9
>>>=
>>>;(92)
where= 1;2:::;NBx,j(;i) =() +iNBx;i= 1;2;:::;NBt 1and= [1;2;:::;NBx]T.
The results for the TC-13 and TC-15 are given in Fig (25) and Fig (26) respectively.
25Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
7.2 1D and 2D unsteady advection-diffusion equations [ TC-9, TC-10]
0 0.5 1-0.200.20.40.60.811.2t=0
0 0.5 1-0.200.20.40.60.811.2t=0.25
0 0.5 1-0.200.20.40.60.811.2t=0.5
Figure 27: Exact and DPIELM solution of unsteady 1D convection diffusion. Red: DPIELM, Blue: exact
Figure 28: DPIELM solution and error for unsteady 2D convection diffusion at t= 0
26Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
Figure 29: DPIELM solution and error for unsteady 2D convection diffusion at t= 0:25
Figure 30: DPIELM solution and error for unsteady 2D convection diffusion at t= 0:5
In this section, we present the DPIELM equation for the 1D case. The equations for the 2D case can be formulated in a
similar fashion. The equations to be solved for 1D unsteady advection-diffusion equation are as follows:
1.  !(i)
f=  !0
'0(Xf(i)W(i)T)  !c(i)(  !n(i)+a  !m(i)   !m(i)  !m(i)) =  !0;i= 1;2;:::;Nc (93)
2.  !(i)
C1=  !0
8
>>><
>>>:'0(Xbc;I 2(j(1;i) 1)W(j(1;i) 1)T)  !c(j(1;i) 1)  !m(j(1;i) 1)
'0(Xbc;I 2(j(2;i) 1)W(j(2;i) 1)T)  !c(j(2;i) 1)  !m(j(2;i) 1)
:::
'0(Xbc;I 2(j(NBt;i) 1)W(j(NBt;i) 1)T)  !c(j(NBt;i) 1)  !m(j(NBt;i) 1)9
>>>=
>>>;=
8
>>><
>>>:'0(Xbc;I 4(j(1;i))W(j(1;i))T)  !c(j(1;i))  !m(j(1;i))
'0(Xbc;I 4(j(2;i))W(j(2;i))T)  !c(j(2;i))  !m(j(2;i))
:::
'0(Xbc;I I4(j(NBt;i))W(j(NBt;i))T)  !c(j(NBt;i))  !m(j(NBt;i))9
>>>=
>>>;(94)
where= 1;2:::;NBt,j(;i) =() +i;i= 1;2;:::;NBx 1and= [1;(1 +NBx);:::;1 + (NBt 
1)NBx]T.
27Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
Rest of the equations i.e.  !(i)
bc=  !0,  !(i)
ic=  !0and  !(i)
C0=  !0are same as that used in 1D unsteady linear advection.
The results for the 1D and 2D cases are given in Fig (27) and Fig (28 to 30) respectively.
This brings us to the end of our numerical experiments. We close this section by highlighting the key points which are
as follows:
1.The process of partitioning of the whole computational domain into multiple cells simpliﬁes the representation
of the complicated function ( and thus PDE ) in the individual cells. As a result, local PIELMs are able to
capture not just the functions with sharp gradients, but also discontinuous functions ( TC-11 ).
2.To our knowledge, this is the ﬁrst demonstration of capability of ELM based algorithms to solve 2D unsteady
PDEs and produce results comparable to sophisticated numerical methods. (TC-10)
3. The distributed version of PIELM exhibits better representation ability than a deep PINN (TC-15).
8 Conclusion and future work
We have presented in this paper PIELM -- an efﬁcient method to utilize physics informed neural networks to solve
stationary and time dependent linear PDEs. As PIELM inherits the unique qualities of its parent algorithms (PINN
and ELM), it works very well on complex geometries, respects the inherent physics of the PDEs and is extremely fast
as well. This leads to several advantages over existing conventional numerical methods; PIELM reduces numerical
artefacts such as false diffusion as well can handle complex geometries in a meshfree approach. PIELM also reduces, to
a certain extent, the arbitrariness of the number of neurons in typical deep PINNs. Our numerical tests also conﬁrm that,
for a ﬁxed problem, our minimal PIELM is more accurate than prior deep NN results [3] while being faster.
We have also presented in this paper the limitations in representing complex functions using a single PIELM or PINN
for the whole domain. For practical problems using PINNs can lead to very deep networks with the concomitant training
problems and efﬁciency issues. Our proposed solution is to use a distributed PIELM (DPIELM) which uses different
representations in different portions of the domain while imposing some continuity and differentiability constraints.
The resultant DPIELM easily captures proﬁles that PINNs have difﬁculty with. Further, on time-dependent problems,
DPIELM gives results that are comparable to sophisticated conventional numerical techniques as seen in Section 7.2.
We believe that the method, as formulated, is already very powerful for linear PDEs with constant or space-varying
coefﬁcients. Two primary areas of development remain, in our opinion. Our preliminary tests show that, for linear
PDEs, unlike deep PINNs [ 13], our method may actually be competitive with conventional techniques in terms of
speed and accuracy. However, a ﬁrm conclusion on this cannot be reached until a more thorough and fair study is done.
Theoretical and numerical evidence for this efﬁcacy is the ﬁrst area which deserves attention, as the number of practical
applications (such as heat conduction, etc) where numerical methods for linear equations are a staple is large. Having
an efﬁcient neural network framework for such problems can be tremendously beneﬁcial to practitioners.
Even more importantly, PIELM’s efﬁcacy is thanks to the linear nature of the ﬁnal problem. We have, therefore, limited
our present study to linear problems. Extending this method to nonlinear equations is the obvious next frontier. This
may be approached in one of two ways. The ﬁrst approach would be to use the PIELM structure as is and then solve the
resultant, non-convex optimization problem. Another approach would be to linearize the equation around the current
time step to predict a future time step. This would be the equivalent of a linearized, explicit time-stepping method in
conventional time marching techniques. We are currently investigating these approaches and will report progress in
future publications.
References
[1]Versteeg, Henk Kaarle, and Weeratunge Malalasekera. An introduction to computational ﬂuid dynamics: the ﬁnite
volume method. Pearson education, 2007.
[2]Quirk, James J. "" A contribution to the great Riemann solver debate."" Upwind and High-Resolution Schemes.
Springer, Berlin, Heidelberg, 1997. 550-569.
[3] Berg, Jens, and Kaj Nyström. A uniﬁed deep artiﬁcial neural network approach to partial differential equations in
complex geometries. Neurocomputing 317 (2018): 28-41.
[4]Lagaris, Isaac E., Aristidis Likas, and Dimitrios I. Fotiadis. "" Artiﬁcial neural networks for solving ordinary and
partial differential equations."" IEEE transactions on neural networks 9.5 (1998): 987-1000.
[5]Lagaris, Isaac E., Aristidis C. Likas, and Dimitris G. Papageorgiou. "" Neural-network methods for boundary value
problems with irregular boundaries."" IEEE Transactions on Neural Networks 11.5 (2000): 1041-1049.
28Numerical solution of PDEs using PIELM V.D WIVEDI *, B.S RINIVASAN
[6]van Milligen, B. Ph, V . Tribaldos, and J. A. Jiménez. "" Neural network differential equation and plasma equilibrium
solver."" Physical review letters 75.20 (1995): 3594.
[7]McFall, K. S., & Mahan, J. R. (2009). Artiﬁcial neural network method for solution of boundary value problems
with exact satisfaction of arbitrary boundary conditions. IEEE Transactions on Neural Networks, 20(8), 1221-1233.
[8]Kumar, Manoj, and Neha Yadav. ""Multilayer perceptrons and radial basis function neural network methods for the
solution of differential equations: a survey."" Computers & Mathematics with Applications 62.10 (2011): 3796-3811.
[9]Mall, Susmita, and Snehashish Chakraverty. "" Application of Legendre Neural Network for solving ordinary
differential equations."" Applied Soft Computing 43 (2016): 347-356.
[10] Sirignano, Justin, and Konstantinos Spiliopoulos. "" DGM: A deep learning algorithm for solving partial differential
equations."" Journal of Computational Physics 375 (2018): 1339-1364.
[11] Raissi, Maziar, and George Em Karniadakis. "" Hidden physics models: Machine learning of nonlinear partial
differential equations."" Journal of Computational Physics 357 (2018): 125-141.
[12] Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. "" Numerical gaussian processes for time-dependent
and nonlinear partial differential equations."" SIAM Journal on Scientiﬁc Computing 40.1 (2018): A172-A198.
[13] Raissi, Maziar, Paris Perdikaris, and George E. Karniadakis. "" Physics-informed neural networks: A deep learning
framework for solving forward and inverse problems involving nonlinear partial differential equations."" Journal of
Computational Physics 378 (2019): 686-707.
[14] G.-B. Huang, Q.-Y . Zhu, C.-K. Siew, Extreme learning machine: theory and applications, Neurocomputing 70
(2006) 489–501.
[15] Balasundaram, S. "" Application of error minimized extreme learning machine for simultaneous learning of a
function and its derivatives."" Neurocomputing 74.16 (2011): 2511-2519.
[16] Yang, Yunlei, Muzhou Hou, and Jianshu Luo. "" A novel improved extreme learning machine algorithm in solving
ordinary differential equations by Legendre neural network methods."" Advances in Difference Equations 2018.1
(2018): 469.
[17] Sun, Hongli, et al. "" Solving partial differential equation based on Bernstein neural network and extreme learning
machine algorithm."" Neural Processing Letters (2018): 1-20.
[18] G.-B. Huang, L. Chen, C.-K. Siew, Universal approximation using incremental constructive feedforward networks
with random hidden nodes, IEEE Transactions on Neural Networks 17 (4) (2006) 879–892.
[19] D. Rumelhart, G. Hintont, R. Williams, Learning representations by backpropagating errors, Nature 323 (6088)
(1986) 533–536.
[20] Baydin, Atilim Gunes, et al. "" Automatic differentiation in machine learning: a survey."" Journal of Machine
Learning Research 18 (2018): 1-43.
[21] D. Serre, Matrices: Theory and Applications, Springer, New York, 2002.
[22] Kopriva, David A., and Gregor J. Gassner. "" An energy stable discontinuous Galerkin spectral element discretization
for variable coefﬁcient advection problems."" SIAM Journal on Scientiﬁc Computing 36.4 (2014): A2076-A2099.
[23] Borker, Raunak, Charbel Farhat, and Radek Tezaur. ""A high-order discontinuous Galerkin method for unsteady
advection–diffusion problems."" Journal of Computational Physics 332 (2017): 520-537.
29"
22,https://arxiv.org/pdf/2205.08304,"Bayesian Physics-Informed Neural Networks
for real-world nonlinear dynamical systems
Kevin Linka1, Amelie Schäfer2, Xuhui Meng3,
Zongren Zou3, George Em Karniadakis3, Ellen Kuhl2
1Institute of Continuum and Material Mechanics,
Hamburg University of Technology, Hamburg, Germany
2Department of Mechanical Engineering,
Stanford University, Stanford, California, United States
3Division of Applied Mathematics,
Brown University, Providence, Rhode Island, United States
Abstract. Understanding real-world dynamical phenomena remains a challenging task.
Across various scientiﬁc disciplines, machine learning has advanced as the go-to tech-
nology to analyze nonlinear dynamical systems, identify patterns in big data, and make
decision around them. Neural networks are now consistently used as universal function
approximators for data with underlying mechanisms that are incompletely understood or
exceedingly complex. However, neural networks alone ignore the fundamental laws of
physics and often fail to make plausible predictions. Here we integrate data, physics, and
uncertainties by combining neural networks, physics-informed modeling, and Bayesian
inference to improve the predictive potential of traditional neural network models. We
embed the physical model of a damped harmonic oscillator into a fully-connected feed-
forward neural network to explore a simple and illustrative model system, the outbreak
dynamics of COVID-19. Our Physics-Informed Neural Networks can seamlessly integrate
data and physics, robustly solve forward and inverse problems, and perform well for both
interpolation and extrapolation, even for a small amount of noisy and incomplete data. At
only minor additional cost, they can self-adaptively learn the weighting between data and
physics. Combined with Bayesian Neural Networks, they can serve as priors in a Bayesian
Inference, and provide credible intervals for uncertainty quantiﬁcation. Our study reveals
the inherent advantages and disadvantages of Neural Networks, Bayesian Inference, and a
combination of both and provides valuable guidelines for model selection. While we have
only demonstrated these different approaches for the simple model problem of a seasonal
endemic infectious disease, we anticipate that the underlying concepts and trends gener-
alize to more complex disease conditions and, more broadly, to a wide variety of nonlinear
dynamical systems.
Keywords. dynamical systems; machine learning; Neural Networks; Physics-Informed
Neural Networks; Bayesian Inference; Bayesian Neural Networks
1arXiv:2205.08304v2  [cs.LG]  24 May 20221 Motivation
Modeling and predicting the behavior of complex nonlinear dynamical systems remains a
challenging scientiﬁc task [24]. Numerous scientists are addressing this challenge by col-
lecting more observational data than ever before; however, more often than not without a
clear picture how to sort, analyze, and understand these enormous amounts of informa-
tion [10]. Throughout the past two decades, machine learning has advanced as the go-to
technology to analyze big data and explore the massive design spaces associated with
them [1]. Simply put, machine learning is an incredibly powerful strategy to make data-
driven recommendations and decisions based on the input data alone. As such, it is has
become an indispensable technology for image or speech recognition, medical diagnos-
tics, or self-driving cars. However, traditional machine learning ignores the fundamental
laws of physics, and, as a consequence, performs well at ﬁtting observations, but often
fails to make consistent and plausible predictions. In the engineering science community,
especially in disciplines that are traditionally not data-rich, these limitations have raised
the question how we can advance machine learning and build in our prior knowledge to
respect underlying physical principles.
The trend of embedding physics into machine learning has recently drawn tremendous
attention in various scientiﬁc applications [25]. As engineering scientists, we have been
modeling complex nonlinear dynamical systems for hundreds of years and we have de-
veloped a reasonable quantitative knowledge about physical parameters, boundary con-
ditions, and constraints [26]. Physics-informed machine learning now allows us to use
this prior knowledge when training machine learning tools [1]. This not only makes the
training more efﬁcient, but also more accurate and robust, especially when working with
missing, noisy, or sparse real-life data [32]. A powerful and effective strategy to seamlessly
integrate data and physics are Physics-Informed Neural Networks [27]. Physics Informed
Neural Networks introduce a learning bias by directly embedding the physics into the loss
function of a neural network [28]. This makes the neural network more robust, especially
in the presence of sparse or imperfect data, and can provide more accurate and physically
consistent predictions, even outside the training window [10]. For example, recent stud-
ies have successfully applied Physics Informed Neural Networks to study the complex
outbreak dynamics of COVID-19 [4, 31] by integrating advance epidemiology models into
deep neural networks [11, 34]. However, the success of these methods depends crucially
on the amount of available data and the complexity of the system itself. For the COVID-19
pandemic, we now know that predictions typically fail beyond a two-week window [3,15],
and that predicting outbreak dynamics beyond this range can have devastating conse-
quences [7]. It seems intuitive to ask how we can quantify uncertainties to estimate the
reliability of our models and to build conﬁdence in our model predictions [17].
Real-world data are inherently stochastic, noisy, and incomplete, and naturally contain
aleatoric uncertainty [20]. This is why we should never just look at the plain data. In-
stead, we should always interpret data in the context of models that allow us to quanti-
fying uncertainties [19]. A recently proposed promising strategy is to interpret Physics
Informed Neural Networks within the framework of Bayesian statistics [32]. This ap-
proach combines a Bayesian Neural Network with a Physics Informed Neural Network
to create prior distributions and uses Hamilton Monte Carlo methods to estimate pos-
terior distributions [33]. Uncertainty quantiﬁcation in the form of credible intervals is a
natural and important by-product of such a Bayesian analysis [5]. Throughout the past
decades, Bayesian statistics have undeniably gained massive popularity [21] and have
stimulated the birth to an entirely new ﬁeld, probabilistic programming [22]. Combined
2with Physics Informed Neural Networks, Bayesian statistics perform well for both forward
and inverse problems including Poisson problems, ﬂow problems, phase separation prob-
lems, and reaction-diffusion problems [33]. However, most of these applications train their
network on synthetic data from a known solution with overlaid noise [18]. This motivates
the question how well Bayesian Physics Informed Neural Networks perform on real-word
data from a nonlinear dynamical system for which the underlying physics are not entirely
known, with both aleatoric and epistemic uncertainty.
The objective of our study is to illustrate the performance of Neural Networks, Bayesian
Inference, and a combination of both using real-world data. However, rather than show-
casing these methods on real big data, we focus on a simple data set that is easy to un-
derstand, interpret, and reproduce: the reported daily number of new COVID-19 cases
worldwide [14] throughout the year of 2021 [9]. We identify a suitable, yet simple math-
ematical model with an analytical solution that allows us to characterize the data. Again,
our objective is not to develop the most rigorous physical model to explain each and ev-
ery feature of the outbreak dynamics of a global pandemic [8]. Instead, we adopt simple
physical model, a damped harmonic oscillator, to characterize the long-term dynamics of
COVID-19 on a global scale. We integrate the case data and the oscillator model using
Neural Networks and Bayesian Inference and compare their model equations, parame-
ters, training, predictions, and uncertainties. We envision that this study sheds light on the
performance of different cutting-edge machine learning tools, highlights their advantages
and disadvantages, and helps engineering scientists to select the best method to analyze
real-world nonlinear dynamical systems.
2 Model problem
2.1 Data - Daily new COVID-19 cases
Figure 1 illustrates our real-world data to compare different machine learning approaches.
As example, we use the number of new COVID-19 cases worldwide [23] throughout the
entire year of 2021, which we draw from a public database [9]. The thin ﬂuctuating line
shows the raw data, the reported daily new cases worldwide from January 1, 2021 to De-
cember 31, 2021. Global reporting started on January 22, 2020 with a total number of cases
of 557 [13]. On January 1, 2021, at the beginning of our analysis window, the number
of newly reported cases worldwide was 572,602 bringing the total number of cases up
to 84,332,767. On December 31, 2021, at the end of our window, the total number of cases
was 288,631,129. Altogether, the reporting window saw three pronounced waves. The ﬁrst
wave had a minimum number of new cases of 281,223 on day 46, February 16, 2021, and a
maximum number of 905,378 on day 118, April 29, 2021, as we can conﬁrm from the global
minimum and maximum in Figure 1. The second wave had a a minimum number of new
cases of 296,808 on day 172, June 22, 2021, and a maximum number of 819,336 cases on
day 221, August 10, 2021, about four months after. To eliminate noise, reporting uncertain-
ties, and weekday-weekend ﬂuctuations, data analysts typically average the reported case
numbers across a seven-day window [12]. The thick smooth line illustrates the seven-day
moving average ˆx(t)of the daily new cases. In the following sections, we will use both the
raw data and their seven-day moving average as an example to illustrate the potential of
Neural Networks, Bayesian Inference, and both methods combined.
3Figure 1: Data - Daily new COVID-19 cases worldwide in 2021. Thin ﬂuctuating line illustrates the reported
daily new cases of COVID-19 worldwide; thick smooth line illustrates the seven-day moving average of the
daily new cases, from January 1, 2021 to December 31, 2021.
2.2 Neural Network modeling - Fully-connected feed-forward neural network
To model the data in Figure 1 without any prior knowledge of the underlying physics,
we use a neural network that approximates the model solution x, the reported daily new
COVID-19 cases, by taking the time coordinates tas input. We adopt one of the simplest
examples of neural networks, a fully-connected feed-forward neural network composed
of multiple hidden layers. We denote the hidden variables of the kthhidden layer as zkand
summarize the neural network, here for two hidden layers, as
z0= t
z1=s(W1z0+b1)
z2=s(W2z1+b2)
z3= W3z2+b3(1)
where the output of the last layer is used to approximate the true solution, xz3. Here,
s()denotes the non-linear activation function for which we select a hyperbolic tangent
function, s() = tanh(), and q=fWk,bkgare the trainable network parameters, the
weight matrix Wkand the bias vector bkof the kthlayer of the network. Throughout
this project, for illustrative purposes, we consider a fully-connected feed-forward network
with one input, the time t, two hidden layers with 32 nodes each, and one output, the
daily new cases x(t). For this type of network, W12R132,W22R3232,W32R321,
andb12R32,b22R32,b32R1, resulting in 32 +3232+32=1088 weights and
32+32+1=65 biases.
2.3 Physic Informed modeling - Damped harmonic oscillator
To model the data in Figure 1 using a physics-based model, we consider a general param-
eterized second order differential equation,
r(t,x,˙x,¨x,J) =0 (2)
4where t2[0,T]is the time, x(t)is the solution with initial conditions x(t0) = x0and
˙x(t0) = ˙x0,ris the residual as a function of xand its ﬁrst and second time derivatives ˙x
and ¨x, and Jare the physics parameters. We now specify the general equation (2) for the
model problem of a damped harmonic oscillator, which is governed by Newton’s second
law, the balance of forces, m¨x+c˙x+k x=0, or, divided by the mass m,
r=¨x+c
m˙x+k
mx=0 or r=¨x+2zw0˙x+w2
0x=0 . (3)
We can parameterize the damped harmonic oscillator equation in terms of the mass m, the
viscous damping coefﬁcient c, and the stiffness k, or, equivalently, in terms of the damping
ratio z=d/w0=c/(2p
mk), the damping d=c/(2m), and the angular frequency w0=p
k/m. Equations (3.1) and (3.2) are homogeneous linear differential equations of second
order with constant coefﬁcients. For solutions to this type of equations, we can make an
exponential ansatz of the form x(t) =Cexp(lt), such that ˙x(t) =lCexp(lt)and ¨x(t) =
l2Cexp(lt). Inserting this ansatz into equations (3.1) and (3.2) yields their characteristic
equations,
l2+c
ml+k
m=0 or l2+2d l+w2
0=0 . (4)
These equations are quadratic equations in normal form with two solutions for l,
l1,2= c
2mrc
2m2
 k
mor l1,2= dq
d2 w2
0. (5)
From equation (5.2) we conclude that the damping ratio z=d/w0, the ratio between
damping dand frequency w0, determines the type of the solution and with it the behavior
of the system: A damped harmonic oscillator can be overdamped for z>1 and d>w0
with two different real valued solutions for l; critically damped for z=1 and d=w0
with two identical real valued solutions for l, or underdamped for z<1 and d<w0
with two conjugate complex solutions for l. Here we consider the underdamped case.
The analytical solution of an underdamped harmonic oscillator describes an exponential
decay of the oscillation,
x(t) =2A0cos(wt+f)exp( dt), (6)
where A0is the amplitude, w=q
w2
0 d2is the natural frequency, and f=arctan ( d/w)
is the phase angle.
Figure 2 illustrates the dynamics of a damped harmonic oscillator. The solid line highlights
the analytical solution m¨x+c˙x+k(x x0) = 0 or ¨x+2zw0˙x+w2
0(x x0) = 0, the
dashed lines highlight the exponential decay in amplitude, x0A0exp( dt), where A0
is the amplitude, d=c/(2m)is the damping, w0=p
k/mis the frequency associated
with the period T=2p/w0, and x0is the offset. We ﬁx the value of the mass to m=1
and collectively summarize the remaining physics parameters in the parameter vector J=
fc,k,x0g.
2.4 Machine Learning - Integrating data and physics
To create learning machines that seamlessly integrate the data from Figure 1, the physics
from Figure 2, or both, we combine Neural Network modeling from Section 2.2 and
5Figure 2: Physics - Damped harmonic oscillator. Characteristic exponential decay of the oscillation in terms
of the period T=2p/w0with frequency w0=p
k/m, damping d=c/(2m), offset x0, and amplitude A0. Solid
lines illustrate the analytical solution m¨x+c˙x+k(x x0) =0or¨x+2zw0˙x+w2
0(x x0) =0, dashed lines
illustrate the exponential decay in amplitude x0A0exp( dt)around the offset x0.
Physics Informed modeling from Section 2.3 and learn the underlying network and physics
parameters. To quantify the uncertainty of the learned parameters, and with it the quality
of the model, we can integrate each of these methods into a Bayesian Inference.
Figure 3 motivates the use of classical Neural Networks, Physics Informed Neural Net-
works, and classical Bayesian Inference before we describe these methods in detail in Sec-
tions 3 and 4. The thin yellow lines indicate daily new case data, the thick orange lines
are their seven-day average, the blue dots are the training data, here for 225 out of 365
days, the dashed red lines are the model simulations, and light blue areas are the credible
intervals of the model prediction. The left column uses the thin yellow lines of the daily
new case data, and the right column uses the thick orange lines of their seven-day average
for training the models.
Neural Networks in the top row approximate the training data of the ﬁrst 225 days well,
but fail to predict the behavior outside the training window of the remaining 140 days. The
neural network model simply continues the learned trend. Since day 225 corresponds to a
plateau with a horizontal tangent, the neural network model predicts a ﬂatline with con-
stant case numbers for the remaining part of the year. This trend is similar when trained
on both the daily case data in the top left and the seven-day average in the top right.
Physics Informed Neural Networks in the middle row approximate both the training data
of the ﬁrst 225 days and the behavior outside the training window of the remaining 140
days with a good accuracy. Throughout the entire year, the red dashed lines of the model
remain close to the orange line of the seven-day case average. The ﬁt of the Physics In-
formed Neural Network is virtually identical for training on the daily case data in the
middle left and on the seven-day average in the middle right.
Bayesian Inference in the bottom row not only approximates both, the training data and
the behavior outside the training window, but also provides credible intervals to estimate
the quality of the ﬁt. Since the Bayesian Inference uses the same underlying physics as the
Physics Informed Neural Network, its red dashed lines also remain close to the orange line
of the seven-day case average throughout the entire year. However, the ﬁt with respect to
6Figure 3: Machine learning - Integrating data and physics. Neural Networks approximate the training data
well, but fail to predict the behavior outside the training window, when trained on both, the daily case data (top
left) and the seven-day average (top right). Physics Informed Neural Networks approximate both the training
data and the behavior outside the training window, when trained on both, the daily case data (middle left) and
the seven-day average data (middle right). Bayesian Inference not only approximates both, the training data
and the behavior outside the training window, but also provides credible intervals, which are wider when model
parameters are inferred using the daily case data (bottom left) than when using the seven-day average data
(bottom right). Thin yellow lines indicate daily new case data, thick orange lines are their seven-day average,
dashed red lines are the model simulations, light blue areas are its credible intervals, blue dots are the training
data, here for 225 out of 365 days.
the training data is worse compared to the Physics Informed Neural Network, because we
bias the solution towards the physics equations. In contrast to the previous two models in
the top and middle rows, the Bayesian Inference displays a clear difference between train-
ing on raw versus averaged data. The light blue areas of its credible intervals are notably
wider when the model parameters are inferred using the daily case data in the bottom left
than when using the seven-day average data in the bottom right. We will now describe
details of the underlying equations for Neural Networks in Section 3 and for Bayesian
Inference in Section 4.
3 Neural Network modeling
The objective of Neural Network modeling is to train the neural network (1) such that the
model output x(t)best approximates the data ˆx, by minimizing a loss function,
L(Q;t)!min , (7)
through iteratively updating the set of model parameters Q. The set of model parameters
could consist of the network parameters q, the physics parameters J, and a weighting
7coefﬁcient #,
Q=fq,J,#g with q=fWk,bkg and J=fc,k,x0g, (8)
where Wkandbkare the network weights and biases from equation (1) and c,k, and x0are
the physical damping, stiffness, and offset from equation (3). We specify the loss function
(7) and the relevant parameters (8) for classical Neural Networks in Section 3.1, for Physics
Informed Neural Networks in Section 3.2, and for Self Adaptive Physics Informed Neural
Networks in Section 3.3.
3.1 Neural Networks
The objective of classical Neural Networks is to learn the network parameters q, without
prior knowledge of the underlying physics, by minimizing a loss function (7) that consists
of a single term Ldata,
L(q;t) =Ldata!min . (9)
The data loss Ldatapenalizes the error between model x(t)and data ˆx. We deﬁne it as the
mean square error, the L2-norm of the difference between model and data, jjx(t) ˆxjj2,
divided by the number of training points ntrn,
Ldata(q;t) =1
ntrnntrn
å
i=1jjx(ti) ˆxijj2. (10)
We minimize the loss function (9) in terms of the mean square error (10) to optimize the
network parameters q, the network weights and biases Wkandbk,
q=fWk,bkg, (11)
using the ADAM optimizer, an adaptive algorithm for gradient-based ﬁrst-order optimiza-
tion.
3.2 Physics Informed Neural Networks
The objective of Physics Informed Neural Networks is to learn both the network parame-
tersqand the physics parameters Jby simultaneously training a neural network (1) and
solving an underlying physics equation (3). We convert both into a single optimization
problem that minimizes the loss function Lto learn the parameters Q=fq,Jg,
L(Q;t) = ( 1 #)Ldata+#Lphys!min . (12)
The ﬁrst term, the data loss Ldata, penalizes the error between model x(t)and data ˆx, the
second term, the physics loss Lphys, penalizes the physics residual r. Since both terms
can be of a different order of magnitude, we weight them with the weighting coefﬁcients
(1 #)and#. For the ﬁrst term, we use the mean square error, the L2-norm of the differ-
ence between model and data, jjx(t) ˆxjj2, divided by the number of training points ntrn
similar to Section 3.1,
Ldata(Q;t) =1
ntrnntrn
å
i=1jjx(ti) ˆxijj2. (13)
8For the second term, we use the L2-norm of the residual, jjrjj2, divided by the total number
of sampling points nsmp,
Lphys(Q;t) =1
nsmpnsmp
å
i=1jjr(ti)jj2=1
nsmpnsmp
å
i=1jj¨x(ti) +c
m˙x(ti) +k
m(x(ti) x0)jj2. (14)
A key step in calculating the physical loss function (14) is to compute the time derivatives
of the model solution x,˙x=dx/dtand ¨x=d˙x/dt, which we address using automatic dif-
ferentiation. Automatic differentiation is part of various deep learning frameworks which
makes it convenient for Physics Informed Neural Networks to evaluate derivatives. We
minimize the overall loss function (12) to optimize the network parameters q, the network
weights Wkand biases bk, and the physics parameters J, the viscous damping c, stiffness
k, and offset x0,
q=fWk,bkgand J=fc,k,x0g, (15)
again using the ADAM optimizer, an adaptive algorithm for gradient-based ﬁrst-order
optimization.
3.3 Self Adaptive Physics Informed Neural Networks
The objective of Self Adaptive Physics Informed Neural Networks is to train a neural net-
work (1) and solve an underlying physics equation (3) similar to Section 3.2, but now,
rather than prescribing the weighting coefﬁcient #between data and physics, we learn it
as a function of time t, along with the other parameters, Q=fq,J,eg[16]. We adopt the
same loss function Las in Section 3.2,
L(Q;t) = [ 1 #(t) ]Ldata+#(t)Lphys, (16)
in terms of the data loss, the weighted error between model xand data xdata,
Ldata(Q;t) =1
ntrnntrn
å
i=1jjx(ti) ˆxijj2, (17)
and the physics loss, the weighted norm of the physics residual r,
Lphys(Q;t) =1
nsmpnsmp
å
i=1jjr(ti)jj2=1
nsmpnsmp
å
i=1jj¨x(ti) +c
m˙x(ti) +k
m(x(ti) x0)jj2. (18)
We minimize the overall loss function (16) to optimize the network parameters, Wkand
bk, the physics parameters, c,k, and x0, and the weighting term #(t),
q=fWk,bkgand J=fm,c,k,x0gand #(t). (19)
The dynamics of the weighting term #(t)provide insight into the relative importance of
data loss Ldataand physics loss Lphys and into the change of both terms in time.
3.4 Comparison of Neural Network models
Figure 4 illustrates the features the Neural Network models of this section. The classical
Neural Networks from Section 3.1 minimize a loss function, L!min, that characterizes
the data loss Ldata, the error between data and model jjˆx x(t)jjshown on the left. The
9Physics Informed Neural Networks from Section 3.2 build additional physics loss tersm
Lphys into the loss function L, for example, the physics residual jjrjjshown on the right.
In a forward problem, Neural Networks learn the network parameters q=fWk,bkg. In
an inverse problem, Neural Networks learn the network parameters q=fWk,bkg. the
physics parameters J=fc,k,x0g. Self Adaptive Physics Informed Neural Networks from
Section 3.3 also learn the dynamic weighting term #(t)between data and physics loss Ldata
andLphys.
Figure 4: Neural Network modeling. Neural Networks minimize a loss function L!minthat could consist
of two terms, a data loss Ldata, the error between data and model jjˆx x(t)jj, and a physics loss Lphys, the
physics residualjjrjj, to learn the network parameters q=fWk,bkg, the physics parameters J=fc,k,x0g,
and possibly even the dynamic weighting term #(t)between LdataandLphys.
Figure 5 illustrates the result of a grid search for the Physics Informed Neural Network.
Here we show the simulation with one and two hidden layers, left and right columns, with
two, four, and eight nodes each, from top to bottom. The number of network weights Wk
and biases bkincreases with increasing number of layers and nodes. The one-hidden-layer
models have 7, 13, and 25 parameters and the two-hidden-layer models have 13, 33, and
97 parameters. The six graphs conﬁrm our intuition that the performance of the Physics
Informed Neural Network increases with increasing number of hidden layers, from left to
right, and increasing number of nodes per layer, from top to bottom. For both models, we
also performed simulations with 16 and 32 nodes, but the performance did not increase
markedly beyond the eight-node models. Figure 5 suggests that the one-hidden-layer
models perform poorly, independent of the number of nodes. For each additional hid-
den layer, the number of parameters increases with the number of nodes squared and the
risk of overﬁtting increases. The two-hidden-layer models seem to be a reasonable com-
promise between underﬁtting and overﬁtting: They perform well, even with only eight
nodes and 97 parameters. Throughout this manuscript, we use Neural Networks with two
hidden layers and 32 nodes.
Figure 6 compares the classical Neural Network with Physics Informed Neural Networks
with varying weighting coefﬁcient #. The thin yellow lines indicate daily new case data, the
thick orange lines are their seven-day average, the blue dots are the training data, here for
225 out of 365 days, the dashed red lines are the simulation with the physics-based model.
In Physics Informed Neural Networks, the loss function, L= ( 1 #)Ldata+#Lphys, is
a weighted average of the data-based mean square error, Ldata, and the physics-based
residual, Lphys. For the special case of #=0 in the top left, the loss function degen-
erates to the loss function of the classical Neural Network L!Ldatafrom Section 3.1.
10Figure 5: Neural Network modeling. Grid search for Physics Informed Neural Network. The performance
and number of parameters of the Physics Informed Neural Network increases with increasing number of hid-
den layers (left to right) and increasing number of nodes per layer (top to bottom). For both one and two
hidden layers, the performance does not increase markedly beyond eight nodes (bottom row). Throughout
this manuscript, we use a Neural Network with two hidden layers and 32 nodes. Thin yellow lines indicate
daily new case data, thick orange lines are their seven-day average, dashed red lines are the physics-based
model, light blue areas are its credible intervals, blue dots are the training data.
The classical Neural Network provides a good approximation of the training data during
the ﬁrst 225 days of the year, but fails to predict the behavior outside the training win-
dow. During the remaining 140 days, the classical Neural Network simply continues the
learned trend, which, on day 225, suggests a plateau with constant case numbers for the
remaining part of the year. For positive weighting coefﬁcients #>0, the loss function
accounts for both data loss Ldataand physics loss Lphys. With increasing weighting coefﬁ-
cients #= [10 ¥, 10 5, 10 4, 10 3, 10 2, 10 0], from top left to bottom right, the inﬂuence
of the data loss Ldatadecreases and the inﬂuence of the physics loss Lphys increases. In
other words, the smaller the weighting coefﬁcient #, the better the ﬁt of the data; the larger
the weighting coefﬁcient #, the better the ﬁt of the physics. For the special case of #=1 in
the bottom right, the loss function degenerates to the loss function of the physical model
L!Lphys from Section 2.3. The network solves the physics of the damped harmonic os-
cillator without accounting for any data, and converges to the trivial solution with a zero
amplitude.
Figure 7 quantiﬁes the contributions to the loss function for Physics Informed Neural Net-
works with weighting coefﬁcients #varying from 10 6to 10 2. In Physics Informed Neural
Networks, the loss function, L= (1 #)Ldata+#Lphys, is a weighted average of the data-
based mean square error, Ldata, summarized in the left panel, and the physics-based resid-
ual,Lphys, summarized in the right panel. Each panel separately reports the descriptive
11Figure 6: Neural Network modeling. Classical Neural Network vs Physics Informed Neural Networks
with varying weighting coefﬁcients #.In Physics Informed Neural Networks, the loss function, L= (1 
#)Ldata+#Lphys, is a weighted average of the data-based mean square error, Ldata, and the physics-based
residual, Lphys. The special case of #=0represents a classical Neural Network (top left). With increasing
weighting coefﬁcients, #= [10 ¥, 10 5, 10 4, 10 3, 10 2, 10 0], the inﬂuence of the data ﬁt decreases and the
inﬂuence of the physics increases (top left to bottom right). Thin yellow lines indicate daily new case data,
thick orange lines are their seven-day average, dashed red lines are the physics-based model, light blue areas
are its credible intervals, blue dots are the training data, here for 225 out of 365 days.
loss, the sum of the daily errors in the training window as orange dots,
Ldata(Q;t) =1
255255
å
i=1jjx(ti) ˆxijj2and Lphys(Q;t) =1
255255
å
i=1jjr(ti)jj2,
and the predictive loss, the sum of the daily errors in the prediction window as red dots,
Ldata(Q;t) =1
140365
å
i=256jjx(ti) ˆxijj2and Lphys(Q;t) =1
140365
å
i=256jjr(ti)jj2.
With increasing weighting coefﬁcients #, the model emphasizes less on the data ﬁt and
more on the physics ﬁt. The predictive data loss, descriptive physics loss, and predictive
physics loss decrease, while the descriptive data loss increases. The quantitative compar-
ison of the four losses in Figure 7 agrees with the qualitative observation in Figure 6: For
smaller weighting coefﬁcients #, the red dashed lines of the model and orange lines of the
seven-day case data average are in close proximity during the ﬁrst 225 days of the descrip-
tive regime, but deviate notably during the remaining 140 days of the predictive regime.
For larger weighting coefﬁcients #, the red and orange lines deviate more during the ﬁrst
225 days of the descriptive regime, but are in close proximity during the remaining 140
days of the predictive regime. This example highlights the importance of selecting an ap-
propriate weighting coefﬁcient #, which can bias the result of a Physics Informed Neural
12Figure 7: Neural Network modeling. Sensitivity analysis for Physics Informed Neural Networks with
varying weighting coefﬁcients #.In Physics Informed Neural Networks, the loss function, L= (1 #)Ldata+
#Lphys, is a weighted average of the data-based mean square error, Ldata, and the physics-based residual,
Lphys. With increasing weighting coefﬁcients #, the model emphasizes less on the data ﬁt and more on the
physics ﬁt; the predictive data loss, descriptive physics loss, and predictive physics loss decrease, while the
descriptive data loss increases. Orange dots indicate the descriptive losses LdataandLphysfor the ﬁrst 255
days; red dots indicate the predictive losses LdataandLphysfor the following 140 days.
Network either towards the data or towards the physics. An ideal weighting coefﬁcient
minimizes the sum of all four loss terms. From Figure 7, we can estimate a reasonable
weighting coefﬁcient on the order of #10 3. This value is of the same order of magnitude
as the learned weighting term #(t)with mean and standard deviation of #=0.0070.003
for the self-adpative Physics Informed Neural Network from Section 3.3.
Figure 8 summarizes the history of the loss function Land of the physics parameters J, the
damping c, stiffness k, and offset x0, for a Physics Informed Neural Network with a weight-
ing coefﬁcient of #=10 3. For the ﬁrst 30K epochs, the loss function decreases while the
physics parameters are still oscillating without clear trends. After 60K epochs, the physics
parameters have converged towards a viscous damping coefﬁcient of c=1.251, a stiffness
ofk=374.6, and an offset of x0=0.558. This corresponds to a damping of d=0.626, a
frequency of w=19.35, and a period of T=0.325 years. This period of approximately
four months agrees well with the reported daily new cases in Figure 1 that display three
pronounced waves throughout the year of 2021.
4 Bayesian Inference modeling
The objective of Bayesian Inference is to estimate the posterior probability distribution of a
set of the parameters Q, such that the statistics of the model x(t)agree with data ˆx[2] and
possibly also satisfy the physics r, by maximizing the prior-weighted likelihood P(ˆx,rjQ),
P(Qjˆx,r) =P(ˆx,rjQ)P(Q)
P(ˆx)P(r)=P(ˆxjQ)P(rjQ)P(Q)
P(ˆx)P(r)!max . (20)
Here, P(ˆx,rjQ)is the likelihood of the data ˆxandP(rjQ)the likelihood of the physics r
for given ﬁxed parameters Q;P(Q)is the prior, the probability distribution of the model
parameters Q;P(ˆx)and P(r)are the marginal likelihood or evidence; and P(Qjˆx,r)is
the posterior, the conditional probability of the parameters Qfor the given data ˆxand
physics r. The ﬁrst likelihood function P(ˆxjQ)evaluates the quality of ﬁt between the
model output x(t), here the simulated number of new cases for given parameters Q, and
the observed data ˆx, here the reported number of new cases at every day i. For the daily
13Figure 8: Physics Informed Neural Network. History of loss function Land physics parameters damp-
ingc, stiffness k, and offset x0.Within 60K epochs, the physics parameters converge towards a viscous
damping coefﬁcient of c=1.251 , a stiffness of k=374.6 , and an offset of x0=0.558 . This corresponds to a
damping of d=0.626 , a frequency of w=19.35 , and a period of T=0.325 years. Simulation with weighting
coefﬁcient of #=10 3and training window of ntrn= 225 days.
likelihood function pi(ˆxjQ), at each time point ti, we select a normal distribution, N(m,s),
where the mean mis the model result x(ti)for the given parameter set Qand the likelihood
width, the standard deviation s, accounts for the observation error in the data ˆx. The
product Õn
i=0of all daily likelihood functions pi(ˆxjQ), in our case throughout the n =365
days of the year 2021, deﬁnes the overall likelihood P(ˆxjQ),
P(ˆxjQ) =n
Õ
i=0pi(ˆxjQ) with pi(ˆxjQ) =1p
2psexp
 jjˆx x(ti)jj2
2s2
. (21)
The second likelihood function P(rjQ)evaluates how accurately the model output x(t),
here the simulated number of new cases for given parameters Q, satisﬁes the physics equa-
tionr(t) =0at every day i. Again, we deﬁne the daily likelihood function pi(rjQ), at each
time point ti, through a normal distribution, N(m,s), where the mean mis the model result
of the physics equation r(x(ti))for the given parameter set Qand the likelihood width is
the standard deviation s. The product Õn
i=0of all daily likelihood functions pi(rjQ), de-
ﬁnes the overall likelihood P(rjQ),
P(rjQ) =n
Õ
i=0pi(rjQ) with pi(rjQ) =1p
2psexp
 jjr(ti)jj2
2s2
. (22)
Similar to the previous section on Neural Network modeling, the set of model parameters
could consist of network parameters qand physics parameters J,
Q=fq,Jg with q=fWk,bkg and J=fc,k,x0g, (23)
where Wkandbkare the network weights and biases from equation (1) and c,k, and x0
are the physical damping, stiffness, and offset from equation (3). We specify the Bayesian
14Inference (20) and the prior distributions of its parameters (23) for classical Bayesian Infer-
ence in Section 4.1, for Bayesian Neural Networks in Section 4.2, and for Bayesian Physics
Informed Neural Networks in Section 4.3.
4.1 Bayesian Inference
The objective of a classical Bayesian Inference is to estimate the posterior parameter dis-
tributions P(Jjˆx)of a set of physics parameters Jsuch that the statistics of a physical
model x(t)agree with data ˆx. For the physical model, we assume that the number of
daily new cases x(t)follows the physics of a damped harmonic oscillator from Section 2.3,
m¨x+c˙x+k x=0, where mis the mass, cis the viscous damping coefﬁcient, and kis the
stiffness. Without loss of generality, we set m1. We consider the underdamped case, for
which the damping ratio is smaller than one, c2<4k. For this case, following equation
(6), the analytical solution for the number of daily new cases is
x(J;t) =x0+A0cos((k 1
2c2)t)exp( 1
2c t). (24)
The physics of the number of new cases are uniquely determined by three parameters,
J=fc,k,x0g, the viscous damping c, the stiffness k, and the offset x0.We now use Bayes’
theorem, to estimate the posterior probability distribution of the physics parameters Jsuch
that the statistics of the model x(t)from equation (24) agree with the reported case data ˆx
in Figure 1,
P(Jjˆx) =P(ˆxjJ)P(J)
P(ˆx). (25)
Here P(ˆxjJ)is the likelihood, the conditional probability of the data ˆxfor given ﬁxed
physics parameters J;P(J)is the prior, the probability distribution of the physics pa-
rameters J;P(ˆx)is the marginal likelihood or evidence; and P(Jjˆx)is the posterior, the
conditional probability of the physics parameters Jfor the given data ˆx. For the likelihood
P(ˆxjJ), the product of the individual point-wise likelihoods pi(ˆxjJ)according to equa-
tion (33), we select a normal distribution N(m,s), where the mean mis the model result
x(ti)for the given physics parameters Jand the likelihood width stakes a half Cauchy
distribution, s=halfCauchy (ﬁ=1.0),
P(ˆxjJ) =n
Õ
i=0pi(ˆxjJ) with pi(ˆxjJ) =1p
2psexp
 jjˆx x(ti)jj2
2s2
. (26)
For the prior probability distributions P(J), we select independent weakly informed priors
with log-normal distributions for the three physics parameters, J=fc,k,x0g, the viscous
damping c, the stiffness k, and the offset x0,
P(J) =P(c,k,x0) withlog(c)N(m=log(2.2),s=0.5)
log(k)N(m=log(350),s=0.5)
log(x0)N(m=log(0.56),s=0.5).(27)
Using the case data from Figure 1, we approximately infer the posterior distributions from
Bayes theorem (25) by employing a NO-U-Turn sampler [6] implementation of the Python
package PyMC3 [29]. We use two chains with the ﬁrst 2000 samples to tune the sampler
and the subsequent 4000 samples to estimate the set of parameters J, and employ a target
acceptance rate of 0.85.
154.2 Bayesian Neural Networks
The objective of Bayesian Neural Networks is to estimate the posterior parameter distri-
butions P(qjˆx)of a set of network parameters q, without any prior information about the
underlying physics, such that the statistics of the output of the neural network x(t)agree
with data ˆx. For the neural network, we use the fully-connected feed-forward neural net-
work composed of multiple hidden layers of Section 2.2 to approximate the output, the
number of daily new cases x, from the input, the time coordinates t. We denote the hidden
variables of the kthhidden layer as zkand summarize the neural network, here for two
hidden layers, as
z0= t
z1=s(W1z0+b1)
z2=s(W2z1+b2)
z3= W3z2+b3,(28)
where the output of the last layer approximates the true solution, xz3. Similar to the
previous sections, s()denotes the non-linear activation function for which we select a
hyperbolic tangent function, s() = tanh(), and Wkandbkare the network weights
and biases of the kthlayer. We use Bayes’ theorem, to estimate the posterior probability
distribution of the network parameters qsuch that the statistics of the neural network
xz3from equation (28) agree with the reported case data ˆxin Figure 1,
P(qjˆx) =P(ˆxjq)P(q)
P(ˆx). (29)
Here P(ˆxjq)is the likelihood, the conditional probability of the data ˆxfor given ﬁxed pa-
rameters q;P(q)is the prior, the probability distribution of the network parameters q;P(ˆx)
is the marginal likelihood or evidence; and P(qjˆx)is the posterior, the conditional proba-
bility of the parameters qfor the given data ˆx. For the likelihood P(ˆxjq), the product of
the individual daily point-wise likelihoods pi(ˆxjq)according to equation (33), we select
a normal distribution N(m,s), where the mean mis the model result x(ti)for the given
network parameters qand the likelihood width sis the standard deviation with s=0.05,
P(ˆxjq) =n
Õ
i=0pi(ˆxjq) with pi(ˆxjq) =1p
2psexp
 jjˆx x(ti)jj2
2s2
. (30)
For the prior probability distributions P(q), we select independent weakly informed priors
with normal distributions with a zero-mean for the two sets of network parameters, q=
fWk,bkg, the network weights Wkand biases bk[33],
P(q) =P(Wk,bk) withWkN(m=0.0,s=2.0)
bkN(m=0.0,s=2.0).(31)
Using the case data from Figure 1, we approximately infer the posterior distributions
from Bayes theorem (29) by employing a Hamiltonian Monte Carlo sampling [33] using
Tensorﬂow-Probability [30]. We use the ﬁrst 3000 samples to tune the sampler and the
subsequent 3000 samples to estimate the set of parameters q.
164.3 Bayesian Physics Informed Neural Networks
The objective of Bayesian Physics Informed Neural Networks is to estimate the posterior
parameter distributions P(Qjˆx,r)of both network and physics parameters, Q=fq,Jg,
such that the statistics of Physics Informed Neural Network x(t)agree with data ˆxand
satisfy the physics equation r. As such, the Bayesian Physics Informed Neural Network in-
tegrates the Physics Informed Neural Network from Section 3.2 into a Bayesian Inference.
We use Bayes’ theorem, to estimate the posterior probability distribution of the parame-
ters such that the statistics of the neural network xz3from equation (1) agree with the
reported case data ˆxin Figure 1,
P(Qjˆx,r) =P(ˆx,rjQ)P(Q)
P(ˆx)P(r)=P(ˆxjQ)P(rjQ)P(q)P(J)
P(ˆx)P(r). (32)
Here P(ˆx,rjQ) =P(ˆxjQ)P(rjQ)are the two likelihood functions, the conditional proba-
bilities of data ˆxand physics rfor given parameters Q;P(Q) =P(q)P(J)are the priors,
the probability distribution of the network and model parameters qandJ;P(ˆx)P(r)is the
marginal likelihood or evidence; and P(Qjˆx,r)is the posterior, the conditional probability
of the parameters Qfor given data ˆxand physics r. The ﬁrst likelihood function P(ˆxjQ)
evaluates the quality of ﬁt between the model output x(t)and the observed data ˆxat every
dayias a product of the daily likelihood functions pi(ˆxjQ), for which we select a normal
distribution,
P(ˆxjQ) =n
Õ
i=0pi(ˆxjQ) with pi(ˆxjQ) =1p
2psexp
 jjˆx x(ti)jj2
2s2
. (33)
The second likelihood function P(rjQ)evaluates how accurately the model output x(t)
satisﬁes the physics equation r=0at every day ias a product of the daily likelihood
functions pi(rjQ), for which we also assume a normal distribution,
P(rjQ) =n
Õ
i=0pi(rjQ) with pi(rjQ) =1p
2psexp
 jjr(ti)jj2
2s2
. (34)
For the prior probability distributions P(Q), we select independent weakly informed pri-
ors with log-normal distributions for the three physics parameters, J=fc,k,x0g, normal
distributions for the network parameters, q=fWk,bkg,
P(Q) =P(c,k,x0,Wk,bk) withlog(c)N(m=log(2.2),s=0.5)
log(k)N(m=log(350),s=0.5)
log(x0)N(m=log(0.56),s=0.5)
WkN(m=0.0, s=2.0)
bkN(m=0.0, s=2.0).(35)
Using the case data from Figure 1, we approximately infer the posterior distributions from
Bayes theorem (29) by employing a Hamiltonian Monte Carlo sampler implementation of
Tensorﬂow-Probability [30]. For the Hamiltonian Monte Carlo sampler, we use 50 leapfrog
steps with an initial time step of d t=510 4, and set the burn-in steps and total number
of samples to 3000. We use the ﬁrst 3000 samples to tune the sampler and the subsequent
3000 samples to estimate the set of parameters Q.
174.4 Comparison of Bayesian Inference modeling
Figure 9 illustrates the features the Bayesian Inference models of this section. The classi-
cal Bayesian Inference from Section 4.1 maximizes a prior-weighted likelihood, P(ˆxjJ), in
terms of the error between data and model jjˆx x(t)jjto infer distributions of the physics
parameters J. The Bayesian Neural Networks from Section 4.2 maximize a prior-weighted
likelihood, P(ˆxjq), in terms of the error between data and model jjˆx x(t)jjto infer dis-
tributions of the network parameters q. The Bayesian Physics Informed Neural Networks
from Section 4.3 maximize a prior-weighted likelihood, P(ˆx,rjQ), in terms of the error be-
tween data and model jjˆx x(t)jj, shown on the left, and the error of the physics jjrjj,
shown on the right, to infer the distributions of both network and physics parameters q
andJ.
Figure 9: Bayesian Inference modeling. Bayesian Inference maximizes a prior-weighted likelihood function
P(Qjˆx,r)!max that could consist of two terms, the likelihoods P(ˆxjQ)andP(rjQ)of data ˆxand physics r
for given parameters Q, to infer distributions of the network parameters q=fWk,bkgand physics parameters
J=fc,k,x0g.
Figure 10 illustrates the results of the classical Bayesian Inference for a varying size of the
training data set. The thin yellow lines indicate daily new case data, the thick orange lines
are their seven-day average, and the blue dots are the training data varying between 150,
175, 200, 225, 250, and 275 days, from top left to bottom right. The dashed red lines repre-
sent the physics-based model and the light blue areas are its credible intervals. First and
foremost, we note that all six panels display a reasonable agreement between data and
model, both inside the training window and beyond. With an increasing size of training
data, from top left to bottom right, the error in the descriptive window increases and the er-
ror in the predictive window decreases. For example, the ﬁrst peak of 905,378 cases on day
118, April 29, 2021, is best approximated for the smallest training data set in the top left,
while the second peak of 819,336 cases on day 221, August 10, 2021, is best approximated
for the largest training data set in the bottom right. In agreement with our expectation, the
width of the credible interval, the light blue area, decreases with an increase in training
data: The more data we use to train the model, the better its ﬁt.
Figure 11 illustrates the posterior distributions of the physics parameters J, the damping
c, stiffness k, and offset x0. The Bayesian Inferences yields a viscous damping coefﬁcient
ofc=1.1110.126, a stiffness of k=402.41.7, and an offset of x0=0.5410.002.
This corresponds to a damping of d=0.556, a frequency of w=20.06, and a period of
18Figure 10: Bayesian Inference. Sensitivity analysis for varying size of training data set. With increasing
training data size of 150, 175, 200, 225, 250, and 275 days, the error in the descriptive window increases, the
error in the predictive window decreases, and the width of the credible interval decreases (top left to bottom
right). Thin yellow lines indicate daily new case data, thick orange lines are their seven-day average, dashed
red lines are the physics-based model, light blue areas are its credible intervals, blue dots are the training
data.
T=0.313 years. These values compare well to the learned parameters of the Physics In-
formed Neural Network in Figure 8, with a viscous damping coefﬁcient of c=1.251, a
stiffness of k=374.6, and an offset of x0=0.558. However, the Bayesian Inference not
only inferred the means of the parameters, but also their posterior distributions, where
narrow distributions indicate a higher conﬁdence in the mean values.
Figure 12 illustrates the posterior distributions of the physics parameters J, the damping c,
stiffness k, and offset x0. The Bayesian Physics Informed Neural Network yields a viscous
damping coefﬁcient of c=1.3120.391, a stiffness of k=319.438.6, and an offset of
x0=0.5710.020. This corresponds to a damping of d=0.65, a frequency of w=17.87,
and a period of T=0.352 years. Compared to the classical Bayesian Inference in Figure 11,
the damping is 18% larger, the stiffness is 21% smaller, and the offset is 6% larger. Notably,
all three parameters of the Bayesian Physics Informed Neural Network show wider stan-
dard deviations than in the classical Bayesian Inference, the damping by a factor 3, stiffness
by a factor 23, and offset by a factor 10. These observations suggests that, for the chosen
training window of ntrn= 225 days, the Bayesian Physics Informed Neural Network is not
only more expensive than the Bayesian Inference, but also less robust.
5 Discussion
Understanding the behavior of nonlinear dynamical systems remains a challenging
task. Machine learning has emerged as a powerful technology to provide insight into
19Figure 11: Bayesian Inference. Posterior distributions of physics parameters damping c, stiffness k,
and offset x0.Inferred viscous damping coefﬁcient of c=1.1110.126 , stiffness of k=402.41.7, and offset
ofx0=0.5410.002 . This corresponds to a damping of d=0.556 , a frequency of w=20.06 , and a period of
T=0.313 years. Simulation with training window of ntrn= 225 days.
Figure 12: Bayesian Physics Informed Neural Network. Posterior distributions of physics parameters
damping c, stiffness k, and offset x0.Inferred viscous damping coefﬁcient of c=1.3120.391 , stiffness of
k=319.438.6, and offset of x0=0.5710.020 . This corresponds to a damping of d=0.65, a frequency of
w=17.87 , and a period of T=0.352 years. Simulation with training window of ntrn= 225 days.
observational data. A vast variety of learning machines have been developed throughout
the past decade, but to the unexperienced user, selecting the right model for a speciﬁc task
is an overwhelming endeavor. This is ampliﬁed by the fact that tutorials or publications
typically introduce new methods using artiﬁcially generated synthetic data for which the
solution is already known. The objective of this study was to compare different families of
models for real-world data, the reported number of COVID-19 cases throughout the year
of 2021, using a simple dynamical model, a damped harmonic oscillator. We reviewed
the underlying model equations, parameters, and characteristic results of two families of
models, Neural Networks and Bayesian Inference, each with three members of increasing
complexity. Both Neural Networks and Bayesian Inference perform equally well
on the raw daily case data with noise, reporting uncertainties, and weekday-weekend
ﬂuctuations and on their smooth seven-day average, as Figure 3 conﬁrms. Our learned
damping, stiffness, and offset of c=1.251, k=374.6, and x0=0.558 for the Physics
Informed Neural Network in Section 3.2, Figure 8, agree well with the inferred means
ofc=1.111, k=402.4, x0=0.541 for the Bayesian Inference in Section 4.1, Figure 11,
and with the combination of both methods of c=1.312, k=319.4, x0=0.571 for the
Bayesian Physics Informed Neural Network in Section 4.3, Figure 12. Our study conﬁrms
our general intuition that the quality of the ﬁt increases with increasing size of the training
data set. For the classical Bayesian Inference in Section 4.1, Figure 10 shows that the
credible intervals become progressively narrower as the size of the training data increases.
Figure 13 compares the convergence of the three Physics Informed Neural Network
models of our study, the plain Physics Informed Neural Network from Section 3.2 the Self
Adaptive Physics Informed Neural Network from Section 3.3, and the Bayesian Physics
Informed Neural Network from Section 4.3. Clearly, for all three methods, the prediction
20Figure 13: Comparison of Physics Informed Neural Network models. Convergence with increasing size of
training data set. Predictive data loss, Ldata, as mean squared error in the predictive window from tntrntotnsmp,
for Physics Informed Neural Network, Self Adaptive Physics Informed Neural Network, and Bayesian Physics
Informed Neural Network. For all three methods, the predictive data loss decreases with an increasing number
of training data points. The Physics Informed Neural Network performs poorly initially, but converges with
increasing training set size. The Self Adaptive Physics Informed Neural Network performs well, even for small
training sets. Both methods perform similarly with increasing training set size. The Bayesian Physics Informed
Neural Network performs reasonably well for small data sets but only improves marginally with increasing
training set size. Training data ntrn= [150, 175, 200, 225, 250, 275, 300].
error decreases with increasing size of the training data set. We close our study with
a direct side-by-side comparison of all six methods from Sections 3 and 4 in Figure 14.
Figure 15 provides a ﬁnal recommendation to improve the performance of the Bayesian
Physics Informed Neural Networks by scaling the physics equation. Table 1 summarizes
the results of Figures 14 and 15 and discusses the advantages and disadvantages of each
method.
Neural Networks are a simple and robust tool to ﬁt training data, but have a
poor predictive potential. Classical Neural Networks have remarkable power to ﬁt a
network model to data without any underlying physics. By minimizing a loss function
that characterizes the error between model and data, the neural network learns the
network parameters q=fWk,bkg, the network weights and biases. For our example
of a feed-forward network with one input, two hidden layers with 32 nodes each, and
one output, it has 32+32 32+32=1088 weights and 32+32+1=65 biases, resulting in a total
of 1153 unknowns. Figure 14, top left, suggests that even in the absence of any prior
physical knowledge, the classical Neural Network provides an excellent approximation
of the training data. However, it fails to predict the behavior outside the training window,
where it simply continues the linear horizontal trend from the last set of training data
points. This becomes particularly clear when the underlying problem is non-monotonic,
or, like in our case, even oscillatory. Since classical Neural Networks provide no credible
intervals, we have no way of knowing, how poor the predictive potential of the network
really is.
Physics Informed Neural Networks integrate data and physics and have a good
predictive potential. Physics Informed Neural Networks ﬁt a network model to data,
and, at the same time, to a physics-based model. If we know the underlying physics, they
are an effective tool to constrain a deep learning method to a lower-dimensional manifold
21Figure 14: Comparison of Neural Network and Bayesian Inference models. Neural Networks approximate
the training data well, but fail to predict the behavior outside the training window (top left). Physics Informed
Neural Networks approximate both the training data and the behavior outside the training window, but are sen-
sitive to the weighting coefﬁcient (middle left). Self Adaptive Physics Informed Neural Networks approximate
both the training data and the behavior outside the training window, and simultaneously learn the weighting
term #(t)(bottom left). Bayesian Inference not only approximates both, the training data and the behavior
outside the training window, but also provides credible intervals of the model (top right). Bayesian Neural Net-
works approximate the training data well, but fail to predict the behavior outside the training window where they
generate a wide credible intervals (middle right). Bayesian Physics Informed Neural Networks approximate the
training data well, but fail to predict the behavior outside the training window (bottom right). Thin yellow lines
indicate daily new case data, thick orange lines are their seven-day average, dashed red lines are the model,
light blue areas are its credible intervals, blue dots are the training data.
and create models that can be trained effectively with a small amount of data. Physics
Informed Neural Networks enforce physics via soft penalty constraints. By minimizing
a loss function that characterizes the error between model and data and the error in
satisfying the physics, they simultaneously learn the network parameters q=fWk,bkg
and the physics parameters J=fc,k,x0g. For our example, the network has 1088 weights
and 65 biases, and the physics model has a damping, stiffness, and offset parameter,
resulting in a total of 1156 unknowns. Figure 14, middle left, suggests that the Physics
Informed Neural Network approximates both the training data and the behavior outside
the training window reasonably well and is equally capable of both interpolation and
extrapolation. From Figure 13 we conclude that Physics Informed Neural Networks
require a relatively large set of training data. For our example, they perform moderately
initially, but converge well with increasing training set size. However, from Figures 6
and 7, we conclude that Physics Informed Neural Networks are sensitive to the weighting
coefﬁcient #that can bias the solution to emphasize on either data or physics. From Figure
15, we add that they are also sensitive to a scaling of the physics parameters J, which, if
done appropriately, can improve the performance of the model. An inherent limitation
of plain Physics Informed Neural Networks is that they are not equipped with built-in
22Figure 15: Comparison of classical and Bayesian Physics Informed Neural Network models for differ-
ent scaling. Both types of models are sensitive to the scaling of the physics equation, ¨x+c˙x+k(x x0)
(top row) and ¨x/k+c˙x/k+ (x x0)(bottom row). Appropriate scaling improves model performance: The ﬁt
between the red dashed lines of the model x(t)and the thick orange lines of the data ˆxincreases and the light
blue credible intervals decrease. Thin yellow lines indicate daily new case data, thick orange lines are their
seven-day average, dashed red lines are the model, light blue areas are its credible intervals, blue dots are
the training data.
uncertainty quantiﬁcation which may restrict their applications, especially in situations
with noisy data.
Self Adaptive Physics Informed Neural Networks provide adaptive and robust ﬁts
of data and physics. Self Adaptive Physics Informed Neural Networks adaptively ﬁt
a network model to data, and, at the same time, to a physics-based model. They inherit
all the advantages of Physics Informed Neural Networks and address the limitation of
bias between data and physics by introducing the weighting coefﬁcient as independent
time-varying unknown. This allows them to perform well, even in regions with steep
gradients, while using a smaller number of training epochs. Self Adaptive Physics
Informed Neural Networks minimize a loss function that characterizes the error between
model and data and between model and physics, and learn the network parameters
q=fWk,bkg, the physics parameters J=fc,k,x0g, and the weighting term #(t)between
network and physics. For our example, the network model has 1088 weights and 65
biases, the physics model has a damping, stiffness, and offset, and the self adaptive model
has a weighting coefﬁcient, resulting in a total of 1157 unknowns. Figure 14, bottom left,
conﬁrms that the Self Adaptive Physics Informed Neural Network approximates both
the training data and the behavior outside the training window, similar to the regular
Physics Informed Neural Network. With only one additional time-varying parameter,
the self-adaptively learned weighting term, it performs well even for small training data
sets, as Figure 13 conﬁrms. One caveat is that Self Adaptive Physics Informed Neural
Networks involve training with complex loss functions that consist of multiple terms and
result in a highly non-convex optimization problem. During training, these terms compete
with one another which implies that the training process may not be robust and stable,
and does not always converge to a global minimum. Self Adaptive Physics Informed
Neural Networks perform best when the equations are well scaled and pre-conditioned
and their parameters all lie within the same range of magnitude. While we have not
explicitly shown the effect of different pre-conditioning and scaling techniques here, we
23Table 1: Comparison of Neural Network and Bayesian Inference models. Advantages and disadvantages
of Neural Networks, Physics Informed Neural Networks, Self Adaptive Physics Informed Neural Networks,
Bayesian Inference, Bayesian Neural Networks, and Bayesian Physics Informed Neural Networks in terms of
parameters, data ﬁt, predictive potential, and robustness.
Neural Network family Bayesian Inference family
NN BI
ﬁts network without physics, no credible intervals ﬁts physics model, provides credible intervals
learns q=fWk,bkg learns distributions of J=fc,k,x0g
here 32+3232+32+32+32+1=1153 unknowns here 32=6 unknowns
good ﬁt of training data, poor predictive potential decent ﬁt of training data, good predictive potential
simple, robust, and straightforward simple, robust, and straightforward
PINN BNN
ﬁts network and physics model, no credible intervals ﬁts network without physics,provides credible intervals
learns q=fWk,bkgandJ=fc,k,x0g learns distributions of q=fWk,bkg
here 32+3232+32+32+32+1+3=1156 unknowns here (32+3232+32+32+32+1)2=2306 unknowns
good ﬁt of training data, good predictive potential good ﬁt of training data, poor predictive potential
sensitive to choice of weighting coefﬁcient # credible intervals provide insight into reliable regimes
SAPINN BPINN
adaptively ﬁts network and physics,no credible intervals ﬁts network and physics, provides credible intervals
learns q=fWk,bkgandJ=fc,k,x0gand#(tdata) learns distributions of q=fWk,bkgandJ=fc,k,x0g
here 32+3232+32+32+32+1+3+1=1157 unknowns here (32+3232+32+32+32+1+3) 2=2312 unknowns
good ﬁt of training data, good predictive potential good ﬁt of training data, moderate predictive potential
robust even for small training data set most expensive method, requires large training data set
have observed that the method is sensitive to scaling and could fail to converge when
scaled inappropriately.
Bayesian Inference ﬁts a physics based model to data and provides credible
intervals. Classical Bayesian Inference is a simple, robust, and stable method that ﬁts
a physics based model to data. This implies that we know the underlying physics. In
our example, we do not know the exact physics; however, we hypothesized that the
data, the daily new cases of COVID-19 worldwide, follow the dynamics of a damped
harmonic oscillator. Bayesian Inference then uses Bayes’ theorem to infer the distribution
of a set of model parameters, J=fc,k,x0g, that best explain the data. For our example,
we have assumed log normal distributions for each parameter, with individual means
mand standard deviations s, introducing a total of 3 2=6 unknowns. Figure 14, top
right, demonstrates that, provided the physics-based model is reasonable, the Bayesian
Inference approximates the behavior well throughout the entire time window. Instead
of only inferring a point value for each parameter, Bayesian Inference infers parameter
distributions and credible intervals that provide valuable insight into the goodness of the
ﬁt as we have seen in the sensitivity analysis for varying training data set sizes in Figure
10: The narrower the credible interval, the better the ﬁt.
Bayesian Neural Networks ﬁt a network model to data and provide credible inter-
vals. Bayesian Neural Networks ﬁt a network model to data without any underlying
physics. They use Bayes’ theorem to infer the distribution of a set of network parameters,
24q=fWk,bkgthat best explain the data. For our example, a feed-forward network with
one input, two hidden layers with 32 nodes each, and one output, the network has 1088
weights and 65 biases. We have assumed log-normal distributions for each parameter,
with individual means mand standard deviations s, introducing a total of 1053 2=2306
unknowns. Figure 14, middle right, shows that the Bayesian Neural Network shares
the features of classical Neural Networks and Bayesian Inference. It approximates the
training data well, but fails to predict the behavior outside the training window. The wide
credible intervals highlight the poor predictive potential of the model and conﬁrm that
any prediction a few days beyond the training window generates unreliable results.
Bayesian Physics Informed Neural Networks provide a good ﬁt and predic-
tion, but are sensitive to scaling. Bayesian Physics Informed Neural Networks ﬁt
both network and physics, and, in addition, provide credible intervals that provide insight
into the quality of the ﬁt. They use Bayes’ theorem to learn the distributions of both
network parameters, q=fWk,bkgand physics parameters, J=fc,k,x0g, with means
mand standard deviations seach, resulting in a total of 2312 unknowns. Figure 14,
bottom right, suggests that Bayesian Physics Informed Neural Networks provide a good
ﬁt of the training data and have a reasonable predictive potential outside the training
window. The narrower credible intervals compared to the Bayesian Neural Network
indicate that including physics increases the performance, especially in the prediction
window. Bayesian Physics Informed Neural Networks are a powerful tool when used
appropriately. They combine the advantages of all methods, and perform best, albeit
at a larger computational cost. Since they have the largest set of parameters, their true
performance is sensitive to an appropriate scaling and pre-conditioning and to the size
of the training data set, as we can conclude from their convergence curve in Figure 13.
However, when scaled appropriately, in our example such that the parameter kassociated
with the unknown x(t)becomes unity, their performance increases drastically, as we
conclude from the narrow credible intervals of the scaling study in Figure 15.
Taken together, our study has shown that by embedding physical principles into a
neural network architecture, we can generate effective models that train well, even with
a small amount of data. Physics-Informed Neural Networks seamlessly integrate data
and physics, robustly solve forward and inverse problems, and perform well for both
interpolation and extrapolation. At only minor additional cost, they can self-adaptively
learn the weighting between data and physics and smoothly integrate real-world data and
physics-based modeling. Combined with Bayesian Neural Networks, Physics-Informed
Neural Networks can serve as a prior in a general Bayesian framework, and can generate
estimators for posterior distributions that provide valuable insight into uncertainty
quantiﬁcation. Here we have only demonstrated these features for the simple model
problem of a seasonal endemic infectious disease, but it is easy to see how the underlying
concepts and trends would generalize to more complex disease conditions and, more
broadly, to a wide variety of nonlinear dynamical systems.
Acknowledgments
This work was supported by a DAAD Fellowship to Kevin Linka, by the MURI/ARO
grant W911NF-15-1-0562 to George Karniadakis, and by the Stanford School of Engineer-
ing COVID-19 Research and Assistance Fund and Stanford Bio-X IIP seed grant to Ellen
Kuhl.
25References
[1] Alber M, Buganza Tepole A, Cannon W, De S, Dura-Bernal S, Garikipati K, Karni-
adakis GE, Lytton WW, Perdikaris P , Petzold L, Kuhl E (2019) Integrating machine
learning and multiscale modeling: Perspectives, challenges, and opportunities in the
biological, biomedical, and behavioral sciences. npj Digital Medicine 2:115.
[2] Bayes T, Price R (1763). An Essay towards Solving a Problem in the Doctrine of
Chances. By the Late Rev. Mr. Bayes, F.R.S. communicated by Mr. Price, in a Letter
to John Canton, A.M.F.R.S. Philosophical Transactions of the Royal Society of Lon-
don. 53:370–418.
[3] Bhouri MA, Sahli Costabal F, Wang H, Linka K, Peirlinck M, Kuhl E, Perdikaris P
(2021) COVID-19 dynamics across the US: A deep learning study of human mobility
and social behavior. Computer Methods in Applied Mechanics and Engineering 382:
113891.
[4] Cai M, Karniadakis GE, Li C (2022) Fractional SEIR model and data-driven predic-
tions of COVID-19 dynamics of omicron variant. doi: 10.48550/arXiv.2205.11379.
[5] Gelman A, Carlin JB, Stern HS, Dunson DB, Vektari A, Rubin DB (2013) Bayesian Data
Analysis. Chapman and Hall/CRC, 3rd edition.
[6] Hoffman MD, Gelman A (2014) The No-U-Turn sampler: adaptively setting path
lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research 15:1593-
1623.
[7] Holmdahl I, Buckee C (2020) Wrong but useful–What Covid-19 epidemiologic models
can and cannot tell us. New England Journal of Medicine 383:303-305.
[8] Jha PK, Cao L, Oden JT (2020) Bayesian-based predictions of COVID-19 evolution in
Texas using multispecies mixture-theoretic continuum models. Computational Me-
chanics 66:1055–1068.
[9] Johns Hopkins University (2021) Coronavirus COVID-19 Global Cases by the Cen-
ter for Systems Science and Engineering. https://coronavirus.jhu.edu/map.html ,
https://github.com/CSSEGISandData/covid-19 assessed: May 1, 2022.
[10] Karniadakis GE, Kevrekidis IG, Lu L, Perdikaris P , Wang S, Yang L (2021) Physics-
informed machine learning. Nature Reviews Physics 3:422-440.
[11] Kharazmi E, Cai M, Zheng X, Zhang Z, Lin G, Karniadakis GE (2021) Identiﬁabil-
ity and predictability of integer-and fractional-order epidemiological models using
physics-informed neural networks. Nature Computational Science 1:744-753.
[12] Kuhl E (2021) Computational Epidemiology. Data-Driven Modeling of COVID-19.
Springer Nature, Switzerland.
[13] Linka K, Peirlinck M, Sahli Costabal F, Kuhl E (2020) Outbreak dynamics of COVID-
19 in Europe and the effect of travel restrictions. Computer Methods in Biomechanics
and Biomedical Engineering 23: 710-717.
[14] Linka K, Peirlinck M, Kuhl E (2020) The reproduction number of COVID-19 and its
correlation with public heath interventions. Computational Mechanics 66:1035-1050.
26[15] Linka K, Goriely A, Kuhl E (2021) Global and local mobility as a barometer for
COVID-19 dynamics. Biomechanics and Modeling in Mechanobiology 20:651–669.
[16] McClenny L, Braga-Neto U (2020) Self-adaptive Physics Informed Neural Networks
using a soft attention mechanism. doi:10.48550/arXiv.2009.04544.
[17] Meng X, Babaee H, GE Karniadakis GE (2021) Multi-ﬁdelity Bayesian neural net-
works: Algorithms and applications Journal of Computational Physics 438:110361.
[18] Meng X, Yang L, Mao Z, del Aguila Ferrandis J, Karniadakis GE (2022) Learning func-
tional priors and posteriors from data and physics. Journal of Computational Physics
457:111073.
[19] Oden JT, Moser R, Ghattas O (2010) Computer predictions with quantiﬁed uncer-
tainty. SIAM News 43:9.
[20] Oden JT, Babuska I, Faghihi D (2017) Predictive computational science: Computer
predictions in the presence of uncertainty. Encyclopedia of Computational Mechanics.
John Wiley & Sons.
[21] Oden JT (2018) Adaptive multiscale predictive modelling. Acta Numerica 2018:353-
450.
[22] Osvaldo M (2018) Bayesian Analysis with Python: Introduction to Statistical Model-
ing and Probabilistic Programming Using PyMC3 and ArviZ. Packt Publishing, 2nd
edition.
[23] Peirlinck M, Linka K, Sahli Costabal F, Kuhl E (2020) Outbreak dynamics of COVID-
19 in China and the United States. Biomechanics and Modeling in Mechanobiology
19:2179-2193.
[24] Peng GCY, Alber M, Buganza Tepole A, Cannon W, De S, Dura-Bernal S, Garikipati K,
Karniadakis GE, Lytton WW, Perdikaris P , Petzold L, Kuhl E (2021) Multiscale model-
ing meets machine learning: What can we learn? Archive of Computational Methods
in Engineering 28:1017-1037.
[25] Raissi M, Perdikaris P , Karniadakis GE (2017) Physics informed deep learning:
Data-driven solutions of nonlinear partial differential equations. arXiv preprint
arXiv:1711.10561.
[26] Raissi M, Perdikaris P , Karniadakis GE (2018) Multistep neural networks for data-
driven discovery of nonlinear dynamical systems. arXiv preprint arXiv:1801.01236.
[27] Raissi M, Perdikaris P , Karniadakis GE (2019) Physics-informed neural networks: a
deep learning framework for solving forward and inverse problems involving non-
linear partial differential equations. Journal of Computational Physics 378:686–707.
[28] Raissi M, Perdikaris P , Karniadakis GE. Physics informed learning machine (2021). US
Patent 10,963,540.
[29] Salvatier J, Wiecki TV , Fonnesbeck C (2016) Probabilistic programming in Python us-
ing PyMC3. PeerJ Computer Science 2:e55.
[30] TensorFlow I/O, version 0.15.0 (2020) https://pypi.org/project/tensorflow-io/0.15.0
assessed: May 1, 2022.
27[31] Treibert S, Ehrhardt M (2021) An unsupervised physics-informed neural network to
model COVID-19 infection and hospitalization scenarios. Bergische Universität Wup-
pertal, Preprint BUW-IAMCM 21/35.
[32] Yang Y, Perdikaris P (2019) Adversarial uncertainty quantiﬁcation in physics-
informed neural networks. Journal Computational Physics 394:136–152.
[33] Yang L, Meng X, Karniadakis GE (2021) B-PINNs: Bayesian physics-informed neural
networks for forward and inverse PDE problems with noisy data. Journal Computa-
tional Physics 425:109913.
[34] Zhang S, Ponce J, Zhang Z, Lin G, Karniadakis G (2021) An integrated framework
for building trustworthy data-driven epidemiological models: Application to the
COVID-19 outbreak in New York City PLoS Computational Biology 17:e1009334.
[35] Zhang Z, Shin Y, Karniadakis GE (2022) GFINNs: GENERIC formalism informed
neural networks for deterministic and stochastic dynamical systems. Philosophical
Transactions A: 20210207.
28"
23,https://arxiv.org/pdf/2503.12244,"Quantum physics informed neural networks for multi-variable partial differential
equations
Giorgio Panichi,1Sebastiano Corli,1and Enrico Prati1, 2,∗
1Dipartimento di Fisica “Aldo Pontremoli”, Universit` a degli studi di Milano,
Via G. Celoria, 16, 20139 Milano, Italy
2Istituto di Fotonica e Nanotecnologie, Consiglio Nazionale delle Ricerche,
Piazza Leonardo da Vinci 32, 20133 Milano
(Dated: March 18, 2025)
Quantum Physics-Informed Neural Networks (QPINNs) integrate quantum computing and ma-
chine learning to impose physical biases on the output of a quantum neural network, aiming to
either solve or discover differential equations. The approach has recently been implemented on both
the gate model and continuous variable quantum computing architecture, where it has been demon-
strated capable of solving ordinary differential equations. Here, we aim to extend the method to
effectively address a wider range of equations, such as the Poisson equation and the heat equation.
To achieve this goal, we introduce an architecture specifically designed to compute second-order
(and higher-order) derivatives without relying on nested automatic differentiation methods. This
approach mitigates the unwanted side effects associated with nested gradients in simulations, paving
the way for more efficient and accurate implementations.
By leveraging such an approach, the quantum circuit addresses partial differential equations – a
challenge not yet tackled using this approach on continuous-variable quantum computers. As a proof-
of-concept, we solve a one-dimensional instance of the heat equation, demonstrating its effectiveness
in handling PDEs. Such a framework paves the way for further developments in continuous-variable
quantum computing and underscores its potential contributions to advancing quantum machine
learning.
I. INTRODUCTION
Quantum Physics-Informed Neural Networks
(QPINNs) integrate quantum computing with classical
Physics-Informed Neural Networks (PINNs), combining
the strengths of quantum computation [1–5]and machine
learning [6–8]. By merging these fields, QPINNs have
the potential to surpass classical computational limita-
tions, particularly in the addressing of complex physics
and engineering problems [3, 9]. Realizing QPINNs
requires the construction of quantum neural networks,
which can be implemented through various quantum
computing architectures, including qubit-based and
continuous-variable quantum computing (CVQC). Using
the fundamental building blocks of CVQC, Continuous
Variable Quantum Neural Networks (CVQNN) emulate
classical neural networks by allowing circuit parameters,
the gate parameters, to be optimized using classical
algorithms [4].
Complementing CVQC, physics-informed neural net-
works (PINNs), initially introduced by Raissi et al. [3],
incorporate established physical laws directly into the
training loss function. These physical laws, typically for-
mulated as differential equations, guide the neural net-
work towards data-consistent solutions that inherently
respect governing physical principles [10, 11]. PINNs
have demonstrated effectiveness in solving complex par-
tial differential equations (PDEs), especially in scenar-
∗enrico.prati@unimi.itios such as high-dimensional problems [12], irregular ge-
ometries [13], non-integrable systems [14], or situations
in which finite-difference and mesh methods become im-
practical [15–17]. Further, notable approaches like the
unified PDE-solving strategy by Berg and Nystr¨ om [18],
and the DeepXDE library by Lu et al. [19], reinforce the
potential of PINNs.
Combining CVQC and PINNs naturally leads to
QPINNs, which exploit quantum computational advan-
tages for physics-informed machine-learning tasks. First
attempts to exploit this potential include applications
such as solving one-dimensional Poisson equations us-
ing single-qumode circuits [20] and employing multi-
qumode structures for deeper networks in various differ-
ential equations [5]. Furthermore, PINNs have been im-
plemented on qubit-based quantum architectures, solving
a diverse array of differential equations [21–23], including
fully quantum [24–26] and hybrid approaches [27].
Despite these advances, existing QPINN implementa-
tions typically rely on nested gradient calculations to
compute higher-order derivatives. This dependence in-
creases computational complexity and can compromise
solution accuracy, restricting the effectiveness of QPINNs
in solving more complex differential equations. Previ-
ously, some of the authors have already addressed quan-
tum machine learning tasks by exploiting gate model
architecture [28], adiabatic architecture [29, 30] and
measurement-based architecture [31]. Here, to address
the above limitation of QPINNs over the continuous
variable encoding, we propose a novel quantum neural
network architecture specifically designed for comput-
ing higher-order derivatives , avoiding nested gradientarXiv:2503.12244v1  [quant-ph]  15 Mar 20252
calculations. Our implementation leverages established
quantum computing and machine learning libraries, no-
tably TensorFlow and Strawberry Fields [32–34], en-
abling more efficient and accurate solutions. We demon-
strate the effectiveness of our proposed QPINN archi-
tecture by solving the temporal evolution of the heat
equation as a representative PDE. Our approach miti-
gates current limitations in existing simulation libraries
and represents a significant step toward solving broader
classes of PDEs with higher precision [35].
This work is organized as follows: Section 2 summa-
rizes the encoding of neural networks over the continu-
ous variable scheme, Section 3 involves our design of the
quantum physics informed neural network, while Section
4 discusses our results. Finally, in the Conclusion section
we outline implications and future directions.
II. ENCODING A NEURAL NETWORK ON A
CONTINUOUS VARIABLE QUANTUM
COMPUTING ARCHITECTURE
In this Section, we provide the framework for build-
ing a neural network, by using the set of quantum gates
natively provided by the CV architecture. More specifi-
cally, we provide the methods required to build QPINN
including encoding, output measurements and simula-
tion constraints. Continuous-variable quantum comput-
ing (CVQC) encodes information in the continuous de-
grees of freedom of the electromagnetic field. Specifi-
cally, computations are performed by using the canon-
ical quadratures of the electric field, ˆXand ˆP, which
obey Heisenberg’s uncertainty principle, meaning that
they cannot be measured simultaneously with arbitrary
precision [2, 36]. In a phase-space representation, the
spectra of ˆXand ˆP– the pair ( x, p) – form a funda-
mental unit of quantum information called qumode. The
use of continuous variables enables floating-point com-
putations, realized through a universal gate set compris-
ing Gaussian operations (such as displacement, squeez-
ing, Fourier transforms, and beam splitters), cubic phase
gates, and measurement-induced gates [37–39]. Although
Gaussian gates can be efficiently simulated on classical
hardware [40], analogously to Clifford gates in qubit-
based quantum computing [41–44], the inclusion of non-
Gaussian gates makes classical simulation challenging.
Nevertheless, non-Gaussian gates are necessary for uni-
versal quantum computation [38, 45].
A. Encoding of a layered feed forward architecture
Classical feed-forward neural networks (FNN) have
layers which can be modeled as such:
fn(x) =σ(Wx+b), (1)where the xvariable stands for the input data, the Wand
btransformations are respectively the weigh matrix and
the bias vector, and σactivation function allows to in-
troduce non-linearities in the overall transformation. As
proved by Cybenko and generalized by Hornik [46–48], by
setting suitable activation functions σ, such architecture
allows to approximate any measurable function, making
NNs universal approximators, later extended to quantum
computers [49]. Through the combinations of Gaussian
and non-Gaussian gates, continuous Variable quantum
computers are able to create an universal neural network
layer similar to the classical one. The goal is pursued
through the application of a sequence of gates [4]:
L= Φ◦D◦U2◦S◦U1, (2)
where the domain of LisRN, representing the N-
dimensional input space, and the codomain is RN, rep-
resenting the N-dimensional output space. Here, Nde-
notes the number of input modes, each mode being a
real number encoded as a quantum state. All the op-
erations implemented in Eq. (2) are manipulations of a
photonic state, which encode the continuous variables.
In a fault-tolerant QC era, such operations are aimed to
be prompted on a photonic chip [50].
In the Fock representation, each qumode is character-
ized by position and momentum variables. Such quadra-
tures form a pair per mode that interact with each other,
serving as the carriers of information for the neural net-
work. The circuit components of Lact on these variable
carried by qumodes. The operator Uk=Uk(θ,ϕ) rep-
resents an N-mode interferometer parameterized by θ
andϕ, which applies a linear transformation to the in-
put modes. The squeezing operator Sis a single-mode
squeezing gate (S-gate) applied to each mode, where the
squeezing parameter riacts as a multiplicative factor on
the corresponding quadrature. Similarly, the displace-
ment operator Ddenotes a single-mode displacement
gate (D-gate) that shifts the position and momentum
quadratures of each mode by a complex displacement αi.
Finally, the operator Φ is a non-Gaussian gate applied to
each mode with parameter λi. A common choice for Φ
is the Kerr gate (K-gate), which is preferred for its nu-
merical stability—largely due to its diagonal form in the
Fock basis.
Therefore the actual structure of the network depends
on the number of qumodes, e.g. for a 2 qumode layer the
structure is shown in Fig. 1.
B. Encoding of variables
In the CV formalism, the displacement gate ˆD(α),α
being a complex variable, acts as a translation [4], shift-
ing the Xmode by Re {α}and the Pone by Im {α}. As
the vacuum state |0⟩encodes the 0 value for both the X
andPqumodes, a displacement ˆD(x) (xthis time being a
real parameter), inserted at the beginning of the circuits3
(a)
(b)
(c)
FIG. 1: (a) Quantum circuit bulding block for
CVQC-based quantum neural network [33]. Here ˆU
represents general n-mode interferometers, ˆSrepresents
single-mode squeezing gates, ˆDrepresents single-mode
displacement gate and ˆΦ represents any non-gaussian
gate (b) & (c) Quantum Neural Network Layer of for a
1 and 2 qumode set-up respectively. Specifically the 2
modes interferometer is implemented through a Beam
Splitter ( BS) and a phase shifter ( R), the squeezing ( S)
and displacement ( D) are single mode and the
non-gaussian gate is implement through a Kerr gate
(K). The 1 qumode configuration correspond to a 2
node fully connected configuration in a classical
network but with a higher number of trainable
parameters, 5 instead of 6, while the 2 qumode
configuration corresponds to a 4 nodes fully connected
structure with 12 trainable parameters instead of 20.
in Figure 1, encodes the initial value where the differen-
tial equation F(x) = 0 is going to be solved. For PDEs,
two or more displacement gates are required, depending
on the number of variables.C. Homodyne detection for quantum
measurements
In the CV framework, the measurements over the
quadratures of the electric field can be performed by a
technique known as homodyne detection. This technique
consists of measuring an observable ˆQϕthat is a linear
combination of both the observables ˆXandˆP. Neverthe-
less, in the work we present, as the previous works [5, 20]
on QNNs in CV, we are just interested in the ˆXob-
servable. The target function uθ(x) is yielded in fact by
quantum measurements via the homodyne detection:
uθ(x) =⟨ψθ|ˆX|ψθ⟩ (3)
where |ψθ⟩stands for the quantum state at the end of
the transformations induced by the circuit, as in Figure
1. The family of parameters θgroups all the angles θi,ϕi
from the interferometers, the squeezing factor rias well
as the parameters αiandλifor the displacement and
the non-linear operations. For sake of simplicity, hence-
forth we write u(x) instead of uθ(x). Nonetheless, in the
scheme we propose, whenever the circuit is composed by
multiple waveguides, other output functions can be com-
puted as well via a homodyne detection on a different
mode. In the scheme of the 1D Poisson equation, see
Figure 3, we deployed two waveguides to achieve greater
expressivity, therefore we adapted such scheme to per-
form the following measurements:
(
u(x) =⟨Ψθ|ˆX1|Ψθ⟩
ux(x) =⟨Ψθ|ˆX2|Ψθ⟩(4)
where ux(x) is a function which should correspond to the
u′(x), derivative of u(x), as we detail in Section IV A.
In the scheme for the 2D heat equation, the same strat-
egy has been adopted to compute TandTx:
(
T(x, t) =⟨Ψθ|ˆX1|Ψθ⟩
Tx(x, t) =⟨Ψθ|ˆX2|Ψθ⟩(5)
D. Fock space and cut-off truncation
When simulating the network, we use the Fock space
representation, which, upon introducing squeezing gates
and displacement gates, becomes an infinite-dimensional
space. To efficiently simulate the states, it is necessary
to truncate the Fock space at a specific cut-off. Its value
has to be carefully chosen before the simulation to achieve
an optimal balance between computational efficiency and
accurate representation of the manipulated states. We
can minimize the cut-off dimension ( n) by looking at the
domain and the predicted co-domain of the equations.
By ensuring:
n≫max
x∈Dx∧n≫max
x∈Du(x). (6)4
we can grant the cut-off to be sufficient. Moreover,
since we are using a variational quantum algorithm
(VQA) [51], we can impose the state normalization as
one of the components of the loss function, which we ex-
plain more in depth in the following Sections.
E. Training the Quantum Neural Network
To train a quantum neural network, we need to per-
form backpropagation techniques, i.e. to compute the
derivatives of the loss function with respect to the train-
ing parameters of the gates. Currently, there is no exact
method for obtaining these derivatives in the presence of
both Gaussian and non-Gaussian gates [52]. The best
known approach relies on a continuous-variable param-
eter shift rule, which only works efficiently if the num-
ber of non-Gaussian gates grows at most logarithmically
with respect to the Gaussian gates [52]. Unfortunately,
our universal architecture [4] includes one non-Gaussian
gate per layer for qumode, violating this condition.
As a result, when training the network directly
on quantum hardware, gradient-free optimization tech-
niques have to be employed. During simulation, how-
ever, this limitation can be sidestepped by using auto-
matic differentiation methods. A choice made available
by Strawberry Fields with a TensorFlow backend, is the
automatic Adam optimizer, which has been shown to
yield the fastest convergence rates for continuous-variable
quantum neural networks [4].
III. QUANTUM PHYSICS-INFORMED
NEURAL NETWORKS
Building on the QNN framework described in the pre-
vious Section, we now shift our focus on integrating the
specialized methods developed for PINNs into our ap-
proach.
A. Merging of Quantum Neural Networks and
Physics-Informed Architecture
Quantum Physics-Informed Neural Networks
(QPINNs) blend the capabilities of Quantum Neu-
ral Networks with the principles of Physics-Informed
Neural Networks. The network is trained to approximate
a target solution function by taking problem-domain
inputs and adjusting its parameters to satisfy the un-
derlying physics, as encoded in the governing equations
and boundary conditions. In this framework, the loss
function is constructed as a function of the governing
differential equations and their associated constraints.
By incorporating boundary conditions and other rele-
vant terms into the loss, the QPINN guides the network
toward physically accurate solutions. The approximatedsolution is given by the network, parametrized by the
set of gates parameters θ:
uθ(x) =⟨ψθ|ˆX|ψθ⟩, (7)
where the input to the quantum network is ˆD(x)|0⟩. For
the definition of |ψθ⟩, we address the readers to Equation
(3), while for the encoding through the displacement op-
erator ˆD(x) to Section II B.
B. Construction of the loss function
Let’s now turn to the detailed description of the com-
ponents of the loss function. The loss function is designed
to drive the network toward a solution that satisfies the
underlying physical laws and boundary conditions. It
is composed of several terms each one corresponding to
a constraint of the problem. Importantly, one of the
terms, called consistency loss , represents the core of the
method to overcome the issue of nested derivation men-
tioned above. The loss function is later evaluated at each
training epoch. Given a general PDE:
N(uθ) =f(x),x∈Ω, (8)
with boundary conditions:
B(uθ) =g(x),x∈∂Ω. (9)
Here, Nis a differential operator acting on the un-
known solution u(x), Ω is the domain, and ∂Ω is its
boundary. In a physics-informed learning framework, we
approximate the solution by a parametric model uθ(x),
in this case via a quantum neural network with parame-
tersθ.
The training of a QPINN involves minimizing a loss
function that incorporates the PDE and boundary con-
ditions as well as other relevant terms. Specifically, the
loss function includes a physics loss LPDE, a boundary
condition loss LBC, a trace loss Ltrace, an additional term
of loss Lextra and the consistency loss Lconsistency , which
replaces the need of nested derivation.
The physics loss enforces the neural network solution
uθto satisfy the underlying PDE, by penalizing the devi-
ation of the PDE operator N(uθ) from the known forcing
term f:
LPDE=X
xi∈ΩN 
uθ(xi)
−f(xi)2. (10)
Theboundary conditions loss ensures that the solution
uθrespects the boundary conditions given by the opera-
torBand the target function g:
LBC=X
xj∈∂ΩB 
uθ(xj)
−g(xj)2. (11)
The trace loss induces the normalization of the state.
Consider the normalized quantum state |ψθ⟩, its density5
matrix is ρ=|ψθ⟩⟨ψθ|. The trace of ρshould be 1 for
proper normalization. Thus, we write:
Ltrace=NX
i=1 
Tr(|ψ⟩⟨ψ|)−12. (12)
The additional terms can include various constraints,
regularization terms, or other problem-specific conditions
to improve convergence and solution quality:
Lextra =X
kλkLk(uθ), (13)
where each Lk(uθ) is tailored to the problem at hand,
weighted by a user-defined hyperparameter λk.
The consistency loss we introduce consists of a loss
component that ensures that the second output of the
network corresponds to the derivative of the first output.
Instead of relying on nested gradient computations, we
directly use the second output as an approximation of the
derivative of the first output, which itself approximates
the implicit function. By enforcing this consistency, we
can compute the remaining components of the loss func-
tion without requiring nested gradients. Specifically, we
achieve this by differentiating the second output of the
neural network:
Lconsistency =d
dxu(x)−ux(x). (14)
where u1(x) is the first output of the QNN while u2(x)
is its second output.
Combining all these loss components into a single total
loss function:
Ltotal=λPDELPDE+λBCLBC+λtraceLtrace+
+Lextra+λconsistency Lconsistency =X
ℓλℓLℓ(15)
where the extra loss term runs in turn over the index
ℓ, and all the loss terms are weighted by a suitable λℓ
hyper-parameters which are their corresponding weight-
ing coefficients.
After each loss evaluation, the parameters θof the
quantum neural network are updated using the Adam
optimizer with automatic differentiation. Iterating this
optimization process leads the QPINN to converge to-
ward an accurate target solution u(x). The structure of
the QPINN is represented in Fig. 2.
IV. RESULTS
Quantum Physics-Informed Neural Networks
(QPINNs) leverage Quantum Processing Units (QPUs)
to operate the neural network and compute its gradients.
Subsequently, a classical computer is employed to update
FIG. 2: QPINN overall structure. The encoding is
implemented by a set of displacement gatesˆD(x) while
output is obtain through the homodyne detection of the
position quadrature of the final state ˆX. A classical
computer then calculates the loss function a carries
optimization by updating the weights of the
parametrized QNN layers.
the weights parameters of the neural network by using a
user-defined optimizer.
In our implementation, we utilize Strawberry Fields ,
a Python library developed by Xanadu [33], to simu-
late the quantum circuits. Meanwhile, TensorFlow is
employed to perform automatic differentiation via its
tf.GradientTape method [32].
Achieving reliable convergence in QPINNs generally
requires substantial fine-tuning. We refer the reader to
Appendix A for details on the specific hyperparameters
used and the rationale behind them Tables IV III.
We proceed in two steps. First, we introduce a new ar-
chitecture designed to overcome existing limitations as-
sociated with nested derivative operations, a capability
that had previously induced significant challenges. Next,
building upon this architectural innovation, we demon-
strate the successful solution of a partial differential equa-
tion (PDE), specifically the heat equation, using this im-
proved QPINN framework.
A. Solution of an ODE: case of 1D Poisson
equation
With this first case, a neural network is built to solve
ordinary differential equations (ODEs) with an architec-
ture designed to avoid gradient nesting while being able
to implement higher order derivation. We used a multi-
output configuration in which the second output of the
network converges towards the derivative of the first out-
put (Fig. 3. To showcase this architecture we solve the
1D Poisson equation with a sinusoidal term (Eq. 16).
u′′(x) + sin(4 x) = 0 , (16)6
with boundary conditions and domain
u(0) = uπ
2
= 0, x ∈h
0,π
2i
. (17)
To solve this equation we set up the network as in Figure
3. The loss function components are illustrated in Table
I.
Loss Expression Weights (λ)
LPDE
∂ux(x)
∂x+ sin(4 x)2
25%
LBC u(0)2+u π
2225%
Lconsistency
∂u
∂x−ux2
25%
Ltrace⟨ψ|ψ⟩ −12
25%
LtotX
ℓλℓLℓ 100%
TABLE I: Loss function components used in the 1D
Poisson equation problem with corresponding weights.
No particular configurations of the weights was found to
be particularly better towards the resolution of the
equation.
To ensure that the domain is correctly represented and
each point in the domain is fitted, the points evaluated
are randomly drawn from the domain, according to sobol
sequence [18].
As illustrated in Fig. 4, the QPINN method solves this
equation efficiently. The Normalized Mean Squared Er-
ror (NMSE) of the final solution returning the accuracy
corresponds to
NMSE =PN
i=1(yi−ˆyi)2
PN
i=1y2
i(18)
which for the best result of the 1D Poisson equation
solved by our methods is:
NMSE = 1.39×10−5. (19)
These low values indicate the convergence of the method
and validate its effectiveness in solving higher-order dif-
ferential equations, as shown in Figure 5. For the sake of
completeness and in order to make the Reader aware of
the behavior of the method in practice, we report there
the full record of a training process, which may show
sudden instabilities, as often happens during training in
other artificial intelligence methods, such as the deep re-
inforcement learning which sometimes suffers of sudden
loss of performances [53, 54]. In these cases, the solution
consists of recording the weight parameters returning at
the minimum loss achieved.B. Solution of a PDE: case of the Heat Equation
The method involving the consistency loss is now ap-
plied to PDEs. As application case, we consider the heat
equation, which describes the temporal evolution of the
temperature distribution in a one-dimensional medium.
It is given by Eq. 20:
∂T
∂t=αd∂2T
∂x2, x∈[−π
2,π
2], t≥0, (20)
where T(x, t) is the temperature at position xand time t,
andαdis the thermal diffusivity. In this equation, each
variable has a physical interpretation, but we deliberately
omit units of measurement. Our goal is to demonstrate
the method’s effectiveness in solving second-order, linear,
parabolic partial differential equations, exemplified here
by the heat equation (Eq. 20). Importantly, the method
remains invariant under rescaling of the domain, there-
fore changing the setting of the boundary conditions does
not affect the quality of the solution. The boundary con-
ditions are:
T(−π
2, t) =T(π
2, t) = 0 , t≥0, (21)
We set αd= 0.30 and the initial condition:
T(x,0) = exp 
− 
x+π
82
2σ!
, σ = 0.2. (22)
We simulate the evolution from t= 0 to t= 0.5.
In the QPINN, both xandtare encoded into a two-
qumode quantum neural network (QNN) by applying
displacement gates on each qumode to represent these
inputs. The network architecture consists of a two-
layer, two-qumode section followed by a two-layer, single-
qumode section (see Fig. 6). This structure enables us
to approximate both the heat equation’s solution T(x, t)
and its spatial derivative∂T
∂x, thanks to the consistency
loss (Eq. 14). We only need this second output for this
specific equation because the equation does not require
us to compute the second derivative with respect to time,
therefore requiring only two outputs.
We denote the two outputs of the network as T(x, t)
andTx(x, t). By automatic differentiation of these out-
puts, we obtain the necessary derivatives∂T
∂x,∂T
∂t, and
∂Tx
∂x. These derivatives are then used to form the loss
function components, ensuring that the learned functions
satisfy the loss functions (Table II).
To ensure that the domain is correctly represented and
each point in the domain is fitted, the evaluated points
are randomly drawn from the domain, according to sobol
squence [18].
To reduce computational cost and accelerate training
the network can be ”pre-trained”, i.e. we can train the
network in the beginning just by using the initial condi-
tion loss which does not require derivative calculations.
The network is then trained for 300 epochs with 258
points distributed on the T(x,0) which greatly reduces7
(a)
(b)
FIG. 3: (a) Schematic network setup used to solve the 1D Poisson equation. The input xis encoded as qumode
displacement. The network applies linear and non-linear transformation in the form of gaussian ( BS,R,S, and D)
and non-gaussian ( K) gates to achieve the desired output. The first output of the QNN is measured and used to
estimate the implicit function u(x). The second one is used to estimate the first derivative of the implicit function
u′(x). (b) Classical equivalent of the actual QNN used to solve the 1D Poisson equation. The layer in (a)
corresponds to a 4 nodes layer in a classical network.
computational times. Afterwards the network is trained
on the equation full domain with all of its loss function
components. Cosine annealing with warm restarts is em-
ployed to prevent the network from convering to global
minima ([55]).
By minimizing the total loss, the QPINN learns a so-
lution that is consistent with the PDE, boundary and
initial conditions, and the quantum model constraints.
After 1000 training epochs, the network successfully con-
verges to an accurate solution of the equation (Fig. 7).
The loss function decreases steadily throughout the train-
ing process, except for a spike at epoch 500, ultimately
reaching a value on the order of 10−3(Fig. 8). This result
demonstrates the capability of QPINN in solving PDEs
but suggests also that further improvements can further
enhance the method’s precision. Further details about
the simulation constraints and overheads are discussed
in the Appendix.V. CONCLUSIONS
We have demonstrated the capability of quantum
physics-informed neural networks to solve partial differ-
ential equations (PDEs). Although our experiments were
conducted using a quantum simulator, which imposes
limitations such as restricting the Fock space to a pre-
defined cutoff dimension and necessitating the rescaling
of the equation’s domain, such constraints are expected
to diminish when transitioning to actual quantum hard-
ware. On real quantum devices, the inherent normaliza-
tion of quantum states eliminates the need for trace loss,
and the absence of a fixed cutoff dimension allows for
more accurate representations without domain rescaling.
However, deploying QPINNs on quantum hardware in-
troduces its own set of challenges that may require mod-
ifications to the neural network architecture. One sig-
nificant bottleneck is the current inability to compute8
FIG. 4: Training progress to solve the case of ODE
represented by the 1D Poisson equation without
gradient nesting while being able to implement higher
order derivation. Top: Evolution of the prediction of
the QPINN after 50, 100, 150 and 200 epochs of
training. Bottom: the best result obtained by the
method corresponding to NMSE = 1 .39×10−5
exact derivatives on quantum hardware, which hampers
the effectiveness of gradient-based optimization methods
essential for training neural networks. While gradient-
free optimization techniques can be employed, one should
carefully consider their convergence speed and accuracy
compared to methods based on exact derivatives.
Despite these hurdles, the potential of QPINNs re-
mains promising. Continued research and development
are crucial to address these challenges and fully leverage
quantum computing for solving PDEs. With further ad-
vancements, QPINNs have the potential to surpass tra-
ditional Physics-Informed Neural Networks (PINNs) in
both efficiency and performance.
FIG. 5: Different components of the loss function during
the training of the neural network for the solution of the
1D Poisson equation. A black dot is used to indicate
the epoch with the lowest loss value. The values are
plotted every 20 epochs to make the lines clearer. The
optimization is able to achieve at its best a lowest loss
given by the NMSE = 1 .39×10−5as measured in Eq.
19. Similarly to what happens with some other machine
learning methods, the method can show instabilities,
requiring to memorize the best network weights during
the training when performances are improved.
Loss Expression Weights (λ)
LPDE
∂ux(x)
∂x+ sin(4 x)2
10%
LIC (u(x,0)−u0(x))260%
LBC u(0)2+u π
2210%
Lconsistency
∂u
∂x−ux2
10%
Ltrace⟨ψ|ψ⟩ −12
10%
LtotX
ℓλℓLℓ 100%
TABLE II: Loss function components with
corresponding weights: 60% for LICand 10% for the
others. These weights were chosen bacause of the
particular physics if the problem, i.e to prevent the
network from ending up in the local minima consisting
in the null solution ( T(x, t) = 0) which would satisfy
the differential equation but not the initial conditions.
VI. ACKNOWLEDGEMENTS
The authors also acknowledge support from the Qx-
treme project funded by the Partenariato Esteso FAIR
(grant N. J33C22002830006). GP and EP gratefully
thank Thales Alenia Space Italia for supporting a PhD
grant.9
(a)
(b)
FIG. 6: (a) Schematic network set-up used for solving the Heat equation. In this case, differently from Fig. 3 the
inputs xandtare encoded as qumode displacements. The network applies linear and non-linear transformation in
the form of gaussian (BS, R, S and D) and non-gaussian (K) gates to achieve the desired output. The network
outputs are measured and give two values: T(x, t), an approximation of the desired solution u(x, t), and Tx(x, t), an
approximation of∂u
∂x. For the heat equation we need only 2 outputs since we do not need to calculate∂2T(x,t)
∂t2;
therefore, we only need to estimate the first derivative with respect to position. (b) Classical equivalent of the actual
QNN used to solve the 1D Poisson equation. The layer in (a) corresponds to a 4 nodes layer in a classical network.
Appendix A: Simulation Constraints and Choice of
Hyper-parameters
Tables III and IV summarize the hyper-parameters
used in our simulations. The major computational over-
head during each training epoch arises from the alloca-
tion of Random Access Memory (RAM) to store all oper-
ations performed during the simulation. These stored op-
erations are subsequently used to compute the loss func-
tion and optimize the network weights. After each epoch,
the RAM is cleared to manage memory efficiently.
Given this constraint, a careful balance must be main-
tained between the number of collocation points, the
depth of the neural network, and the cutoff dimension. In
both simulations, we employed a 4-layer quantum neuralnetwork with 2 qumodes. The first two layers allow inter-
action between the qumodes, while in the final two lay-
ers, each qumode acts only on its own state, represented
in phase space by the position ( ˆX) and momentum ( ˆP)
quadratures. This architecture was determined through
trial and error during preliminary simulations.
Regarding the cutoff dimension, a value of 15 was suffi-
cient to achieve accurate simulations for both equations.
The number of collocation points ( n) per training
epoch is a crucial hyper-parameter that significantly im-
pacts simulation accuracy. To maximize performance, n
was chosen to fully utilize the available 64 GB of RAM.
Additionally, nwas set to 2k+2, ensuring optimal scram-
bling of 2kpoints by the Sobol algorithm, while two ad-
ditional points were fixed at the boundary conditions.10
FIG. 7: Heatmap of T(x, t) illustrating how temperature (color-coded) propagates through the material as time
progresses. Warmer regions appear in lighter hues, indicating higher temperatures, while darker regions are cooler.
The dashed contour lines represent isotherms (constant-temperature curves), and the axes show the spatial
coordinate ( x) and time ( t), respectively.
FIG. 8: Loss function components values during the
training of the QPINN used to estimate the solution of
the Heat Equation (Eq. 7). The model is trained for
1000 epoch and a steadly descent in the loss function is
appreciatable. We can see that in the end of the
training the loss function reaches a values of 10−1which
has to be divided by 100 (total weights of the loss
function) to obatian an estimate of the final precision of
the method 10−3
[1] R. P. Feynman, Simulating physics with computers, in
Feynman and computation (cRc Press, 2018) pp. 133–
153.
[2] S. Lloyd and S. L. Braunstein, Quantum computation
over continuous variables, Physical Review Letters 82,
1784 (1999).
[3] M. Raissi, P. Perdikaris, and G. E. Karniadakis, Physics-
informed neural networks: A deep learning framework forsolving forward and inverse problems involving nonlinear
partial differential equations, Journal of Computational
Physics 378, 686 (2019).
[4] N. Killoran, T. R. Bromley, J. M. Arrazola, M. Schuld,
N. Quesada, and S. Lloyd, Continuous-variable quan-
tum neural networks, Physical Review Research 1,
10.1103/PhysRevResearch.1.033063 (2019).
[5] M. Knudsen and C. B. Mendl, Solving differential equa-11
Hyper-parameter Value Description
Multi-qumode layers 2Number of QNN layers
acting on multiple
qumodes
Single-qumode layers 2Number of QNN layers
acting on a single
qumode
Cutoff dimension 20Dimension of the
truncated Hilbert space
Learning rate 0.1Reduced initial learning
rate for the optimizer
Optimizer type AdamType of optimizer (e.g.,
’Adam’, ’SGD’)
Epochs 5000Number of training
epochs
Collocation points 258Number of points for
training
TABLE III: Hyper-parameters used for the 1D poisson
equation simulation
Hyper-parameter Value Description
Multi-qumode layers 2Number of QNN layers
acting on multiple
qumodes
Single-qumode layers 2Number of QNN layers
acting on a single
qumode
Cutoff dimension 20Dimension of the
truncated Hilbert space
Learning rate 0.01Step size for the
optimization process
Optimizer type AdamOptimization algorithm
used for training
Epochs 1000Number of training
iterations
Spatial collocation
points 18Number of collocation
points along the spatial
dimension
Temporal collocation
points 10Number of collocation
points along the
temporal dimension
TABLE IV: Hyper-parameters used for Heat equation
simulation
tions via continuous-variable quantum computers (2020),
arXiv:2012.12220 [quant-ph].
[6] E. Prati, Quantum neuromorphic hardware for quantum
artificial intelligence, in Journal of Physics: Conference
Series , Vol. 880 (IOP Publishing, 2017) p. 012018.
[7] J. Biamonte, P. Wittek, N. Pancotti, P. Rebentrost,
N. Wiebe, and S. Lloyd, Quantum machine learning, Na-ture549, 195 (2017).
[8] S. Corli, L. Moro, D. Dragoni, M. Dispenza, and E. Prati,
Quantum machine learning algorithms for anomaly de-
tection: A review, Future Generation Computer Systems
, 107632 (2024).
[9] M. Schuld, I. Sinayskiy, and F. Petruccione, An intro-
duction to quantum machine learning, Contemporary
Physics 56, 172 (2015).
[10] M. Raissi, P. Perdikaris, and G. E. Karniadakis, Physics-
informed neural networks: A deep learning framework for
solving forward and inverse problems involving nonlinear
partial differential equations, Journal of Computational
Physics 378, 10.1016/j.jcp.2018.10.045 (2019).
[11] L. Brevi, A. Mandarino, and E. Prati, A tutorial on
the use of physics-informed neural networks to compute
the spectrum of quantum systems, Technologies 12, 174
(2024).
[12] Z. Hu, K. Shukla, G. E. Karniadakis, and K. Kawaguchi,
Tackling the curse of dimensionality with physics-
informed neural networks, Neural Networks 176, 106369
(2024).
[13] Z. Xiang, W. Peng, W. Zhou, and W. Yao, Hybrid
finite difference with the physics-informed neural net-
work for solving pde in complex geometries (2022),
arXiv:2202.07926 [physics.comp-ph].
[14] L. Brevi, A. Mandarino, and E. Prati, Addressing the
non-perturbative regime of the quantum anharmonic os-
cillator by physics-informed neural networks, New Jour-
nal of Physics 26, 103015 (2024).
[15] X. Jin, S. Cai, H. Li, and G. E. Karniadakis, Nsfnets
(navier-stokes flow nets): Physics-informed neural net-
works for the incompressible navier-stokes equations,
Journal of Computational Physics 426, 109951 (2021).
[16] B. Hu and D. McDaniel, Applying physics-informed neu-
ral networks to solve navier–stokes equations for laminar
flow around a particle, Mathematical and Computational
Applications 28, 102 (2023).
[17] L. Gu, S. Qin, L. Xu, and R. Chen, Physics-informed
neural networks with domain decomposition for the in-
compressible navier–stokes equations, Physics of Fluids
36(2024).
[18] J. Berg and K. Nystr¨ om, A unified deep artificial neu-
ral network approach to partial differential equations in
complex geometries, Neurocomputing 317, 28 (2018).
[19] L. Lu, X. Meng, Z. Mao, and G. E. Karniadakis, Deepxde:
A deep learning library for solving differential equations,
SIAM review 63, 208 (2021).
[20] S. Markidis, On physics-informed neural networks for
quantum computers, Frontiers in Applied Mathematics
and Statistics 8, 10.3389/fams.2022.1036711 (2022).
[21] C. Trahan, M. Loveland, and S. Dent, Quan-
tum physics-informed neural networks, Entropy 26,
10.3390/e26080649 (2024).
[22] A. Sedykh, M. Podapaka, A. Sagingalieva, K. Pinto,
M. Pflitsch, and A. Melnikov, Hybrid quantum physics-
informed neural networks for simulating computational
fluid dynamics in complex shapes, Machine Learning:
Science and Technology (2024).
[23] P. Siegl, S. Wassing, D. M. Mieth, S. Langer, and
P. Bekemeyer, Solving transport equations on quan-
tum computers—potential and limitations of physics-
informed quantum circuits, CEAS Aeronautical Journal
10.1007/s13272-024-00774-2 (2024).
[24] F. Y. Leong, W.-B. Ewe, and D. E. Koh, Variational12
quantum evolution equation solver, Scientific reports 12,
10817 (2022).
[25] F. Gaitan, Finding flows of a navier–stokes fluid through
quantum computing, npj Quantum Information 6, 61
(2020).
[26] A. E. Paine, V. E. Elfving, and O. Kyriienko, Physics-
informed quantum machine learning: Solving nonlinear
differential equations in latent spaces without costly grid
evaluations, arXiv preprint arXiv:2308.01827 (2023).
[27] C. Trahan, M. Loveland, and S. Dent, Quantum physics-
informed neural networks, Entropy 26, 649 (2024).
[28] M. Lazzarin, D. E. Galli, and E. Prati, Multi-class quan-
tum classifiers with tensor network circuits for quantum
phase recognition, Physics Letters A 434, 128056 (2022).
[29] L. Moro and E. Prati, Anomaly detection speed-up by
quantum restricted boltzmann machines, Communica-
tions Physics 6, 269 (2023).
[30] D. No` e, L. Rocutto, L. Moro, and E. Prati, Quantum
parallel training of a boltzmann machine on an adiabatic
quantum computer, Advanced Quantum Technologies 7,
2300330 (2024).
[31] S. Corli, D. Dragoni, M. Proietti, M. Dispenza, C. Cavaz-
zoni, and E. Prati, A max k-cut implementation for qaoa
in the measurement based quantum computing formal-
ism, in 2023 IEEE International Conference on Quantum
Computing and Engineering (QCE) , Vol. 2 (IEEE, 2023)
pp. 284–285.
[32] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen,
C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin,
S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Is-
ard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Lev-
enberg, D. Man´ e, R. Monga, S. Moore, D. Murray,
C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever,
K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan,
F. Vi´ egas, O. Vinyals, P. Warden, M. Wattenberg,
M. Wicke, Y. Yu, and X. Zheng, Tensorflow: Large-
scale machine learning on heterogeneous systems, https:
//www.tensorflow.org/ (2015).
[33] Xanadu, Quantum neural network, https:
//strawberryfields.ai/photonics/demos/run_
quantum_neural_network.html , accessed: 2024-12-
10.
[34] N. Killoran, J. Izaac, N. Quesada, V. Bergholm, M. Amy,
and C. Weedbrook, Strawberry fields: A software plat-
form for photonic quantum computing, Quantum 3, 129
(2019).
[35] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haber-
land, T. Reddy, D. Cournapeau, E. Burovski, P. Peter-
son, W. Weckesser, J. Bright, et al. , Scipy 1.0: fundamen-
tal algorithms for scientific computing in python, Nature
methods 17, 261 (2020).
[36] F. Hanamura, W. Asavanant, H. Nagayoshi, A. Sak-
aguchi, R. Ide, K. Fukui, P. van Loock, and A. Furusawa,
Implementing arbitrary multimode continuous-variable
quantum gates with fixed non-gaussian states and adap-
tive linear optics, Physical Review A 110, 022614 (2024).
[37] S. Takeda and A. Furusawa, Universal quantum comput-
ing with measurement-induced continuous-variable gate
sequence in a loop-based architecture, Physical review
letters 119, 120504 (2017).
[38] T. Hillmann, F. Quijandr´ ıa, G. Johansson, A. Fer-
raro, S. Gasparinetti, and G. Ferrini, Universal gateset for continuous-variable quantum computation with
microwave circuits, Physical review letters 125, 160501
(2020).
[39] S. Bangar, L. Sunny, K. Yeter-Aydeniz, and G. Siopsis,
Experimentally realizable continuous-variable quantum
neural networks, Physical Review A 108, 042414 (2023).
[40] S. Ghose and B. C. Sanders, Non-gaussian ancilla states
for continuous variable quantum computation via gaus-
sian maps, Journal of Modern Optics 54, 855 (2007).
[41] S. Anders and H. J. Briegel, Fast simulation of stabi-
lizer circuits using a graph-state representation, Physical
Review A—Atomic, Molecular, and Optical Physics 73,
022334 (2006).
[42] D. Gottesman, The Heisenberg representation of
quantum computers, arXiv preprint quant-ph/9807006
(1998).
[43] K. Fujii, Quantum Computation with Topological Codes:
from qubit to topological fault-tolerance , Vol. 8 (Springer,
2015).
[44] M. A. Nielsen and I. L. Chuang, Quantum computation
and quantum information , Vol. 2 (Cambridge university
press Cambridge, 2001).
[45] K. Sharma and M. M. Wilde, Characterizing the per-
formance of continuous-variable gaussian quantum gates,
Physical Review Research 2, 013126 (2020).
[46] G. Cybenko, Approximation by superpositions of a sig-
moidal function, Mathematics of control, signals and sys-
tems2, 303 (1989).
[47] K. Hornik, M. Stinchcombe, and H. White, Multilayer
feedforward networks are universal approximators, Neu-
ral networks 2, 359 (1989).
[48] K. Hornik, Approximation capabilities of multilayer feed-
forward networks, Neural networks 4, 251 (1991).
[49] M. Maronese, C. Destri, and E. Prati, Quantum acti-
vation functions for quantum neural networks (2022),
arXiv:2201.03700 [quant-ph].
[50] F. Lenzini, J. Janousek, O. Thearle, M. Villa, B. Haylock,
S. Kasture, L. Cui, H.-P. Phan, D. V. Dao, H. Yonezawa,
et al. , Integrated photonic platform for quantum infor-
mation with continuous variables, Science advances 4,
eaat9331 (2018).
[51] M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin,
S. Endo, K. Fujii, J. R. McClean, K. Mitarai, X. Yuan,
L. Cincio, et al. , Variational quantum algorithms, Nature
Reviews Physics 3, 625 (2021).
[52] M. Schuld, V. Bergholm, C. Gogolin, J. Izaac, and N. Kil-
loran, Evaluating analytic gradients on quantum hard-
ware, Physical Review A 99, 10.1103/physreva.99.032331
(2019).
[53] S. Corli, L. Moro, D. E. Galli, and E. Prati, Solving ru-
bik’s cube via quantum mechanics and deep reinforce-
ment learning, Journal of Physics A: Mathematical and
Theoretical 54, 425302 (2021).
[54] L. Moro, A. Likmeta, E. Prati, M. Restelli, et al. , Goal-
directed planning via hindsight experience replay, in 10th
International Conference on Learning Representations,
ICLR 2022 (2022) pp. 1–16.
[55] I. Loshchilov and F. Hutter, Sgdr: Stochastic gradi-
ent descent with warm restarts (2017), arXiv:1608.03983
[cs.LG]."
24,https://arxiv.org/pdf/2211.05520,"Unravelling the Performance of Physics-informed
Graph Neural Networks for Dynamical Systems
Abishek Thangamuthu, Gunjan Kumar
Department of Computer Science and Engineering
Indian Institute of Technology Delhi
New Delhi 110016, IndiaSuresh Bishnoi
School of Interdisciplinary Research
Indian Institute of Technology Delhi
New Delhi 110016, India
Ravinder Bhattoo
Department of Civil Engineering
Indian Institute of Technology Delhi
New Delhi 110016, IndiaN M Anoop Krishnan, Sayan Ranu
Yardi School of Artiﬁcial Intelligence
Indian Institute of Technology Delhi
New Delhi 110016, India
{krishnan,sayanranu}@iitd.ac.in
Abstract
Recently, graph neural networks have been gaining a lot of attention to simulate
dynamical systems due to their inductive nature leading to zero-shot generalizabil-
ity. Similarly, physics-informed inductive biases in deep-learning frameworks have
been shown to give superior performance in learning the dynamics of physical
systems. There is a growing volume of literature that attempts to combine these two
approaches. Here, we evaluate the performance of thirteen different graph neural
networks, namely, Hamiltonian andLagrangian graph neural networks, graph
neural ODE , and their variants with explicit constraints and different architectures.
We brieﬂy explain the theoretical formulation highlighting the similarities and
differences in the inductive biases and graph architecture of these systems. We
evaluate these models on spring, pendulum, gravitational, and 3D deformable solid
systems to compare the performance in terms of rollout error, conserved quantities
such as energy and momentum, and generalizability to unseen system sizes. Our
study demonstrates that GNNs with additional inductive biases, such as explicit
constraints and decoupling of kinetic and potential energies, exhibit signiﬁcantly
enhanced performance. Further, all the physics-informed GNNs exhibit zero-shot
generalizability to system sizes an order of magnitude larger than the training
system, thus providing a promising route to simulate large-scale realistic systems.
1 Introduction and Related Works
Understanding the time evolution or “dynamics” of physical systems is a long-standing problem of
interest with both fundamental and practical relevance in areas of physics, engineering, mathematics,
and biology Goldstein (2011); Karniadakis et al. (2021); LaValle (2006); Murray et al. (2017); Park
et al. (2021); Noether (1971). Traditionally, the dynamics of physical systems are expressed in terms
of differential equations with respect to their state variables, such as the position ( x(t)) or velocity
(_x(t)) Goldstein (2011); LaValle (2006). Note that the state variables are actual observable quantities
and deﬁne the conﬁgurational state of a system at any point of time t. The differential equation is
then solved with the initial and boundary conditions to predict the future states of the system. While
this conventional approach is highly efﬁcient and requires little data to predict the dynamics, in many
cases the exact differential equation may be unknown. Further, the formulation of the differential
equations might require the knowledge of abstract quantities such as the energy, or force distribution
of the system, which are not directly measurable in most cases Cranmer et al. (2020b).
36th Conference on Neural Information Processing Systems (NeurIPS 2022) Datasets and Benchmarks Track.arXiv:2211.05520v2  [cs.LG]  2 Feb 2023Figure 1: Comparison of physics-informed neural networks ( NODE,HNN, and LNN) and their
graph-counterparts ( GNODE ,HGNN,LGNN) for 3-pendulum systems. The error bar represents the
95% conﬁdence interval over 100trajectories generated from random initial conditions. Further
details of the architectures, and the datasets are discussed in § 3 and § 4.1 respectively.
To this extent, neural networks or MLPs present as efﬁcient function approximators, that can learn
the dynamics directly from the state or trajectory Karniadakis et al. (2021); Chen et al. (2018). The
learned dynamics can then be used to infer the future states of the system with different initial
conditions. It has been shown recently that the learning can be signiﬁcantly enhanced if physics-based
inductive biases are provided to these MLPs Cranmer et al. (2020a); Finzi et al. (2020); Roehrl et al.
(2020); Bhattoo et al. (2022); Bishnoi et al. (2022). Speciﬁcally, these biases allow the MLP to
preserve the characteristics of physical systems, such as energy and momentum conservation, and
thus lead to a realistic realization of a trajectory of the system Greydanus et al. (2019); Cranmer
et al. (2020a); Zhong and Leonard (2020). The most popular choices for learning dynamics are
theneural ODE (NODE) Chen et al. (2018); Gruver et al. (2021); Bishnoi et al. (2022), Lagrangian
(LNNs) Cranmer et al. (2020a); Finzi et al. (2020); Lutter et al. (2019); Bhattoo et al. (2022), and
Hamiltonian neural networks ( HNNs) Sanchez-Gonzalez et al. (2019); Greydanus et al. (2019);
Zhong et al. (2020, 2019). While NODE learns the differential equations as a parameterized neural
network Chen et al. (2018), LNNandHNNlearn the Lagrangian andHamiltonian of the system,
respectively, which is then used to predict the forward trajectory through the physics-based equation.
It is worth noting that in all these cases, the training is purely based on the trajectory or state of the
system Haitsiukevich and Ilin (2022).
One of the major disadvantages of these systems is that they are transductive in nature, that is,
they work only for the systems they are trained for. For instance, an LNNtrained for a double
pendulum can be used to infer the dynamics of a double pendulum only and not any n-pendulum.
This signiﬁcantly limits the application of LNN,HNN, and NODE to simple systems since for each
system the training trajectory needs to be generated and the model needs to be trained. It has been
shown the transductivity of MLPs could be addressed by incorporating an additional inductive
bias in the structure by accounting for the topology of the system in the graph framework using a
graph neural network ( GNN) Battaglia et al. (2016); Sanchez-Gonzalez et al. (2020); Cranmer et al.
(2020b); Sanchez-Gonzalez et al. (2019); Bhattoo et al. (2022); Bishnoi et al. (2022). GNNs, once
trained has the capability to generalize to arbitrary system sizes.
It is worth noting that most of the studies on GNNs for dynamical systems use a purely data-driven
approach, where the GNNs are used to learn the position and velocity update directly from the data.
Recently, physics-informed GNNs have been used to simulate complex physical systems Sanchez-
Gonzalez et al. (2020). In addition, since the GNNs are trained at the node and edge level, they can
potentially learn more efﬁciently from the same number of data points in comparison to their fully
connected counterparts. Figure 1 shows the energy and rollout error of NODE,LNN, and HNNwith
their graph-based counterparts, namely, G NODE , LGNN, and H GNN (detailed structure discussed in
Section 3) for 3-pendulum systems. We observe that the graph-based versions provide comparable or
better performance than their counterparts when trained on the same amount of data for the same
number of epochs. While this difference is not signiﬁcant in NODE, inLGNandHGN, we observe that
the difference is more pronounced. In addition, as demonstrated later in this work (see Section 4.3.3),
the graph-versions have the additional advantage of inductivity to generalize to larger system sizes.
Despite the wide use of GNNs to model physical systems, there exist no work thus far that systemati-
cally benchmark their performance for learning and inferring the dynamics of physical systems. In
this work, we aim to address this gap by evaluating the role of different physics-based inductive biases
inGNNs for learning the dynamics of complex systems such as n-spring and pendulum systems,
gravitational bodies, and elastically deformable 3D solid. The major contributions of the present
work are as follows.
21.Topology-aware modeling. We benchmark thirteen different physics-informed GNNs that model
physical systems. By analyzing their energy, rollout, and momentum violation, we carefully
evaluate and benchmark their performance.
2.Physics-informed inductive bias. We analyze the nature of inductive bias provided for GNNs by
Lagrangian, Hamiltonian and Newtonian mechanics in learning the dynamics, although they, in
principle, are equivalent formulations.
3.Explicit constraints. We analyze the role of providing explicit constraints as an inductive bias on
the performance of different G NNs.
4.Decoupling potential and kinetic energies. We analyze the effect of exploiting the Hamiltonian
and Lagrangian structure, which allows decoupling of kinetic and potential energies in the
Cartesian coordinates. Speciﬁcally, we evaluate how this decoupling, by modifying the graph
architecture, affect the performance of G NNs.
5.Zero-shot generalizability. Finally, we evaluate the ability of these GNNs to generalize to
arbitrary system sizes an order of magnitude larger than the systems they have been trained on.
2 Preliminaries on Learning Dynamical Systems
We consider a rigid body system comprising of ninteracting particles. The conﬁguration of this
system is represented as a set of Cartesian coordinates x(t) = (x1(t);x2(t);:::;xn(t)). Since we
are using a graph neural network to model the physical interactions, it is natural to select the Cartesian
coordinates for the features such as position as velocity. While this may result in an increased
complexity in the form of the Hamiltonian or Lagrangian, it signiﬁcantly simpliﬁes the mass matrix
for particle-based systems by making it positive deﬁnite Finzi et al. (2020) and diagonal Finzi et al.
(2020); Zhong et al. (2021a).
2.1 ODE Formulation of Dynamics
Traditionally, the dynamics of a system can be expressed in terms of the D’Alembert’s principle
as LaValle (2006)
Mx F(x;_x) = 0 (1)
where, in Cartesian coordinates, Mis the constant mass matrix that is independent of the coordi-
nates Zhong et al. (2021a), and Frepresents the dynamics of the system. Accordingly, the acceleration
xof the system can be computed as:
x=M 1(F(x;_x)) (2)
In case of systems with constraints, for instance a pendulum system where the length between the
two bobs are maintained constant, Eq. 1 can be modiﬁed to feature the constraints explicitly LaValle
(2006); Murray et al. (2017).
Mx F(x) +AT= 0 (3)
Here, the constraints of the system are given by A(x)_x= 0, whereA(x)2RkDrepresentsk
constraints associated with the Ddegrees of freedom (See App. A for details on why constraints are
expressed through this form). Thus, Arepresents the non-normalized basis of constraint forces given
byA=rx(), whereis the matrix corresponding to the constraints of the system and is the
Lagrange multiplier corresponding to the relative magnitude of the constraint forces.
To solve for, the constraint equation can be differentiated with respect to time to obtain Ax+_A_x= 0.
Substituting for xfrom Eq. 3 and solving for , we get:
= (AM 1AT) 1(AM 1(F) +_A_x) (4)
Accordingly, xcan be obtained as:
x=M 1
F AT(AM 1AT) 1
AM 1(F) +_A_x
(5)
2.2 Lagrangian Dynamics
The standard form of Lagrange’s equation for a system with holonomic constraints is given by
d
dt(r_xL) (rxL) = 0 (6)
where the Lagrangian is L(x;_x;t) =T(x;_x;t) V(x;t)withT(x;_x;t)andV(x;t)representing
the total kinetic energy of the system and the potential function from which generalized forces
3can be derived, respectively. Accordingly, the dynamics of the system can be represented using
Euler-Lagrange (EL) equations as
x= (r_x_xL) 1[rxL (r_xxL)_x] (7)
Here,r_x_xrefers to@2
@_x2. In systems with constraints, the Lagrangian formulation can be modiﬁed to
include the explicit constraints LaValle (2006). Accordingly, the acceleration can be computed as
x=r_x_xL
 r_xxL_x r xL AT(A(r_x_xL) 1AT) 1
A(r_x_xL) 1( r_xxL_x r xL) +_A_x
(8)
In Cartesian coordinates, the Lagrangian simpliﬁes to L(x;_x) =1
2_xTM_x V(x). Exploiting
the structure of Lagrangian by decoupling the kinetic and potential energies, and substituting this
expression in Eq. 8, we obtain M=r_x_xLas a constant matrix independent of coordinates, C=
r_xxL= 0, and F=rxV(x). Accordingly, the xcan be obtained as
x=M 1
 r xV(x) AT(AM 1AT) 1
AM 1( r xV(x)) + _A_x
(9)
2.3 Hamiltonian Dynamics
Hamiltonian equations of motion are given by
x=rpxH; _px= r xH (10)
where, px=r_xL=M_xrepresents the momentum of the system in Cartesian coordinates and
H(x;px) =_xTpx L(x;_x) =T(_x) +V(x)represents the Hamiltonian of the system. The equation
can be simpliﬁed by assuming Z= [x;px]andJ= [0;I; I;0]then the Hamiltonian equation can
be written as
rZH+J_Z= 0 (11)
Note that this coupled ﬁrst order differential equations are equivalent to the Lagrangian Eq. 7.
In systems with constraints, the Hamiltonian equations of motion can be modiﬁed to feature the
constraints explicitly, similar to the Lagrangian and ODE formulations. Hamiltonian equations with
explicit constraints can be written as Zhong et al. (2021a)
rZH+J_Z+ (DZ	)T= 0 (12)
where, (DZ	)Trepresents the effect of constraints on both the equations. Here, 	(Z) = (; _)
and = ( x) = 0 represent the constraints equation, which implies 	(Z) = 0 . Thus, (DZ	)_Z= 0.
Substituting for _Zand solving for yields
= [(DZ	)J(DZ	)T] 1[(DZ	)J(rH)] (13)
Substituting this value into the Eq. 12 and solving for _Zyields
_Z=J[rZH (DZ	)T[(DZ	)J(DZ	)T] 1(DZ	)JrZH] (14)
2.4 Physics-informed G NNs
Data-driven GNNs take a given conﬁguration as input and predict the updated conﬁguration Battaglia
et al. (2016). Instead, physics-informed GNNs take the conﬁguration (position and velocity) as input
and predict abstract quantities such as Lagrangian orHamiltonian or force. These output values are
then used along with physics-based equations (as deﬁned in § 2.1-2.3) to obtain the updated trajectory.
Thus, in physics-informed GNNs, the neural network essentially learns the function relating the
position and velocity to quantities such as force or energy, by training on trajectory.
3 Models Studied
In this section, we describe the models studied in this work. An overview of the models and the
relationship between them is presented in Fig. 2. Speciﬁcally, the full graph network Sanchez-
Gonzalez et al. (2020) lies at the root, i.e., the base G NNmodel. On this basic framework, we study
the impact of physics-based inductive biases in the form of Neural ODE, Lagrangian and Hamiltonian
dynamics. Each of these inductive biases is further reﬁned through the injection of explicit constraints
4Figure 2: An overview of the various models being benchmarked and the relationship between them.
Here, “Decoupled” indicates the model variety where the kinetic and potential energies are decoupled
with the force being a function of only the position and the mass matrix being diagonal in nature.
and “decoupled” modeling of the potential and kinetic energies. We next explain each of these
speciﬁc models. Note that the detailed architecture of the models are not discussed since they are
available in the original papers that introduced the works. Accordingly, we mention the names of the
models used in this study, and their major features.
Full Graph Network (FG NN)Sanchez-Gonzalez et al. (2020): FGNNis amessage-passing GNN,
wherein each node v(and potentially edges as well) draws “messages” from its 1-hop neighbors (i.e.,
their representations in the form of feature vectors), and passes these messages through a multi-layer
perceptron ( MLP) to construct v’s own representation. An FGNNof`layers, therefore, learns node
representations that capture the topology of the `-hop neighborhood around each node. FGNN
attempts to directly predict the property being modeled (such as acceleration) without exploiting
any physics-informed inductive biases.
FGNODE Sanchez-Gonzalez et al. (2019): FGNODE refers to a neural ODE version of FGNN. In
FGNODE , the particle positions and velocities are given as the input to each node, while the difference
in the position of nodes is given as a feature to each edge. The node-level output of the model is the
acceleration on each node, which is then integrated to obtain the updated position and velocity using
Eq. 2.
GNODE :GNODE is equivalent to FGNODE with a minor modiﬁcation in the architecture Bishnoi
et al. (2022). Speciﬁcally, we note that in particle-based systems in Cartesian coordinates, the kinetic
and potential energies can be decoupled with the force being a function of only the position and the
mass matrix being diagonal in nature Finzi et al. (2020); Lutter et al. (2019); Zhong et al. (2021a);
Bishnoi et al. (2022). Thus, for GNODE , only the position of the particle is given as a node input and
not the velocity, which is then used to predict the node-level acceleration using Eq. 2. Further details
of this architecture is provided in App. C.
CFG NODE and CG NODE :CFG NODE andCG NODE areFGNODE andGNODE with explicit
constraints Finzi et al. (2020) as given by Eq. 5, respectively.
Lagrangian Graph Network (L GN) Cranmer et al. (2020a): Here, the graph architecture, which
is an FGNN, directly predicts Lagrangian of the system. The acceleration is then predicted from the
Lagrangian using Euler-Lagrange equation (Eq. 8).
LGNN :LGNN improves on LGN, where the kinetic and potential energies are decoupled Bhattoo
et al. (2022). Further, the potential energy is predicted using a GNNwith the position as the node input
and distance between the nodes as the edge input. The diagonal nature of mass matrix in particle-
based rigid body systems in Cartesian coordinates is exploited to learn the parametric masses Cranmer
et al. (2020a); Finzi et al. (2020); Lutter et al. (2019). Further details of this architecture is provided
in App. D.
CLGNand CL GNN :CLGNandCLGNN refers to LNNandLGNN with explicit constraints
respectively. Speciﬁcally, the acceleration is computed using Eq. 9 Bhattoo et al. (2022); LaValle
(2006); Finzi et al. (2020).
5Figure 3: (From left to right) Visualizations of the systems considered, namely, 3-pendulum, 5-spring,
elastically deformable 3D solid, and 4-body gravitational system.
HGN:HGNrefers to Hamiltonian graph network, where the Hamiltonian of a system is predicted
using the full graph network Sanchez-Gonzalez et al. (2020, 2019). Further, the acceleration is
computed using Eq. 11.
HGNN :HGNN refers to Hamiltonian graph neural network, where the structure of the Hamiltonian
of a system is exploited to decouple it into potential and kinetic energies Bhattoo et al. (2022);
Sanchez-Gonzalez et al. (2019); Greydanus et al. (2019). Further, the potential energy is predicted
using the GNNand the diagonal mass matrix is trained as a learnable parameter. The acceleration
is then predicted using Eq. 11. Further details of H GNN is provided in App. E.
CH GNand CH GNN :CH GNandCH GNN refer to HGNandHGNN with explicit constraints
respectively (Eq. 12-Eq. 14).
4 Benchmarking Evaluation
In this section, we conduct in-depth empirical analysis of the architectures discussed in § 3. To
evaluate the models, we consider four systems (see Fig. 3), namely, n-pendulums with n= (3;4;5),
n-springs where n= (3;4;5), 4-body gravitational system and an elastically deformable 3D solid
discretized as particles. All the simulations and training were carried out in the JAX environ-
ment Schoenholz and Cubuk (2020); Bradbury et al. (2020). The graph architecture was developed
using the jraph package Godwin* et al. (2020). The experiments were conducted on a linux machine
running Ubuntu 18.04 LTS with Intel Xeon processor and 128GB RAM. All codes and data used in
the benchmarking study are available at https://github :com/M3RG-IITD/benchmarking _graph and
https://doi:org/10:5281/zenodo :7015041, respectively.
4.1 Data Generation and Training
Data generation. The training data is generated by forward simulation using the known kinetic and
potential energies of the systems employing physics-based equations. The timestep used for the
forward simulation of the pendulum system is 10 5swith the data collected every 1000 timesteps. For
the spring system, the timestep is 10 3swith the data collected every 100 timesteps. Integration of the
equations of motion is performed using the velocity-Verlet algorithm. In both systems, 100 datapoints
are collected from each trajectory and 100 such trajectories based on random initial conditions are
used to generate ground truth. This resulted in a total of 10,000 training datapoints for each system.
Further details of the experimental systems used for the data generation are provided in the App. B.
Trajectory prediction and training. Based on the predicted x, the positions and velocities are
predicted using the velocity Verlet integration. The loss function is computed by using the predicted
and actual accelerations at timesteps 2;3;:::;Tin a trajectory T, which is then back-propagated to
train the G NNs. Speciﬁcally, the loss function is as follows.
L=1
n nX
i=1
xT;t
i 
^xT;t
i2!
(15)
Here,
^xT;t
i
is the predicted acceleration for the ithparticle in trajectory Tat timetandxT;t
iis
the true acceleration. Tdenotes a trajectory from T, the set of training trajectories. Note that the
accelerations are computed directly from the ground truth trajectory using the Verlet algorithm as:
xi(t) =1
(t)2[xi(t+ t) +xi(t t) 2xi(t)] (16)
Since the integration of the equations of motion for the predicted trajectory is also performed using
the same algorithm as: xi(t+ t) = 2xi(t) xi(t t) + xi(t)2, this method is equivalent to
training from trajectory (i.e, positions).
6Figure 4: Geometric mean of rollout error and energy error for 3-, 4-, 5-spring and 3-,4-,5-pendulum
systems without constraints for LGNN,LGN,HGN,HGNN ,GNODE ,FGNODE andFGNN. The
error bar represents the 95% conﬁdence interval over 100 trajectories generated from random initial
conditions.
We use 10000 data points generated from 100 trajectories to train all the models. This dataset is
divided randomly in 75:25 ratio as training and validation set. All models were trained till the decrease
in loss saturates to less than 0.001 over 100 epochs. The model performance is evaluated on a test set
containing 100forward trajectories of 1sin the case of pendulum and 10sin the case of spring. Note
that this trajectory is 4-5orders of magnitude larger than the training trajectories from which the
training data has been sampled. The dynamics of n-body system is known to be chaotic for n2.
Hence, all the results are averaged over trajectories generated from 100 different initial conditions.
The default hyper-parameter values are listed in App. G.4. In addition, we have performed extensive
hyper-parameter search to measure their effect on the architectures, the details of which are provided
in App. G.5.
4.2 Evaluation Metric
Following the work of Finzi et al. (2020), we evaluate performance by computing the relative error
in three different quantities as detailed below. (1) Rollout Error: Relative error in the trajectory,
known as the rollout error , is given by RE(t) =jj^x(t) x(t)jj2
jj^x(t)jj2+jjx(t)jj2.(2) Energy violation: The error in
energy violation is given by EE(t) =jj^H Hjj2
(jj^Hjj2+jjHjj2).(3) Momentum conservation: The relative
error in momentum conservation is ME(t) =jj^M Mjj 2
jj^Mjj 2+jjMjj 2Note that all the variables with a hat, for
example ^x, represent the predicted values based on the trained model and the variables without hat,
x, represent the ground truth. To summarize the performance over a trajectory, following previous
works Finzi et al. (2020), we use the geometric mean of relative error of each of the quantities above
since the error compounds with time.
4.3 Results on Pendulum and Spring systems
For springs and pendulums, the models are trained on 5-spring, and 3-pendulum systems. The
trained models are evaluated on unseen system sizes to evaluate their performance on zero-shot
generalizability. To benchmark generalization ability to even larger unseen systems, we simulate 5-,
10-,20-pendulum system and 5-,20-,50-spring systems. To compare the performance efﬁciently, we
group the systems without and with explicit constraints separately.
4.3.1 Trajectory error and energy conservation
Systems without explicit constraints. Figure 4 shows the geometric mean of rollout and energy
error of LGNN,LGN,HGN,HGNN,GNODE ,FGNODE andFGNN for 3-, 4-, 5-spring and pendulum
systems. Fig. 5 shows the evolution of these errors with respect to time. Note that all the systems are
trained on 3-pendulum or 5-spring systems alone and performance is evaluated by forward simulation
on other systems. The error bar represents the 95% conﬁdence interval obtained based on 100
trajectories generated from different initial conditions. First, we analyze the response on the spring
systems (see Fig. 4 top row). We observe that the HGNN exhibits minimum error. This is followed by
LGNN andHGNboth of which comparable error but higher than that of HGNN. These systems are
followed by GNODE . Finally, FGNN exhibits the maximum error. This result is not surprising since
FGNN is not physics-informed and learns directly from data.
7Figure 5: Rollout error and energy error for 3-, 4-, 5-spring and 3-, 4-, 5-pendulum systems without
constraints with respect to time for LGNN,LGN,HGN,HGNN,GNODE ,FGNODE andFGNN. The
curve represents the average over 100 trajectories generated from random initial conditions.
Figure 6: Geometric mean of rollout error and energy error for 3-,4-,5-pendulum systems with
constraints for CLGNN,CLGN,CHGN,CHGNN,CGNODE , and CFG NODE . The error bar represents
the 95% conﬁdence interval over 100 trajectories generated from random initial conditions.
Now, we focus on the pendulum systems (see Fig. 4 bottom row). Interestingly, in this case, we
observe that HGNexhibits a slightly higher error. It is worth noting that the dynamics of spring
system is primarily governed by the internal interactions between the balls connected by the springs.
In contrast, in pendulum systems, the dynamics is primarily governed by the external gravitational
ﬁeld and the connections simply serve as constraints. These results suggest that in systems, where
the dynamics is governed primarily by the internal interactions, the architecture of the graph plays a
major role with HGNN exhibiting the best performance for the spring systems. FGNN continues to
perform poorly in pendulum systems, particularly in energy violation.
In summary, two key observations emerge from these experiments. First, HGNN consistently provides
the lowest error across all setup, with it being more pronounced on spring systems, potentially due to
its ﬁrst-order nature. Second, the decoupled architectures are consistently better (i.e., GNODE and
HGNN produces lower error than FG NODE and H GNrespectively), which could be attributed to the
ability of GNNs to learn the parametric masses and potential energy functions, independently and
uniquely. This observation is consistent with previous works on MLPs where decoupling is found
to have signiﬁcantly improved the performance of HNNandLNNZhong et al. (2021a); Finzi et al.
(2020); Lutter et al. (2019).
Systems with explicit constraints. Figure 6 shows the performance of the constrained architectures
for pendulum systems. Figure 7 shows the time evolution of energy and rollout error. Note that in
the spring system there are no explicit constraints. Hence, these approaches will be equivalent to
Figure 7: Rollout error and energy error for 3-,4-,5-pendulum systems with constraints with respect
to time for CLGNN,CLGN,CHGN,CHGNN,CGNODE , and CFG NODE . The curve represents the
average over 100 trajectories generated from random initial conditions.
8learning without constraints in the spring systems as the constraints terms in the equations vanish.
We observe that the error in systems with explicit constraints are signiﬁcantly lower than that without
explicit constraints. Similar behavior was observed for fully-connected architectures earlier Finzi
et al. (2020).
We also observe that CLGNexhibits the maximum error on average, followed closely by CH GN.
The poor performance of CLGNis not surprising. In pendulum systems, the potential energy of the
system depends on the position of the bob. However, in LGNorHGNfamily of architectures, the
actual position of the particle is not given as an input to the graph, rather the edge distance is given as
an input. Thus, it is not possible for an LGNorHGNto learn the dynamics of the pendulum system.
To address this, we train CLGNandCH GNby giving the position of the bob explicitly as a node
input feature. However, despite providing this input, we observe that the ﬁnal model obtained after
training has high loss in comparison to other models.
4.3.2 Momentum conservation
Figure 8: Momentum error for spring systems 3-, 4-, and
5- spring systems for LGNN,LGN,HGN,HGNN,GNODE ,
FGNODE andFGNN. The curve represents the average over
100 trajectories generated from random initial conditions.While most of the previous studies
have focused on energy and rollout
error, very few studies have analyzed
the momentum error in the trajectory
predicted by these systems. It should
be noted that conservation of momen-
tum is one of the fundamental laws
(as much as the energy conservation),
which physical systems are expected
to follow. While violation of energy
conservation results in spurious gen-
eration or dissipation of energy in the
system, violation of momentum con-
servation results in such effects in the
total force on a particle in the system. This, in turn, affects the force equilibrium of a system. Figure 8
shows the evolution of momentum error in FGNN,FGNODE ,GNODE ,HGN,HGNN,LGNandLGNN
for 3-, 4-, and 5-spring systems. Interestingly, we observe that LGNN exhibits least momentum error
with a stable value over time. This suggests that the momentum error in the LGNN is saturated and
does not diverge over time. Although HGNN exhibits comparable errors, we observe that the value
increases with respect to time suggesting a potential divergence at long time scales. This is followed
byHGN, which exhibits a momentum error that 4 orders of magnitude larger. While FGNODE
andGNODE exhibits comparable momentum error at smaller length scales of trajectory, FGNODE
diverges signiﬁcantly faster that GNODE , leading to large unrealistic errors. The improved performed
ofLGNN andHGNN could be attributed to the decoupling of kinetic and potential energies, and the
computation of the potential energy at the edge level, which enforces the momentum conservation
indirectly due to the translational symmetry. These results reafﬁrm that, in interacting systems, the
graph architecture and the nature of the inductive bias ( NODE vsLNNvsHNN) play crucial roles in
governing the stability of the system.
4.3.3 Generalizability to unseen system sizes
Now, we analyze the ability of the GNNs to generalize to unseen system sizes. To this extent,
we evaluate the performance of the constrained systems for 5-, 10-, and 20-link pendulums and
unconstrained systems for 5-, 20-, and 50-link springs. Note that the constrained systems are
considered for the pendulum as they exhibit superior performance in comparison to the unconstrained
versions. Figure 9 shows the geometric mean of rollout and energy error for these systems. First,
we observe that all the graph-based systems exhibit zero-shot generalizability to systems that are
almost an order of magnitude larger than the training data with similar errors in both energy and
rollout. Further, we observe that the trend in the error for the systems for pendulum and spring
systems remain consistent with increasing system sizes. This suggests that there is no additional error
added to any of the models considered due to zero-shot generalization. This conﬁrms the superiority
of physics-informed GNNs over the traditional MLPs to generate large-scale realistic systems after
learning on a signiﬁcantly smaller system.
4.4 Gravitational and 3D solid systems
To test the performance of the models on more complex systems, we consider a 4-body gravitational
system and a 3D solid system (see Fig. 3). For gravitational system, a stable four body conﬁguration
9Figure 9: Geometric mean of rollout and energy error for zero-shot generalizability to unseen
system sizes for pendulum systems with FGNN,CLGN,CLGNN,CH GN,CH GNN,CG NODE , and
CFG NODE and spring systems with FGNN,LGN,LGNN,HGN,HGNN,GNODE ,FGNODE . The
error bar represents the 95% conﬁdence interval over 100 trajectories generated from random initial
conditions.
Figure 10: (left to right) Geometric mean of rollout error, energy error for 4-body gravitational system
forLGNN,LGNHGN,HGNN,GNODE ,FGNODE andFGNN. Geometric mean of rollout error and
momentum error for rigid body system for HGN,HGNN,GNODE ,FGNODE andFGNN. The error bar
represents the 95% conﬁdence interval over 100 trajectories generated from random initial conditions.
interacting with each other through the gravitational law and having initial velocities such that they
rotate with respect to a common centre is considered (see: App. B). Figure 10 shows the time
evolution of energy and rollout error for these systems. We observe that LGNN exhibits the lowest
error followed by H GNN. This is followed by L GNand G NODE which exhibits comparable errors.
Now, we evaluate the performance on the elastic deformation of a 3D solid cube. For this, a 555
solid cube, discretized into 125particles, is used for simulating the ground truth in the peridynamics
framework. The system is compressed isotropically and then released to simulate the dynamics of the
solid, that is, the contraction and expansion in 3D as a function of time. Figure 10 shows the rollout
and momentum error for this system (see Fig. 16 for time evolution). Interestingly, we ﬁnd that the
rollout and momentum error for all the models are comparable. This could be attributed to the nature
of deformation of the structure, which exhibits only small displacements within the elastic regime.
Note that this dynamics is much simpler and non-chaotic in nature. Thus, all the models are able to
learn and infer the dynamics with similar accuracy. It may be concluded from this experiment that for
dynamics that is not chaotic and relatively small in terms of magnitude, physics-informed GNNs may
not have any additional advantage over the data-driven ones.
5 Concluding Insights
In this work, we benchmark the performance of thirteen different physics-informed GNNs for
simulating interacting physical systems such as springs and pendulums. The key insights drawn from
our study are summarized below:
•Architecture matters: We show the nature of the inductive bias provided by the ODE, Hamiltonian
and Lagrangian equations lead to different performances for the same graph architecture, although
these equations are, in-principle, equivalent Zhong et al. (2021a). Speciﬁcally, the ODE and
Lagrangian formulations result in a second-order differential equation, while the Hamiltonian
formulation results in a ﬁrst-order differential equation.
10•Physics-informed G NNs are better: All of the physics-informed GNNs exhibit better performance
than FGNN, that is learning purely from data except in the case of small displacements that are
non-chaotic in nature (elastic deformation of 3D solid). The inductive bias provided for learning
and inference by Lagrangian, Hamiltonian, and Newtonian mechanics to GNNs are clearly distinct,
although the formulations are equivalent in principle.
•Constraints help: Incorporating constraints explicitly as an inductive bias signiﬁcantly simpliﬁes
the learning (see Fig. 14) and enhances the performance of all the graph-based models.
•Kinetic and potential energies should be decoupled: We observe that exploiting the fact that
the kinetic and potential energies can be decoupled (in Cartesian coordinates) leads to improved
performance in all the models— GNODE better than FGNODE ,HGNN better than HGN, and LGNN
better than LGNfor most systems. This decoupling exhibits a signiﬁcantly stronger enforcement of
the momentum conservation error. This could be attributed to the fact that, when the potential and
kinetic energies are decoupled, additional spurious cross-terms involving both xand_xmay not be
learned by the model, which leads to lower error in the governing equation and the momentum error.
•Zero-shot generalizability: We show that all the graph-based models generalize to larger systems
with comparable error as the smaller systems. Thus, a graph-based simulator with low error in small
systems shall also exhibit similar error in signiﬁcantly larger systems—thanks to their inductive bias.
•The L GNfamily is slow to train: Due to the double derivative present in the Lagrangian, the
LGNfamily exhibits highest training and inference times in comparison to other models (See
App. H). These slow running times do not provide any beneﬁt on accuracy. Hence, GNODE and
HGNprovide better efﬁciency-efﬁcacy balance while making a G NNphysics-informed.
Limitations and outlook. Our results clearly highlight the importance of constraints. Current
physics-informed GNNs require these constraints to be explicitly incorporated. An important future
direction of research would therefore be to learn the constraints directly from the trajectory. In
addition, incorporating deformations, contacts, and other realistic phenomena remains to be explored
in physics-informed graph architecture, although similar approaches have been employed in fully
connected MLPs Zhong et al. (2020, 2021b). Finally, we observe that there is a 10-fold increase in
error in the presence of noise in the training data (see App. F.2). This behavior points towards the
need to build architectures that are more robust to noise.
Acknowledgments
The authors thank IIT Delhi HPC facility for computational and storage resources.
References
Battaglia, P., Pascanu, R., Lai, M., Jimenez Rezende, D., et al. (2016). Interaction networks for
learning about objects, relations and physics. Advances in neural information processing systems ,
29.
Bhattoo, R., Ranu, S., and Krishnan, N. M. A. (2022). Learning the dynamics of particle-based
systems with lagrangian graph neural networks. arXiv preprint arXiv:2209.01476 .
Bishnoi, S., Bhattoo, R., Ranu, S., and Krishnan, N. M. A. (2022). Enhancing the inductive biases of
graph neural ode for modeling dynamical systems. arXiv preprint arXiv:2209.10740 .
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M. J., Leary, C., Maclaurin, D., and Wanderman-
Milne, S. (2020). Jax: composable transformations of python+ numpy programs, 2018. URL
http://github. com/google/jax , 4:16.
Chen, R. T., Rubanova, Y ., Bettencourt, J., and Duvenaud, D. (2018). Neural ordinary differential
equations. In Proceedings of the 32nd International Conference on Neural Information Processing
Systems , pages 6572–6583.
Cranmer, M., Greydanus, S., Hoyer, S., Battaglia, P., Spergel, D., and Ho, S. (2020a). Lagrangian
neural networks. In ICLR 2020 Workshop on Integration of Deep Neural Models and Differential
Equations .
Cranmer, M., Sanchez Gonzalez, A., Battaglia, P., Xu, R., Cranmer, K., Spergel, D., and Ho, S.
(2020b). Discovering symbolic models from deep learning with inductive biases. Advances in
Neural Information Processing Systems , 33.
11Finzi, M., Wang, K. A., and Wilson, A. G. (2020). Simplifying hamiltonian and lagrangian neural
networks via explicit constraints. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F.,
and Lin, H., editors, Advances in Neural Information Processing Systems , volume 33, pages
13880–13889. Curran Associates, Inc.
Godwin*, J., Keck*, T., Battaglia, P., Bapst, V ., Kipf, T., Li, Y ., Stachenfeld, K., Veli ˇckovi ´c, P., and
Sanchez-Gonzalez, A. (2020). Jraph: A library for graph neural networks in jax.
Goldstein, H. (2011). Classical mechanics . Pearson Education India.
Greydanus, S., Dzamba, M., and Yosinski, J. (2019). Hamiltonian neural networks. Advances in
Neural Information Processing Systems , 32:15379–15389.
Gruver, N., Finzi, M. A., Stanton, S. D., and Wilson, A. G. (2021). Deconstructing the inductive
biases of hamiltonian neural networks. In International Conference on Learning Representations .
Haitsiukevich, K. and Ilin, A. (2022). Learning trajectories of hamiltonian systems with neural
networks. arXiv preprint arXiv:2204.05077 .
Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., and Yang, L. (2021). Physics-
informed machine learning. Nature Reviews Physics , 3(6):422–440.
LaValle, S. M. (2006). Planning algorithms . Cambridge university press.
Lutter, M., Ritter, C., and Peters, J. (2019). Deep lagrangian networks: Using physics as model prior
for deep learning. In International Conference on Learning Representations .
Murray, R. M., Li, Z., and Sastry, S. S. (2017). A mathematical introduction to robotic manipulation .
CRC press.
Noether, E. (1971). Invariant variation problems. Transport theory and statistical physics , 1(3):186–
207.
Park, C. W., Kornbluth, M., Vandermause, J., Wolverton, C., Kozinsky, B., and Mailoa, J. P. (2021).
Accurate and scalable graph neural network force ﬁeld and molecular dynamics with direct force
architecture. npj Computational Materials , 7(1):1–9.
Roehrl, M. A., Runkler, T. A., Brandtstetter, V ., Tokic, M., and Obermayer, S. (2020). Modeling
system dynamics with physics-informed neural networks based on lagrangian mechanics. IFAC-
PapersOnLine , 53(2):9195–9200.
Sanchez-Gonzalez, A., Bapst, V ., Cranmer, K., and Battaglia, P. (2019). Hamiltonian graph networks
with ode integrators. arXiv e-prints , pages arXiv–1909.
Sanchez-Gonzalez, A., Godwin, J., Pfaff, T., Ying, R., Leskovec, J., and Battaglia, P. (2020).
Learning to simulate complex physics with graph networks. In International Conference on
Machine Learning , pages 8459–8468. PMLR.
Schoenholz, S. and Cubuk, E. D. (2020). Jax md: a framework for differentiable physics. Advances
in Neural Information Processing Systems , 33.
Zhong, Y . D., Dey, B., and Chakraborty, A. (2019). Symplectic ode-net: Learning hamiltonian
dynamics with control. In International Conference on Learning Representations .
Zhong, Y . D., Dey, B., and Chakraborty, A. (2020). Dissipative symoden: Encoding hamiltonian
dynamics with dissipation and control into deep learning. arXiv preprint arXiv:2002.08860 .
Zhong, Y . D., Dey, B., and Chakraborty, A. (2021a). Benchmarking energy-conserving neural
networks for learning dynamics from data. In Learning for Dynamics and Control , pages 1218–
1229. PMLR.
Zhong, Y . D., Dey, B., and Chakraborty, A. (2021b). Extending lagrangian and hamiltonian neural
networks with differentiable contact models. Advances in Neural Information Processing Systems ,
34.Zhong, Y . D. and Leonard, N. (2020). Unsupervised learning of lagrangian dynamics from images
for prediction and control. Advances in Neural Information Processing Systems , 33.
Supplementary: Unravelling the Performance of
Physics-informed Graph Neural Networks for
Dynamical Systems
Abishek Thangamuthu, Gunjan Kumar
Department of Computer Science and Engineering
Indian Institute of Technology Delhi
New Delhi 110016, IndiaSuresh Bishnoi
School of Interdisciplinary Research
Indian Institute of Technology Delhi
New Delhi 110016, India
Ravinder Bhattoo
Department of Civil Engineering
Indian Institute of Technology Delhi
New Delhi 110016, IndiaN M Anoop Krishnan, Sayan Ranu
Yardi School of Artiﬁcial Intelligence
Indian Institute of Technology Delhi
New Delhi 110016, India
{krishnan,sayanranu}@iitd.ac.in
A Expressing constraints
A constraint on a system essentially restricts the motion of a system to a subspace among all the
allowable paths. For instance, in the case of two particles with the coordinates (x;y)and(0;0)
connected by an in-extensible rod, the constraint equation can be given as (x2+y2) =l2. Such
constraints are known holonomic constraints. However, a different set of constraints act in cases such
as multi-ﬁngered grasping, known as Pfafﬁan constraints, where instead of positions, constraints
are enforced on velocities. The generic form of a Pfafﬁan constraint is A(x)_x= 0. Note that
any holonomic constraint can also be written in the form of a Pfafﬁan constraint by differentiating
the original form. For instance, the constraint equation for two particles mentioned earlier can be
differentiated to obtain x_x+y_y= 0, which is of the form A(x)_x= 0. For the sake of generality,
here we adopt this form to express the constraints. More details on this can be found in the Section 1,
Chapter 6 of Murray et al. (Murray, R.M., Li, Z. and Sastry, S.S., 2017. A mathematical introduction
to robotic manipulation. CRC press.)
B Experimental systems
To simulate the ground truth, physics-based equations derived using Lagrangian mechanics is em-
ployed. The equations for n-pendulum and spring systems are given in detail below.
B.1n-Pendulum
For ann-pendulum system, n-point masses, representing the bobs, are connected by rigid (non-
deformable) bars. These bars, thus, impose a distance constraint between two point masses as
jjxi xi 1jj2=l2
i (17)
where,lirepresents the length of the bar connecting the (i 1)thandithmass. This constraint can
be differentiated to write in the form of a Pfafﬁan constraint as
(xi xi 1)( _xi _xi 1) = 0 (18)
36th Conference on Neural Information Processing Systems (NeurIPS 2022) Datasets and Benchmarks Track.
13Note that such constraint can be obtained for each of the nmasses considered to obtain the A(q).
The Lagrangian of this system can be written as
L=nX
i=1
1=2mi_xiT_xi migx(2)
i
(19)
wheremirepresents the mass of the ithparticle,grepresents the acceleration due to gravity in the
x(2)direction and x(2)represents the position of the particle in the x(2)direction.
B.2n-spring system
Here,n-point masses are connected by elastic springs that deform linearly (elastically) with extension
or compression. Note that similar to the pendulum setup, each mass miis connected to two masses
mi 1andmi+1through springs so that all the masses form a closed connection. The Lagrangian of
this system is given by
L=nX
i=11=2mi_xiT_xi nX
i=11=2k(jjxi 1 xijj r0)2(20)
wherer0andkrepresent the undeformed length and the stiffness, respectively, of the spring.
B.3n-body gravitational system
Here,npoint masses are in a gravitational ﬁeld generated by the point masses themselves. The
Lagrangian of this system is given by
L=nX
i=11=2mi_xiT_xi+nX
i=1nX
j=1;j6=iGmimj=2(jjxi xjjj) (21)
whereGrepresents the Gravitational constant.
B.4 Rigid-body system
Here, in a solid cube of 555size, the dynamics of an elastically deformable body is simulated.
Speciﬁcally, a 555solid cube, discretized into 125particles, is used for simulating the ground
truth. 3D solid system is simulated using the peridynamics framework. The system is compressed
isotropically and then released to simulate the dynamics of the solid, that is, the contraction and
expansion in 3D.
C Graph Neural ODE (G NODE )
To learn the dynamical systems, GNODE s parameterize the dynamics F(x;_x;t)using a neural network
to learn the approximate function ^F(xt;_xt;t)by minimizing the loss between the predicted and
actual trajectories, that is, L=jjxt+1 ^xt+1jj. Thus, a GNODE essentially uses graph topology
to learn the approximate dynamics ^Fby training directly from the trajectory. Figure 11 shows the
architecture of the G NODE , which is discussed in detail below.
Graph structure. First, ann-particle system is represented as a undirected graph G=fV;Eg,
where the nodes represent the particles and the edges represents the connections or interactions
between them. For example, in pendulum or spring systems, the nodes correspond to bobs or balls,
respectively, and the edges correspond to the bars or springs, respectively.
Input features. Each node is characterized by the features of the particles, namely, the particle type
(t),position (xi), and velocity (_xi). The type distinguishes particles of differing characteristics, for
instance, balls or bobs with different masses. Further, each edge is represented by the edge features
wij= (xi xj), which represents the relative displacement of the nodes connected by the given
edge.
Pre-Processing. In the pre-processing layer, we construct a dense vector representation for each
nodeviand edgeeijusing MLPemas:
h0
i=squareplus (MLPem(one-hot (ti);xi;_xi)) (22)
h0
ij=squareplus (MLPem(wij)) (23)
14Figure 11: G NODE architecture.
squareplus is an activation function. Note that the MLPemcorresponding to the node and edge
embedding functions are parameterized with different weights. Here, for the sake of brevity, we
simply mention them as MLPem.
Acceleration prediction. In many cases, internal forces in a system that govern the dynamics are
closely dependent on the topology of the structure. To capture this information, we employ multiple
layers of message-passing between the nodes and edges. In the lthlayer of message passing, the
node embedding is updated as:
hl+1
i=squareplus0
@hl
i+X
j2N iWl
V 
hl
jjjhl
ij1
A (24)
where,Ni=fvj2Vjeij2Eg are the neighbors of vi.Wl
Vis a layer-speciﬁc learnable weight
matrix. hl
ijrepresents the embedding of incoming edge eijonviin thelthlayer, which is computed
as follows.
hl+1
ij=squareplus 
hl
ij+Wl
E 
hl
ijjhl
j
(25)
Similar to Wl
V,Wl
Eis a layer-speciﬁc learnable weight matrix speciﬁc to the edge set. The
message passing is performed over Llayers, where Lis a hyper-parameter. The ﬁnal node and edge
representations in the Lthlayer are denoted as hL
iandhL
ijrespectively.
In addition to the internal forces, there could be forces that are independent of the topology and
depend only on the features of the particle, for example, gravitational force. To account for these, an
additional node embedding that is not included in the message passing, namely, hg
iis concatenated
with the ﬁnal node representation after message passing as zi= (hL
ijjhg
i). Finally, the acceleration
of the particle qiis predicted as:
xi=squareplus (MLPV(zi)) (26)
Note that the major difference between GNODE andFGNODE , in addition to the other parametric
and architectural differences, is the inclusion of this additional global feature embedding in GNODE ,
which is absent in FGNODE . As seen earlier, inclusion of this additional embedding signiﬁcantly
improves the performance in cases where there are forces due to external ﬁelds such as gravity.
D Lagrangian Graph Neural Network (L GNN )
Figure 12 shows the the neural network architecture of the LGNN. The architecture directly predicts
the Lagrangian of the system exploiting the topology of the system encoded as graph. Note that
the graph structure, input features, pre-processing and the message passing leading to intermediate
embedding of nodes and edges for LGNN are developed exactly following the same as GNODE ,
15Figure 12: L GNN architecture.
detailed as per section C. Two major differences for LGNN from GNODE is in the computation of the
kinetic energy and the potential energy, which are absent in G NODE , as detailed below.
Kinetic energy. Since the system is comprised of n-point particles, the mass matrix becomes
diagonal in Cartesian coordinates Finzi et al. (2020). Thus, the kinetic energy, i, of a point particle
depends only on its velocity and mass. Here, we learn the mass of each particle based on the node
embedding h0
ias
i=squareplus (MLP(h0
ik_xi)) (27)
The kinetic energy of the individual particles are summed up to compute the total kinetic energy as
T=X
ui2Ui (28)
Potential energy. Potential energy of a system can have complex combination of absolute and
topological features. For instance, a system such as a pendulum in a gravitational ﬁeld have a simple
potential energy function that does not depend on topology. On the contrary, for a system such as
balls connected with spring, the potential energy depends on the connections and hence, the topology.
Therefore, similar to GNODE , we use ﬁnal node ( hL
i) and edge ( hL
ij) embedding from message
passing (representing topology) and global node ( hg
i) embedding to calculate the potential energy of
the system as
V=X
ui2Uvi+X
eij2Evij (29)
wherevi=squareplus (MLPvi(hg
i) +squareplus (MLP mp;vi(hL
i))represents the energy due to the
attributes of the particle themselves, and vij=squareplus (MLPvij(hL
ij))represents energy due to
interactions (topology).
Lagrangian. Finally, the Lagrangian of the system is deﬁned as L=T VwhereTis total
kinetic energy of system and Vis the total potential energy of the system. Finally, the acceleration is
computed using the predicted Lagrangian employing the appropriate ELequation.
E Hamiltonian Graph Neural Network (H GNN )
Figure 13 shows the architecture of the HGNN. Note that HGNN has exactly the same architecture
asLGNN and follows all the computations exactly in the same fashion until kinetic and potential
energies. Once these energies are obtained, instead of computing the Lagrangian, the Hamiltonian of
the system is computed using the equation H=T+VwhereTis total kinetic energy of system and
Vis the total potential energy of the system. Finally, the acceleration is computed using the predicted
Hamiltonian employing the appropriate Hamiltonian’s equation of motion.
16Figure 13: H GNN architecture.
Figure 14: Variation of rollout error against the number of data points used to train the models.
F Additional Experiments
F.1 Data Efﬁciency
Figure 14, shows the dataefﬁciency of the different models considers. Speciﬁcally, we evaluate the
rollout error with respect to the number of data-points used to train each of the models. A clear
trend emerges from this experiment. Speciﬁcally, in pendulum systems, we observe that models with
explicit constraints signiﬁcantly outperform their unconstrained counterparts with more data points
by5-6 orders of magnitude. In contrast, the unconstrained architectures show limited reduction in
error in both spring and pendulum systems. This trend indicates that injecting explicit constraints
in the model leads to more effective training. Further, we observe that the performance of CLGNN,
CHGNN, and CGNODE are comparable for pendulum systems, while that of CHGNis poorer, despite
having explicit constraints.
F.2 Robustness to Noise
To evaluate robustness of the evaluated GNNs to noise, we inject Gaussian noise to every data point in
the training dataset with mean 0and standard deviation 1. The forward simulation error is calculated
by comparing it to the ground truth trajectories, without adding any noise to those data points. Due to
space limitations, the plots are in the appendix. Figure 17 shows the performance on unconstrained
architectures, while Figure 18 shows the time evolution of energy and rollout error. Figure 19 and
Figure 20 analyze the same, respectively, on pendulum for constrained systems. Finally, we also
show the variation of energy and rollout error for spring system for varying percentages of noise,
namely, 1%, 5%, 10% and 50% of the standard deviation of the data (see Figs. 21,22.)
17Figure 15: Rollout error and energy error for 4-body gravitational system with constraints with
respect to time for LGNN,LGNHGN,HGNN,GNODE ,FGNODE andFGNN. The curve represents
the average over 100 trajectories generated from random initial conditions.
Figure 16: Rollout error and energy error for rigid body system with respect to time for HGN,HGNN,
GNODE ,FGNODE andFGNN. The curve represents the average over 10 trajectories over the test
dataset.
When compared to training on clean data, we observe that the trends remain similar. Speciﬁcally,
CLGNandCH GNcontinue to be the poorest performers in the constrained setting. In the uncon-
strained setting, the same trend continues; FGNN andLGNcontinue exhibiting highest errors, while
HGNremains the best architecture. However, across architectures we observe almost a 10-fold
increase in error. All in all, this experiment reveals that while the choice of architectures remain
unaffected, all display reduced accuracy. Hence, enabling better robustness would be an important
research direction to pursue.
18Figure 17: Geometric mean of rollout error and energy error for 3-, 4-, 5-spring and 3-,4-,5-pendulum
systems without constraints for LGNN,LGNHGN,HGNN,GNODE ,FGNODE andFGNN on noisy
data. The error bar represents the 95% conﬁdence interval over 100 trajectories generated from
random initial conditions.
Figure 18: Rollout error and energy error for 3-, 4-, 5-spring and 3-, 4-, 5-pendulum systems without
constraints with respect to time for LGNN,LGNHGN,HGNN,GNODE ,FGNODE andFGNN on noisy
data. The curve represents the average over 100 trajectories generated from random initial conditions.
G Details of Experimental Setup
G.1 Dataset generation
Software packages: numpy-1.20.3, jax-0.2.24, jax-md-0.1.20, jaxlib-0.1.73, jraph-0.0.1.dev
Hardware: Chip: Intel Xeon, Total Number of Cores: 64, Memory: 128 GB, System OS: Ubuntu
18.04.5 LTS.
For all variants of LGNN,LGN,GNODE ,FGNODE ,FGNN: All the datasets are generated using the
known Lagrangian of the pendulum and spring systems, along with the constraints, as described in
Section 4. For each system, we create the training data by performing forward simulations with 100
random initial conditions. For the pendulum system, a timestep of 10 5sis used to integrate the
equations of motion, while for the spring system, a timestep of 10 3sis used. The velocity-Verlet
algorithm is used to integrate the equations of motion due to its ability to conserve the energy in long
trajectory integration.
While for HGNandHGNN, datasets are generated using Hamiltonian mechanics. Runge-Kutta
integrator is used to integrate the equations of motion due to the ﬁrst order nature of the Hamiltonian
equations in contrast to the second order nature of L GNN and G NODE .
From the 100 simulations for pendulum and spring system, obtained from the rollout starting from
100 random initial conditions, 100 data points are extracted per simulation, resulting in a total of
10000 data points. Data points were collected every 1000 and 100 timesteps for the pendulum and
spring systems, respectively. Thus, each training trajectory of the spring and pendulum systems are
19Figure 19: Geometric mean of rollout error and energy error for 3-,4-,5-pendulum systems with
constraints for CLGNN,CLGNCH GN,CH GNN,CG NODE , and CFG NODE on noisy data. The
error bar represents the 95% conﬁdence interval over 100 trajectories generated from random initial
conditions.
Figure 20: Rollout error and energy error for 3-,4-,5-pendulum systems with constraints with respect
to time for CLGNN,CLGNCH GN,CH GNN,CG NODE , and CFG NODE on noisy data. The curve
represents the average over 100 trajectories generated from random initial conditions.
10sand1slong, respectively. Here, we do not train from the trajectory. Rather, we randomly sample
different states from the training set to predict the acceleration.
For the gravitational system, the dataset is generated using the known Lagrangian of the gravitational
system. We create the training data by performing forward simulation from a known stable state.
We use a timestep of 10 3s, which is used to integrate the equations of motion, and similar to the
pendulum and spring system, we use the velocity-verlet algorithm for the integration of the equations.
The known stable state is simulated forward and datapoints were collected every 100 timesteps, for a
total of 10000 datapoints. Similar to the pendulum and spring systems, we randomly sample different
states from the training set to predict the acceleration.
For 3D solid cube, we have generated ground truth data using peridynamics simulation, single initially
compressed cube was relaxed for 100swith time step 0:1s. Using this we have generated total 1000
data points.
G.2 Training details
The training dataset is divided in 75:25 ratio randomly, where the 75% is used for training and 25%
is used as the validation set. Further, the trained models are tested on its ability to predict the correct
trajectory, a task it was not trained on. Speciﬁcally, the pendulum systems are tested for 1s, that is
105timesteps, and spring systems for 20s, that is 2104timesteps on 100 different trajectories
created from random initial conditions. All models are trained for 10000 epochs. A learning rate of
10 3was used with the Adam optimizer for the training.
G.3 Loss function
Based on the predicted x, the positions and velocities are predicted using the Velocity Verlet integration.
The loss function is computed by using the predicted and actual accelerations at timesteps 2;3;:::;T
in a trajectory T, which is then back-propagated to train the MLPs. Speciﬁcally, the loss function is
as follows.
L=1
n nX
i=1
xT;t
i 
^xT;t
i2!
(30)
20Figure 21: Rollout error with respect to percentage noise in the dataset used to train the 5-spring
system.
Figure 22: Energy error with respect to percentage of noise in the dataset used to train the 5-spring
model.
Here, (^xT;t
i)is the predicted acceleration for the ithparticle in trajectory Tat timetandxT;t
iis
the true acceleration. Tdenotes a trajectory from T, the set of training trajectories. Note that the
accelerations are computed directly from the ground truth trajectory using the Verlet algorithm as:
x(t) =1
(t)2[x(t+ t) +x(t t) 2x(t)] (31)
Since the integration of the equations of motion for the predicted trajectory is also performed using
the same algorithm as: x(t+t) = 2 x(t) x(t t)+x(t)2, this method is equivalent to training
from trajectory/positions.
G.4 Hyper-parameters
The default hyper-parameters used for training each architecture is provided below.
GNODE , CG NODE
Parameter Value
Node embedding dimension 5
Edge embedding dimension 5
Hidden layer neurons (MLP) 5
Number of hidden layers (MLP) 2
Activation function squareplus
Number of layers of message passing 1
Optimizer ADAM
Learning rate 1:0e 3
Batch size 100
21LGN, CL GN, HGN, FG NODE , CFG NODE , FGNN
Parameter Value
Node embedding dimension 8
Edge embedding dimension 8
Hidden layer neurons (MLP) 16
Number of hidden layers (MLP) 2
Activation function squareplus
Number of layers of message passing 1
Optimizer ADAM
Learning rate 1:0e 3
Batch size 100
LGNN , CL GNN , HGNN , CH GNN
Parameter Value
Node embedding dimension 5
Edge embedding dimension 5
Hidden layer neurons (MLP) 5
Number of hidden layers (MLP) 2
Activation function squareplus
Number of layers of message passing(pendulum) 2
Number of layers of message passing(spring) 1
Optimizer ADAM
Learning rate 1:0e 3
Batch size 100
G.5 Hyper-parameter Search
Learning rate
FGNN
LR Value Geometric mean of Zerr Time (in sec)
0.001 0.0852 4226
0.003 0.0616 4394
0.01 0.1219 4376
0.03 0.0962 4436
0.1 0.0846 4476
0.3 0.0628 4557
GNODE
LR Value Geometric mean of Zerr Time (in sec)
0.001 0.1371 5189
0.003 0.1507 5242
0.01 0.1288 5250
0.03 0.1267 5176
0.1 0.1284 5206
0.3 0.1491 5179
HGNN
22LR Value Geometric mean of Zerr Time (in sec)
0.001 0.1868 3856
0.003 0.1895 3613
0.01 0.1622 3878
0.03 0.1878 4089
0.1 0.146 9195
0.3 0.2356 6859
LGNN
LR Value Geometric mean of Zerr Time (in sec)
0.001 0.1939 38082
0.003 0.189 11904
0.01 0.1869 11890
0.03 0.1879 12314
0.1 0.2316 11845
0.3 0.279 12320
Number of message-passing layers
FGNN
No of message passing layers Geometric mean of Zerr Time (in sec)
1 0.0852 6234
2 1.0 7552
3 0.1724 8024
4 0.0786 8455
GNODE
No of message passing layers Geometric mean of Zerr Time (in sec)
1 0.1491 7833
2 0.1649 6850
3 0.1721 6924
4 0.2078 7429
HGNN
No of message passing layers Geometric mean of Zerr Time (in sec)
1 0.1782 8924
2 0.1796 8254
3 0.1583 9095
4 0.1608 11199
LGNN
No of message passing layers Geometric mean of Zerr Time (in sec)
1 0.1887 11649
2 0.2319 12345
3 0.1903 12172
4 0.1839 12838
Number of hidden layers in MLP
FGNN
No of hidden layers Geometric mean of Zerr Time (in sec)
5 0.1132 5423
10 0.0848 5926
15 0.0821 6583
25 0.0934 7446
23GNODE
No of hidden layers Geometric mean of Zerr Time (in sec)
5 0.2078 25559
10 0.1697 9246
15 0.2084 9728
25 0.185 10747
HGNN
No of hidden layers Geometric mean of Zerr Time (in sec)
5 0.1782 8984
10 0.1524 11307
15 0.1543 12605
25 0.1497 17498
LGNN
No of hidden layers Geometric mean of Zerr Time (in sec)
5 0.1887 12885
10 0.18 14954
15 0.1692 16533
25 0.1731 21011
Embedding dimensionality in hidden layers of MLP
FGNN
No of Neurons Geometric mean of Zerr Time (in sec)
1 0.0646 3973
2 0.1132 5462
4 0.0763 8258
8 0.075 13900
GNODE
No of Neurons Geometric mean of Zerr Time (in sec)
1 0.187 7664
2 0.2078 9895
4 0.1869 12258
8 0.7755 20041
HGNN
No of Neurons Geometric mean of Zerr Time (in sec)
1 0.1886 7689
2 0.1782 8984
4 0.1555 12615
8 0.1553 19389
LGNN
No of Neurons Geometric mean of Zerr Time (in sec)
1 0.2351 10448
2 0.1887 13070
4 0.18 15710
8 0.1674 24039
24Activation function
FGNN
Activation Function Geometric mean of Zerr Time (in sec)
softplus 0.886 6141
squareplus 0.1757 1340
GNODE
Activation Function Geometric mean of Zerr Time (in sec)
softplus 0.1287 6970
squareplus 0.1371 6425
HGNN
Activation Function Geometric mean of Zerr Time (in sec)
softplus 0.1953 9685
squareplus 0.1782 8463
LGNN
Activation Function Geometric mean of Zerr Time (in sec)
softplus 0.1921 11620
squareplus 0.1887 38082
H Training and Simulation Time
The key insight obtained from Tables 1-3 is that the LGNfamily of architectures take signiﬁcantly
longer to train. The GNODE family is marginally faster on average than the HGNfamily. The LGN
family is the slowest since the lagrangian needs to be differentiated, which leads to the differentiation
over the GNNparameters. In HGN, the GNNoutputs Hamiltonian and thus there is only one layer of
differentiation to learn the GNNparameters. Finally, in GNODE , the output is only integrated. Thus,
to summarize, in LGNfamily, the order of differentiation is double, in HGNthe order is single and in
GNODE , the order is zero.
Models Training time (in sec) Forward Simulation time (in sec)
CFG NODE 9475 2.21
CGNODE 8784 1.57
CLGN 55810 16.97
CLGNN 27614 3.85
CHGN 6130 0.54
CHGNN 11038 0.82
FGNN 1325 0.02
FGNODE 8097 1.75
GNODE 6341 1.02
LGN 55042 14.82
LGNN 37752 13.53
HGN 2512 0.76
HGNN 8365 0.51
Table 1: Training and inference times in pendulum systems.
25Models Training time (in sec) Forward Simulation time (in sec)
FGNN 1738 0.01
FGNODE 1337 0.25
GNODE 6977 0.10
LGN 141962 5.81
LGNN 25710 0.81
HGN 14053 0.43
HGNN 18128 0.89
Table 2: Training and inference times in spring systems.
Models Training time (in sec) Forward Simulation time (in sec)
FGNN 13136 0.30
FGNODE 13238 12.94
GNODE 11422 8.58
HGN 56996 5.21
HGNN 46038 8.04
Table 3: Training and inference times in rigid body systems.
26"
25,https://github.com/NVIDIA/physicsnemo,"






































































GitHub - NVIDIA/physicsnemo: Open-source deep-learning framework for building, training, and fine-tuning deep learning models using state-of-the-art Physics-ML methods














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        NVIDIA
 
/

physicsnemo

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    301




 


          Star
 1.4k








        Open-source deep-learning framework for building, training, and fine-tuning deep learning models using state-of-the-art Physics-ML methods
      





developer.nvidia.com/physicsnemo


License





     Apache-2.0 license
    






1.4k
          stars
 



301
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
62






Pull requests
26






Discussions







Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Discussions











          Actions











          Projects











          Security











          Insights






 





NVIDIA/physicsnemo



 












    mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History457 Commits.github.github  .gitlab.gitlab  docsdocs  examplesexamples  physicsnemophysicsnemo  testtest  .dockerignore.dockerignore  .gitattributes.gitattributes  .gitignore.gitignore  .gitmodules.gitmodules  .markdownlint.yaml.markdownlint.yaml  .pre-commit-config.yaml.pre-commit-config.yaml  CHANGELOG.mdCHANGELOG.md  CITATION.cffCITATION.cff  CONTRIBUTING.mdCONTRIBUTING.md  DockerfileDockerfile  FAQ.mdFAQ.md  LICENSE.txtLICENSE.txt  MakefileMakefile  README.mdREADME.md  pyproject.tomlpyproject.toml  View all filesRepository files navigationREADMEApache-2.0 licenseNVIDIA PhysicsNeMo
📝 NVIDIA Modulus has been renamed to NVIDIA PhysicsNeMo



Getting Started
| Install guide
| Contributing Guidelines
| Resources
| PhysicsNeMo Migration Guide
| Communication
| License
What is PhysicsNeMo?
NVIDIA PhysicsNeMo is an open-source deep-learning framework for building, training,
and fine-tuning deep learning models using state-of-the-art SciML methods for
AI4science and engineering.
PhysicsNeMo provides utilities and optimized pipelines to develop AI models that combine
physics knowledge with data, enabling real-time predictions.
Whether you are exploring the use of Neural operators, GNNs, or transformers or are
interested in Physics-informed Neural Networks or a hybrid approach in between, PhysicsNeMo
provides you with an optimized stack that will enable you to train your models at scale.




More About PhysicsNeMo

Scalable GPU-optimized training Library
A suite of Physics-Informed ML Models
Seamless PyTorch Integration
Easy Customization and Extension
AI4Science Library

Domain Specific Packages




Who is contributing to PhysicsNeMo
Why use PhysicsNeMo
Getting Started
Resources
Installation
Contributing
Communication
License

More About PhysicsNeMo
At a granular level, PhysicsNeMo provides a library of a few key components:



Component
Description




physicsnemo.models
A collection of optimized, customizable, and easy-to-use models such as Fourier Neural Operators, Graph Neural Networks, and many more


physicsnemo.datapipes
A data pipeline and data loader library, including benchmark datapipes, weather daptapipes, and graph datapipes


physicsnemo.distributed
A distributed computing library build on top of torch.distributed to enable parallel training with just a few steps


physicsnemo.sym.geometry
A library to handle geometry for DL training using the Constructive Solid Geometry modeling and CAD files in STL format.


physicsnemo.sym.eq
A library to use PDEs in your DL training with several implementations of commonly observed equations and easy ways for customization.



For a complete list, refer to the PhysicsNeMo API documentation for
PhysicsNeMo Core
and
PhysicsNeMo Sym.
Usually, PhysicsNeMo is used either as:

A complementary tool to Pytorch when exploring AI for SciML and AI4Science applications.
A deep learning research platform that provides scale and optimal performance on
NVIDIA GPUs.

Elaborating Further:
Scalable GPU-optimized training Library
PhysicsNeMo provides a highly optimized and scalable training library for maximizing the
power of NVIDIA GPUs.
Distributed computing
utilities allow for efficient scaling from a single GPU to multi-node GPU clusters with
a few lines of code, ensuring that large-scale.
physics-informed machine learning (ML) models can be trained quickly and effectively.
The framework includes support for advanced.
optimization utilities,
tailor made datapipes,
validation utilities
to enhance the end to end training speed.
A suite of Physics Informed ML Models
PhysicsNeMo offers a comprehensive library of state-of-the-art models specifically designed
for physics-ML applications.
The Model Zoo
includes generalizable model architectures such as
Fourier Neural Operators (FNOs),
DeepONet,
Physics-Informed Neural Networks (PINNs),
Graph Neural Networks (GNNs),
and generative AI models like Diffusion Models
as well as domain-specific models such as Deep Learning Weather Prediction (DLWP)
and Super Resolution Network (SrNN) among others.
These models are optimized for various physics domains, such as computational fluid
dynamics, structural mechanics, and electromagnetics. Users can download, customize, and
build upon these models to suit their specific needs, significantly reducing the time
required to develop high-fidelity simulations.
Seamless PyTorch Integration
PhysicsNeMo is built on top of PyTorch, providing a familiar and user-friendly experience
for those already proficient with PyTorch.
This includes a simple Python interface and modular design, making it easy to use
PhysicsNeMo with existing PyTorch workflows.
Users can leverage the extensive PyTorch ecosystem, including its libraries and tools
while benefiting from PhysicsNeMo's specialized capabilities for physics-ML. This seamless
integration ensures users can quickly adopt PhysicsNeMo without a steep learning curve.
For more information, refer Converting PyTorch Models to PhysicsNeMo Models
Easy Customization and Extension
PhysicsNeMo is designed to be highly extensible, allowing users to add new functionality
with minimal effort. The framework provides Pythonic APIs for
defining new physics models, geometries, and constraints, making it easy to extend its
capabilities to new use cases.
The adaptability of PhysicsNeMo is further enhanced by key features such as
ONNX support
for flexible model deployment,
robust logging utilities
for streamlined error handling,
and efficient
checkpointing
to simplify model loading and saving.
This extensibility ensures that PhysicsNeMo can adapt to the evolving needs of researchers
and engineers, facilitating the development of innovative solutions in the field of physics-ML.
Detailed information on features and capabilities can be found in the PhysicsNeMo documentation.
Reference samples cover a broad spectrum of physics-constrained
and data-driven
workflows to suit the diversity of use cases in the science and engineering disciplines.
TipHave questions about how PhysicsNeMo can assist you? Try our [Experimental] chatbot,
PhysicsNeMo Guide, for answers.

Hello world
You can start using PhysicsNeMo in your PyTorch code as simple as shown here:
python
>>> import torch
>>> from physicsnemo.models.mlp.fully_connected import FullyConnected
>>> model = FullyConnected(in_features=32, out_features=64)
>>> input = torch.randn(128, 32)
>>> output = model(input)
>>> output.shape
torch.Size([128, 64])
AI4Science Library

PhysicsNeMo Symbolic: This repository of
algorithms and utilities allows SciML researchers and developers to physics inform model
training and model validation. It also provides a higher level abstraction
for domain experts that is native to science and engineering.

Domain Specific Packages
The following are packages dedicated for domain experts of specific communities catering
to their unique exploration needs.

Earth-2 Studio: Open source project
to enable climate researchers and scientists to explore and experiment with
AI models for weather and climate.

Research packages
The following are research packages that get packaged into PhysicsNeMo once they are stable.

PhysicsNeMo Makani: Experimental library
designed to enable the research and development of machine-learning based weather and
climate models.
Earth2 Grid: Experimental library with
utilities for working geographic data defined on various grids.
Earth-2 MIP: Experimental library with
utilities for model intercomparison for weather and climate models.

Who is using and contributing to PhysicsNeMo
PhysicsNeMo is an open source project and gets contributions from researchers in
the SciML and AI4science fields. While PhysicsNeMo team works on optimizing the
underlying SW stack, the community collaborates and contributes model architectures,
datasets, and reference applications so we can innovate in the pursuit of
developing generalizable model architectures and algorithms.
Some latest examples of community contributors are HP Labs 3D Printing team,
Stanford Cardiovascular research team,
UIUC team,
CMU team
etc.
Latest examples of research teams using PhysicsNeMo are
ORNL team,
TU Munich CFD team etc.
Please navigate to this page for a complete list of research work leveraging PhysicsNeMo.
For a list of enterprises using PhysicsNeMo refer here.
Using PhysicsNeMo and interested in showcasing your work on
NVIDIA Blogs?
Fill out this proposal form and we will get back
to you!
Why are they using PhysicsNeMo
Here are some of the key benefits of PhysicsNeMo for SciML model development:










SciML Benchmarking and validation
Ease of using generalized SciML recipes with heterogenous datasets
Out of the box performance and scalability


PhysicsNeMo enables researchers to benchmark their AI model against proven architectures for standard benchmark problems with detailed domain-specific validation criteria.
PhysicsNeMo enables researchers to pick from SOTA SciML architectures and use built-in data pipelines for their use case.
PhysicsNeMo provides out-of-the-box performant training pipelines including optimized ETL pipelines for heterogrneous engineering and scientific datasets and out of the box scaling across multi-GPU and multi-node GPUs.



See what your peer SciML researchers are saying about PhysicsNeMo (Coming soon).
Getting started
The following resources will help you in learning how to use PhysicsNeMo. The best
way is to start with a reference sample and then update it for your own use case.

Using PhysicsNeMo with your PyTorch model
Using PhysicsNeMo built-in models
Getting started Guide
Reference Samples
User guide Documentation

Resources

Getting started Webinar
AI4Science PhysicsNeMo Bootcamp
PhysicsNeMo Pretrained models
PhysicsNeMo Datasets and Supplementary materials
Self-paced PhysicsNeMo DLI training
Deep Learning for Science and Engineering Lecture Series with PhysicsNeMo

PhysicsNeMo: purpose and usage


Video Tutorials

Installation
PyPi
The recommended method for installing the latest version of PhysicsNeMo is using PyPi:
pip install nvidia-physicsnemo
The installation can be verified by running the hello world example as demonstrated here.
Optional dependencies
PhysicsNeMo has many optional dependencies that are used in specific components.
When using pip, all dependencies used in PhysicsNeMo can be installed with
pip install nvidia-physicsnemo[all]. If you are developing PhysicsNeMo, developer dependencies
can be installed using pip install nvidia-physicsnemo[dev]. Otherwise, additional dependencies
can be installed on a case by case basis. Detailed information on installing the
optional dependencies can be found in the
Getting Started Guide.
NVCR Container
The recommended PhysicsNeMo docker image can be pulled from the
NVIDIA Container Registry
(refer to the NGC registry for the latest tag):
docker pull nvcr.io/nvidia/physicsnemo/physicsnemo:25.03
Inside the container, you can clone the PhysicsNeMo git repositories and get
started with the examples. The below command shows the instructions to launch
the physicsnemo container and run examples from this repo.
docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --runtime nvidia \
--rm -it nvcr.io/nvidia/physicsnemo/physicsnemo:25.03 bash
git clone https://github.com/NVIDIA/physicsnemo.git
cd physicsnemo/examples/cfd/darcy_fno/
pip install warp-lang # install NVIDIA Warp to run the darcy example
python train_fno_darcy.py
For enterprise supported NVAIE container, refer PhysicsNeMo Secured Feature Branch
From Source
Package
For a local build of the PhysicsNeMo Python package from source use:
git clone git@github.com:NVIDIA/physicsnemo.git && cd physicsnemo

pip install --upgrade pip
pip install .
Source Container
To build PhysicsNeMo docker image:
docker build -t physicsnemo:deploy \
    --build-arg TARGETPLATFORM=linux/amd64 --target deploy -f Dockerfile .
Alternatively, you can run make container-deploy
To build CI image:
docker build -t physicsnemo:ci \
    --build-arg TARGETPLATFORM=linux/amd64 --target ci -f Dockerfile .
Alternatively, you can run make container-ci.
Currently, only linux/amd64 and linux/arm64 platforms are supported. If using
linux/arm64, some dependencies like warp-lang might not install correctly.
PhysicsNeMo Migration Guide
NVIDIA Modulus has been renamed to NVIDIA PhysicsNeMo. For migration:

Use pip install nvidia-physicsnemo rather than pip install nvidia-modulus
for PyPi wheels.
Use nvcr.io/nvidia/physicsnemo/physicsnemo:<tag> rather than
nvcr.io/nvidia/modulus/modulus:<tag> for Docker containers.
Replace nvidia-modulus by nvidia-physicsnemo in your pip requirements
files (requirements.txt, setup.py, setup.cfg, pyproject.toml, etc.)
In your code, change the import statements from import modulus to
import physicsnemo

The old PyPi registry and the NGC container registry will be deprecated soon
and will not receive any bug fixes/updates. The old checkpoints will remain
compatible with these updates.
More details to follow soon.
Contributing to PhysicsNeMo
PhysicsNeMo is an open source collaboration and its success is rooted in community
contribution to further the field of Physics-ML. Thank you for contributing to the
project so others can build on top of your contribution.
For guidance on contributing to PhysicsNeMo, please refer to the
contributing guidelines.
Cite PhysicsNeMo
If PhysicsNeMo helped your research and you would like to cite it, please refer to the guidelines
Communication

Github Discussions: Discuss new architectures, implementations, Physics-ML research, etc.
GitHub Issues: Bug reports, feature requests, install issues, etc.
PhysicsNeMo Forum: The PhysicsNeMo Forum
hosts an audience of new to moderate-level users and developers for general chat, online
discussions, collaboration, etc.

Feedback
Want to suggest some improvements to PhysicsNeMo? Use our feedback form
here.
License
PhysicsNeMo is provided under the Apache License 2.0, please see LICENSE.txt
for full license text. Enterprise SLA, support and preview access are available
under NVAIE.
   








About

        Open-source deep-learning framework for building, training, and fine-tuning deep learning models using state-of-the-art Physics-ML methods
      





developer.nvidia.com/physicsnemo


Topics



  machine-learning


  deep-learning


  physics


  pytorch


  nvidia-gpu



Resources





        Readme
 
License





     Apache-2.0 license
    







Activity 




Custom properties 
Stars




1.4k
      stars 
Watchers




41
      watching 
Forks




301
      forks 


          Report repository
 






Releases
      12






v1.0.1

          Latest
 
Mar 25, 2025

 
+ 11 releases





Packages
      0

        No packages published 












Contributors
      61









































































+ 47 contributors




Languages











Python
99.6%







Other
0.4%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
26,https://doc.openfoam.com/2312/quickstart/,"






OpenFOAM Documentation - Quickstart




























Top


        OpenFOAM v2312 released - see the latest features here



        OpenâFOAM
        





â







Doc
Src










Quickstart









Home

Quickstart

Installation
Overview
Download
Source code contents



Fundamentals
Overview
About

Case structure
Overview
controlDict
fvOptions
fvSchemes
fvSolution



Input types
Overview
Expressions

Function1
Overview
inputValueMapper




Command line
Tracking issues



Tools
Overview

Pre-processing
Overview

Mesh
Overview
Mesh conversion

Mesh generation
Overview
blockMesh
makeFaMesh

snappyHexMesh
Overview
Castellation

Geometry
Overview
searchableBox
searchableCone
searchableCylinder
searchableDisk
searchableExtrudedCircle
searchablePlane
searchablePlate
searchableRotatedBox
searchableSphere
searchableSurfaceCollection
searchableSurfaceWithGaps


Global settings
Layer addition
Mesh quality
Quick reference
Snapping





Mesh manipulation
Overview
surfaceTransformPoints
topoSet





Surface
Overview
surfaceInertia
surfaceLambdaMuSmooth



Field
Overview
applyBoundaryLayer
setTurbulenceFields





Processing
Overview

Boundary conditions
Overview

atmospheric
Overview
atmAlphatkWallFunction
atmBoundaryLayer
atmBoundaryLayerInletEpsilon
atmBoundaryLayerInletK
atmBoundaryLayerInletOmega
atmBoundaryLayerInletVelocity
atmEpsilonWallFunction
atmNutUWallFunction
atmNutWallFunction
atmNutkWallFunction
atmOmegaWallFunction
atmTurbulentHeatFluxTemperature


Common combinations

coupled
Overview
cyclic
cyclicAMI
activeBaffleVelocity
activePressureForceBaffleVelocity
fan
fixedJump
fixedJumpAMI
humidityTemperatureCoupledMixed
swirlFanVelocity
uniformJump
uniformJumpAMI



finiteArea
Overview
clampedPlate
edgeNormalFixedValue
fixedValueOutflow
ignore
inletOutlet
outletInlet
slip
timeVaryingUniformFixedValue
uniformFixedGradient
uniformFixedValue
uniformMixed



general
Overview
fixedGradient
mixed
zeroGradient
codedFixedValue
codedMixed
copiedFixedValue
electrostaticDeposition
fixedInternalValue
fixedNormalSlip
fixedProfile
fixedValue
interfaceCompression
mappedField
mappedFixedInternalValue
mappedFixedPushedInternalValue
mappedFixedValue
mappedMixed
prghPressure
prghTotalHydrostaticPressure
prghTotalPressure
scaledFixedValue
solidBodyMotionDisplacement
surfaceNormalFixedValue
uniformDensityHydrostaticPressure
uniformFixedGradient
uniformFixedValue
uniformMixed
variableHeightFlowRate
waveSurfacePressure



constraint
Overview
empty
processor
symmetryPlane
wedge



inlet
Overview
SRFVelocity
turbulentIntensityKineticEnergyInlet
turbulentMixingLengthFrequencyInlet
activeBaffleVelocity
activePressureForceBaffleVelocity
cylindricalInletVelocity
fixedFluxPressure
fixedMean
fixedPressureCompressibleDensity
flowRateInletVelocity
interstitialInletVelocity
mappedFlowRate
mappedVelocityFluxFixedValue
outletInlet
outletMappedUniformInlet
plenumPressure
pressureDirectedInletVelocity
pressureInletUniformVelocity
pressureInletVelocity
pressurePIDControlInletVelocity
swirlFlowRateInletVelocity
swirlInletVelocity
syringePressure
timeVaryingMappedFixedValue
turbulentDFSEMInlet
turbulentDigitalFilterInlet
turbulentInlet
uniformNormalFixedValue



inletOutlet
Overview
SRFFreestreamVelocity
fanPressure
fixedMeanOutletInlet
fixedNormalInletOutletVelocity
freestream
freestreamPressure
freestreamVelocity
inletOutlet
pressureDirectedInletOutletVelocity
pressureInletOutletParSlipVelocity
pressureInletOutletVelocity
pressureNormalInletOutletVelocity
pressurePermeableAlphaInletOutletVelocity
prghPermeableAlphaTotalPressure
rotatingPressureInletOutletVelocity
rotatingTotalPressure
supersonicFreestream
totalPressure
totalTemperature
turbulentIntensityKineticEnergyInlet
turbulentMixingLengthDissipationRateInlet
turbulentMixingLengthFrequencyInlet



meshMotion
Overview
angularOscillatingDisplacement
angularOscillatingVelocity
cellMotion
compressible-thermalBaffle
oscillatingDisplacement
oscillatingVelocity
sixDoFRigidBodyDisplacement
surfaceDisplacement
surfaceSlipDisplacement
timeVaryingMappedFixedValue
uncoupledSixDoFRigidBodyDisplacement
uniformInterpolatedDisplacement
waveDisplacement



multiphase
Overview
JohnsonJacksonParticleSlip
JohnsonJacksonParticleTheta
alphaContactAngle
alphatFixedDmdtWallBoilingWallFunction
alphatPhaseChangeJayatillekeWallFunction
alphatPhaseChangeWallFunction
alphatWallBoilingWallFunction
fixedMultiPhaseHeatFlux
timeVaryingMassSorption



optimisation
Overview
adjointFarFieldNuaTilda
adjointFarFieldTMVar1
adjointFarFieldTMVar2
adjointInletNuaTilda
adjointOutletFlux
adjointOutletKa
adjointOutletNuaTilda
adjointOutletNuaTildaFlux
adjointOutletWa
kaqRWallFunction
waWallFunction



outlet
Overview
inletOutlet
pressureInletOutletVelocity
acousticWaveTransmissive
advective
flowRateOutletVelocity
fluxCorrectedVelocity
matchedFlowRateOutletVelocity
outletPhaseMeanVelocity
waveTransmissive



region
Overview
alphatFilmWallFunction
filmHeightInletVelocity
filmPyrolysisRadiativeCoupledMixed
filmPyrolysisTemperatureCoupled
filmPyrolysisVelocityCoupled
inclinedFilmNusseltHeight
inclinedFilmNusseltVelocity
nutkFilmWallFunction



regionFiniteArea
Overview
thermalShell
velocityFilmShell
vibrationShell



thermal
Overview
MarshakRadiation
MarshakRadiationFixedTemperature
alphatJayatillekeWallFunction
alphatWallFunction
convectiveHeatTransfer
enthalpySorption
externalWallHeatFluxTemperature
fixedEnergy
fixedIncidentRadiation
fixedUnburntEnthalpy
gradientEnergy
gradientUnburntEnthalpy
greyDiffusiveRadiation
greyDiffusiveViewFactor
lumpedMassWallTemperature
mixedEnergy
mixedUnburntEnthalpy
outletMachNumberPressure
outletMappedUniformInletHeatAddition
semiPermeableBaffleMassFraction
semiPermeableBaffleVelocity
sorptionWallFunction
speciesSorption
specularRadiation
thermalBaffle1D
totalFlowRateAdvectiveDiffusive
turbulentTemperatureCoupledBaffleMixed
turbulentTemperatureRadCoupledMixed
wallHeatTransfer
wideBandDiffusiveRadiation



wall
Overview
SRFWallVelocity
epsilonWallFunction
fixedNormalSlip
fixedShearStress
incompressible-alphatJayatillekeWallFunction
kLowReWallFunction
kqRWallFunction
movingWallVelocity
noSlip
nutLowReWallFunction
nutUBlendedWallFunction
nutURoughWallFunction
nutUSpaldingWallFunction
nutUTabulatedWallFunction
nutUWallFunction
nutWallFunction
nutkRoughWallFunction
nutkWallFunction
partialSlip
porousBafflePressure
rotatingWallVelocity
slip
translatingWallVelocity



wave
Overview
waveVelocity
waveMaker
waveAlpha




Mesh motion

Models
Overview

Thermophysical
Overview

Equation of state
Overview
adiabaticPerfectFluid
Boussinesq
rhoConst
incompressiblePerfectGas
icoPolynomial
icoTabulated
linear
PengRobinsonGas
perfectFluid
perfectGas
rPolynomial



Mixture
Overview
multiComponentMixture
pureMixture
reactingMixture


Specie

Thermodynamics
Overview
eConst
hConst
janaf
hPolynomial
hPower
hTabulated



Transport
Overview
const
logPolynomial
polynomial
sutherland
tabulated
WLF





Turbulence
Overview

DES
Overview
SpalartAllmarasDDES
SpalartAllmarasDES
SpalartAllmarasIDDES
kOmegaSSTDDES
kOmegaSSTDES
kOmegaSSTIDDES



LES
Overview
dynamicKEqn
Smagorinsky
WALE
kEqn



RAS
Overview

Linear EVM
Overview
kOmegaSSTLM
LienLeschziner
RNGkEpsilon
realizableKEpsilon
SpalartAllmaras
kkLOmega
kEpsilon
kEpsilonPhitF
kOmegaSST
qZeta



Non-linear EVM
Overview
LienCubicKE
ShihQuadraticKE



RSTM
Overview
LRR
SSG



Wall functions
Overview
nutUBlended
nutkWallFunction







Wave
Overview
Boussinesq
cnoidal
Grimshaw
McCowan
shallowWaterAbsorption
stokesI
stokesII
stokesV
streamFunction





Numerics
Overview

fvOptions
Overview

Constraints
Overview
fixedTemperature
fixedValue
velocityDamping



Corrections
Overview
limitTemperature
limitVelocity



Sources
Overview
acousticDamping
actuationDisk
buoyancyEnergy
buoyancyForce
directionalPressureGradient
coded
explicitPorosity
effectivenessHeatExchanger
interRegionExplicitPorosity
interRegionHeatTransfer
jouleHeating
meanVelocityForce
radialActuationDisk
rotorDisk
semiImplicit
tabulatedAcceleration
viscousDissipation
atmAmbientTurbSource
atmBuoyancyTurbSource
atmCoriolisUSource
atmLengthScaleTurbSource
atmNutSource
atmPlantCanopyTSource
atmPlantCanopyTurbSource
atmPlantCanopyUSource





Solvers
Overview
Case termination

Conjugate gradient
Overview
preconditioner-DIC
preconditioner-DILU
preconditioner-diagonal
preconditioner-FDIC
preconditioner-GAMG
PBiCG
PCG
PBiCGStab



Multigrid
Overview
GAMG


Residuals

Smooth solvers
Overview
DICGaussSeidel
DIC
DILU
gaussSeidel
smooth
symGaussSeidel


Under relaxation


Overset

Schemes
Overview

Divergence
Overview
Example
Implementation details
NVD and TVD


Examples
Gauss Theorem

Gradient
Overview
Example


Interpolation

Laplacian
Overview
Implementation details


localEuler

SnGrad
Overview
corrected
faceCorrected
limited
orthogonal
uncorrected


Time
Wall distance





Solver Applications
Overview

basic
Overview
laplacianFoam
potentialFoam
scalarTransportFoam



combustion
Overview
XiFoam
chemFoam
coldEngineFoam
engineFoam
fireFoam
reactingFoam



compressible
Overview
rhoCentralFoam
rhoPimpleFoam
rhoSimpleFoam


dns
discrete-methods
electro-magnetics
Energy transport equation
financial

heat-transfer
Overview
buoyantPimpleFoam
buoyantSimpleFoam
chtMultiRegionFoam
thermoFoam


Hydrostatic pressure effects

incompressible
Overview
boundaryFoam
icoFoam
pimpleFoam
pisoFoam
simpleFoam


Kinematic pressure

lagrangian-particle
Overview
reactingParcelFoam
sprayFoam


Mass transport equation
Momentum transport equation

multiphase
Overview
interFoam



Pressure-velocity algorithms
Overview
PIMPLE algorithm
PISO algorithm
SIMPLE algorithm







Post-processing
Overview

Function objects
Overview

Field
Overview
AMIWeights
CourantNo
Curle
DESModelRegions
LambVector
Lambda2
MachNo
ObukhovLength
PecletNo
Q
STDMD
XiReactionRate
add
blendingFactor
columnAverage
components
continuityError
ddt
ddt2
derivedFields
div
enstrophy
exprField
externalCoupled
extractEulerianParticles
fieldAverage
fieldAverageItem
fieldCoordinateSystemTransform
fieldExpression
fieldExtents
fieldMinMax
fieldValue
fieldsExpression
flowType
flux
fluxSummary
grad
heatTransferCoeff
histogram
interfaceHeight
limitFields
log
mag
magSqr
mapFields
momentum
momentumError
nearWallFields
norm
particleDistribution
pow
pressure
processorField
proudmanAcousticPower
randomise
reactionSensitivityAnalysis
readFields
reference
regionSizeDistribution
setFlow
stabilityBlendingFactor
streamFunction
streamline
subtract
surfaceDistance
surfaceFieldValue
surfaceInterpolate
turbulenceFields
valueAverage
volFieldValue
vorticity
wallBoundedStreamLine
wallHeatFlux
wallShearStress
writeCellCentres
writeCellVolumes
writeFile
yPlus
zeroGradient



Forces
Overview
Force coefficients
Forces



Graphics
Overview
Run-time post-processing



Lagrangian
Overview
Cloud information



Sampling
Overview

Points
Overview
cloud
shortestPath



Surfaces
Overview
cuttingPlane
distanceSurface
isoSurfaceCell
sampledIsoSurface
sampledMeshedSurface


patchProbes
probes



Solvers
Overview
Scalar transport



Utilities
Overview
ensightWrite
runTimeControl
solverInfo
writeDictionary





Utilities
Overview

noise
Overview
pointNoise
surfaceNoise


postProcess





Parallel
Overview
redistributePar





Examples
Overview
Test cases

Tutorials
Overview
Rotating mesh



Verification and Validation
Overview

Chemistry
Overview
Reactions



Combustion
Overview
Compartment fire



Heat transfer
Overview
Buoyant cavity



Laminar flow
Overview
Planar Poiseuille
Rotating cylinders



Turbulent flow
Overview
Backward facing step
Boundary layer
Bump (2D)
Decay of HIIT
Periodic hill
Surface mounted cube
Turbulence transition T3A
Turbulent flat plate
NACA0012 airfoil
Plane channel






References
Tags

Contributing
Overview
Contributors
How to contribute








Quickstart












Welcome to the OpenFOAMÂ® quickstart guide!
This guide provides a simplified step-by-step overview to help you quickly
get started with the installation, setup, and basic usage of OpenFOAMÂ®,
a powerful free/open-source computational fluid dynamics (CFD) software.
OpenFOAMÂ® Installationð

OpenFOAMÂ® is easily accessible on a wide range of operating systems,
including Linux distributions, Microsoft Windows, and macOS. You can
conveniently obtain OpenFOAMÂ® in the form of
precompiled packages
or as source code
that you can build yourself.
In this guide, we will install the precompiled package of the latest OpenFOAMÂ®
version on Microsoft Windows 10 Enterprise operating system.
Download the package of the latest OpenFOAMÂ® version by simply clicking
the link below (Please ensure that you have at least 300MB of available storage
space on your hard disk):
Link to OpenFOAM-windows-mingw.exe
The package is an executable. Run this executable to open the installation
wizard, and simply follow the wizardâs installation instructions specific to
your system. A typical view of the wizard is shown below
(Please ensure that you have enough available storage
space on your hard disk):

You may also need to install Microsoft MPI (MS-MPI). Similary, download
the following package (i.e. msmpisetup.exe), and follow its installation
wizard:
Link to Microsoft MPI v10.0
Upon completion of the above steps, an icon will be created on your desktop.
Double-click this icon to launch a terminal window. Running this icon will load
the OpenFOAMÂ® environment. Verify the contents of OpenFOAMÂ® in a
terminal as follows ($ is the command prompt, indicating that the
terminal is ready to
accept a command.):
$ ls -p
OpenFOAM/

$ cd $WM_PROJECT_DIR

$ ls -p
bin/  COPYING  etc/  etc-mingw  META-INFO  platforms/  README.md  ThirdParty/  tutorials/

Problem Setupð

The problem setup is derived from the experiment conducted by Pitz and Daily
(1983).
The setup involves a steady simulation of a non-reacting, single-phase,
Newtonian, incompressible fluid flow, which comprises a range of intricate
turbulence phenomena such as flow detachment/reattachment and formation of
recirculation zones.
You can browse the problem setup:
$ cd $FOAM_TUTORIALS/incompressible/simpleFoam/pitzDaily/

$ ls -p
0/  constant/  system/

$ ls -p system/
blockMeshDict  controlDict  fvSchemes  fvSolution  streamlines

$ ls -p constant/
transportProperties  turbulenceProperties

$ ls -p 0/
epsilon  k  p  U

In OpenFOAMÂ®, simulation settings are customised using text files.
Each parameter in these files follows a straightforward key-value pair format.
However, it is important to note that each file has its own unique set of
mandatory and optional keywords. The location and content of these files vary
depending on the chosen solver application, simulation setup, and the specific
aspects you wish to modify. Therefore, it is necessary to familiarize yourself
with the structure and significance of these keywords in relevant files.
Pre-processð

Pre-processing involves the typical preparation steps of a CFD problem
setup.
To carry out these steps, it is necessary to be familiar first with the typical
directory structure of an OpenFOAMÂ® setup and the meaning of these
directories.
An OpenFOAMÂ® simulation generally consists of the following three
directories:


0: (zero directory) contains field initial/boundary conditions at timestep
(or iteration) zero. Note that fields are typically named according to their
mathematical representation, e.g. u for velocity, p for pressure, T for
temperature etc.

constant: contains files that define the geometric and physical properties
of the simulation.

system: contains files that define the settings of the simulation
applications and tools.

Physical domainð

In OpenFOAMÂ®, there are multiple ways to provide the physical domain
specifications for a simulation. These include:

Geometry import: OpenFOAMÂ® supports the import of geometry from
external sources in formats such as STL, STEP, or IGES, to name a few.
Geometry definition: OpenFOAMÂ® allows manual definition of the physical
domain within itself.
Mesh generation: OpenFOAMÂ® provides native meshing tools including
blockMesh, snappyHexMesh, and
mesh converters to generate meshes that represent the physical domain.

In this example, we generate the physical domain alongside the mesh
using the blockMesh utility. The physical domain includes
a narrow inlet passage, a backward-facing step, and a converging section, as
shown in the side view below:

Physical propertiesð

In this example, we consider a simple non-reacting, single-phase, Newtonian,
incompressible fluid flow, with the following physical properties:



Metrics
Values




Fluid kinematic viscosity, \(\nu\)
\(1e\text{-}5\,[\mathrm{m}^2\text{/}\mathrm{s}]\)



In OpenFOAMÂ®, the type of fluid and the value of the fluid kinematic
viscosity are set using the transportProperties file located in the
constant directory.
$ cat constant/transportProperties

[...]

transportModel  Newtonian;
nu              1e-05;

[...]

Spatial domain discretisationð

In this example, we generate the spatial domain discretisation, also known
as the mesh, using the blockMesh utility configured by
the blockMeshDict file in the system directory.
You can skim through the content of this file via (for further information, please
see blockMesh):
$ cat system/blockMeshDict

The side view of the generated mesh is illustrated below:

In OpenFOAMÂ®, the spatial domain discretization is typically performed
using one of three methods, depending on the complexity of the
physical domain and the desired mesh characteristics:


blockMesh: built-in mesh generation tool in
OpenFOAMÂ® providing a simple and intuitive way to generate structured meshes
for simple geometries.

snappyHexMesh: powerful built-in mesh generation
tool in OpenFOAMÂ® used for generating high-quality, unstructured meshes. It
can handle complex geometries and supports various meshing strategies, such as
refinement regions and boundary layer additions.
Mesh conversion: OpenFOAMÂ® supports the import of meshes generated by
various external mesh generators using tools like fluentMeshToFoam.

Temporal domain discretisationð

In this example, the temporal domain discretization, i.e. the division of the
simulation time into discrete steps, is steady state.
In OpenFOAMÂ®, the temporal domain discretization is set in the
controlDict file located in the system directory.
The following key-value pairs in the controlDict file
allow users to configure the temporal behaviour of the simulation:
$ cat system/controlDict

[...]

startFrom       startTime;
startTime       0;
stopAt          endTime;
endTime         2000;
deltaT          1;
adjustTimeStep  off;

[...]

OpenFOAMÂ® provides several methods to handle the temporal
discretization, allowing users to control the time advancement and accuracy of
their simulations. Here are the main methods for generating the temporal domain
discretization in OpenFOAMÂ®:

Steady-state simulations
Explicit time stepping
Implicit time stepping
Adaptive time stepping

Equation discretisationð

In OpenFOAMÂ®, the equation discretization refers to the numerical
approximation of the governing equations that describe fluid flow or other
physical phenomena. OpenFOAMÂ® provides a wide range of discretization
schemes that can be used to discretize the equations and solve them numerically.
The selection of discretization schemes is usually defined for each equation
field and equation type in the fvSchemes file found in the
system directory.
Within the fvSchemes file, you will find configurations for
discretization schemes applied to gradient,
divergence,
Laplacian, and other terms in the governing
equations.
For instance, you can examine the settings for time and gradient schemes within
the fvSchemes file, as shown below:
$ cat system/fvSchemes

[...]

ddtSchemes
{
    default         steadyState;
}

gradSchemes
{
    default         Gauss linear;
}

[...]

Initial/boundary conditionsð

In this example, the initial and boundary conditions of the governing
equations at geometric boundaries are set as follows:



Property
Inlet
Outlet
Walls
Internal




$$\text{Velocity}, \u \, [\text{m/s}]$$
$$(10, 0, 0)$$
$$\grad \u = \tensor{0}$$
$$(0, 0, 0)$$
$$(0, 0, 0)$$


$$\text{Pressure}, p \, [\mathrm{m}^2\text{/}\mathrm{s}^2]$$
$$\grad p = \vec{0}$$
$$0$$
$$\grad p = \vec{0}$$
$$0$$


$$\text{Turbulent kinetic energy}, k \, [\mathrm{m}^2\text{/}\mathrm{s}^2]$$
$$0.375$$
$$\grad k = \vec{0}$$
$$\text{wall function}$$
$$0.375$$


$$\text{Turbulent kinetic energy dissipation rate}, \epsilon \, [\mathrm{m}^2\text{/}\mathrm{s}^3]$$
$$14.855$$
$$\grad \epsilon = \vec{0}$$
$$\text{wall function}$$
$$14.855$$



In OpenFOAMÂ®, the initial and boundary conditions are specified using
field files located within time directories for each field variable, such as
velocity. The initial conditions are applied to the entire domain volume,
while the boundary conditions are specified on the boundaries of the domain,
which are divided into numerical patches.
For example, the initial condition for pressure field (\(p\)) is specified in
the p file within the 0 directory as shown below:
$ cat 0/p

[...]

internalField   uniform 0;

[...]

Similarly, as an example, the boundary condition for velocity field (\(\u\)) at
inlet patch is set in the U file within the 0 directory in the following
manner:
$ cat 0/U

[...]

boundaryField
{
    inlet
    {
        type            fixedValue;
        value           uniform (10 0 0);
    }

[...]

Pressure-velocity coupling algorithmð

In this example, the choice of the pressure-velocity coupling algorithm
is the SIMPLE algorithm. The corresponding solver application in OpenFOAMÂ®
is called simpleFoam.
The settings for the SIMPLE algorithm can be specified in a sub-dictionary within
the fvSolution file, which is located in the system
directory:
$ cat system/fvSolution

[...]

SIMPLE
{
    nNonOrthogonalCorrectors 0;
    consistent      yes;           // SIMPLEC

    residualControl                // Additional control on simulation
    {
        p               1e-2;
        U               1e-3;
        ""(k|epsilon)""   1e-3;
    }
}

[...]

Note that OpenFOAMÂ® provides three pressure-velocity coupling algorithms:


SIMPLE: Semi-Implicit Method for Pressure-Linked Equations

PISO: Pressure Implicit with Splitting of Operators

PIMPLE: Combination of PISO and SIMPLE

Linear solversð

OpenFOAMÂ® offers a range of linear solvers, including iterative solvers like
GAMG, PCG, and
PBiCG, as well as interfaces to external solvers, e.g.
PETSc. The choice of linear solvers and their parameters depends on various
factors such as the problem characteristics, size of the linear system, and
desired computational efficiency. OpenFOAMÂ® provides extensive options for
fine-tuning its solver suites.
In OpenFOAMÂ®, the settings for linear solvers are typically defined in the
fvSolution file located in the system directory.
For instance, the linear solver settings for the pressure field (\(p\)) are
specified with the corresponding smoother and convergence parameters,
as demonstrated below:
$ cat system/fvSolution

[...]

p
{
    solver          GAMG;
    smoother        GaussSeidel;
    tolerance       1e-06;
    relTol          0.1;
}

[...]

Case controlð

In OpenFOAMÂ®, the main case controls can be set in the
controlDict file
within the system directory. The controlDict file is
a key configuration file that allows you to control various aspects of the
simulation and specify case-specific settings such as:

Time/Iteration control
Output control
Runtime control
Function-object control
Debug control
Optimisation control
External library control

The following shows a typical set of key-value pairs available in the
controlDict:
$ cat system/controlDict

[...]

application     simpleFoam;         // name of solver application

startFrom       startTime;          <--
startTime       0;                  //
stopAt          endTime;            // Time/Iteration control
endTime         2000;               //
deltaT          1;                  -->

writeControl    timeStep;           <--
writeInterval   100;                //
purgeWrite      0;                  //
writeFormat     ascii;              // Output control
writePrecision  6;                  //
writeCompression off;               //
timeFormat      general;            //
timePrecision   6;                  -->

runTimeModifiable true;             // Runtime modifications

functions                           <--
{                                   //
    #includeFunc streamlines        // Function objects
    #include ""streamlines""          //
}                                   -->

DebugSwitches                       <--
{                                   //
    SolverPerformance   0;          // Debug control
}                                   -->

OptimisationSwitches                <--
{                                   //
    writeNowSignal  12;             // Optimisation control
}                                   -->

libs                                <--
(                                   //
    externalLibraryName             // External library control
);                                  -->

[...]

Processð

To run this case, you can simply execute two consecutive commands.
First, the mesh is generated using the blockMesh utility.
Run the utility with the following command (the execution should take a few
seconds):
$ blockMesh

This command will display various utility messages and generate the mesh in the
constant/polyMesh directory. You can verify the mesh generation by checking
the contents of the directory using the command:
$ ls -p constant/polyMesh/
boundary  faces  neighbour  owner  points

If you need to make changes to the blockMeshDict settings or redirect the
utilityâs output to a log file, you can rerun the
blockMesh using the command:
$ blockMesh >& log.blockMesh

You can also use the internal runner functions available in OpenFOAMÂ®
(e.g. runApplication):
$ source ${WM_PROJECT_DIR:?}/bin/tools/RunFunctions

$ runApplication blockMesh

The next and final step is to run the solver application by executing
the following command (the execution should take a few seconds):
$ simpleFoam >& log.simpleFoam

Running this command will run the simulation and print valuable information
into the log file. This information includes updates on the convergence of the
linear solvers, progress in simulation iterations, and details about function
objects, among others.
Upon completion of the simulation, you will notice that OpenFOAMÂ® has
created new time directories containing solutions specific to each time step,
post-processing data generated by function objects, and log files:
$ ls -p
0/  100/  200/  282/  constant/  log.blockMesh  log.simpleFoam  postProcessing/  system/

Post-processð

Once the simulation has been completed, the next step is post-processing
the results to extract meaningful information and visualize the data.
OpenFOAMÂ® provides many powerful tools for post-processing that can
be executed during runtime and/or after the simulation, e.g.
postProcess utility.
You can visualise the simulation results by an external visualiation toolkit.
One of the most commonly used tools for field visualization is ParaView,
an open-source visualization software that integrates well with OpenFOAMÂ®.
An example visualisation of the velocity magnitude field at the last
iteration step using ParaView can be seen below:





Search results
Number of hits : 





Found a content problem with this page?

Submit a bug report
Edit source code on GitLab
View source code on GitLab

Want to get more involved? Learn how to contribute
Last updated: Jan 02, 2024


 Author(s): OpenCFD Ltd.
 Copyright Â© 2024 OpenCFD Ltd.




This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License



OpenFOAMÂ® Installation
Problem Setup

Pre-process 
Physical domain
Physical properties
Spatial domain discretisation
Temporal domain discretisation
Equation discretisation
Initial/boundary conditions
Pressure-velocity coupling algorithm
Linear solvers
Case control


Process
Post-process

















"
27,https://github.com/Jianxun-Wang/phygeonet,"






































































GitHub - Jianxun-Wang/phygeonet: PhyGeoNet: Physics-Informed Geometry-Adaptive Convolutional Neural Networks for Solving Parametric PDEs on Irregular Domain














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        Jianxun-Wang
 
/

phygeonet

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    32




 


          Star
 84








        PhyGeoNet: Physics-Informed Geometry-Adaptive Convolutional Neural Networks for Solving Parametric PDEs on Irregular Domain
      





84
          stars
 



32
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
5






Pull requests
0






Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Actions











          Projects











          Security











          Insights






 





Jianxun-Wang/phygeonet



 












    masterBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History20 Commitscase0case0  case1case1  case2case2  case3case3  case4case4  sourcesource  PleaseReadMe.txtPleaseReadMe.txt  README.mdREADME.md  View all filesRepository files navigationREADMEPhyGeoNet: Physics-Informed Geometry-Adaptive Convolutional Neural Networks for Solving Steady-State Parametric PDEs on Irregular Domain
Physics-Informed Geometry-Adaptive Convolutional Neural Networks for Solving Steady-State Parametric PDEs on Irregular Domain
Han Gao, Luning Sun, Jian-Xun Wang



Geometry-Adaptive






Citation
If you find this repo useful for your research, please consider to cite:
@article{gao_phygeonet:_2020,
	title = {{PhyGeoNet}: {Physics}-informed geometry-adaptive convolutional neural networks for solving {Parameterized} {Steady}-{State} {PDEs} on irregular domain},
	issn = {00219991},
	shorttitle = {{PhyGeoNet}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999120308536},
	doi = {10.1016/j.jcp.2020.110079},
	language = {en},
	urldate = {2021-01-04},
	journal = {Journal of Computational Physics},
	author = {Gao, Han and Sun, Luning and Wang, Jian-Xun},
	month = dec,
	year = {2020},
	pages = {110079},
}
   








About

        PhyGeoNet: Physics-Informed Geometry-Adaptive Convolutional Neural Networks for Solving Parametric PDEs on Irregular Domain
      
Resources





        Readme
 






Activity 
Stars




84
      stars 
Watchers




9
      watching 
Forks




32
      forks 


          Report repository
 






Releases
No releases published





Packages
      0

        No packages published 












Contributors
      2







gaohan1234
Han Gao

 






Jianxun-Wang
Jian-Xun Wang

 





Languages











C++
99.8%







Python
0.2%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
28,https://docs.sciml.ai/Overview/stable/,"SciML: Open Source Software for Scientific Machine Learning with Julia Â· Overview of Julia's SciMLHomeModelingModeling LanguagesModelingToolkitCatalystNBodySimulatorParameterizedFunctionsModel Libraries and ImportersModelingToolkitStandardLibraryModelingToolkitNeuralNetsDiffEqCallbacksFiniteStateProjectionCellMLToolkitSBMLToolkitBaseModelicaReactionNetworkImportersSymbolic ToolsModelOrderReductionSymbolicsSymbolicUtilsArray LibrariesRecursiveArrayToolsComponentArraysLabelledArraysMultiScaleArraysSolversEquation SolversLinearSolveNonlinearSolveDifferentialEquationsIntegralsDifferenceEquationsOptimizationJumpProcessesLineSearchInverse Problems / EstimationSciMLSensitivityDiffEqParamEstimDiffEqBayesPDE SolversMethodOfLinesNeuralPDENeuralOperatorsFEniCSHighDimPDEDiffEqOperatorsAdvanced Solver APIsOrdinaryDiffEqBoundaryValueDiffEqDiffEqGPUAnalysisParameter AnalysisEasyModelAnalysisGlobalSensitivityStructuralIdentifiabilityUncertainty QuantificationPolyChaosSciMLExpectationsMachine LearningFunction ApproximationSurrogatesReservoirComputingImplicit Layer Deep LearningDiffEqFluxDeepEquilibriumNetworksSymbolic LearningDataDrivenDiffEqSymbolicNumericIntegrationThird-Party Differentiation ToolingSparseDiffToolsFiniteDiffDeveloper ToolsNumerical UtilitiesExponentialUtilitiesDiffEqNoiseProcessPreallocationToolsEllipsisNotationDataInterpolationsPoissonRandomQuasiMonteCarloRuntimeGeneratedFunctionsMuladdMacroFindFirstFunctionsSparseDiffToolsHigh-Level InterfacesSciMLBaseSciMLStructuresADTypesSymbolicIndexingInterfaceTermInterfaceSciMLOperatorsSurrogatesBaseCommonSolveThird-Party InterfacesArrayInterfaceStaticArrayInterfaceDeveloper DocumentationSciMLStyleColPracDiffEq Developer DocumentationExtra ResourcesSciMLWorkshopExtended SciML TutorialsThe SciML BenchmarksModelingToolkitCourseCommercial SupportCommercial SupportJuliaHub offers commercial support for ModelingToolkit and the SciML ecosystem.  Contact us today to discuss your needs!Products built with SciML
        JuliaSim
    
        Pumas
    
        Cedar EDA
    
        Neuroblox
    
        Planting Space
    /Overview of Julia's SciMLSearch docs (Ctrl + /)SciML: Open Source Software for Scientific Machine Learning with JuliaWhere to Start?ReproducibilityGetting StartedGetting Started with Julia's SciMLNew User TutorialsInstalling SciML SoftwareBuild and run your first simulation with Julia's SciMLSolve your first optimization problemFit a simulation to a datasetFind the root of an equation (i.e. solve f(u)=0)Comparison With Other ToolsGetting Started with Julia's SciML for the Python UserGetting Started with  Julia's SciML for the MATLAB UserGetting Started with Julia's SciML for the R UserGetting Started with Julia's SciML for the C++/Fortran UserShowcase of Cool ExamplesThe SciML ShowcaseAutomated Model DiscoveryAutomatically Discover Missing Physics by Embedding Machine Learning into Differential EquationsUncertainty Quantified Deep Bayesian Model DiscoveryDiscovering the Relativistic Corrections to Binary Black Hole DynamicsSolving Difficult Equations EfficientlyAutomated Efficient Solution of Nonlinear Partial Differential EquationsGPU-Accelerated Physics-Informed Neural Network (PINN) PDE SolversMassively Data-Parallel ODE Solving on GPUsGPU-Accelerated Stochastic Partial Differential EquationsUseful Cool Wonky ThingsAutomatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia's Type SystemSymbolic-Numeric Analysis of Parameter Identifiability and Model StabilityOptimization Under UncertaintyWhat is SciML?Detailed Overview of the SciML Software EcosystemSolversEquation SolversParameter Estimation, Bayesian Analysis, and Inverse ProblemsPartial Differential Equations (PDE)Modeling ToolsModeling LanguagesModel Libraries and ImportersSymbolic Model Tooling and JuliaSymbolicsModeling Array LibrariesSimulation AnalysisParameter Analysis UtilitiesUncertainty QuantificationSciML-Supported Plotting and Visualization LibrariesMachine LearningFunction ApproximationImplicit Layer Deep LearningSymbolic Learning and Artificial IntelligenceDeveloper ToolsSciML Numerical Utility LibrariesThe SciML Interface LibrariesDeveloper DocumentationExtra Learning ResourcesCurated Learning, Teaching, and Training ResourcesVersionSciML: Open Source Software for Scientific Machine Learning with JuliaSciML: Open Source Software for Scientific Machine Learning with JuliaïGitHubïSciML: Differentiable Modeling and Simulation Combined with Machine LearningThe SciML organization is a collection of tools for solving equations and modeling systems developed in the Julia programming language with bindings to other languages such as R and Python. The organization provides well-maintained tools which compose together as a coherent ecosystem. It has a coherent development principle, unified APIs over large collections of equation solvers, pervasive differentiability and sensitivity analysis, and features many of the highest performance and parallel implementations one can find.Scientific Machine Learning (SciML) = Scientific Computing + Machine LearningWhere to Start?Want to get started running some code? Check out the Getting Started tutorials.What is SciML? Check out our Overview.Want to see some cool end-to-end examples? Check out the SciML Showcase.Curious about our performance claims? Check out the SciML Open Benchmarks.Want to learn more about how SciML does scientific machine learning? Check out the SciML Book (from MIT's 18.337 graduate course).Want to chat with someone? Check out our chat room and forums.Want to see our code? Check out the SciML GitHub organization.And for diving into the details, use the bar on the top to navigate to the submodule of interest!ReproducibilityThe documentation of the SciML Showcase was built using these direct dependencies,Status `/var/lib/buildkite-agent/builds/gpuci-3/julialang/scimldocs/docs/Project.toml`
  [0bf59076] AdvancedHMC v0.6.2
  [6e4b80f9] BenchmarkTools v1.5.0
  [336ed68f] CSV v0.10.15
  [052768ef] CUDA v5.5.2
  [b0b7db55] ComponentArrays v0.15.17
  [2445eb08] DataDrivenDiffEq v1.5.0
  [5b588203] DataDrivenSparse v0.1.2
  [a93c6f00] DataFrames v1.7.0
  [071ae1c0] DiffEqGPU v3.4.1
  [0c46a032] DifferentialEquations v7.14.0
  [31c24e10] Distributions v0.25.112
  [e30172f5] Documenter v1.7.0
  [5b8099bc] DomainSets v0.7.14
  [587475ba] Flux v0.14.22
  [f6369f11] ForwardDiff v0.10.36
  [40713840] IncompleteLU v0.2.1
  [de52edbc] Integrals v4.5.0
  [d3d80556] LineSearches v7.3.0
  [7ed4a6bd] LinearSolve v2.36.1
  [b2108857] Lux v1.2.0
  [d0bbae9a] LuxCUDA v0.3.3
  [c7f686f2] MCMCChains v6.0.6
  [eff96d63] Measurements v2.11.0
  [94925ecb] MethodOfLines v0.11.6
  [961ee093] ModelingToolkit v9.49.0
  [87ed4bf0] MultiDocumenter v0.7.0
  [315f7962] NeuralPDE v5.17.0
  [8913a72c] NonlinearSolve v3.15.1
  [7f7a1694] Optimization v4.0.5
  [fd9f6733] OptimizationMOI v0.5.1
  [4e6fcdb7] OptimizationNLopt v0.3.1
  [36348300] OptimizationOptimJL v0.4.1
  [42dfb2eb] OptimizationOptimisers v0.3.4
  [500b13db] OptimizationPolyalgorithms v0.3.0
  [1dea7af3] OrdinaryDiffEq v6.89.0
  [91a5bcdd] Plots v1.40.8
  [afe9f18d] SciMLExpectations v2.2.0
â [1ed8b502] SciMLSensitivity v7.68.0
  [860ef19b] StableRNGs v1.0.2
  [90137ffa] StaticArrays v1.9.8
  [10745b16] Statistics v1.11.1
  [f3b207a7] StatsPlots v0.15.7
  [1986cc42] Unitful v1.21.0
  [e88e6eb3] Zygote v0.6.72
  [76f85450] LibGit2 v1.11.0
  [37e2e46d] LinearAlgebra v1.11.0
  [44cfe95a] Pkg v1.11.0
  [de0858da] Printf v1.11.0
  [9a3f8284] Random v1.11.0
Info Packages marked with â have new versions available and may be upgradable.and using this machine and Julia version.Julia Version 1.11.1
Commit 8f5b7ca12ad (2024-10-16 10:53 UTC)
Build Info:
  Official https://julialang.org/ release
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: 48 Ã AMD EPYC 7402 24-Core Processor
  WORD_SIZE: 64
  LLVM: libLLVM-16.0.6 (ORCJIT, znver2)
Threads: 1 default, 0 interactive, 1 GC (on 2 virtual cores)
Environment:
  JULIA_CPU_THREADS = 2
  JULIA_DEBUG = Documenter
  JULIA_DEPOT_PATH = /root/.cache/julia-buildkite-plugin/depots/0183cc98-c3b4-4959-aaaa-6c0d5f351407
  LD_LIBRARY_PATH = /usr/local/nvidia/lib:/usr/local/nvidia/lib64
  JULIA_PKG_SERVER =A more complete overview of all dependencies and their versions is also provided.Status `/var/lib/buildkite-agent/builds/gpuci-3/julialang/scimldocs/docs/Manifest.toml`
  [47edcb42] ADTypes v1.9.0
  [a4c015fc] ANSIColoredPrinters v0.0.1
  [621f4979] AbstractFFTs v1.5.0
  [80f14c24] AbstractMCMC v5.6.0
  [1520ce14] AbstractTrees v0.4.5
  [7d9f7c33] Accessors v0.1.38
  [79e6a3ab] Adapt v4.1.0
  [0bf59076] AdvancedHMC v0.6.2
  [66dad0bd] AliasTables v1.1.3
  [dce04be8] ArgCheck v2.3.0
  [ec485272] ArnoldiMethod v0.4.0
  [7d9fca2a] Arpack v0.5.4
  [4fba245c] ArrayInterface v7.16.0
  [4c555306] ArrayLayouts v1.10.4
  [a9b6321e] Atomix v0.1.0
  [13072b0f] AxisAlgorithms v1.1.0
  [39de3d68] AxisArrays v0.4.7
  [ab4f0b2a] BFloat16s v0.5.0
  [aae01518] BandedMatrices v1.7.5
  [198e06fe] BangBang v0.4.3
  [9718e550] Baselet v0.1.1
  [6e4b80f9] BenchmarkTools v1.5.0
  [e2ed5e7c] Bijections v0.1.9
  [d1d4a3ce] BitFlags v0.1.9
  [62783981] BitTwiddlingConvenienceFunctions v0.1.6
  [8e7c35d0] BlockArrays v1.1.1
  [764a87c0] BoundaryValueDiffEq v5.11.0
  [fa961155] CEnum v0.5.0
  [2a0fbf3d] CPUSummary v0.2.6
  [00ebfdb7] CSTParser v3.4.3
  [336ed68f] CSV v0.10.15
  [052768ef] CUDA v5.5.2
  [1af6417a] CUDA_Runtime_Discovery v0.3.5
  [49dc2e85] Calculus v0.5.2
  [7057c7e9] Cassette v0.3.14
  [082447d4] ChainRules v1.71.0
  [d360d2e6] ChainRulesCore v1.25.0
  [fb6a15b2] CloseOpenIntervals v0.1.13
  [aaaa29a8] Clustering v0.15.7
  [523fee87] CodecBzip2 v0.8.4
  [944b1d66] CodecZlib v0.7.6
  [35d6a980] ColorSchemes v3.27.0
â [3da002f7] ColorTypes v0.11.5
  [c3611d14] ColorVectorSpace v0.10.0
â [5ae59095] Colors v0.12.11
  [861a8166] Combinatorics v1.0.2
  [a80b9123] CommonMark v0.8.15
  [38540f10] CommonSolve v0.2.4
  [bbf7d656] CommonSubexpressions v0.3.1
  [f70d9fcc] CommonWorldInvalidations v1.0.0
  [34da2185] Compat v4.16.0
  [b0b7db55] ComponentArrays v0.15.17
  [b152e2b5] CompositeTypes v0.1.4
  [a33af91c] CompositionsBase v0.1.2
  [2569d6c7] ConcreteStructs v0.2.3
  [f0e56b4a] ConcurrentUtilities v2.4.2
  [88cd18e8] ConsoleProgressMonitor v0.1.2
  [187b0558] ConstructionBase v1.5.8
  [6add18c4] ContextVariablesX v0.1.3
  [d38c429a] Contour v0.6.3
  [adafc99b] CpuId v0.3.1
  [a8cc5b0e] Crayons v4.1.1
  [667455a9] Cubature v1.5.1
  [9a962f9c] DataAPI v1.16.0
  [2445eb08] DataDrivenDiffEq v1.5.0
  [5b588203] DataDrivenSparse v0.1.2
  [a93c6f00] DataFrames v1.7.0
  [82cc6244] DataInterpolations v6.5.2
  [864edb3b] DataStructures v0.18.20
  [e2d170a0] DataValueInterfaces v1.0.0
  [244e2a9f] DefineSingletons v0.1.2
  [bcd4f6db] DelayDiffEq v5.48.1
  [8bb1440f] DelimitedFiles v1.9.1
  [2b5f629d] DiffEqBase v6.158.3
â [459566f4] DiffEqCallbacks v3.9.1
  [071ae1c0] DiffEqGPU v3.4.1
  [77a26b50] DiffEqNoiseProcess v5.23.0
  [163ba53b] DiffResults v1.1.0
  [b552c78f] DiffRules v1.15.1
  [0c46a032] DifferentialEquations v7.14.0
  [a0c0ee7d] DifferentiationInterface v0.6.17
  [8d63f2c5] DispatchDoctor v0.4.17
  [b4f34e82] Distances v0.10.12
  [31c24e10] Distributions v0.25.112
  [ffbed154] DocStringExtensions v0.9.3
  [e30172f5] Documenter v1.7.0
  [5b8099bc] DomainSets v0.7.14
  [7c1d4256] DynamicPolynomials v0.6.0
  [06fc5a27] DynamicQuantities v1.1.0
  [da5c29d0] EllipsisNotation v1.8.0
  [4e289a0a] EnumX v1.0.4
  [7da242da] Enzyme v0.13.12
  [f151be2c] EnzymeCore v0.8.4
  [460bff9d] ExceptionUnwrapping v0.1.10
  [d4d017d3] ExponentialUtilities v1.26.1
  [e2ba6199] ExprTools v0.1.10
â [6b7a57c9] Expronicon v0.8.5
  [c87230d0] FFMPEG v0.4.2
  [7a1cc6ca] FFTW v1.8.0
  [cc61a311] FLoops v0.2.2
  [b9860ae5] FLoopsBase v0.1.1
  [9d29842c] FastAlmostBandedMatrices v0.1.4
  [7034ab61] FastBroadcast v0.3.5
  [9aa1b823] FastClosures v0.3.2
  [29a986be] FastLapackInterface v2.0.4
  [a4df4552] FastPower v1.1.1
  [48062228] FilePathsBase v0.9.22
  [1a297f60] FillArrays v1.13.0
  [64ca27bc] FindFirstFunctions v1.4.1
  [6a86dc24] FiniteDiff v2.26.0
  [53c48c17] FixedPointNumbers v0.8.5
  [587475ba] Flux v0.14.22
  [1fa38f19] Format v1.3.7
  [f6369f11] ForwardDiff v0.10.36
  [f62d2435] FunctionProperties v0.1.2
  [069b7b12] FunctionWrappers v1.1.3
  [77dc65aa] FunctionWrappersWrappers v0.1.3
  [d9f16b24] Functors v0.4.12
â [0c68f7d7] GPUArrays v10.3.1
â [46192b85] GPUArraysCore v0.1.6
â [61eb1bfa] GPUCompiler v0.27.8
  [28b8d3ca] GR v0.73.8
  [14197337] GenericLinearAlgebra v0.3.14
  [c145ed77] GenericSchur v0.5.4
  [d7ba0133] Git v1.3.1
  [c27321d9] Glob v1.3.1
  [86223c79] Graphs v1.12.0
  [42e2da0e] Grisu v1.0.2
  [708ec375] Gumbo v0.8.2
  [19dc6840] HCubature v1.7.0
  [cd3eb016] HTTP v1.10.9
  [3e5b6fbb] HostCPUFeatures v0.1.17
  [0e44f5e4] Hwloc v3.3.0
  [34004b35] HypergeometricFunctions v0.3.24
  [ac1192a8] HypertextLiteral v0.9.5
  [b5f81e59] IOCapture v0.2.5
  [7869d1d1] IRTools v0.4.14
  [615f187c] IfElse v0.1.1
  [40713840] IncompleteLU v0.2.1
  [d25df0c9] Inflate v0.1.5
  [22cec73e] InitialValues v0.3.1
  [842dd82b] InlineStrings v1.4.2
  [505f98c9] InplaceOps v0.3.0
  [18e54dd8] IntegerMathUtils v0.1.2
  [de52edbc] Integrals v4.5.0
  [a98d9a8b] Interpolations v0.15.1
  [8197267c] IntervalSets v0.7.10
  [3587e190] InverseFunctions v0.1.17
  [41ab1584] InvertedIndices v1.3.0
  [92d709cd] IrrationalConstants v0.2.2
  [c8e1da08] IterTools v1.10.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [1019f520] JLFzf v0.1.8
  [692b3bcd] JLLWrappers v1.6.1
  [682c06a0] JSON v0.21.4
  [98e50ef6] JuliaFormatter v1.0.62
  [b14d175d] JuliaVariables v0.2.4
  [ccbc3e58] JumpProcesses v9.14.0
  [ef3ab10e] KLU v0.6.0
  [63c18a36] KernelAbstractions v0.9.29
  [5ab0869b] KernelDensity v0.6.9
  [ba0b0d4f] Krylov v0.9.8
  [5be7bae1] LBFGSB v0.4.1
  [929cbde3] LLVM v9.1.3
  [8b046642] LLVMLoopInfo v1.0.0
  [b964fa9f] LaTeXStrings v1.4.0
  [23fbe1c1] Latexify v0.16.5
  [73f95e8e] LatticeRules v0.0.1
  [10f19ff3] LayoutPointers v0.1.17
  [0e77f7df] LazilyInitializedFields v1.2.2
  [5078a376] LazyArrays v2.2.1
  [1d6d02ad] LeftChildRightSiblingTrees v0.2.0
  [2d8b4e74] LevyArea v1.0.0
  [87fe0de2] LineSearch v0.1.4
  [d3d80556] LineSearches v7.3.0
  [7ed4a6bd] LinearSolve v2.36.1
  [6fdf6af0] LogDensityProblems v2.1.2
  [996a588d] LogDensityProblemsAD v1.11.0
  [2ab3a3ac] LogExpFunctions v0.3.28
  [e6f89c97] LoggingExtras v1.1.0
  [bdcacae8] LoopVectorization v0.12.171
  [b2108857] Lux v1.2.0
  [d0bbae9a] LuxCUDA v0.3.3
  [bb33d45b] LuxCore v1.0.1
  [82251201] LuxLib v1.3.6
  [c7f686f2] MCMCChains v6.0.6
  [be115224] MCMCDiagnosticTools v0.3.10
  [7e8f7934] MLDataDevices v1.4.2
  [e80e1ace] MLJModelInterface v1.11.0
  [d8e11817] MLStyle v0.4.17
  [f1d291b0] MLUtils v0.4.4
  [1914dd2f] MacroTools v0.5.13
  [d125e4d3] ManualMemory v0.1.8
  [d0879d2d] MarkdownAST v0.1.2
  [b8f27783] MathOptInterface v1.33.0
  [a3b82374] MatrixFactorizations v3.0.1
  [bb5d69b7] MaybeInplace v0.1.4
  [739be429] MbedTLS v1.1.9
  [eff96d63] Measurements v2.11.0
  [442fdcdd] Measures v0.3.2
  [94925ecb] MethodOfLines v0.11.6
  [128add7d] MicroCollections v0.2.0
  [e1d29d7a] Missings v1.2.0
  [961ee093] ModelingToolkit v9.49.0
  [4886b29c] MonteCarloIntegration v0.2.0
  [0987c9cc] MonteCarloMeasurements v1.2.1
  [46d2c3a1] MuladdMacro v0.2.4
  [87ed4bf0] MultiDocumenter v0.7.0
  [102ac46a] MultivariatePolynomials v0.5.7
  [6f286f6a] MultivariateStats v0.10.3
  [d8a4904e] MutableArithmetics v1.5.2
  [d41bc354] NLSolversBase v7.8.3
  [76087f3c] NLopt v1.1.1
  [2774e3e8] NLsolve v4.5.1
  [872c559c] NNlib v0.9.24
  [5da4648a] NVTX v0.3.4
  [77ba4419] NaNMath v1.0.2
  [71a1bf82] NameResolution v0.1.5
  [c020b1a1] NaturalSort v1.0.0
  [b8a86587] NearestNeighbors v0.4.20
  [315f7962] NeuralPDE v5.17.0
  [2bd173c7] NodeJS v2.0.0
  [8913a72c] NonlinearSolve v3.15.1
  [d8793406] ObjectFile v0.4.2
  [510215fc] Observables v0.5.5
  [6fe1bfb0] OffsetArrays v1.14.1
  [0b1bfda6] OneHotArrays v0.2.5
  [4d8831e6] OpenSSL v1.4.3
  [429524aa] Optim v1.9.4
  [3bd65402] Optimisers v0.3.3
  [7f7a1694] Optimization v4.0.5
  [bca83a33] OptimizationBase v2.3.0
  [fd9f6733] OptimizationMOI v0.5.1
  [4e6fcdb7] OptimizationNLopt v0.3.1
  [36348300] OptimizationOptimJL v0.4.1
  [42dfb2eb] OptimizationOptimisers v0.3.4
  [500b13db] OptimizationPolyalgorithms v0.3.0
  [bac558e1] OrderedCollections v1.6.3
  [1dea7af3] OrdinaryDiffEq v6.89.0
  [89bda076] OrdinaryDiffEqAdamsBashforthMoulton v1.1.0
  [6ad6398a] OrdinaryDiffEqBDF v1.1.2
  [bbf590c4] OrdinaryDiffEqCore v1.9.0
  [50262376] OrdinaryDiffEqDefault v1.1.0
  [4302a76b] OrdinaryDiffEqDifferentiation v1.1.0
  [9286f039] OrdinaryDiffEqExplicitRK v1.1.0
  [e0540318] OrdinaryDiffEqExponentialRK v1.1.0
  [becaefa8] OrdinaryDiffEqExtrapolation v1.2.1
  [5960d6e9] OrdinaryDiffEqFIRK v1.2.0
  [101fe9f7] OrdinaryDiffEqFeagin v1.1.0
  [d3585ca7] OrdinaryDiffEqFunctionMap v1.1.1
  [d28bc4f8] OrdinaryDiffEqHighOrderRK v1.1.0
  [9f002381] OrdinaryDiffEqIMEXMultistep v1.1.0
  [521117fe] OrdinaryDiffEqLinear v1.1.0
  [1344f307] OrdinaryDiffEqLowOrderRK v1.2.0
  [b0944070] OrdinaryDiffEqLowStorageRK v1.2.1
  [127b3ac7] OrdinaryDiffEqNonlinearSolve v1.2.1
  [c9986a66] OrdinaryDiffEqNordsieck v1.1.0
  [5dd0a6cf] OrdinaryDiffEqPDIRK v1.1.0
  [5b33eab2] OrdinaryDiffEqPRK v1.1.0
  [04162be5] OrdinaryDiffEqQPRK v1.1.0
  [af6ede74] OrdinaryDiffEqRKN v1.1.0
  [43230ef6] OrdinaryDiffEqRosenbrock v1.2.0
  [2d112036] OrdinaryDiffEqSDIRK v1.1.0
  [669c94d9] OrdinaryDiffEqSSPRK v1.2.0
  [e3e12d00] OrdinaryDiffEqStabilizedIRK v1.1.0
  [358294b1] OrdinaryDiffEqStabilizedRK v1.1.0
  [fa646aed] OrdinaryDiffEqSymplecticRK v1.1.0
  [b1df2697] OrdinaryDiffEqTsit5 v1.1.0
  [79d7bb75] OrdinaryDiffEqVerner v1.1.1
  [a7812802] PDEBase v0.1.15
  [90014a1f] PDMats v0.11.31
  [65ce6f38] PackageExtensionCompat v1.0.2
  [d96e819e] Parameters v0.12.3
  [69de0a69] Parsers v2.8.1
  [b98c9c47] Pipe v1.3.0
  [ccf2f8ad] PlotThemes v3.3.0
  [995b91a9] PlotUtils v1.4.2
  [91a5bcdd] Plots v1.40.8
  [e409e4f3] PoissonRandom v0.4.4
  [f517fe37] Polyester v0.7.16
  [1d0040c9] PolyesterWeave v0.2.2
  [f27b6e38] Polynomials v4.0.11
  [2dfb63ee] PooledArrays v1.4.3
  [85a6dd25] PositiveFactorizations v0.2.4
  [d236fae5] PreallocationTools v0.4.24
  [aea7be01] PrecompileTools v1.2.1
  [21216c6a] Preferences v1.4.3
  [8162dcfd] PrettyPrint v0.2.0
  [08abe8d2] PrettyTables v2.4.0
  [27ebfcd6] Primes v0.5.6
  [33c8b6b6] ProgressLogging v0.1.4
  [92933f4c] ProgressMeter v1.10.2
  [43287f4e] PtrArrays v1.2.1
  [1fd47b50] QuadGK v2.11.1
  [8a4e6c94] QuasiMonteCarlo v0.3.3
  [74087812] Random123 v1.7.0
  [e6cf234a] RandomNumbers v1.6.0
  [b3c3ace0] RangeArrays v0.3.2
  [c84ed2f1] Ratios v0.4.5
  [c1ae055f] RealDot v0.1.0
  [3cdcf5f2] RecipesBase v1.3.4
  [01d81517] RecipesPipeline v0.6.12
  [731186ca] RecursiveArrayTools v3.27.1
  [f2c3362d] RecursiveFactorization v0.2.23
  [189a3867] Reexport v1.2.2
  [2792f1a3] RegistryInstances v0.1.0
  [05181044] RelocatableFolders v1.0.1
  [ae029012] Requires v1.3.0
  [ae5879a3] ResettableStacks v1.1.1
  [37e2e3b7] ReverseDiff v1.15.3
  [79098fc4] Rmath v0.8.0
  [47965b36] RootedTrees v2.23.1
  [7e49a35a] RuntimeGeneratedFunctions v0.5.13
  [94e857df] SIMDTypes v0.1.0
  [476501e8] SLEEFPirates v0.6.43
  [0bca4576] SciMLBase v2.57.2
  [afe9f18d] SciMLExpectations v2.2.0
  [19f34311] SciMLJacobianOperators v0.1.0
  [c0aeaf25] SciMLOperators v0.3.11
â [1ed8b502] SciMLSensitivity v7.68.0
  [53ae85a6] SciMLStructures v1.5.0
  [30f210dd] ScientificTypesBase v3.0.0
  [6c6a2e73] Scratch v1.2.1
  [91c51154] SentinelArrays v1.4.6
  [efcf1570] Setfield v1.1.1
  [605ecd9f] ShowCases v0.1.0
  [992d4aef] Showoff v1.0.3
  [777ac1f9] SimpleBufferStream v1.2.0
  [05bca326] SimpleDiffEq v1.11.1
  [727e6d20] SimpleNonlinearSolve v1.12.3
  [699a6c99] SimpleTraits v0.9.4
  [ce78b400] SimpleUnPack v1.1.0
  [ed01d8cd] Sobol v1.5.0
  [a2af1166] SortingAlgorithms v1.2.1
  [9f842d2f] SparseConnectivityTracer v0.6.8
  [47a9eef4] SparseDiffTools v2.23.0
  [dc90abb0] SparseInverseSubset v0.1.2
  [0a514795] SparseMatrixColorings v0.4.8
  [e56a9233] Sparspak v0.3.9
  [276daf66] SpecialFunctions v2.4.0
  [171d559e] SplittablesBase v0.1.15
  [860ef19b] StableRNGs v1.0.2
  [aedffcd0] Static v1.1.1
  [0d7ed370] StaticArrayInterface v1.8.0
  [90137ffa] StaticArrays v1.9.8
  [1e83bf80] StaticArraysCore v1.4.3
  [64bff920] StatisticalTraits v3.4.0
  [10745b16] Statistics v1.11.1
  [82ae8749] StatsAPI v1.7.0
  [2913bbd2] StatsBase v0.34.3
  [4c63d2b9] StatsFuns v1.3.2
  [f3b207a7] StatsPlots v0.15.7
  [9672c7b4] SteadyStateDiffEq v2.4.1
  [789caeaf] StochasticDiffEq v6.70.0
  [7792a7ef] StrideArraysCore v0.5.7
  [892a3eda] StringManipulation v0.4.0
  [09ab397b] StructArrays v0.6.18
  [53d494c1] StructIO v0.3.1
  [c3572dad] Sundials v4.26.0
  [2efcf032] SymbolicIndexingInterface v0.3.33
  [19f23fe9] SymbolicLimits v0.2.2
  [d1185830] SymbolicUtils v3.7.2
  [0c5d862f] Symbolics v6.16.0
  [ab02a1b2] TableOperations v1.2.0
  [3783bdb8] TableTraits v1.0.1
  [bd369af6] Tables v1.12.0
  [62fd8b95] TensorCore v0.1.1
  [8ea1fca8] TermInterface v2.0.0
  [5d786b92] TerminalLoggers v0.1.7
  [1c621080] TestItems v1.0.0
  [8290d209] ThreadingUtilities v0.5.2
  [a759f4b9] TimerOutputs v0.5.25
  [0796e94c] Tokenize v0.5.29
  [9f7883ad] Tracker v0.2.35
  [3bb67fe8] TranscodingStreams v0.11.3
  [28d57a85] Transducers v0.4.84
  [d5829a12] TriangularSolve v0.2.1
  [410a4b4d] Tricks v0.1.9
  [781d530d] TruncatedStacktraces v1.4.0
  [5c2747f8] URIs v1.5.1
  [3a884ed6] UnPack v1.0.2
  [1cfade01] UnicodeFun v0.4.1
  [1986cc42] Unitful v1.21.0
  [45397f5d] UnitfulLatexify v1.6.4
  [a7c27f48] Unityper v0.1.6
  [013be700] UnsafeAtomics v0.2.1
  [d80eeb9a] UnsafeAtomicsLLVM v0.2.1
  [41fe7b60] Unzip v0.2.0
  [3d5dd08c] VectorizationBase v0.21.70
  [19fa3120] VertexSafeGraphs v0.2.0
  [ea10d353] WeakRefStrings v1.4.2
  [d49dbf32] WeightInitializers v1.0.4
  [cc8bc4a8] Widgets v0.6.6
  [efce3f68] WoodburyMatrices v1.0.0
  [76eceee3] WorkerUtilities v1.6.1
  [e88e6eb3] Zygote v0.6.72
  [700de1a5] ZygoteRules v0.2.5
  [02a925ec] cuDNN v1.4.0
â [68821587] Arpack_jll v3.5.1+1
  [6e34b625] Bzip2_jll v1.0.8+2
  [4ee394cb] CUDA_Driver_jll v0.10.3+0
  [76a88914] CUDA_Runtime_jll v0.15.3+0
  [62b44479] CUDNN_jll v9.4.0+0
  [83423d85] Cairo_jll v1.18.2+1
  [7bc98958] Cubature_jll v1.0.5+0
  [ee1fde0b] Dbus_jll v1.14.10+0
  [7cc45869] Enzyme_jll v0.0.157+0
  [2702e6a9] EpollShim_jll v0.0.20230411+0
  [2e619515] Expat_jll v2.6.2+0
â [b22a6f82] FFMPEG_jll v4.4.4+1
  [f5851436] FFTW_jll v3.3.10+1
  [a3f928ae] Fontconfig_jll v2.13.96+0
  [d7e528f0] FreeType2_jll v2.13.2+0
  [559328eb] FriBidi_jll v1.0.14+0
  [0656b61e] GLFW_jll v3.4.0+1
  [d2c73de3] GR_jll v0.73.8+0
  [78b55507] Gettext_jll v0.21.0+0
  [f8c6e375] Git_jll v2.46.2+0
  [7746bdde] Glib_jll v2.80.5+0
  [3b182d85] Graphite2_jll v1.3.14+0
  [528830af] Gumbo_jll v0.10.2+0
  [2e76f6c2] HarfBuzz_jll v8.3.1+0
  [e33a78d0] Hwloc_jll v2.11.2+0
  [1d5cc7b8] IntelOpenMP_jll v2024.2.1+0
  [aacddb02] JpegTurbo_jll v3.0.4+0
  [9c1d0b0a] JuliaNVTXCallbacks_jll v0.2.1+0
  [c1c5ebd0] LAME_jll v3.100.2+0
  [88015f11] LERC_jll v4.0.0+0
  [dad2f222] LLVMExtra_jll v0.0.34+0
  [1d63c593] LLVMOpenMP_jll v18.1.7+0
  [dd4b983a] LZO_jll v2.10.2+1
  [81d17ec3] L_BFGS_B_jll v3.0.1+0
â [e9f186c6] Libffi_jll v3.2.2+1
  [d4300ac3] Libgcrypt_jll v1.11.0+0
  [7e76a0d4] Libglvnd_jll v1.6.0+0
  [7add5ba3] Libgpg_error_jll v1.50.0+0
  [94ce4f54] Libiconv_jll v1.17.0+1
  [4b2f31a3] Libmount_jll v2.40.1+0
  [89763e89] Libtiff_jll v4.7.0+0
  [38a345b3] Libuuid_jll v2.40.1+0
  [856f044c] MKL_jll v2024.2.0+0
  [079eb43e] NLopt_jll v2.8.0+0
  [e98f9f5b] NVTX_jll v3.1.0+2
  [e7412a2a] Ogg_jll v1.3.5+1
  [458c3c95] OpenSSL_jll v3.0.15+1
  [efe28fd5] OpenSpecFun_jll v0.5.5+0
  [91d4177d] Opus_jll v1.3.3+0
  [36c8627f] Pango_jll v1.54.1+0
  [30392449] Pixman_jll v0.43.4+0
  [c0090381] Qt6Base_jll v6.7.1+1
  [629bc702] Qt6Declarative_jll v6.7.1+2
  [ce943373] Qt6ShaderTools_jll v6.7.1+1
  [e99dba38] Qt6Wayland_jll v6.7.1+1
  [f50d1b31] Rmath_jll v0.5.1+0
â [fb77eaff] Sundials_jll v5.2.3+0
  [a44049a8] Vulkan_Loader_jll v1.3.243+0
  [a2964d1f] Wayland_jll v1.21.0+1
  [2381bf8a] Wayland_protocols_jll v1.31.0+0
  [02c8fc9c] XML2_jll v2.13.4+0
  [aed1982a] XSLT_jll v1.1.41+0
  [ffd25f8a] XZ_jll v5.6.3+0
  [f67eecfb] Xorg_libICE_jll v1.1.1+0
  [c834827a] Xorg_libSM_jll v1.2.4+0
  [4f6342f7] Xorg_libX11_jll v1.8.6+0
  [0c0b7dd1] Xorg_libXau_jll v1.0.11+0
  [935fb764] Xorg_libXcursor_jll v1.2.0+4
  [a3789734] Xorg_libXdmcp_jll v1.1.4+0
  [1082639a] Xorg_libXext_jll v1.3.6+0
  [d091e8ba] Xorg_libXfixes_jll v5.0.3+4
  [a51aa0fd] Xorg_libXi_jll v1.7.10+4
  [d1454406] Xorg_libXinerama_jll v1.1.4+4
  [ec84b674] Xorg_libXrandr_jll v1.5.2+4
  [ea2f1a96] Xorg_libXrender_jll v0.9.11+0
  [14d82f49] Xorg_libpthread_stubs_jll v0.1.1+0
  [c7cfdc94] Xorg_libxcb_jll v1.17.0+0
  [cc61e674] Xorg_libxkbfile_jll v1.1.2+0
  [e920d4aa] Xorg_xcb_util_cursor_jll v0.1.4+0
  [12413925] Xorg_xcb_util_image_jll v0.4.0+1
  [2def613f] Xorg_xcb_util_jll v0.4.0+1
  [975044d2] Xorg_xcb_util_keysyms_jll v0.4.0+1
  [0d47668e] Xorg_xcb_util_renderutil_jll v0.3.9+1
  [c22f9ab0] Xorg_xcb_util_wm_jll v0.4.1+1
  [35661453] Xorg_xkbcomp_jll v1.4.6+0
  [33bec58e] Xorg_xkeyboard_config_jll v2.39.0+0
  [c5fb5394] Xorg_xtrans_jll v1.5.0+0
  [3161d3a3] Zstd_jll v1.5.6+1
  [1e29f10c] demumble_jll v1.3.0+0
  [35ca27e7] eudev_jll v3.2.9+0
  [214eeab7] fzf_jll v0.53.0+0
  [1a1c6b14] gperf_jll v3.1.1+0
  [a4ae2306] libaom_jll v3.9.0+0
  [0ac62f75] libass_jll v0.15.2+0
  [1183f4f0] libdecor_jll v0.2.2+0
  [2db6ffa8] libevdev_jll v1.11.0+0
  [f638f0a6] libfdk_aac_jll v2.0.3+0
  [36db933b] libinput_jll v1.18.0+0
  [b53b4c65] libpng_jll v1.6.44+0
  [f27f6e37] libvorbis_jll v1.3.7+2
  [009596ad] mtdev_jll v1.1.6+0
  [1317d2d5] oneTBB_jll v2021.12.0+0
â [1270edf5] x264_jll v2021.5.5+0
â [dfaa095f] x265_jll v3.5.0+0
  [d8fb68d0] xkbcommon_jll v1.4.1+1
  [0dad84c5] ArgTools v1.1.2
  [56f22d72] Artifacts v1.11.0
  [2a0f44e3] Base64 v1.11.0
  [ade2ca70] Dates v1.11.0
  [8ba89e20] Distributed v1.11.0
  [f43a241f] Downloads v1.6.0
  [7b1f6079] FileWatching v1.11.0
  [9fa8497b] Future v1.11.0
  [b77e0a4c] InteractiveUtils v1.11.0
  [4af54fe1] LazyArtifacts v1.11.0
  [b27032c2] LibCURL v0.6.4
  [76f85450] LibGit2 v1.11.0
  [8f399da3] Libdl v1.11.0
  [37e2e46d] LinearAlgebra v1.11.0
  [56ddb016] Logging v1.11.0
  [d6f4376e] Markdown v1.11.0
  [a63ad114] Mmap v1.11.0
  [ca575930] NetworkOptions v1.2.0
  [44cfe95a] Pkg v1.11.0
  [de0858da] Printf v1.11.0
  [9abbd945] Profile v1.11.0
  [3fa0cd96] REPL v1.11.0
  [9a3f8284] Random v1.11.0
  [ea8e919c] SHA v0.7.0
  [9e88b42a] Serialization v1.11.0
  [1a1011a3] SharedArrays v1.11.0
  [6462fe0b] Sockets v1.11.0
  [2f01184e] SparseArrays v1.11.0
  [f489334b] StyledStrings v1.11.0
  [4607b0f0] SuiteSparse
  [fa267f1f] TOML v1.0.3
  [a4e569a6] Tar v1.10.0
  [8dfed614] Test v1.11.0
  [cf7118a7] UUIDs v1.11.0
  [4ec0a83e] Unicode v1.11.0
  [e66e0078] CompilerSupportLibraries_jll v1.1.1+0
  [deac9b47] LibCURL_jll v8.6.0+0
  [e37daf67] LibGit2_jll v1.7.2+0
  [29816b5a] LibSSH2_jll v1.11.0+1
  [c8ffd9c3] MbedTLS_jll v2.28.6+0
  [14a3606d] MozillaCACerts_jll v2023.12.12
  [4536629a] OpenBLAS_jll v0.3.27+1
  [05823500] OpenLibm_jll v0.8.1+2
  [efcefdf7] PCRE2_jll v10.42.0+1
  [bea87d4a] SuiteSparse_jll v7.7.0+0
  [83775a58] Zlib_jll v1.2.13+1
  [8e850b90] libblastrampoline_jll v5.11.0+0
  [8e850ede] nghttp2_jll v1.59.0+0
  [3f19e933] p7zip_jll v17.4.0+2
Info Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`You can also download the manifest file and the project file.Getting Started with Julia's SciML Â»Powered by Documenter.jl and the Julia Programming Language.SettingsThemeAutomatic (OS)documenter-lightdocumenter-darkcatppuccin-lattecatppuccin-frappecatppuccin-macchiatocatppuccin-mochaThis document was generated with Documenter.jl version 1.7.0 on Tuesday 29 October 2024. Using Julia version 1.11.1."
29,https://runge-kutta-pinn-cmi-cmi-public-aaca66b00a12c20ef6731763c12508c.pages.desy.de/,"






runge-kutta-pinns documentation








Contents





Menu







Expand





Light mode













Dark mode






Auto light/dark mode














Hide navigation sidebar


Hide table of contents sidebar





Toggle site navigation sidebar




runge-kutta-pinns  documentation




Toggle Light / Dark / Auto color theme






Toggle table of contents sidebar







runge-kutta-pinns  documentation







Usage
Reference
License













Back to top




Toggle Light / Dark / Auto color theme






Toggle table of contents sidebar





IRK-PINNs#

A framework for high-order Runge-Kutta time-discrete Physics-Informed Neural Networks (IRK-PINNs).#




Documentation#
The code of this repository belongs to the manuscript Learning phase-space flows using time-discrete implicit Runge-Kutta PINNs {add full reference to proceedings and arXiv}; when using the code, this manuscript should be referenced. Please see the full documentation at https://cmi.pages.desy.de/CMI-public/runge-kutta-pinn.
The necessary code for creation and training of the high-order PINNs is stored in /IRK_PINNs/runge_kutta.py.
It can be installed following the installation guide.
To use IRK-PINNs, the order q of the implicit Runge-Kutta method needs to be defined. The error of the method scales as
$O(\Delta t ^{2q})$, where $\Delta t$ is the time step.
The Butcher’s tableau for the q={30, 100, 499} is provided in the folder /IRK_weights, as obtained from https://github.com/maziarraissi/PINNs.
These coefficients were computed using Gauss-Legendre Runge-Kutta method, which is A-stable for all orders. Any other order/method could also be used by adding the coefficients with the same format.


Examples#
We provide a notebook for each of the examples shown in the manuscript and add some other examples
that were not included in it.
We divide the examples, following the paper’s convention, into phase_space_trajectories and, for completion, functional.
In phase_space_trajectories, we provide the solution of the two examples provided in the paper:
The mass particle in a Gaussian central potential and the charged particle under the action of a periodic laser field.
In addition, an extra example for a charged particle in an inhomogeneous electric field is added.
In functional, the solution to the Allen-Cahn equation, the 2D heat equation, the Taylor-Green vortices
solution of the Navier-Stokes equation and the non-linear Schrödinger equation are provided.
All the examples follow a similar structure: we define/load a solution to benchmark our results,
then, we provide the details of the IRK and NN that we want to use. Next, we define the
partial differential equation that we are solving and its boundary condition (if any).
With all of this, we train the Neural Network and provide a visualization of the results.


Features#
Project based on:

Poetry for packaging and dependency management
Nox for automation of checks and other development tasks

It comes with many pre-installed modules for testing, documentation, auto-formatting and so on. For
more details, please refere to Hypermodern Python Cookiecutter.  It provides a solid basis for any
Python project.
To get up to scratch, refer to The Good Research Code Handbook for a good introduction about
software development in a scientific environment.


Installation#
You need four tools to use this installation:

Conda/Mamba to manage your virtual environments
Poetry to manage packaging and dependencies
Nox to automate checks and other tasks
nox-poetry for using Poetry in Nox sessions

Install Poetry by running:
$ conda install poetry



Installation guide#

Create a new Conda environment with poetry installed if you don’t have installed as described above.
$ conda create --name myenv poetry



Activate the Conda environment.
$ conda activate myenv



Install new project in environment:
$ poetry install



Install pre-commit hooks
$ pre-commit install



Open REPL and import module
from IRK_PINNs import runge_kutta



Run test case
runge_kutta.main()







License#
Distributed under the terms of the GPL 3.0 license,
IRK-PINNs is free and open source software.


Issues#
If you encounter any problems,
please file an issue along with a detailed description.


Credits#
This project was generated from @cjolowicz’s Hypermodern Python Cookiecutter template and @drivendata’s Cookiecutter Data Science.


Usage
Reference
IRK_PINNs
MLP
PINN_RK
PINN_RK.setup()


create_AC_diff_eq()
dir_
loss_RK()
train_ADAM()
train_LBFGS()
train_RK()




License











Next

Usage







                Copyright © 2024, Álvaro Fernández
            
            Made with Sphinx and @pradyunsg's
            
            Furo










            On this page
          




IRK-PINNs
A framework for high-order Runge-Kutta time-discrete Physics-Informed Neural Networks (IRK-PINNs).
Documentation
Examples
Features
Installation
Installation guide


License
Issues
Credits













"
30,https://github.com/google-deepmind/graphcast,"






































































GitHub - google-deepmind/graphcast














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        google-deepmind
 
/

graphcast

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    733




 


          Star
 5.9k







License





     Apache-2.0 license
    






5.9k
          stars
 



733
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
49






Pull requests
4






Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Actions











          Projects











          Security











          Insights






 





google-deepmind/graphcast



 












    mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History28 Commitsdocsdocs  graphcastgraphcast  CONTRIBUTING.mdCONTRIBUTING.md  LICENSELICENSE  README.mdREADME.md  gencast_demo_cloud_vm.ipynbgencast_demo_cloud_vm.ipynb  gencast_mini_demo.ipynbgencast_mini_demo.ipynb  graphcast_demo.ipynbgraphcast_demo.ipynb  setup.pysetup.py  View all filesRepository files navigationREADMEApache-2.0 licenseGoogle DeepMind GraphCast and GenCast
This package contains example code to run and train the weather models used in the research papers GraphCast and GenCast.
It also provides pretrained model weights, normalization statistics and example input data on Google Cloud Bucket.
Full model training requires downloading the
ERA5
dataset, available from ECMWF. This can best be
accessed as Zarr from Weatherbench2's ERA5 data.
Data for operational fine-tuning can similarly be accessed at Weatherbench2's HRES 0th frame data.
These datasets may be governed by separate terms and conditions or license provisions. Your use of such third-party materials is subject to any such terms and you should check that you can comply with any applicable restrictions or terms and conditions before use.
Overview of files common to models

autoregressive.py: Wrapper used to run (and train) the one-step predictions
to produce a sequence of predictions by auto-regressively feeding the
outputs back as inputs at each step, in JAX a differentiable way.
checkpoint.py: Utils to serialize and deserialize trees.
data_utils.py: Utils for data preprocessing.
deep_typed_graph_net.py: General purpose deep graph neural network (GNN)
that operates on TypedGraph's where both inputs and outputs are flat
vectors of features for each of the nodes and edges.
grid_mesh_connectivity.py: Tools for converting between regular grids on a
sphere and triangular meshes.
icosahedral_mesh.py: Definition of an icosahedral multi-mesh.
losses.py: Loss computations, including latitude-weighting.
mlp.py: Utils for building MLPs with norm conditioning layers.
model_utils.py: Utilities to produce flat node and edge vector features
from input grid data, and to manipulate the node output vectors back
into a multilevel grid data.
normalization.py: Wrapper used to normalize inputs according to historical
values, and targets according to historical time differences.
predictor_base.py: Defines the interface of the predictor, which models
and all of the wrappers implement.
rollout.py: Similar to autoregressive.py but used only at inference time
using a python loop to produce longer, but non-differentiable trajectories.
typed_graph.py: Definition of TypedGraph's.
typed_graph_net.py: Implementation of simple graph neural network
building blocks defined over TypedGraph's that can be combined to build
deeper models.
xarray_jax.py: A wrapper to let JAX work with xarrays.
xarray_tree.py: An implementation of tree.map_structure that works with
xarrays.

GenCast: Diffusion-based ensemble forecasting for medium-range weather
This package provides four pretrained models:


GenCast 0p25deg <2019, GenCast model at 0.25deg resolution with 13
pressure levels and a 6 times refined icosahedral mesh. This model is trained on
ERA5 data from 1979 to 2018 (inclusive), and can be causally evaluated on 2019
and later years. This model was described in the paper
GenCast: Diffusion-based ensemble forecasting for medium-range weather
(https://arxiv.org/abs/2312.15796)


GenCast 0p25deg Operational <2022, GenCast model at 0.25deg resolution, with 13 pressure levels and a 6
times refined icosahedral mesh. This model is trained on ERA5 data from
1979 to 2018, and fine-tuned on HRES-fc0 data from
2016 to 2021 and can be causally evaluated on 2022 and later years.
This model can make predictions in an operational setting (i.e., initialised
from HRES-fc0)


GenCast 1p0deg <2019, GenCast model at 1deg resolution, with 13 pressure
levels and a 5 times refined icosahedral mesh. This model is
trained on ERA5 data from 1979 to 2018, and can be causally evaluated on 2019 and later years.
This model has a smaller memory footprint than the 0.25deg models


GenCast 1p0deg Mini <2019, GenCast model at 1deg resolution, with 13 pressure levels and a
4 times refined icosahedral mesh. This model is trained on ERA5 data
from 1979 to 2018, and can be causally evaluated on 2019 and later years.
This model has the smallest memory footprint of those provided and has been
provided to enable low cost demonstrations (for example, it is runnable in a free Colab notebook).
While its performance is reasonable, it is not representative of the performance
of the GenCast models (1-3) above. For reference, a scorecard comparing its performance to ENS can be found in docs/. Note that in this scorecard,
GenCast Mini only uses 8 member ensembles (vs. ENS' 50) so we use the fair (unbiased)
CRPS to allow for fair comparison.


The best starting point is to open gencast_mini_demo.ipynb in Colaboratory, which gives an
example of loading data, generating random weights or loading a GenCast 1p0deg Mini <2019
snapshot, generating predictions, computing the loss and computing gradients.
The one-step implementation of GenCast architecture is provided in
gencast.py and the relevant data, weights and statistics are in the gencast/
subdir of the Google Cloud Bucket.
Instructions for running GenCast on Google Cloud compute
cloud_vm_setup.md
contains detailed instructions on launching a Google Cloud TPU VM. This provides
a means of running models (1-3) in the separate gencast_demo_cloud_vm.ipynb through Colaboratory.
The document also provides instructions for running GenCast on a GPU. This requires using a different attention implementation.
Brief description of relevant library files

denoiser.py: The GenCast denoiser for one step predictions.
denoisers_base.py: Defines the interface of the denoiser.
dpm_solver_plus_plus_2s.py: Sampler using DPM-Solver++ 2S from [1].
gencast.py: Combines the GenCast model architecture, wrapped as a
denoiser, with a sampler to generate predictions.
nan_cleaning.py: Wraps a predictor to allow it to work with data
cleaned of NaNs. Used to remove NaNs from sea surface temperature.
samplers_base.py: Defines the interface of the sampler.
samplers_utils.py: Utility methods for the sampler.
sparse_transformer.py: General purpose sparse transformer that
operates on TypedGraph's where both inputs and outputs are flat vectors of
features for each of the nodes and edges. predictor.py uses one of these
for the mesh GNN.
sparse_transformer_utils.py: Utility methods for the sparse
transformer.
transformer.py: Wraps the mesh transformer, swapping the leading
two axes of the nodes in the input graph.

[1] DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic
Models, https://arxiv.org/abs/2211.01095
GraphCast: Learning skillful medium-range global weather forecasting
This package provides three pretrained models:


GraphCast, the high-resolution model used in the GraphCast paper (0.25 degree
resolution, 37 pressure levels), trained on ERA5 data from 1979 to 2017,


GraphCast_small, a smaller, low-resolution version of GraphCast (1 degree
resolution, 13 pressure levels, and a smaller mesh), trained on ERA5 data from
1979 to 2015, useful to run a model with lower memory and compute constraints,


GraphCast_operational, a high-resolution model (0.25 degree resolution, 13
pressure levels) pre-trained on ERA5 data from 1979 to 2017 and fine-tuned on
HRES data from 2016 to 2021. This model can be initialized from HRES data (does
not require precipitation inputs).


The best starting point is to open graphcast_demo.ipynb in Colaboratory, which gives an
example of loading data, generating random weights or load a pre-trained
snapshot, generating predictions, computing the loss and computing gradients.
The one-step implementation of GraphCast architecture, is provided in
graphcast.py and the relevant data, weights and statistics are in the graphcast/
subdir of the Google Cloud Bucket.
WARNING: For backwards compatibility, we have also left GraphCast data in the top level of the bucket. These will eventually be deleted in favour of the graphcast/ subdir.
Brief description of relevant library files:

casting.py: Wrapper used around GraphCast to make it work using
BFloat16 precision.
graphcast.py: The main GraphCast model architecture for one-step of
predictions.
solar_radiation.py: Computes Top-Of-the-Atmosphere (TOA) incident solar
radiation compatible with ERA5. This is used as a forcing variable and thus
needs to be computed for target lead times in an operational setting.

Dependencies.
Chex,
Dask,
Dinosaur,
Haiku,
JAX,
JAXline,
Jraph,
Numpy,
Pandas,
Python,
SciPy,
Tree,
Trimesh,
XArray and
XArray-TensorStore.
License and Disclaimers
The Colab notebooks and the associated code are licensed under the Apache License, Version 2.0. You may obtain a copy of the License at: https://www.apache.org/licenses/LICENSE-2.0.
The model weights are made available for use under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). You may obtain a copy of the License at: https://creativecommons.org/licenses/by-nc-sa/4.0/.
This is not an officially supported Google product.
Unless required by applicable law or agreed to in writing, all software and materials distributed here under the Apache 2.0 or CC-BY-NC-SA 4.0 licenses are distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the licenses for the specific language governing permissions and limitations under those licenses.
GenCast and GraphCast are part of an experimental research project. You are solely responsible for determining the appropriateness of using or distributing GenCast, GraphCast or any outputs generated and assume all risks associated with your use or distribution of GenCast, GraphCast and outputs and your exercise of rights and permissions granted by Google to you under the relevant License. Use discretion before relying on, publishing, downloading or otherwise using GenCast, GraphCast or any outputs generated. GenCast, GraphCast or any outputs generated (i) are not based on data published by; (ii) have not been produced in collaboration with; and (iii) have not been endorsed by any government meteorological agency or department and in no way replaces official alerts, warnings or notices published by such agencies.
Copyright 2024 DeepMind Technologies Limited.
Citations
If you use this work, consider citing our papers (blog post, Science, arXiv, arxiv GenCast):
@article{lam2023learning,
  title={Learning skillful medium-range global weather forecasting},
  author={Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and Eaton-Rosen, Zach and Hu, Weihua and others},
  journal={Science},
  volume={382},
  number={6677},
  pages={1416--1421},
  year={2023},
  publisher={American Association for the Advancement of Science}
}
@article{price2023gencast,
  title={GenCast: Diffusion-based ensemble forecasting for medium-range weather},
  author={Price, Ilan and Sanchez-Gonzalez, Alvaro and Alet, Ferran and Andersson, Tom R and El-Kadi, Andrew and Masters, Dominic and Ewalds, Timo and Stott, Jacklynn and Mohamed, Shakir and Battaglia, Peter and Lam, Remi and Willson, Matthew},
  journal={arXiv preprint arXiv:2312.15796},
  year={2023}
}
Acknowledgements
The (i) GenCast and GraphCast communicate with and/or reference with the following separate libraries and packages and the colab notebooks include a few examples of ECMWF’s ERA5 and HRES data that can be used as input to the models.
Data and products of the European Centre for Medium-range Weather Forecasts (ECMWF), as modified by Google.
Modified Copernicus Climate Change Service information 2023. Neither the European Commission nor ECMWF is responsible for any use that may be made of the Copernicus information or data it contains.
ECMWF HRES datasets
Copyright statement: Copyright ""© 2023 European Centre for Medium-Range Weather Forecasts (ECMWF)"".
Source: www.ecmwf.int
License Statement: ECMWF open data is published under a Creative Commons Attribution 4.0 International (CC BY 4.0). https://creativecommons.org/licenses/by/4.0/
Disclaimer: ECMWF does not accept any liability whatsoever for any error or omission in the data, their availability, or for any loss or damage arising from their use.
Use of the third-party materials referred to above may be governed by separate terms and conditions or license provisions. Your use of the third-party materials is subject to any such terms and you should check that you can comply with any applicable restrictions or terms and conditions before use.
Contact
For feedback and questions, contact us at gencast@google.com.
   








About

        No description or website provided.
      
Topics



  weather


  weather-forecast



Resources





        Readme
 
License





     Apache-2.0 license
    







Activity 




Custom properties 
Stars




5.9k
      stars 
Watchers




88
      watching 
Forks




733
      forks 


          Report repository
 






Releases
      2






Version 0.1.1

          Latest
 
Oct 9, 2024

 
+ 1 release





Packages
      0

        No packages published 












Contributors
      8














































Languages











Python
80.9%







Jupyter Notebook
19.1%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
31,https://github.com/maziarraissi/PINNs,"






































































GitHub - maziarraissi/PINNs: Physics Informed Deep Learning: Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations














































Skip to content













Navigation Menu

Toggle navigation




 













            Sign in
          








        Product
        













GitHub Copilot
        Write better code with AI
      







Security
        Find and fix vulnerabilities
      







Actions
        Automate any workflow
      







Codespaces
        Instant dev environments
      







Issues
        Plan and track work
      







Code Review
        Manage code changes
      







Discussions
        Collaborate outside of code
      







Code Search
        Find more, search less
      






Explore



      All features

    



      Documentation

    





      GitHub Skills

    





      Blog

    










        Solutions
        






By company size



      Enterprises

    



      Small and medium teams

    



      Startups

    



      Nonprofits

    




By use case



      DevSecOps

    



      DevOps

    



      CI/CD

    



      View all use cases

    






By industry



      Healthcare

    



      Financial services

    



      Manufacturing

    



      Government

    



      View all industries

    






              View all solutions
              


 




        Resources
        






Topics



      AI

    



      DevOps

    



      Security

    



      Software Development

    



      View all

    






Explore



      Learning Pathways

    





      Events & Webinars

    





      Ebooks & Whitepapers

    



      Customer Stories

    



      Partners

    





      Executive Insights

    








        Open Source
        










GitHub Sponsors
        Fund open source developers
      








The ReadME Project
        GitHub community articles
      




Repositories



      Topics

    



      Trending

    



      Collections

    








        Enterprise
        













Enterprise platform
        AI-powered developer platform
      




Available add-ons







Advanced Security
        Enterprise-grade security features
      







Copilot for business
        Enterprise-grade AI features
      







Premium Support
        Enterprise-grade 24/7 support
      







Pricing












Search or jump to...







Search code, repositories, users, issues, pull requests...

 




        Search
      













Clear
 
















































 



Search syntax tips 














        Provide feedback
      









 
We read every piece of feedback, and take your input very seriously.


Include my email address so I can be contacted


     Cancel

    Submit feedback










        Saved searches
      
Use saved searches to filter your results more quickly









 





Name






Query



            To see all available qualifiers, see our documentation.
          
 





     Cancel

    Create saved search








                Sign in
              


                Sign up
              
Reseting focus









You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
 


Dismiss alert


















        maziarraissi
 
/

PINNs

Public





 

Notifications
 You must be signed in to change notification settings


 

Fork
    1.4k




 


          Star
 4.5k








        Physics Informed Deep Learning: Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations
      





maziarraissi.github.io/PINNs


License





     MIT license
    






4.5k
          stars
 



1.4k
          forks
 



Branches
 



Tags
 



Activity
 



 


          Star




 

Notifications
 You must be signed in to change notification settings













Code







Issues
49






Pull requests
1






Actions







Projects
0






Security







Insights



 

 


Additional navigation options


 










          Code











          Issues











          Pull requests











          Actions











          Projects











          Security











          Insights






 





maziarraissi/PINNs



 












    masterBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History47 CommitsUtilitiesUtilities  appendixappendix  docsdocs  mainmain  LICENSELICENSE  README.mdREADME.md  View all filesRepository files navigationREADMEMIT licensePhysics Informed Neural Networks

Notice: This repository is no longer under active maintenance. It is highly recommended to utilize implementations of Physics-Informed Neural Networks (PINNs) available in PyTorch, JAX, and TensorFlow v2.

We introduce physics informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial differential equations. We present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct classes of algorithms, namely continuous time and discrete time models. The resulting neural networks form a new class of data-efficient universal function approximators that naturally encode any underlying physical laws as prior information. In the first part, we demonstrate how these networks can be used to infer solutions to partial differential equations, and obtain physics-informed surrogate models that are fully differentiable with respect to all input coordinates and free parameters. In the second part, we focus on the problem of data-driven discovery of partial differential equations.
For more information, please refer to the following: (https://maziarraissi.github.io/PINNs/)


Raissi, Maziar, Paris Perdikaris, and George E. Karniadakis. ""Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations."" Journal of Computational Physics 378 (2019): 686-707.


Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. ""Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations."" arXiv preprint arXiv:1711.10561 (2017).


Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. ""Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations."" arXiv preprint arXiv:1711.10566 (2017).


Citation
@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}

@article{raissi2017physicsI,
  title={Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1711.10561},
  year={2017}
}

@article{raissi2017physicsII,
  title={Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1711.10566},
  year={2017}
}

   








About

        Physics Informed Deep Learning: Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations
      





maziarraissi.github.io/PINNs


Resources





        Readme
 
License





     MIT license
    







Activity 
Stars




4.5k
      stars 
Watchers




122
      watching 
Forks




1.4k
      forks 


          Report repository
 






Releases
No releases published





Packages
      0

        No packages published 












Contributors
      2







maziarraissi
Maziar Raissi

 






rezaakb
Reza Akbarian Bafghi

 





Languages











Python
93.5%







Mathematica
6.5%















Footer








        © 2025 GitHub, Inc.
      


Footer navigation


Terms


Privacy


Security


Status


Docs


Contact




      Manage cookies
    





      Do not share my personal information
    
















    You can’t perform that action at this time.
  












"
32,https://arxiv.org/pdf/2005.10632,"Extreme Theory of Functional Connections: A Physics-Informed
Neural Network Method for Solving Parametric Dierential
Equations
Enrico Schiassi, Carl Leake, Mario De Florio, Hunter Johnston, Roberto Furfaro, Daniele Mortari
Abstract
In this work we present a novel, accurate, and robust physics-informed method for solving problems
involving parametric dierential equations (DEs) called the Extreme Theory of Functional Connections
(X-TFC). The proposed method is a synergy of two recently developed frameworks for solving problems
involving parametric DEs, 1) the Theory of Functional Connections TFC, developed by Mortari et al.
[1, 2, 3], and 2) the Physics-Informed Neural Networks PINN, developed by Raissi et al. [4]. Although
this paper focuses on the solution of exact problems involving parametric DEs (i.e. problems where the
modeling error is negligible) with known parameters, X-TFC can also be used for data-driven solutions and
data-driven discovery of parametric DEs. In the proposed method, the latent solution of the parametric
DEs is approximated by a TFC constrained expression that uses a Neural Network (NN) as the free-
function. This approximate solution form always analytically satises the constraints of the DE [1], while
maintaining a NN with unconstrained parameters, like the Deep-TFC method by Leake et al. [5]. X-
TFC diers from PINN and Deep-TFC; whereas PINN and Deep-TFC use a deep-NN, X-TFC uses a
single-layer NN, or more precisely, an Extreme Learning Machine (ELM). This choice is based on the
properties of the ELM algorithm developed by Huang et al. [6]. In order to numerically validate the
method, it was tested over a range of problems including the approximation of solutions to linear and
non-linear ordinary DEs (ODEs), systems of ODEs (SODEs), and partial DEs (PDEs). The results show
that X-TFC achieves high accuracy with low computational time and thus it is comparable with the other
state-of-the-art methods.
1 Introduction
Parametric Dierential Equations (DEs) are a powerful tool used for the mathematical modelling of vari-
ous problems, and are present in elds including, but not limited to, physics, engineering, nance, biology,
chemistry, and oceanography. There exist two types of parametric DEs: 1) parametric ordinary DEs (ODEs)
which are univariate independent variable equations, and 2) parametric partial DEs (PDEs) which are mul-
tivariate independent variable equations. The solution of these equations can be used to simulate, identify,
characterize, design, and verify the design of a variety of systems. In many practical problems, it is not
trivial to nd an analytical solution to these parametric DEs. Thus, for these cases, it is preferred to solve
these equations numerically.
For the numerical solution of ODEs, a variety of methods exist with the most popular being based on the
Runge-Kutta family [7]. Other methods include nite dierence, Chebyshev-Picard iteration [8], and pseudo-
spectral methods [9]. However, a recently developed method called the Theory of Functional Connections
(TFC), Mortari et al. [1, 2, 3], has signicantly improved the state-of-the-art for numerically estimating the
solutions of parametric ODEs. According to the TFC method, the unknown (or latent [4]) solution of the
equation is approximated with an expression, called constrained expression . The constrained expression is
the sum of a function that analytically satises the constraints, and a functional containing a freely-chosen
function that projects this free-function onto the space of functions that vanish at the constraints. In the
classic TFC method, the free-function is chosen to be a linear combination of orthogonal polynomials, such
as Legendre or Chebyshev polynomials [2, 3]. While the free-function could easily be dened by an explicit
polynomial of a specic degree, orthogonal polynomials are used for their benecial numerical properties.
For example, the properties of the Chebyshev polynomials produce a function that minimizes the maximum
error in its application, and therefore, is well suited for approximating other functions [10, 11]. Studies have
shown that the TFC method can be used to numerically estimate parametric linear and non-linear ODEs
1arXiv:2005.10632v1  [cs.LG]  15 May 2020with machine-level error in milliseconds [2, 3, 12, 13]. For this reason, TFC is an appealing choice for many
dierent applications. For example, TFC has already been used to solve ODEs with initial value constraints,
boundary value constraints [2, 3], relative constraints, integral constraints [14], and linear combinations of
constraints. Additionally, this technique has been utilized to solve optimal control problems including energy
optimal [12] and fuel optimal landing trajectories on large planetary bodies [13]. Moreover, in De Florio et.
al. [15], the TFC was leveraged to solve a class of Rareed-Gas Dynamics problems, matching the bench-
marks published by Barichello et. al [16, 17], and Ganapol [18].
Similarly, Yang et al. in [19] proposed a method based on Articial Neural Networks (ANNs), in particular,
Legendre Neural Networks (LeNNs). The LeNNs are single layer NNs where the activation functions are
Legendre Polynomials and the network is trained via the Extreme Learning Machine (ELM) algorithm, pro-
posed by Huang et al. [6]. This algorithm is used for Single-hidden Layer Feed-forward Networks (SLFNs).
It randomly selects hidden input weights and biases, and computes the output weights via least-squares
[6]. Although the results obtained from the LeNN method are fast and accurate, the accuracy is aected
(especially in the solution of non-linear ODEs) by the fact that the equation constraints are not analytically
satised as in the TFC framework. Instead, the method adds the constraints as a penalty to the loss function
and are minimized when training the neural network (NN).
For PDEs, a multitude of numerical methods exist, the most widely used being the Finite Element Method
(FEM) [20, 21, 22, 23]. In fact, FEM has been successfully applied to solve PDEs in a variety of elds
such as structures, uids, and acoustics. In this method, the domain is discretized into smaller parts called
nite elements and simple approximated equations are used to model these elements. Ultimately, these el-
ements are then assembled into a larger system of equations that model the entire problem. However, the
major drawback to FEM is the number of subdivisions needed to capture large variations in the solution.
For example, this discretization works well for low-dimensional PDEs, but suers in higher dimensions; the
number of elements grows exponentially with the number of independent variables. Thus, the discretization
becomes prohibitive as the number of variables increases. Moreover, in the FEM framework, the PDE is
solved at discrete nodes and if the solution is needed at dierent points, an interpolation scheme is required.
As mentioned in Ref. [24], this aects the accuracy of the solution at the interpolated points. Furthermore,
extra numerical techniques are needed to perform further manipulation of the FEM solution such as taking
the gradients, or computing the integrals.
The solution of PDEs has also become an area of interest in the machine learning community where authors
have explored using NNs to solve parametric PDEs. In particular, Raissi et al. [4] dened frameworks
that use NNs and Deep-NNs (DNNs) to solve these equations as physics-informed neural networks (PINNs),
wherein the latent solution of a PDE is approximated via a NN or DNN. To solve the equations, the network
must be trained to learn the parameters of the approximated latent solution. This would result in a classic
regression problem if the training process was not informed by the physics governing the equation. To inform
the training with the physics governing the problem, the parametric PDE, in its implicit form, is added as
a penalty (e.g. a regulator) to the loss function and it is minimized when training the network. Hence, in
Raissi et al. [4], the term physics-informed neural network was coined.
The physics-informed methods explored in Refs. [4] and [25] show that the use of NNs overcomes some
of FEM's limitations. One major benet of physics-informed methods is that the points can be randomly
sampled from the domain. Therefore, the discretization of the entire domain into a number of elements
that grows exponentially with the scale of the problems is avoided. Moreover, the NN is an analytical ap-
proximation of the latent solution. This leads to two major advantages: 1) once the network is trained, no
interpolation schemes are needed when estimating the solution at points that did not appear during training,
and 2) further solution manipulation, such as computing gradients or integrals, can be done analytically.
Although this method was created to numerically estimate the solutions of PDEs, it can also be used to
approximate the solutions of ODEs. According to this, both the TFC and the LeNN methods can be seen as
physics-informed methods. Demonstrated in Raissi et al.[4], these method can also be used to solve inverse
problems for parameter estimation, where the physics phenomena are modeled via parametric DEs. How-
ever, what was presented in Refs. [4] and [25] can still be improved both in terms of solution accuracy and
computational speed.
The technique mentioned above [4, 25] rely on DNNs to approximate the latent solution. This aects the
computational cost as gradient descent based methods are needed to train the networks. This limitation
is overcome by expanding the latent solution with a single layer NN trained via the ELM algorithm [26]1.
Another limitation of the DNN approach presented in Refs. [4] and [25] is that the equation constraints are
1In this manuscript single layer NNs trained via the ELM algorithm will be refereed to simply as ELMs
2managed by adding extra terms to the loss function which aects the solution accuracy.
One way to overcome this limitation is to approximate the solution in such a way that the constraints must
be satised, regardless of the values of the training parameters in the network. Lagaris et al. [24] handled
constraints in this way when solving both ODEs and PDEs via a physics-informed method that leverages
a technique similar to the Coons' patch [27] to satisfy the constraints analytically. As stated in Ref. [5],
analytical satisfaction of the constraints is of signicant interest for a variety of problems. This is particularly
true when the condence in the constraint information is high. Moreover, embedding the constraints in this
way allows the NN to sample points only from interior of the domain [5]. This reduces the number of training
points needed, and thereby decreases the computational cost of training. While the method proposed by
Lagaris et. al [24] works well for ODEs and low-dimensional PDEs with simple boundary constraints, its
application is limited, since it does not provide a generalized framework to derive higher-dimensional or more
complex constraints. Fortunately, the TFC framework overcomes this limitation, and thereby extends the
work of Lagaris et. al. [24].
In fact, a recent extension of the univariate TFC to n-dimensions was formalized in Ref. [28]. This ex-
tension highlighted a succinct method to derive constrained expressions for value constraints and arbitrary
order derivative constraints of ( n 1)-dimensional manifolds in n-dimensional space. This means the TFC
framework can generate constrained expressions that satisfy the boundary constraints of multidimensional,
large-scale, parametric PDEs [29]. In fact, this framework has already been utilized to solve PDEs in com-
bination with machine learning algorithms, such as support vector machines [30] and DNNs [5].
As previously mentioned, numerical techniques based on the TFC framework to solve ODEs have typically
used a linear combination of orthogonal polynomials with unknown coecients as the free-function. This
approach leads to a solution via least-squares for linear problems [2], and via iterative least-squares for non-
linear problems [3]. In later studies, this method was extended to the solution of bivariate PDEs [29], where
the free function was expressed as the product of two linear combinations of orthogonal polynomials with
unknown coecients. Since the free-function remained linear in these coecients, a linear least-squares or
iterative least-squares method could still be used to estimate the PDEs solution. However, as the dimension
of the problem increases or the scale of the problem becomes larger, this process will become computationally
prohibitive. As proposed by Leake et al. [5], one way to overcome this limitation is to select a NN as the
free-function. In this study, the authors used DNNs as the free-function, in a framework called Deep-TFC ,
and the results showed that the method was comparable with the ANN proposed by Lagaris et al. [24] in
terms of accuracy and computational cost. While Leake et al. [5] improved upon what was presented in
Lagaris et al. [24] by using the TFC to derive the constrained expressions, both methods rely on gradient
based methods to train their networks which are computationally expensive.
This article introduces the Extreme Theory of Functional Connections , or Extreme-TFC (X-TFC), which
is a synergy between the Theory of Functional Connections (TFC) and Physics-Informed (PI) methods [4].
This is achieved by utilizing the TFC constrained expression and expressing the free-function as an ELM.
Therefore, X-TFC is intended to be a novel PI method to solve forward and inverse problems involving para-
metric DEs. The proposed framework is able to overcome some of the limitations of the TFC approaches
and the other state-of-the-art PI methods explained above. Indeed, X-TFC can handle large-scale problems
(e.g. PDEs with several independent variables), while preserving high accuracy and low computational time
compared to competing methods. Moreover, this method is classied as a PI method for two reasons. First,
similar to the Raissi et al. [4] PINN method and the PI methods, the X-TFC framework uses a NN to directly
solve parametric DEs with known parameters, and for data-driven solutions of parametric DEs with known
parameters, where the approximated solution is posed in such a way that the physics of the problems are not
violated. Additionally, although in this paper we focus only on the solution of parametric DEs with known
parameters (i.e. forward modeling fashion), X-TFC can also be used for data-driven discovery of parametric
DEs (i.e. solutions of inverse problems for parameter estimation) both in deterministic and probabilistic (e.g.
Bayesian Inversion) fashions.
The remainder of this article is organized as follows. First, the theory for the X-TFC framework is explained
in detail in Section 2. Next, the results are presented and discussed in Section 3. In this section, X-TFC is
used to solve a few typical problems of interest in physics and engineering, such as the classic Emden-Fowler
equation, Radiative Transfer (RT) equation, and Heat Transfer (HT) equation. Additionally, all results are
compared with the other state-of-the-art methods.
32 Extreme Theory of Functional Connections
As mentioned previously, the X-TFC framework can be used for solving direct and inverse problems involving
parametric DEs with high accuracy and low computational time. When solving direct problems involving
parametric DEs, the parameters governing the equations are assumed to be known within a certain accuracy.
Therefore, two possible scenarios exist: 1) the parametric DE exactly approximates the physical phenomena
that it describes, i.e. there are no modeling errors; hence, these problems are called exact problems , and
2) the parametric DE approximates the physical phenomena that it describes with non-negligible modeling
errors. In the rst scenario no data is needed to solve the equation with high accuracy. Thus, when applying
the X-TFC method, the solution of the DE reduces to an unconstrained optimization problem. In the second
scenario, data is needed to solve the equation with high accuracy. In this case, the solution of the parametric
DE is called a data-driven solution [4]. In Ref. [4], data-driven solutions of parametric DEs are achieved
via training NNs in a supervised fashion that includes the DEs in its implicit form in the cost function as a
penalty that guarantees that physics is not violated.
When solving inverse problems involving parametric DEs, the parameters governing the DE are unknown
and need to be estimated. These kind of problems are called data-driven discovery of parametric DEs [4],
as the goal is to discover (i.e. estimate) the parameters that govern the equation by comparing the equation
solution with data. For example, a typical eld where solving inverse problems is of extreme interest is remote
sensing [31, 32, 33, 34]. For instance, in Ref. [35], the authors couple radiative and heat transfer equations
to form a set of parametric DEs. The solutions of this set of DEs is compared with real data to discover the
thermal inertia and the grain size of planetary regoliths, which are the parameters governing the DEs.
Although this paper focuses on the solution of exact problems, in this section we present the general X-
TFC method that can be also used for data-driven solution of parametric DEs, and for data-driven discovery
of parametric DEs. We also present in detail how to build the constrained expression [5], and give a brief
description of the ELM algorithm [6].
2.1 Method
As previously stated, parametric DEs are a powerful mathematical tool that can be used to model problems
of interest in many dierent elds such as nance, chemistry, physics, and engineering [5]. We can express
parametric DEs, in their most general implicit form, as,
ft+N[f;] +"" U= 0 (1)
subject to constraints given by the initial conditions (IC) and boundary conditions (BC). In Equation (1),
t2TR0+,x2DRn,f:=f(t;x;(t;x);(t;x)) is the unknown (or latent) solution , :=(t;x)2
GRand:=(t;x)2LRmare the parameters governing the parametric DE (which are known
when dealing with direct problems, and latent when dealing with inverse problems)2,N[;] is a linear or
non-linear operator acting on fand parameterized by , the subscript trefers to the partial derivative of f
with respect to t, i.e.ft=@f
@t3,""is the modeling error that is negligible when solving exact problems , and
Uis a known function that in general can depend on tandx, and can be parametrized by and.
The rst step in our general physics-informed framework is to approximate the latent solution fwith a
constrained expression that analytically satises the constraints as follows,
f(x;) =fCE(x;g(x);) =A(x;) +B(x;g(x););
where x= [t;x]T2
Rn+1witht0,= [;]T2PRm+1,A(x;) analytically satises the
constraints, and B(x;g(x);) projects the free-function g(x) onto the space of functions that vanish at the
constraints [5]. According to the X-TFC method, the free-function, g(x), is chosen to be a single layer feed
forward NN, in particular, an ELM [6]. That is,
g(x) =LX
j=1j 
wT
jx+bj
;
2In general, even if it is not explicitly reported in the notation, fis a function of tandx, and it is parameterized by and
, that in general can be tandxdependent as well.
3When dealing with ODEs, the partials derivatives become ordinary derivatives, thus, ft=@f
@t=df
dt.
4whereLis the number of hidden neurons, wj= [wj;1;:::;wj;n+1]T2Rn+1is the input weights vector
connecting the jthhidden neuron and the input nodes, j2Rwithj= 1;:::;L is thejthoutput weight
connecting the jthhidden neuron and the output node, and bjis the threshold (aka bias) of the jthhidden
neuron, and () are activation functions. According to the ELM algorithm [6], input weights and biases
are randomly selected and not tuned during the training, thus they are known parameters. The activation
functions,(), are chosen by the user, so they are also known. Therefore, the only unknowns to compute
are the output weights = [1;:::;L]T. Hence we can write,
f(x;) =fCE(x;g(x);) =fCE(x;;):
The step-by-step process to derive the constrained expression is provided in Section 2.2. Now that fis
approximated with a NN, the second step of the X-TFC physics-informed method is to dene a loss function,
L(x;;) =fCE;t+N[fCE;] +"" U;
that according to Raissi et al. [4] results in a physics-informed neural network . Now, the Mean Square Errors
(MSEs ) for the latent solution, MSEf, and for the physics-informed neural network ,MSEL, are dened,
MSEf=1
2NNX
p=1
efp fp;CE(x;;)2
MSEL=1
2NNX
p=1(Lp(x;;))2
whereh
xp;efpiN
p=1areNdistinct sample data points with xp= [tp;xp;1;:::;xp;n]T2Rn+1, andefp2Rfor
eachp= 1;:::;N . The nal step is to compute the latent solution f, and in the case of the inverse problem
the parameters , that minimize the cost function J,
min
;J=  fMSEf+  LMSEL; (2)
where  fand  Lare positive parameters whose values are chosen based on the relative importance of the
MSEs in the computation of the unknowns. In other words, these values are problem-dependent and user
specied. Using the X-TFC framework, the problem posed in Eq. (2) is an unconstrained regularized
regression problem that can be solved via any supervised-learning technique.
As mentioned previously, this article only focuses on the solutions of exact problems; problems in which
the parameters are known within a certain accuracy, and the model error, "", is negligible (i.e. ""= 0).
Therefore the only quantity to compute is the latent solution, f, which is approximated via the constrained
expression, fCE, as explained above. Thus, the problem reduces to,
min
J=L(x;;); (3)
where the loss function, L, of the physics-informed neural network is given by,
L(x;;) =fCE;t+N[fCE;] U:
The minimization problem given in Eq. (3) is an unconstrained optimization problem that can be solved
via any optimization scheme, such as least-squares (for linear problems [2]) or iterative-least-squares (for
non-linear problems [3]) [5].
2.2 Constrained Expression Derivation
This section gives a step-by-step derivation of multivariate TFC constrained expressions, which in general
aren+ 1 dimensional as they depends on the vector xas previously dened. As mentioned earlier, the
multivariate form of the constrained expression is written as follows,
fCE(x;g(x)) =Mi1;i2;;in+1(c(x))vi1(t)vi2(x1)vin+1(xn)| {z }
A(x)+
+g(x) Mi1;i2;;in+1(g(x))vi1(t)vi2(x1)vin+1(xn)| {z }
B(x;g(x))
5where x=ft; x 1;; xngTis a vector of the n+ 1 independent variables, Mis an (n+ 1)thorder
tensor containing the boundary conditions c(x),vi1;;vin+1are vectors whose elements are functions of
the independent variables, g(x) is the free-function that can be any function that is dened at the constraints
[1]. According to Ref. [5], A(x) analytically satises the constraints and B(x;g(x)) projects the free-function
g(x) onto the space of functions that vanish at the constraints. As already explained, in the X-TFC method,
the free-chosen function is an ELM. A mathematical proof that this form of the constrained expression always
analytically satises the constraints is given in Ref. [28].
Some preliminary mathematical notation is dened here that will assist in the derivation of the constrained
expression. For consistency, this article uses the same notation as Ref. [5]. Let k2[1;n+ 1] be the index
that refers to the kthindependent variable. Letkcd
q:=@dc(x)
@xd
k
xk=qbe the constraint dened by taking
thedthorder derivative of the constraint function c(x) and evaluating the result at the xk=qhyperplane.
Moreover, letkcdkqkbe the vector of `kconstraints dened at the xk=qkhyperplanes with derivative orders
ofdk, where qkanddk2R`k. Finally, letkbd
qdenote the boundary condition operator, where,
kbd
q[f(x)] =@df(x)
@xd
k
xk=q:
This operator takes the dthorder derivative with respect to xkof a function, and then evaluates the result
at thexk=qhyperplane.
Now, the step-by-step process for building the constrained expressions is shown, beginning with the M
tensor. The easiest way to explain this derivation is via an example. As in [5], the construction of this M
tensor will be presented via a 3D example with Dirichlet boundary conditions in x1and initial conditions in
x2, andx3on the domain x1;x2;x32[0;1][0;1][0;1]. TheMtensor is constructed in three steps.
First, the element M111= 0. Secondly, the rst order sub-tensors of Mspecied by keeping one dimension's
index free and setting all other dimension's indices to 1 consists of the value 0 and the boundary conditions
for that dimension. That is,
M1;:::;1;ik;1;:::;1=0;kcdkqk	
: (4)
For the example considered here, these rst-order sub-tensors are,
Mi111=
0;c(0;x2;x3);c(1;x2;x3)T
M1i21=
0;c(x1;0;x3);cx2(x1;0;x3)T
M11i3=
0;c(x1;x2;0);cx3(x1;x2;0)T:
Third, the remaining elements of the Mtensor are those with at least two indices that are not equal to one.
These elements are the geometric intersection of the boundary condition elements of the rst order tensors
given in Eq. (4), plus a sign (+ or  ) that is determined by the number of elements being intersected. In
general, this can be formally written as follows,
Mi1i2:::in+1=1bd1
i1 1
q1
i1 1
2bd2
i2 1
q2
i2 1
:::
n+1bdn+1
in
qn+1
in[c(x)]
:::
( 1)m+1;
wheremis the number of indices for the element that are not equal to one. Using the example constraints,
some of these remaining elements are,
M133= cx2x3(x1;0;0)
M221= c(0;0;x3)
M332=cx2(1;0;0):
6Combining these steps results in the full Mtensor; for the example constraints, the full Mtensor is,
Mij1=2
40c(0;x2;x3)c(1;x2;x3)
c(x1;0;x3) c(0;0;x3) c(1;0;x3)
cx2(x1;0;x3) cx2(0;0;x3) cx2(1;0;x3)3
5
Mij2=2
4c(x1;x2;0) c(0;x2;0) c(1;x2;0)
 c(x1;0;0)c(0;0;0)c(1;0;0)
 cx2(x1;0;0)cx2(0;0;0)cx2(1;0;0)3
5
Mij3=2
4cx3(x1;x2;0) cx3(0;x2;0) cx3(1;x2;0)
 cx3(x1;0;0)cx3(0;0;0)cx3(1;0;0)
 cx2x3(x1;0;0)cx2x3(0;0;0)cx2x3(1;0;0)3
5
A standard step-by-step procedure also exists for constructing the vikvectors. The general form of vik
vectors is given by,
vik=(
1;`kX
i=1i1hi(xk);`kX
i=1i2hi(xk); :::;`kX
i=1i`khi(xk))T
;
wherehi(xk) can be any `klinearly independent functions that produce a nonsingular matrix in Eq. (5). As
suggested in Refs. [1, 5, 28], the simplest set of linearly independent functions are monomials. That is,
hi(xk) =xi 1
k
Finally, the `k`kcoecients ijare simply computed via matrix inversion,
2
6664kbd1q1[h1]kbd1q1[h2]:::kbd1q1[h`k]
kbd2q2[h1]kbd2q2[h2]:::kbd2q2[h`k]
............
kbd`kq`k[h1]kbd`kq`k[h2]:::kbd`kq`k[h`k]3
77752
66641112:::  1`k
2122:::  2`k
............
`k1`k2::: `k`k3
7775=2
66641 0::: 0
0 1::: 0
............
0 0::: 13
7775: (5)
The interested reader can refer to [28] and [5] for further details, a mathematical proof that this procedure for
generating theMtensor and the vvectors produces a valid constrained expression, and for more examples.
2.3 Extreme Learning Machine Algorithm
According to the physics-informed method introduced in this article, the free-chosen function in the TFC
constrained expression is chosen to be an ELM. The ELM used in this method is based on the ELM algorithm
proposed by Huang et al. [6]. ELM is a learning algorithm for Single-hidden Layer Feed-forward Networks
(SLFNs) that randomly selects hidden input weights and biases, and computes the output weights via least-
squares. That is, input weights and biases are selected randomly and not tuned during the training. Thus,
the output weights can be computed by least-squares. Consider Ndistinct training samples, [ xi;yi]N
i=1,
where xi= [xi1;:::;xin]T2Rnandyi= [yi1;:::;yim]T2Rm, were a standard SLFN with Lhidden neurons
and activation function () are used as follows,
yi=LX
j=1j(wT
jxi+bj);i= 1;:::;N
where wj= [wj1;:::;wjn]T2Rnis the input weight vector connecting the jthhidden neuron and the input
nodes,j= [j1;:::;jm]T2Rmis the output weight vector connecting the jthhidden neuron and the
output nodes, and bjis the threshold of the jthhidden neuron. The Nequations above can be rewritten in
following compact form,
HB=Y; (6)
where H2RNLwhereHij=(wT
jxi+bj) withi= 1;:::;N andj= 1;:::;L ,B2RLmwhere Bi=T
i
andi= 1;:::;L , and Y2RNmwhere Yi=yT
iandi= 1;:::;N . As the input weights and biases of the
7ELM are not tuned, the only unknowns in Eq. (6) are B. Thus, (6) reduces to a least-squares problem. In
Ref. [6], Bis computed as follows,
B=HyY
where Hyis the Moore-Penrose generalized inverse of the matrix H, which is computed via singular value
decomposition (SVD) [6].
The ELM learning algorithm is based on theorem 2.1 and theorem 2.2 of [6]. These theorems guarantee the
existence of the solution of (6), for any input weights and bias randomly chosen according to any continuous
probability distribution. In [6], the interested reader can nd the formalisation of those theorems and their
proofs.
3 Results
In this section, the X-TFC method is tested on a series of problems of interest in physics and engineering. The
problems considered are linear and non-linear ODEs, System of ODEs (SODEs), and PDEs. Moreover, when
they are available, the X-TFC method is compared with other state-of-the-art methods and with analytical
solutions. The results show that the X-TFC method is as accurate or more accurate than all other methods
except the classic TFC; although it should be noted here that in all cases the classic TFC and X-TFC have
solutions errors that are on the same order of magnitude.
3.1 ODEs
In this section, X-TFC is applied to linear and non-linear ODEs and SODEs. Each problem was solved in
MATLAB on an Intel Core i7 - 9700 CPU PC with 64 GB of RAM.
Although this manuscript only reports a few examples, the physics-informed X-TFC method was used on
several dierent linear and non-linear ODEs and SODEs, many of which are problems of interest in physics
and engineering, such as classic Emden{Folwer equation, advection equation, diusion equation, advection-
diusion equation, radiative transfer equations, and Bernoulli equations, to name a few. As explained
previously, in the X-TFC method there are several hyperparameters that can be modied to obtain accurate
solutions. These hyperparameters are the number of training points, n, the number of neurons, L, the type
of activation function, and the probability distribution used to initialize the weights and biases of the ELM.
An analysis was performed to study the sensitivity of the X-TFC framework to these hyperparameters. This
analysis showed that, for the problems considered, the solution accuracy is not as sensitive to the type of
activation function used or to the probability distribution used to initialize the weights and biases as it is
to the number of training and the number of neurons. The solution accuracy trends for the number of
training points and number of neurons for problem 1 is shown in Figs. 1(a) and 1(b). Figure 1(a) shows
the solution accuracy as a function of the number of training points while holding the number of neurons
constant, and Fig.1(b) shows the solution accuracy as a function of the number neurons for a xed number
of training points. Since the X-TFC methodology uses random numbers to initialize the weights and biases
that are untrained, the method is inherently stochastic. Thus, each point in plots of Figs. 1(a) and 1(b) is
the maximum absolute error of 103Monte Carlo simulations. In this article the sensitivity analysis is only
shown for problem 1, because the same behaviour was observed for all the problems analyzed.
For all the problems reported in this section, the activation function used in the ELM was a logistic acti-
vation function, and the weights and biases of the ELM were randomly sampled from a uniform distribution,
(wj; bj)unif( 10;10) wherej= 1;:::;L . As previously mentioned, due to the inherently stochastic nature
of the X-TFC method, for each problem solved in this section, 103Monte Carlo simulations were performed
to show the variability and test the robustness of the method.
3.1.1 Problem 1
The following equation is a non-linear ODE taken from Yang et al. [19],
ytt=1
2x2(y3 2y2)
80 50 100 150 200 250 300 350 400 450 500
Number of Points10-1610-1410-1210-1010-810-610-4max(abs(err))(a) Maximum absolute error as a function of number of points n, for xed number of neurons
L= 100
0 50 100 150 200 250 300 350 400 450 500
Number of Neurons10-1610-1510-1410-1310-1210-1110-1010-910-810-7max(abs(err))
(b) Maximum absolute error as a function of number of neurons L, for xed number of points
n= 100
Figure 1: Solution accuracy sensitivity analysis for problem #1
9subject to y(1) = 1 and y(2) = 4=3 fort2[1;2]. The exact solution is y(t) =2t
t+ 1. The constrained
expression for this problem is,
y(t) = [+ (t 2)0+ (1 t)f]T+t+ 2
3;
where0andfare the free-functions computed at t= 1 andt= 2, respectively.
The results for Problem 1 are presented in gures 2 and 3, and tables 1. The results show that the average
absolute errors for both training and testing are on the order of O(10 16). The computational time is on the
order ofO(10 3) seconds. Note that, this problem requires an iterative-least squares procedure to compute
the solution [3]. However, the computational time for each iteration is on the order of O(10 4) seconds.
Figure 2: histogram of 103Monte Carlo simulations for problem 1 with a logistic activation function,
n= 50, andL= 50.
3.1.2 Problem 2
Problem 2 is a system of non-linear ODEs taken from Lagaris et al. [24],
y1t= cost+y2
1+y2 (1 +t2+ sin2t)
y2t= 2t (1 +t2) sint+y1y2
101 1.2 1.4 1.6 1.8 2
t11.051.11.151.21.251.31.35y
Exact Solution
ETFC Solution
1 1.2 1.4 1.6 1.8 2
t3456abs(err)10-16 Absolute Training Error 
1 1.2 1.4 1.6 1.8 2
t10-1410-13abs(Loss)Absolute Training Loss
1 1.2 1.4 1.6 1.8 2
t3456abs(err)10-16 Absolute Test ErrorFigure 3: Solution and performances for problem 1: exact solution versus X-TFC solution, absolute
training error, absolute loss, and absolute test error, with a logistic activation function, n= 51, andL= 51.
The convergence is achieved in 5 iterations with a tolerance set to 4 :440892098500626 10 16. The
computational time is 1 :0993 milliseconds, the maximum absolute training error is 6 :6613410 16, the
maximum absolute training loss is 3 :068110 13, and the maximum absolute test error is 6 :6613410 16
11subject toy1(0) = 0 and y2(0) = 1 where t2[0;3]. The exact solutions are y1(t) = sin(t) andy2(t) = 1 +t2.
The constrained expressions for this problem are,
y1(t) = [ 0]T1
y2(t) = [ 0]T2+ 1
where0is the free-function computed at t= 0.
The results are reported in gures 4-6, and tables 2 and 3. For y1, the average absolute errors for both
training and testing are on the order of O(10 12), while for y2, the average absolute errors for both training
and testing are on the order of O(10 11). The computational time for both y1andy2is on the order of
O(10 2) seconds.
Figure 4: histogram of 103Monte Carlo simulations for problem 2 with a logistic activation function,
n= 100, and L= 100.
3.2 PDEs
This section presents the results of the proposed method when applied a variety of PDEs. For each problem,
the PDE and its constraints are summarized along with the relevant equations needed to construct the
constrained expression. Each problem follows the same format. First, the Mtensor and vvectors are
presented followed by an expanded form of the constrained expression. Problem 1 provides a reminder of the
notation used in the constrained expressions, while the latter examples simply state the terms used. For a
more detailed explanation on how to build constrained expression, consult Refs. [1, 28].
All PDE problems shown in this article were implemented in Python and utilized the autograd package [36],
12Test
PointsX-TFC TFC
1 0 0
1.1 0 0
1.2 2.210 160
1.3 2.210 162.210 16
1.4 2.210 160
1.5 2.210 162.210 16
1.6 0 2.2 10 16
1.7 2.210 162.210 16
1.8 2.210 162.210 16
1.9 0 0
2 0 0
Table 1: Problem #1: X-TFC and TFC absolute errors with respect the exact solution. The absolute
errors of LeNN method [19] are not reported. As reported in [19], the average absolute error of LeNN
method is ofO(10 3)
0 0.5 1 1.5 2 2.5 3
t00.20.40.60.81y1
Exact Solution y1
ETFC Solution y1
0 0.5 1 1.5 2 2.5 3
t10-1610-1410-1210-1010-8abs(err1)Absolute Training Error 1
0 0.5 1 1.5 2 2.5 3
t10-1410-1210-1010-8abs(Loss1)Absolute Loss 1 
0 0.5 1 1.5 2 2.5 3
t10-1610-1410-1210-1010-8abs(err1)Absolute Test Error 1
Figure 5: Solution and performances for problem 2, y1: exact solution versus X-TFC solution, absolute
training error, absolute loss, and absolute test error, with a logistic activation function, n= 100, and
L= 100. The convergence is achieved in 9 iterations with a tolerance set to 10 10 6. The computational
time is 25:8953 milliseconds, the maximum absolute training error is 4 :3182210 10, the maximum
absolute training loss is 2 :1387810 8, and the maximum absolute test error is 5 :543410 10
130 0.5 1 1.5 2 2.5 3
t0246810y2
Exact Solution y2
ETFC Solution y2
0 0.5 1 1.5 2 2.5 3
t10-1410-1210-1010-8abs(err2)Absolute Training Error 2 
0 0.5 1 1.5 2 2.5 3
t10-1610-1410-1210-1010-810-6abs(Loss2)Absolute Loss 2 
0 0.5 1 1.5 2 2.5 3
t10-1410-1210-1010-8abs(err2)Absolute Test Error 2Figure 6: Solution and performances for problem 2, y1: exact solution versus X-TFC solution, absolute
training error, absolute loss, and absolute test error, with a logistic activation function, n= 100, and
L= 100. The convergence is achieved in 9 iterations with a tolerance set to 10 10 6. The computational
time is 25:8953 milliseconds, the maximum absolute training error is 1 :2305610 9, the maximum
absolute training loss is 6 :0965410 8, and the maximum absolute test error is 1 :5812210 9
Test
PointsX-TFC TFC
0 0 0
0.3 1.110 131.210 13
0.6 1.710 132.910 13
0.9 3.010 137.210 13
1.2 6.710 131.610 12
1.5 1.710 124.110 12
1.8 4.410 121.110 11
2.1 1.210 113.010 11
2.4 3.410 118.010 11
2.7 9.410 111.810 10
3 1.810 101.610 10
Table 2: Problem #2: X-TFC and TFC absolute errors on y1with respect the analytical solution. The
maximum absolute error obtained with the ANN method [24] is of O(10 4)
14which uses automatic dierentiation [37] to compute the derivatives. Consequently, two specic computation
times are provided, 1) the full run-time of the problem and 2) the computation time associated with the
least-squares. As observed in the results, the full run-time is drastically aected by the computation overhead
from autograd with full run times on the order of 1 - 100 seconds. However, the computation time for the
least squares and nonlinear least squares is on the order of 1 - 100 milliseconds. Therefore, the second time
reported, the one associated with the least squares, is the expected computation time if the partial derivative
of the problem were computed analytically and explicitly programmed and/or if the problems were solved in
a compiled language. All input weights and biases for all problems were randomly sampled from a uniform
distribution, ( wj; bj)unif( 1;1) wherej= 1;:::;L .
For the PDEs, the same sensitivity analysis was performed as for the ODEs. The results of one of these
studies is shown in Figs. 7 and 8 for the PDE of problem number 1. Figure 7 shows the solution error for
the PDE of problem number 1 as a function of the number of training points in the grid. The x-axis in
this gure shows the number of training points used per independent variable: the total number of training
points used was the square of the values on the x-axis. Each data point in Fig. 7 used 170 basis functions.
Figure 8 shows the solution error for the PDE of problem number 1 as a function of the number of basis
functions. The number of training points used for each point in Fig. 8 was 900, a 30 30 grid. The results
are consistent with the results obtained for the ODEs: the solution error asymptotically decreases as the
number of basis functions increases, and the solution error asymptotically decreases as the the number of
training points increases.
0 5 10 15 20 25 30
Number of points per independent variable1014
1011
108
105
102
101Average test set error
Figure 7: Average test set error as a function of the number of points per side in the grid
The tests in this section were performed on a MacBook Pro (2016) macOS Version 10.15.3 with a 3.3 GHz
Dual-Core IntelRCoreTMi7 and with 16 GB of RAM. All run times were calculated using the default timer
function in the Python timeit package.
3.2.1 Problem 1
Consider the PDE solved in Largaris et al. [24], Mall & Chakraverty [38], and Sun et al. [39],
fxx(x;y) +fyy(x;y) =e x(x 2 +y3+ 6y)
15Test
PointsX-TFC TFC
0 0 0
0.3 6.510 142.210 13
0.6 1.310 132.010 13
0.9 2.510 131.210 12
1.2 6.610 131.410 12
1.5 2.010 125.510 12
1.8 6.310 121.510 11
2.1 2.110 115.210 11
2.4 7.010 111.610 10
2.7 2.310 104.510 10
3 5.210 104.710 10
Table 3: Problem #4: X-TFC and TFC absolute errors on scattered ux y2with respect the exact solution.
The maximum absolute error obtained with the ANN method [24] is of O(10 5)
0 25 50 75 100 125 150 175 200
Number of basis functions1015
1012
109
106
103
100Average test set error
Figure 8: Average test set error as a function of the number of basis functions
16wherex;y2[0;1] and subject to,
f(0;y) =y3
f(1;y) = (1 + y3)e 1
f(x;0) =xe x
f(x;1) =e x(x+ 1);
which has the true solution f(x;y) =e x(x+y3). Using the TFC [28], the constrained expression for the
specied boundary conditions can be written in its compact form,
f(x;y) =g(x;y) +v(x)TM(c(x;y) g(x;y))v(y);
whereg(x;y) will be dened as an ELM, the cterms are dened by the constraints (e.g. c(0;y) :=f(0;y)),
and the values c(0;0);c(0;1);c(1;0);andc(1;1) coincide with the intersection of the constraints and are
therefore dened by the constraints. Furthermore, for this problem,
M(c(x;y)) =2
40c(x;0)c(x;1)
c(0;y) c(0;0) c(0;1)
c(1;y) c(1;0) c(1;1)3
5:
and
v(x) =1;1 x; x	T;v(y) =1;1 y; y	T:
It follows that the expanded constrained expression is,
f(x;y) =g(x;y) (x 1) 
y( g(0;0) +g(0;1) 1) +g(0;0) +y3
+ (x 1)g(0;y)
+x(yg(1;1) (y 1)g(1;0)) xg(1;y) + (y 1)g(x;0) yg(x;1) +xy 
y2 1
e+e x(x+y)
For this problem, the free-function, g(x;y), was chosen to be an ELM with 170 neurons that used tanh as
the non-linear activation function. Then, the constrained expression and its derivatives were substituted into
the dierential equation, which converts the dierential equation into an algebraic equation. To solve this
algebraic equation, the problem was discretized over 30 30 training points that spanned the domain. This
system of equations was solved using NumPy's lstsq function.
The total execution time was 3.48 seconds, and the least-squares took 8.07 milliseconds. Additionally, the
training set maximum error was 3 :80810 13, and the training set average error was 6 :47510 14. The
test set maximum error was 5 :05410 13, and the test set average error was 7 :64010 14. Figure 9 shows
a plot of the error over the domain, and Table 4 compares the X-TFC solution with the FEM and Refs.
[24, 38, 39]. Figure 9 shows that the error is distributed approximately evenly throughout the domain.
MethodTraining Set
Maximum ErrorTest Set
Maximum Error
X-TFC 3 :810 135:110 13
FEM 210 81:510 5
Ref. [24] 510 7510 7
Ref. [38]   3:210 2
Ref. [39]   2:410 4
Table 4: Comparison of maximum training and test error of X-TFC with current state-of-the-art techniques
for Problem 1.
Table 4 shows that the X-TFC method outperforms the other methods in terms of solution error by 5 to 11
orders of magnitude.
173.2.2 Problem 2
Consider the PDE solved in Largaris et al. [24] and Mall & Chakraverty [38],
fxx(x;y) +fyy(x;y) = (2 2y2) sin(x)
wherex;y2[0;1] and subject to,
f(0;y) = 0
f(1;y) = 0
f(x;0) = 0
fy(x;1) = 2 sin( x);
which has the true solution f(x;y) =y2sin(x).
Constrained expression (compact):
f(x;y) =g(x;y) +v(x)TM(c(x;y) g(x;y))v(y)
where
M(c(x;y)) =2
40c(x;0)cy(x;1)
c(0;y) c(0;0) cy(0;1)
c(1;y) c(1;0) cy(1;1)3
5
and
v(x) =
1;1 x; x	T;v(y) =
1;1; y	T:
Constrained expression (expanded):
f(x;y) =y((1 x)gy(0;1) +xgy(1;1) gy(x;1) + 2 sin(x))
 (1 x)g(0;y) xg(1;y) +g(x;y) + (1 x)g(0;0) +xg(1;0) g(x;0)
For this problem, the free-function was chosen to be an with 170 neurons that used tanh as the activation
function. The problem was discretized over 30 30 training points that spanned the domain, and the least-
squares problem was solved using NumPy's lstsq function.
The total execution time was 3.54 seconds, and the least-squares took 9.34 milliseconds. Furthermore, the
training set maximum error was 6 :33210 12, and the training set average error was 1 :18710 12. The
test set maximum error was 7 :58110 12, and the test set average error was 1 :32210 12. Figure 10
shows a plot of the error over the domain, and Table 5 compares the X-TFC solution with the FEM and
Refs. [24] and [38]. Figure 10 shows that the solution error is lower near where constraints are dened on
MethodTraining Set
Maximum ErrorTest Set
Maximum Error
X-TFC 6 :310 127:610 12
FEM 710 7410 5
Ref. [24] 610 6610 6
Ref. [38]   310 3
Table 5: Comparison of maximum training and test error of X-TFC with current state-of-the-art techniques
for Problem 2.
the boundary value than where they are dened on the derivative. Intuitively, this makes sense as the TFC
constrained expressions guarantees there will be no error in the solution value for constraints dened on the
boundary value, but not for constraints on the derivative (there it only garuantees that the deriative will
have no error). Table 5 shows that the X-TFC method outperforms all other methods in terms of accuracy
by 5 to 9 orders of magnitude.
18x0.0
0.2
0.4
0.6
0.8
1.0y
0.00.20.40.60.81.0|fftrue|
1e13
012345
0.51.01.52.02.53.03.51e13
Figure 9: Solution error using X-TFC in problem 1
x0.00.2
0.4
0.6
0.8
1.0y
0.00.20.40.60.81.0|fftrue|
1e12
01234567
12345671e12
Figure 10: Solution error using X-TFC in problem 2
193.2.3 Problem 3
Consider the PDE solved in Largaris et al. [24],
fxx(x;y) +fyy(x;y) +f(x;y)fy(x;y) = sin(x)
2 2y2+ 2y3sin(x)
wherex;y2[0;1] and subject to,
f(0;y) = 0
f(1;y) = 0
f(x;0) = 0
fy(x;1) = 2 sin( x);
which has the true solution f(x;y) =y2sin(x).
Constrained expression (compact):
f(x;y) =g(x;y) +v(x)TM(c(x;y) g(x;y))v(y)
where
M(c(x;y)) =2
40c(x;0)cy(x;1)
c(0;y) c(0;0) cy(0;1)
c(1;y) c(1;0) cy(1;1)3
5
and
v(x) =1;1 x; x	T;v(y) =1;1; y	T:
Constrained expression (expanded):
f(x;y) =y((1 x)gy(0;1) +xgy(1;1) gy(x;1) + 2 sin(x))
 (1 x)g(0;y) xg(1;y) +g(x;y) + (1 x)g(0;0) +xg(1;0) g(x;0)
For this problem, the free-function was chosen to be an ELM with 150 neurons that used tanh as the
activation function. The problem was discretized over 20 20 training points that spanned the domain,
and each iteration of the non-linear least-squares was solved using NumPy's lstsq function. The total
execution time was 22.48 seconds, and the nonlinear least-squares, which needed 10 iterations, took 52.6
milliseconds. In addition, the training set maximum error was 7 :63410 11, and the training set average
error was 9 :49710 12. The test set maximum error was 8 :97710 11, and the test set average error
was 1:06810 11. Figure 11 shows a plot of the error over the domain, and Table 6 compares the X-TFC
solution with the FEM method and Ref. [24]. As in problem 2, Fig. 11 shows illustrates that the solution
MethodTraining Set
Maximum ErrorTest Set
Maximum Error
X-TFC 8 :810 119:010 11
FEM 610 7410 5
Ref. [24] 1 :510 51:510 5
Table 6: Comparison of maximum training and test error of X-TFC with current state-of-the-art techniques
for Problem 3.
error is lower near where constraints are dened on the boundary value than where they are dened on the
derivative, because the TFC constrained expressions guarantees there will be no error in the solution value for
constraints dened on the boundary. Table 6 shows that the X-TFC method outperforms all other methods
in terms of accuracy by 4 to 6 orders of magnitude.
203.2.4 Problem 4 (1D Time-Dependent Heat Equation)
fxx(x;t) =ft(x;t)
wherex;t2[0;1][0;1] and= 1, subject to
f(0;t) = 0
f(1;t) = 0
f(x;0) = sin( x);
which has the true solution f(x;t) = sin(x)e 2t.
Constrained expression (compact):
f(x;t) =g(x;t) +v(x)TM
c(x;t) g(x;t)
v(t)
where
M
c(x;t)
=2
40c(x;0)
c(0;t) c(0;0)
c(L;t) c(L;0)3
5
and
v(x) =1;1 x; x	T; v(t) =1;1	T:
Constrained expression (expanded):
f(x;t) =g(x;t) + (x 1)g(0;t) xg(1;t) xg(0;0) +xg(1;0) g(x;0) +g(0;0) + sin(x)
For this problem, the free-function was chosen to be an ELM with 196 neurons that used tanh as the
activation function. The problem was discretized over 30 30 training points that spanned the domain,
and the least-squares problem was solved using NumPy's lstsq function. The total execution time was
3.21 seconds, and the least-squares took 9.90 milliseconds. Additionally, the training set max error was
5:61110 7, and the training set average error was 6 :55110 8. The test set maximum error was 5 :78510 7,
and the test set average error was 6 :92810 8. Figure 12 shows a plot of the error over the domain. Figure
12 shows that the error is larger at smaller time steps. Of course, the solution error is zero at t= 0, because
the TFC constrained expression guarantees the constraint c(x;0) is satised. The reason the solution error,
in general, is larger for smaller values of tis the solution is changing much more rapidly for smaller values
oftthan larger values of t(i.e. the gradients for smaller values of tare larger than the gradients for larger
values oft).
3.2.5 Problem 5 (2D Time-Dependent Heat Equation)
fxx(x;y;t ) +fyy(x;y;t ) =ft(x;y;t )
wherex;y;t2[0;L][0;H][0;1], subject to
f(0;y;t) = 0
f(L;y;t ) = 0
f(x;0;t) = 0
f(x;H;t ) = 0
f(x;y;0) = sinx
L
siny
H
;
which has the true solution f(x;y;t ) = sin
x
L
sin
y
H
e 
2
L2+2
H2
t. Here, the values L= 2,H= 1, and
= 1 are used.
21x0.00.2
0.4
0.6
0.8
1.0y
0.00.20.40.60.81.0|fftrue|
1e11
012345678
123456781e11
Figure 11: Solution error using X-TFC in problem 3
x0.0
0.2
0.4
0.6
0.8
1.0t
0.00.20.40.60.81.0|fftrue|
1e7
012345
123451e7
Figure 12: Solution error using X-TFC in problem 4
22Constrained expression (compact):
f(x;y;t ) =g(x;y;t ) +Mijk
c(x;y;t ) g(x;y;t )
vi(x)vj(y)vk(t)
where
Mij1
c(x;y;t )
=2
40c(x;0;t)c(x;H;t )
c(0;y;t) c(0;0;t) c(0;H;t )
c(L;y;t ) c(L;0;t) c(L;H;t )3
5
Mij2
c(x;y;t )
=2
4c(x;y;0) c(x;0;0) c(x;H; 0)
 c(0;y;0)c(0;0;0)c(0;H;0)
 c(L;y; 0)c(L;0;0)c(L;H; 0)3
5
and
vi(x) =
1;L x
L;x
L	T; vj(y) =
1;H y
H;y
H	T; vk(t) =
1;1	T:
Constrained expression (expanded):
f(x;y;t ) =(H y)
(L x)g(0;0;t)
L+xg(L;0;t)
L g(x;0;t)
H+y
(L x)g(0;H;t)
L+xg(L;H;t )
L g(x;H;t )
H
+(H y)
 g(0;0;0)(L x)
L xg(L;0;0)
L+g(x;0;0)
H+y
 (L x)g(0;H;0)
L xg(L;H;0)
L+g(x;H; 0)
H
 (L x)g(0;y;t)
L xg(L;y;t )
L+(L x)g(0;y;0)
L+xg(L;y; 0)
L+g(x;y;t ) g(x;y;0)
+ siny
H
sinx
L
For this problem, the free-function was chosen to be an ELM with 400 neurons that used tanh as the
activation function. The problem was discretized over 13 1313 training points that spanned the domain,
and the least-squares problem was solved using NumPy's lstsq function.
The total execution time was 159.3 seconds, and the nonlinear least-squares took 55.4 milliseconds. Further-
more, the training set maximum error was 3 :98510 4, and the training set average error was 1 :70510 5.
The test set maximum error was 4 :02510 4, and the test set average error was 2 :09010 5.
3.2.6 Problem 6 (Non-linear 2D time-dependent PDE)
zt(x;y;t )zx(x;y;t ) +zy(x;y;t ) =t2+ (t 1)x+ 2xcos(2xy) + (2ty+xy)
(t 1)y+ 2ycos(2xy)
wherex;y;t2[0;1], subject to
z(0;y;t) =t2y
z(x;0;t) = 0
z(x;y;1) =y+ sin(2xy);
which has the true solution z(x;y;t ) = sin(2xy) +t2y+ (t 1)xy.
Constrained expression (compact):
f(x;y;t ) =g(x;y;t ) +Mijk
c(x;y;t ) g(x;y;t )
vi(x)vj(y)vk(t)
where
Mij1
c(x;y;t )
=
0c(x;0;t)
c(0;y;t) c(0;0;t)
Mij2
c(x;y;t )
=c(x;y;1) c(x;0;1)
 c(0;y;1)c(0;0;1)
23and
vi(x) =1;1	T; vj(y) =1;1	T; vk(t) =1;1	T:
Constrained expression (expanded):
z(x;y;t ) =g(x;y;t ) g(x;0;t) g(0;y;t) +g(0;0;t) g(x;y;1) +g(x;0;1) +g(0;y;1) g(0;0;1)
+t2y+ sin(2xy)
For this problem, the free-function was chosen to be an ELM with 255 neurons that used tanh as the
activation function. The problem was discretized over 8 88 training points that spanned the domain, and
each iteration of the non-linear least-squares was solved using NumPy's lstsq function.
The total execution time was 32.19 seconds, and the nonlinear least-squares, which needed 10 iterations, took
0.140 seconds. In addition, the training set maximum error was 1 :65710 8, and the training set average
error was 1 :00610 9. The test set maximum error was 1 :65710 8, and the test set average error was
1:01810 9.
3.2.7 Problem 7 (Non-linear 3D time-dependent PDE)
fx(x;y;z;t )fy(x;y;z;t )fz(x;y;z;t ) +ftt(x;y;z;t ) =
(t 1)tx(z 1) +x2cos 
x2y
+3
2xpyz


(t 1)ty(z 1) + 2xycos 
x2y
+y3=2z


2t2cos(2z) + (t 1)txy+xy3=2
+ 2xy(z 1)
+ 2 sin(2z)
wherex;y;t2[0;1], subject to
f(0;y;z;t ) =t2sin(2z)
f(x;0;z;t) =t2sin(2z)
f(x;y;1;t) = sin 
x2y
+xpy
f(x;y;z; 0) = sin 
x2y
+xpyz
f(x;y;z; 1) = sin 
x2y
+xpyz+ sin(2z);
which has the true solution f(x;y;z;t ) =t2sin(2z) + sin 
x2y
+xy3=2z+xyt(z 1)(t 1).
Constrained expression (compact):
f(x;y;z;t ) =g(x;y;z;t ) +Mijkl
c(x;y;z;t ) g(x;y;z;t )
vi(x)vj(y)vk(z)vl(t)
where
Mij11
c(x;y;z;t )
=0c(x;0;z;t)
c(0;y;z;t ) c(0;0;z;t)
Mij12
c(x;y;z;t )
=c(x;y;z; 0) c(x;0;z;0)
 c(0;y;z; 0)c(0;0;z;0)
Mij13
c(x;y;z;t )
=c(x;y;z; 1) c(x;0;z;1)
 c(0;y;z; 1)c(0;0;z;1)
Mij21
c(x;y;z;t )
=
c(x;y;1;t) c(x;0;1;t)
 c(0;y;1;t)c(0;0;1;t)
Mij22
c(x;y;z;t )
= c(x;y;1;0)c(x;0;1;0)
c(0;y;1;0) c(0;0;1;0)
Mij23
c(x;y;z;t )
= c(x;y;1;1)c(x;0;1;1)
c(0;y;1;1) c(0;0;1;1)
24and
vi(x) =1;1	Tvj(y) =1;1	Tvk(z) =1;1	Tvl(t) =1;1 t; t	T:
Constrained expression (expanded):
f(x;y;z;t ) =g(x;y;z;t ) + (1 t)
 g(x;y;z; 0) +g(x;y;1;0) +g(x;0;z;0) g(x;0;1;0) +g(0;y;z; 0)
 g(0;y;1;0) g(0;0;z;0) +g(0;0;1;0) +xy3=2z xy3=2
+t
 g(x;y;z; 1)
+g(x;y;1;1) +g(x;0;z;1) g(x;0;1;1) +g(0;y;z; 1) g(0;y;1;1) g(0;0;z;1)
+g(0;0;1;1) +xy3=2z xy3=2
 g(x;y;1;t) g(x;0;z;t) +g(x;0;1;t) g(0;y;z;t )
+g(0;y;1;t) +g(0;0;z;t) g(0;0;1;t) +t2sin(2z) + sin 
x2y
+xy3=2
For this problem, the free-function was chosen to be an ELM with 340 neurons that used tanh as the
activation function. The problem was discretized over 5 555 training points that spanned the domain,
and each iteration of the non-linear least-squares was solved using NumPy's lstsq function.
The total execution time was 321.9 seconds, and the nonlinear least-squares, which needed 10 iterations, took
0.229 seconds. Additionally, the training set maximum error was 2 :74410 5, and the training set average
error was 6 :64110 7. The test set maximum error was 2 :97810 5, and the test set average error was
8:08210 7.
4 Conclusions
In this article, a novel, accurate, and robust physics-informed (PI) method for solving problems involving
parametric DEs called the Extreme Theory of Functional Connection , orExtreme-TFC (X-TFC) was devel-
oped. Although this article focuses on the solution of exact problems (e.g. problems where the modeling
error is negligible), X-TFC can also handle data-driven solutions and data-driven discovery of parametric
DEs. X-TFC is a synergy of the standard TFC method developed by Mortari et al. [1, 2, 3], where the latent
solution of the DE is approximated by a constrained expression, which analytically satises the constraints
while maintaining a free-function that can be used to satisfy the parametric DE, and the classic physics-
informed neural network (PINN) methods proposed by Raissi et al. [4] and [25], where the free-function is
chosen as a NN. In X-TFC, the NN used is not a deep-NN, but a single layer NN, that is trained based on
the ELM learning algorithm proposed by Huang et al. [6].
The results presented in this manuscript show that the proposed PI method can solve several types of ex-
act problems involving parametric DEs with high accuracy and low computational time. For linear and
non-linear ordinary dierential equations (ODEs) and systems of ODEs (SODEs) the proposed framework
achieves machine level accuracy in milliseconds. This makes the X-TFC method is as accurate or more accu-
rate than all other state-of-the-art methods except the classic TFC; although it should be noted that in all
cases the classic TFC and X-TFC have solutions errors that are on the same order of magnitude. For linear
and non-linear bi-dimensional PDEs, the results achieved by the X-TFC framework are comparable with
state-of-the-art methods in terms of speed and outperforms state-of-the-art methods in terms of accuracy
by four to 11 orders of magnitude. Furthermore, X-TFC was tested on higher dimensional problems such
as a 2D time-dependent non-linear PDE and a 3D time-dependent non-linear PDE. These problems showed
that while the method's accuracy and computational time are aected by the increase in the number of
dimensions, the method is still well suited for a variety of applications involving PDEs of this dimensionality.
In fact, X-TFC is well suited for a variety of applications, even real-time applications that require accurate
and fast solutions, such as optimal control problems in aerospace applications. To this end, the authors are
currently applying X-TFC to optimal control problems such as energy optimal landing on planetary bodies,
minimum time orbit transfer, and maximum radius orbit transfer, to name a few. Moreover, X-TFC is
being applied to the solution of transport theory problems such as Radiative Transfer problems (for remote
sensing applications and space exploration), and Rareed Gas Dynamic problems. As mentioned previously,
the physics-informed X-TFC method can also be used for data-driven solutions and data-driven discovery
of parametric DEs. Currently, progress is begin made on the data-driven discovery of problems involving
25parametric ODEs from both a deterministic and probabilistic approach.
Of course, there is still room to further improve the performance and capability of this new PI method.
The authors are currently investigating the possibility to use new activation functions in addition to the
well known logistic, hyperbolic tangent, sinusoid, and Gaussian. Currently under investigation is the use to
dierent probability distribution to sample input weights and biases, in addition to the uniform and normal
distributions. Future work will attempt to create a Distributed-X-TFC framework similar to the one proposed
in Ref. [26], to target problems where the latent solution contains piece-wise continuous behaviour, sharp
derivatives, and/or the problems are suciently complex such as Navier-Stokes type problems. In addition
to exploring these areas further, future work will also focus on the extension of X-TFC to multi-dimensional
problems with non-rectangular domains [4, 26, 40].
Conicts of Interest
The authors declare no conict of interest.
Acknowledgements
This work was partially supported by a NASA Space Technology Research Fellowship, Leake [NSTRF 2019]
Grant #: 80NSSC19K1152 and Johnston [NSTRF 2019] Grant #: 80NSSC19K1149.
In addition, the authors would like to acknowledge Professor Barry D. Ganapol and Mr. Andrea
D'Ambrosio for their precious advises that helped to improve this manuscript, and for suggesting a few
remote sensing and aerospace applications, where X-TFC can be tested, as future work topics.
References
[1] D. Mortari, \The Theory of Connections: Connecting Points,"" MDPI Mathematics , vol. 5, no. 57, 2017.
[2] D. Mortari, \Least-squares Solution of Linear Dierential Equations,"" MDPI Mathematics , vol. 5, no. 48,
pp. 1{18, 2017.
[3] D. Mortari, H. Johnston, and L. Smith, \High accuracy least-squares solutions of nonlinear dierential
equations,"" Journal of Computational and Applied Mathematics , vol. 352, pp. 293 { 307, 2019.
[4] M. Raissi, P. Perdikaris, and G. E. Karniadakis, \Physics-informed neural networks: A deep learning
framework for solving forward and inverse problems involving nonlinear partial dierential equations,""
Journal of Computational Physics , vol. 378, pp. 686{707, 2019.
[5] C. Leake and D. Mortari, \Deep Theory of Functional Connections: A New Method for Estimating the
Solutions of Partial Dierential Equations,"" Machine Learning and Knowledge Extraction , vol. 2, no. 1,
pp. 37{55, 2020.
[6] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, \ Extreme learning machine: Theory and applications ,""
Neurocomputing , vol. 70, pp. 489{501, May 2006.
[7] J. Dormand and P. Prince, \A Family of Embedded Runge-Kutta Formulae,"" J. Comp. Appl. Math. ,
vol. 6, pp. 19{26, 1980.
[8] J. L. Junkins, A. B. Younes, R. Woollands, and X. Bai, \Picard Iteration, Chebyshev Polynomials, and
Chebyshev Picard Methods: Application in Astrodynamics,"" The Journal of the Astronautical Sciences,
vol. 60, pp. 623{653, December 2015.
[9] D. Gottlieb and S. A. Orszag, Numerical Analysis of Spectral Methods: Theory and Applications . Society
for Industrial and Applied Mathematics, 1977.
[10] A. Gil, J. Segura, and N. Temme, Numerical Methods for Special Functions . Society for Industrial and
Applied Mathematics, 1 2007.
[11] C. Lanczos, Applied Analysis . New York: Dover Publications, Inc., 1957.
26[12] R. Furfaro and D. Mortari, \Least-squares solution of a class of optimal space guidance problems via
Theory of Connections,"" Acta Astronautica , 2019.
[13] H. Johnston, E. Schiassi, R. Furfaro, and D. Mortari, \Fuel-Ecient Powered Descent Guidance on Large
Planetary Bodies via Theory of Functional Connections,"" The Journal of the Astronautical Sciences ,
under review.
[14] H. Johnston and D. Mortari, \Linear Dierential Equations Subject to Multivalued, Relative and/or
Integral Constraints with Comparisons to Chebfun,"" SIAM Journal of Numerical Analysis , 2018. Sub-
mitted.
[15] M. De Florio, E. Schiassi, R. Furfaro, and B. D. Ganapol, \An Accurate Solution for Poiseuille Flow in
a Plane Channel via Theory of Functional Connections,"" In preparation , 2020.
[16] L. Barichello and C. Siewert, \A discrete-ordinates solution for Poiseuille ow in a plane channel,""
Zeitschrift f ur angewandte Mathematik und Physik ZAMP , vol. 50, no. 6, pp. 972{981, 1999.
[17] L. Barichello, M. Camargo, P. Rodrigues, and C. Siewert, \Unied solutions to classical ow problems
based on the BGK model,"" Zeitschrift f ur angewandte Mathematik und Physik ZAMP , vol. 52, no. 3,
pp. 517{534, 2001.
[18] B. D. Ganapol, \Poiseuille channel ow by adding and doubling,"" in AIP Conference Proceedings ,
vol. 1786, p. 070009, AIP Publishing LLC, 2016.
[19] Y. Yang, M. Hou, and J. Luo, \A novel improved extreme learning machine algorithm in solving ordinary
dierential equations by Legendre neural network methods,"" Advances in Dierence Equations , vol. 2018,
no. 1, p. 469, 2018.
[20] J. N. Reddy, \An Introduction to the Finite Element Method,"" Journal of Pressure Vessel Technology ,
vol. 111, pp. 348{349, 08 1989.
[21] J. Argyris and S. Kelsey, \Energy Theorems and Structural Analysis: A Generalized Discourse with
Applications on Energy Principles of Structural Analysis Including the Eects of Temperature and
NonLinear StressStrain Relations,"" Aircraft Engineering and Aerospace Technology , vol. 26, no. 10,
pp. 347{356, 1954.
[22] M. J. Turner, R. W. Clough, H. C. Martin, and L. J. Topp, \Stiness and Deection Analysis of Complex
Structures,"" Journal of the Aeronautical Sciences , vol. 23, pp. 805{823, sep 1956.
[23] R. W. Clough, The nite element method in plane stress analysis . American Society of Civil Engineers,
1960.
[24] I. E. Lagaris, A. Likas, and D. I. Fotiadis, \Articial neural networks for solving ordinary and partial
dierential equations,"" IEEE Transactions on Neural Networks , vol. 9, pp. 987{1000, Sept 1998.
[25] J. Sirignano and K. Spiliopoulos, \DGM: A deep learning algorithm for solving partial dierential
equations,"" September 2018.
[26] D. Vikas and S. Balaji, \Physics-Informed Extreme Learning Machine (PIELM)- A Rapid Method For
The Numerical Solution Of Partial Dierential Equations,"" arXiv , vol. Xiv:1907.03507v1, 2019.
[27] S. A. Coons, \SURFACES FOR COMPUTER-AIDED DESIGN OF SPACE FORMS,"" tech. rep., Mas-
sachusetts Institute of Technology, Cambridge, MA, USA, 1967.
[28] D. Mortari and C. Leake, \The Multivariate Theory of Connections,"" MDPI Mathematics , vol. 7, no. 3,
p. 296, 2019.
[29] C. Leake and D. Mortari, \An Explanation and Implementation of Multivariate Theory of Connections
via Examples,"" in 2019 AAS/AIAA Astrodynamics Specialist Conference, Portland, MN, August 11{15,
2019, AAS/AIAA, 2019.
27[30] C. Leake, H. Johnston, L. Smith, and D. Mortari, \Analytically Embedding Dierential Equation Con-
straints into Least Squares Support Vector Machines Using the Theory of Functional Connections,""
Machine Learning and Knowledge Extraction , vol. 1, pp. 1058{1083, Oct. 2019.
[31] E. Schiassi, R. Furfaro, J. S. Kargel, C. S. Watson, D. H. Shugar, and U. K. Haritashya, \GLAM
Bio-Lith RT: A Tool for Remote Sensing Reectance Simulation and Water Components Concentration
Retrieval in Glacial Lakes,"" Frontiers in Earth Science , vol. 7, 2019.
[32] E. Schiassi, R. Furfaro, and D. Mostacci, \Bayesian inversion of coupled radiative and heat transfer
models for asteroid regoliths and lakes,"" Radiation Eects and Defects in Solids , vol. 171, no. 9-10,
pp. 736{745, 2016.
[33] B. Hapke, \Bidirectional reectance spectroscopy: 1. Theory,"" Journal of Geophysical Research: Solid
Earth , vol. 86, no. B4, pp. 3039{3054, 1981.
[34] B. Hapke, \A model of radiative and conductive energy transfer in planetary regoliths,"" Journal of
Geophysical Research: Planets , vol. 101, no. E7, pp. 16817{16831, 1996.
[35] A. S. Hale and B. Hapke, \A time-dependent model of radiative and conductive thermal energy transport
in planetary regoliths with applications to the Moon and Mercury,"" Icarus , vol. 156, no. 2, pp. 318{334,
2002.
[36] D. Maclaurin, D. Duvenaud, M. Johnson, and J. Townsend, \Autograd."" https://github.com/HIPS/
autograd , 2013.
[37] A. G. Baydin, B. A. Pearlmutter, A. A. Radul, and J. M. Siskind, \Automatic dierentiation in machine
learning: a survey,"" 2015.
[38] S. Mall and S. Chakraverty, \Single Layer Chebyshev Neural Network Model for Solving Elliptic Partial
Dierential Equations,"" Neural Processing Letters , vol. 45, no. 3, pp. 825{840, 2017.
[39] H. Sun, M. Hou, Y. Yang, T. Zhang, F. Weng, and F. Han, \Solving Partial Dierential Equation Based
on Bernstein Neural Network and Extreme Learning Machine Algorithm,"" Neural Processing Letters ,
vol. 50, no. 2, pp. 1153{1172, 2019.
[40] J. Berg and N. Kaj, \A unied deep articial neural network approach to partial dierential equations
in complex geometries,"" Neurocomputing , vol. 317, pp. 28{41, 2018.
28"
33,https://pymor.org/,"




pyMOR | Model Order Reduction with Python


























Model Order Reduction with Python
View on GitHub
Documentation and tutorials
pyMOR School 2024












pyMOR - Model Order Reduction with Python
pyMOR is a software library for building
model order reduction
applications with the Python programming language.
All algorithms in pyMOR are formulated in terms of abstract interfaces,
allowing generic implementations to work with different backends,
from NumPy/SciPy to external partial differential equation solver packages.
Features

Reduced basis methods for parametric linear and non-linear problems.
System-theoretic methods for linear time-invariant systems.
Neural network-based methods for parametric problems.
Proper orthogonal decomposition.
Dynamic mode decomposition.
Rational interpolation of data (Loewner, AAA).
Numerical linear algebra (Gram-Schmidt, time-stepping, …).
Pure Python implementations of finite element and finite volume
discretizations using the NumPy/SciPy scientific computing stack.

License
pyMOR is licensed under BSD-2-clause.
See LICENSE.txt.
Citing
If you use pyMOR for academic work, please consider citing our
publication:
R. Milk, S. Rave, F. Schindler
pyMOR - Generic Algorithms and Interfaces for Model Order Reduction
SIAM J. Sci. Comput., 38(5), pp. S194--S216, 2016

Installation via pip
pyMOR can easily be installed using Python package managers like
pip.
We recommend installation of pyMOR into a
virtual environment
to avoid dependency conflicts.
For an installation with minimal dependencies, run
pip install pymor

Since most included demo scripts require Qt bindings such as pyside6 to function,
we recommend install pyMOR with the gui extra:
pip install 'pymor[gui]'

The following installs the latest release of pyMOR on your system with most
optional dependencies:
pip install 'pymor[full]'

To obtain an environment with the exact same package versions used in our
Linux continuous integration tests, you can use the
requirements-ci-current.txt,
file from the pyMOR repository
pip install -r requirements-ci-current.txt
pip install pymor

If you are using a stable release, you should download the file from the
corresponding release branch of the repository.
Additional dependencies
There are some optional packages not included with pymor[full]
because they need additional setup on your system:


mpi4py:
support of MPI distributed models and parallelization of greedy
algorithms (requires MPI development headers and a C compiler):
pip install mpi4py
 


Slycot:
dense matrix equation solvers for system-theoretic methods and
H-infinity norm calculation (requires OpenBLAS headers and a
Fortran compiler):
pip install slycot
 
Note that building Slycot might fail for the following reasons:

The Slycot package contains a cmake check which fails when it
detects multiply NumPy include directories. This will cause the
build to fail in venvs with any Python interpreter that has NumPy
globally installed.
To circumvent this problem, use another Python interpreter. If
you do not want to build CPython yourself, you can use
pyenv,
uv or
mise-en-place
to easily install another interpreter.
Slycot’s build environment contains numpy>=2. However,
scikit-builds’s FindF2PY.cmake
will select any globally installed f2py3 executable
to generate the Fortran wrapper code.
On most systems, an older NumPy version is installed, whose
f2py will generate incorrect wrapper code for numpy>=2.
To mitigate this issue, install numpy>=2 into your venv
and link f2py3 to f2py its /bin directory.
Building Slycot on Windows is challenging. We recommend using
conda-forge packages instead. If you do not want to install
the pyMOR conda-forge package, you can also pip install pyMOR
into an existing conda environment.

If you are on Linux and don’t want to build Slycot yourself, you
can try our experimental
manylinux wheels for Slycot.


Installation via conda
pyMOR is packaged in conda-forge and can be installed
by running
conda install -c conda-forge pymor

This will install pyMOR with its core dependencies into the current active conda
environment. To replicate an environment with most optional dependencies, which
is also used in our continuous integration tests, you can use the
conda-linux-64.lock,
conda-osx-64.lock,
conda-win-64.lock
lock files from the pyMOR repository:
conda create -n pymorenv --file ./conda-{linux,osx,win}-64.lock
conda activate pymorenv
conda install pymor

Documentation
Documentation is available online.
We recommend starting with
getting started,
tutorials, and
technical overview.
To build the documentation locally,
run the following from inside the root directory of the pyMOR source tree:
make docs

This will generate HTML documentation in docs/_build/html.
External PDE Solvers
pyMOR has been designed with easy integration of external PDE solvers in mind.
We provide bindings for the following solver libraries:


FEniCS
MPI-compatible wrapper classes for dolfin linear algebra data structures are
  shipped with pyMOR (pymor.bindings.fenics).
  For an example see pymordemos.thermalblock, pymordemos.thermalblock_simple.
  It is tested using FEniCS version 2019.1.0.


deal.II
Python bindings and pyMOR wrapper classes can be found
  here.


NGSolve
Wrapper classes for the NGSolve finite element library are shipped with pyMOR
  (pymor.bindings.ngsolve).
  For an example see pymordemos.thermalblock_simple.
  It is tested using NGSolve version v6.2.2104.


A simple example for direct integration of pyMOR with a a custom solver
can be found in pymordemos.minimal_cpp_demo.
An alternative approach is to import system matrices from file and use
scipy.sparse-based solvers.
Environments for pyMOR Development and Tests
Please see the Developer Documentation.
Contact
Should you have any questions regarding pyMOR or wish to contribute,
do not hesitate to send us an email at
main.developers@pymor.org


pymor is maintained by pymor.
This page was generated by GitHub Pages.




"
34,https://en.wikipedia.org/wiki/Molecular_dynamics,"



Molecular dynamics - Wikipedia



































Jump to content







Main menu





Main menu
move to sidebar
hide



		Navigation
	


Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us





		Contribute
	


HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages



















Search











Search






















Appearance
















Donate

Create account

Log in








Personal tools





Donate Create account Log in





		Pages for logged out editors learn more



ContributionsTalk




























Contents
move to sidebar
hide




(Top)





1
History








2
Areas of application and limits








3
Design constraints




Toggle Design constraints subsection





3.1
Microcanonical ensemble (NVE)








3.2
Canonical ensemble (NVT)








3.3
Isothermal–isobaric (NPT) ensemble








3.4
Generalized ensembles










4
Potentials in MD simulations




Toggle Potentials in MD simulations subsection





4.1
Empirical potentials








4.2
Pair potentials versus many-body potentials








4.3
Semi-empirical potentials








4.4
Polarizable potentials








4.5
Potentials in ab initio methods








4.6
Hybrid QM/MM








4.7
Coarse-graining and reduced representations








4.8
Machine Learning Force Fields










5
Incorporating solvent effects








6
Long-range forces








7
Steered molecular dynamics (SMD)








8
Examples of applications








9
Molecular dynamics algorithms




Toggle Molecular dynamics algorithms subsection





9.1
Integrators








9.2
Short-range interaction algorithms








9.3
Long-range interaction algorithms








9.4
Parallelization strategies








9.5
Ab-initio molecular dynamics










10
Specialized hardware for MD simulations








11
Graphics card as a hardware for MD simulations








12
See also








13
References




Toggle References subsection





13.1
General references










14
External links


















Toggle the table of contents







Molecular dynamics



30 languages




AfrikaansالعربيةCatalàČeštinaDeutschEestiEspañolفارسیFrançais한국어ՀայերենBahasa IndonesiaItalianoעבריתМакедонскиNederlands日本語Norsk bokmålPolskiPortuguêsRomânăРусскийSlovenčinaСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaTürkçeУкраїнська中文

Edit links











ArticleTalk





English

















ReadEditView history







Tools





Tools
move to sidebar
hide



		Actions
	


ReadEditView history





		General
	


What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code





		Print/export
	


Download as PDFPrintable version





		In other projects
	


Wikimedia CommonsWikiquoteWikidata item





















Appearance
move to sidebar
hide










From Wikipedia, the free encyclopedia


Computer simulations to discover and understand chemical properties


Example of a molecular dynamics simulation in a simple system: deposition of one copper (Cu) atom on a cold crystal of copper (Miller index (001) surface). Each circle represents the position of one atom. The kinetic energy of the atom approaching from the top is redistributed among the other atoms, so instead of bouncing off it remains attached due to attractive forces between the atoms.
Molecular dynamics simulations are often used to study biophysical systems. Depicted here is a 100 ps simulation of water.
A simplified description of the standard molecular dynamics simulation algorithm, when a predictor-corrector-type integrator is used. The forces may come either from classical interatomic potentials (described mathematically as 



F
=
−
∇
V
(



r
→



)


{\displaystyle F=-\nabla V({\vec {r}})}

) or quantum mechanical (described mathematically as 



F
=
F
(
Ψ
(



r
→



)
)


{\displaystyle F=F(\Psi ({\vec {r}}))}

) methods. Large differences exist between different integrators; some do not have exactly the same highest-order terms as indicated in the flow chart, many also use higher-order time derivatives, and some use both the current and prior time step in variable-time step schemes.
Molecular dynamics (MD) is a computer simulation method for analyzing the physical movements of atoms and molecules. The atoms and molecules are allowed to interact for a fixed period of time, giving a view of the dynamic ""evolution"" of the system. In the most common version, the trajectories of atoms and molecules are determined by numerically solving Newton's equations of motion for a system of interacting particles, where forces between the particles and their potential energies are often calculated using interatomic potentials or molecular mechanical force fields. The method is applied mostly in chemical physics, materials science, and biophysics.
Because molecular systems typically consist of a vast number of particles, it is impossible to determine the properties of such complex systems analytically; MD simulation circumvents this problem by using numerical methods. However, long MD simulations are mathematically ill-conditioned, generating cumulative errors in numerical integration that can be minimized with proper selection of algorithms and parameters, but not eliminated.
For systems that obey the ergodic hypothesis, the evolution of one molecular dynamics simulation may be used to determine the macroscopic thermodynamic properties of the system: the time averages of an ergodic system correspond to microcanonical ensemble averages. MD has also been termed ""statistical mechanics by numbers"" and ""Laplace's vision of Newtonian mechanics"" of predicting the future by animating nature's forces[1] and allowing insight into molecular motion on an atomic scale.


History[edit]
MD was originally developed in the early 1950s, following earlier successes with Monte Carlo simulations—which themselves date back to the eighteenth century, in the Buffon's needle problem for example—but was popularized for statistical mechanics at Los Alamos National Laboratory by Marshall Rosenbluth and Nicholas Metropolis in what is known today as the Metropolis–Hastings algorithm. Interest in the time evolution of N-body systems dates much earlier to the seventeenth century, beginning with Isaac Newton, and continued into the following century largely with a focus on celestial mechanics and issues such as the stability of the solar system. Many of the numerical methods used today were developed during this time period, which predates the use of computers; for example, the most common integration algorithm used today, the Verlet integration algorithm, was used as early as 1791 by Jean Baptiste Joseph Delambre. Numerical calculations with these algorithms can be considered to be MD done ""by hand"".

As early as 1941, integration of the many-body equations of motion was carried out with analog computers. Some undertook the labor-intensive work of modeling atomic motion by constructing physical models, e.g., using macroscopic spheres. The aim was to arrange them in such a way as to replicate the structure of a liquid and use this to examine its behavior. J.D. Bernal describes this process in 1962, writing:[2]... I took a number of rubber balls and stuck them together with rods of a selection of different lengths ranging from 2.75 to 4 inches. I tried to do this in the first place as casually as possible, working in my own office, being interrupted every five minutes or so and not remembering what I had done before the interruption.Following the discovery of microscopic particles and the development of computers, interest expanded beyond the proving ground of gravitational systems to the statistical properties of matter. In an attempt to understand the origin of irreversibility, Enrico Fermi proposed in 1953, and published in 1955,[3] the use of the early computer MANIAC I, also at Los Alamos National Laboratory, to solve the time evolution of the equations of motion for a many-body system subject to several choices of force laws. Today, this seminal work is known as the Fermi–Pasta–Ulam–Tsingou problem. The time evolution of the energy from the original work is shown in the figure to the right.
One of the earliest simulations of an N-body system was carried out on the MANIAC-I by Fermi and coworkers to understand the origins of irreversibility in nature. Shown here is the energy versus time for a 64-particle system.
In 1957, Berni Alder and Thomas Wainwright used an IBM 704 computer to simulate perfectly elastic collisions between hard spheres.[4] In 1960, in perhaps the first realistic simulation of matter, J.B. Gibson et al. simulated radiation damage of solid copper by using a Born–Mayer type of repulsive interaction along with a cohesive surface force.[5] In 1964, Aneesur Rahman published simulations of liquid argon that used a Lennard-Jones potential; calculations of system properties, such as the coefficient of self-diffusion, compared well with experimental data.[6] Today, the Lennard-Jones potential is still one of the most frequently used intermolecular potentials.[7][8] It is used for describing simple substances (a.k.a. Lennard-Jonesium[9][10][11]) for conceptual and model studies and as a building block in many force fields of real substances.[12][13]

Areas of application and limits[edit]
First used in theoretical physics, the molecular dynamics method gained popularity in materials science soon afterward, and since the 1970s it has also been commonly used in biochemistry and biophysics. MD is frequently used to refine 3-dimensional structures of proteins and other macromolecules based on experimental constraints from X-ray crystallography or NMR spectroscopy. In physics, MD is used to examine the dynamics of atomic-level phenomena that cannot be observed directly, such as thin film growth and ion subplantation, and to examine the physical properties of nanotechnological devices that have not or cannot yet be created. In biophysics and structural biology, the method is frequently applied to study the motions of macromolecules such as proteins and nucleic acids, which can be useful for interpreting the results of certain biophysical experiments and for modeling interactions with other molecules, as in ligand docking. In principle, MD can be used for ab initio prediction of protein structure by simulating folding of the polypeptide chain from a random coil.
The results of MD simulations can be tested through comparison to experiments that measure molecular dynamics, of which a popular method is NMR spectroscopy. MD-derived structure predictions can be tested through community-wide experiments in Critical Assessment of Protein Structure Prediction (CASP), although the method has historically had limited success in this area. Michael Levitt, who shared the Nobel Prize partly for the application of MD to proteins, wrote in 1999 that CASP participants usually did not use the method due to ""... a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure"".[14] Improvements in computational resources permitting more and longer MD trajectories, combined with modern improvements in the quality of force field parameters, have yielded some improvements in both structure prediction and homology model refinement, without reaching the point of practical utility in these areas; many identify force field parameters as a key area for further development.[15][16][17]
MD simulation has been reported for pharmacophore development and drug design.[18] For example, Pinto et al. implemented MD simulations of Bcl-xL complexes to calculate average positions of critical amino acids involved in ligand binding.[19] Carlson et al. implemented molecular dynamics simulations to identify compounds that complement a receptor while causing minimal disruption to the conformation and flexibility of the active site. Snapshots of the protein at constant time intervals during the simulation were overlaid to identify conserved binding regions (conserved in at least three out of eleven frames) for pharmacophore development. Spyrakis et al. relied on a workflow of MD simulations, fingerprints for ligands and proteins (FLAP) and linear discriminant analysis (LDA) to identify the best ligand-protein conformations to act as pharmacophore templates based on retrospective ROC analysis of the resulting pharmacophores. In an attempt to ameliorate structure-based drug discovery modeling, vis-à-vis the need for many modeled compounds, Hatmal et al. proposed a combination of MD simulation and ligand-receptor intermolecular contacts analysis to discern critical intermolecular contacts (binding interactions) from redundant ones in a single ligand–protein complex. Critical contacts can then be converted into pharmacophore models that can be used for virtual screening.[20]
An important factor is intramolecular hydrogen bonds,[21] which are not explicitly included in modern force fields, but described as Coulomb interactions of atomic point charges.[citation needed] This is a crude approximation because hydrogen bonds have a partially quantum mechanical and chemical nature. Furthermore, electrostatic interactions are usually calculated using the dielectric constant of a vacuum, even though the surrounding aqueous solution has a much higher dielectric constant. Thus, using the macroscopic dielectric constant at short interatomic distances is questionable. Finally, van der Waals interactions in MD are usually described by Lennard-Jones potentials[22][23] based on the Fritz London theory that is only applicable in a vacuum.[citation needed] However, all types of van der Waals forces are ultimately of electrostatic origin and therefore depend on dielectric properties of the environment.[24] The direct measurement of attraction forces between different materials (as Hamaker constant) shows that ""the interaction between hydrocarbons across water is about 10% of that across vacuum"".[24] The environment-dependence of van der Waals forces is neglected in standard simulations, but can be included by developing polarizable force fields.

Design constraints[edit]
The design of a molecular dynamics simulation should account for the available computational power. Simulation size (n = number of particles), timestep, and total time duration must be selected so that the calculation can finish within a reasonable time period. However, the simulations should be long enough to be relevant to the time scales of the natural processes being studied. To make statistically valid conclusions from the simulations, the time span simulated should match the kinetics of the natural process. Otherwise, it is analogous to making conclusions about how a human walks when only looking at less than one footstep. Most scientific publications about the dynamics of proteins and DNA[25][26] use data from simulations spanning nanoseconds (10−9 s) to microseconds (10−6 s). To obtain these simulations, several CPU-days to CPU-years are needed. Parallel algorithms allow the load to be distributed among CPUs; an example is the spatial or force decomposition algorithm.[27]
During a classical MD simulation, the most CPU intensive task is the evaluation of the potential as a function of the particles' internal coordinates. Within that energy evaluation, the most expensive one is the non-bonded or non-covalent part. In big O notation, common molecular dynamics simulations scale by 



O
(

n

2


)


{\displaystyle O(n^{2})}

 if all pair-wise electrostatic and van der Waals interactions must be accounted for explicitly. This computational cost can be reduced by employing electrostatics methods such as particle mesh Ewald summation ( 



O
(
n
log
⁡
(
n
)
)


{\displaystyle O(n\log(n))}

 ), particle-particle-particle mesh (P3M), or good spherical cutoff methods ( 



O
(
n
)


{\displaystyle O(n)}

 ). [citation needed]
Another factor that impacts total CPU time needed by a simulation is the size of the integration timestep. This is the time length between evaluations of the potential. The timestep must be chosen small enough to avoid discretization errors (i.e., smaller than the period related to fastest vibrational frequency in the system). Typical timesteps for classical MD are on the order of 1 femtosecond (10−15 s). This value may be extended by using algorithms such as the SHAKE constraint algorithm, which fix the vibrations of the fastest atoms (e.g., hydrogens) into place. Multiple time scale methods have also been developed, which allow extended times between updates of slower long-range forces.[28][29][30]
For simulating molecules in a solvent, a choice should be made between an explicit and implicit solvent. Explicit solvent particles (such as the TIP3P, SPC/E and SPC-f water models) must be calculated expensively by the force field, while implicit solvents use a mean-field approach. Using an explicit solvent is computationally expensive, requiring inclusion of roughly ten times more particles in the simulation. But the granularity and viscosity of explicit solvent is essential to reproduce certain properties of the solute molecules. This is especially important to reproduce chemical kinetics.
In all kinds of molecular dynamics simulations, the simulation box size must be large enough to avoid boundary condition artifacts. Boundary conditions are often treated by choosing fixed values at the edges (which may cause artifacts), or by employing periodic boundary conditions in which one side of the simulation loops back to the opposite side, mimicking a bulk phase (which may cause artifacts too).

Schematic representation of the sampling of the system's potential energy surface with molecular dynamics (in red) compared to Monte Carlo methods (in blue)
Microcanonical ensemble (NVE)[edit]
In the microcanonical ensemble, the system is isolated from changes in moles (N), volume (V), and energy (E). It corresponds to an adiabatic process with no heat exchange. A microcanonical molecular dynamics trajectory may be seen as an exchange of potential and kinetic energy, with total energy being conserved. For a system of N particles with coordinates 



X


{\displaystyle X}

 and velocities 



V


{\displaystyle V}

, the following pair of first order differential equations may be written in Newton's notation as





F
(
X
)
=
−
∇
U
(
X
)
=
M



V
˙



(
t
)


{\displaystyle F(X)=-\nabla U(X)=M{\dot {V}}(t)}






V
(
t
)
=



X
˙



(
t
)
.


{\displaystyle V(t)={\dot {X}}(t).}


The potential energy function 



U
(
X
)


{\displaystyle U(X)}

 of the system is a function of the particle coordinates 



X


{\displaystyle X}

. It is referred to simply as the potential in physics, or the force field in chemistry. The first equation comes from Newton's laws of motion; the force 



F


{\displaystyle F}

 acting on each particle in the system can be calculated as the negative gradient of 



U
(
X
)


{\displaystyle U(X)}

.
For every time step, each particle's position 



X


{\displaystyle X}

 and velocity 



V


{\displaystyle V}

 may be integrated with a symplectic integrator method such as Verlet integration. The time evolution of 



X


{\displaystyle X}

 and 



V


{\displaystyle V}

 is called a trajectory. Given the initial positions (e.g., from theoretical knowledge) and velocities (e.g., randomized Gaussian), we can calculate all future (or past) positions and velocities.
One frequent source of confusion is the meaning of temperature in MD. Commonly we have experience with macroscopic temperatures, which involve a huge number of particles, but temperature is a statistical quantity. If there is a large enough number of atoms, statistical temperature can be estimated from the instantaneous temperature, which is found by equating the kinetic energy of the system to nkBT/2, where n is the number of degrees of freedom of the system.
A temperature-related phenomenon arises due to the small number of atoms that are used in MD simulations. For example, consider simulating the growth of a copper film starting with a substrate containing 500 atoms and a deposition energy of 100 eV. In the real world, the 100 eV from the deposited atom would rapidly be transported through and shared among a large number of atoms (




10

10




{\displaystyle 10^{10}}

 or more) with no big change in temperature. When there are only 500 atoms, however, the substrate is almost immediately vaporized by the deposition. Something similar happens in biophysical simulations. The temperature of the system in NVE is naturally raised when macromolecules such as proteins undergo exothermic conformational changes and binding.

Canonical ensemble (NVT)[edit]
In the canonical ensemble, amount of substance (N), volume (V) and temperature (T) are conserved. It is also sometimes called constant temperature molecular dynamics (CTMD). In NVT, the energy of endothermic and exothermic processes is exchanged with a thermostat.
A variety of thermostat algorithms are available to add and remove energy from the boundaries of an MD simulation in a more or less realistic way, approximating the canonical ensemble. Popular methods to control temperature include velocity rescaling, the Nosé–Hoover thermostat, Nosé–Hoover chains, the Berendsen thermostat, the Andersen thermostat and Langevin dynamics. The Berendsen thermostat might introduce the flying ice cube effect, which leads to unphysical translations and rotations of the simulated system.
It is not trivial to obtain a canonical ensemble distribution of conformations and velocities using these algorithms. How this depends on system size, thermostat choice, thermostat parameters, time step and integrator is the subject of many articles in the field.

Isothermal–isobaric (NPT) ensemble[edit]
In the isothermal–isobaric ensemble, amount of substance (N), pressure (P) and temperature (T) are conserved. In addition to a thermostat, a barostat is needed. It corresponds most closely to laboratory conditions with a flask open to ambient temperature and pressure.
In the simulation of biological membranes, isotropic pressure control is not appropriate. For lipid bilayers, pressure control occurs under constant membrane area (NPAT) or constant surface tension ""gamma"" (NPγT).

Generalized ensembles[edit]
The replica exchange method is a generalized ensemble. It was originally created to deal with the slow dynamics of disordered spin systems. It is also called parallel tempering. The replica exchange MD (REMD) formulation[31] tries to overcome the multiple-minima problem by exchanging the temperature of non-interacting replicas of the system running at several temperatures.

Potentials in MD simulations[edit]
Main articles: Interatomic potential, Force field, and Comparison of force field implementations
A molecular dynamics simulation requires the definition of a potential function, or a description of the terms by which the particles in the simulation will interact. In chemistry and biology this is usually referred to as a force field and in materials physics as an interatomic potential. Potentials may be defined at many levels of physical accuracy; those most commonly used in chemistry are based on molecular mechanics and embody a classical mechanics treatment of particle-particle interactions that can reproduce structural and conformational changes but usually cannot reproduce chemical reactions.
The reduction from a fully quantum description to a classical potential entails two main approximations. The first one is the Born–Oppenheimer approximation, which states that the dynamics of electrons are so fast that they can be considered to react instantaneously to the motion of their nuclei. As a consequence, they may be treated separately. The second one treats the nuclei, which are much heavier than electrons, as point particles that follow classical Newtonian dynamics. In classical molecular dynamics, the effect of the electrons is approximated as one potential energy surface, usually representing the ground state.
When finer levels of detail are needed, potentials based on quantum mechanics are used; some methods attempt to create hybrid classical/quantum potentials where the bulk of the system is treated classically but a small region is treated as a quantum system, usually undergoing a chemical transformation.

Empirical potentials[edit]
Empirical potentials used in chemistry are frequently called force fields, while those used in materials physics are called interatomic potentials.
Most force fields in chemistry are empirical and consist of a summation of bonded forces associated with chemical bonds, bond angles, and bond dihedrals, and non-bonded forces associated with van der Waals forces and electrostatic charge.[32] Empirical potentials represent quantum-mechanical effects in a limited way through ad hoc functional approximations. These potentials contain free parameters such as atomic charge, van der Waals parameters reflecting estimates of atomic radius, and equilibrium bond length, angle, and dihedral; these are obtained by fitting against detailed electronic calculations (quantum chemical simulations) or experimental physical properties such as elastic constants, lattice parameters and spectroscopic measurements.
Because of the non-local nature of non-bonded interactions, they involve at least weak interactions between all particles in the system. Its calculation is normally the bottleneck in the speed of MD simulations. To lower the computational cost, force fields employ numerical approximations such as shifted cutoff radii, reaction field algorithms, particle mesh Ewald summation, or the newer particle–particle-particle–mesh (P3M).
Chemistry force fields commonly employ preset bonding arrangements (an exception being ab initio dynamics), and thus are unable to model the process of chemical bond breaking and reactions explicitly. On the other hand, many of the potentials used in physics, such as those based on the bond order formalism can describe several different coordinations of a system and bond breaking.[33][34] Examples of such potentials include the Brenner potential[35] for hydrocarbons and its
further developments for the C-Si-H[36] and C-O-H[37] systems. The ReaxFF potential[38] can be considered a fully reactive hybrid between bond order potentials and chemistry force fields.

Pair potentials versus many-body potentials[edit]
The potential functions representing the non-bonded energy are formulated as a sum over interactions between the particles of the system. The simplest choice, employed in many popular force fields, is the ""pair potential"", in which the total potential energy can be calculated from the sum of energy contributions between pairs of atoms. Therefore, these force fields are also called ""additive force fields"". An example of such a pair potential is the non-bonded Lennard-Jones potential (also termed the 6–12 potential), used for calculating van der Waals forces.





U
(
r
)
=
4
ε

[



(


σ
r


)


12


−


(


σ
r


)


6



]



{\displaystyle U(r)=4\varepsilon \left[\left({\frac {\sigma }{r}}\right)^{12}-\left({\frac {\sigma }{r}}\right)^{6}\right]}


Another example is the Born (ionic) model of the ionic lattice. The first term in the next equation is Coulomb's law for a pair of ions, the second term is the short-range repulsion explained by Pauli's exclusion principle and the final term is the dispersion interaction term. Usually, a simulation only includes the dipolar term, although sometimes the quadrupolar term is also included.[39][40] When nl = 6, this potential is also called the Coulomb–Buckingham potential.






U

i
j


(

r

i
j


)
=




z

i



z

j




4
π

ϵ

0







1

r

i
j




+

A

l


exp
⁡



−

r

i
j




p

l




+

C

l



r

i
j


−

n

l




+
⋯


{\displaystyle U_{ij}(r_{ij})={\frac {z_{i}z_{j}}{4\pi \epsilon _{0}}}{\frac {1}{r_{ij}}}+A_{l}\exp {\frac {-r_{ij}}{p_{l}}}+C_{l}r_{ij}^{-n_{l}}+\cdots }


In many-body potentials, the potential energy includes the effects of three or more particles interacting with each other.[41] In simulations with pairwise potentials, global interactions in the system also exist, but they occur only through pairwise terms. In many-body potentials, the potential energy cannot be found by a sum over pairs of atoms, as these interactions are calculated explicitly as a combination of higher-order terms. In the statistical view, the dependency between the variables cannot in general be expressed using only pairwise products of the degrees of freedom. For example, the Tersoff potential,[42] which was originally used to simulate carbon, silicon, and germanium, and has since been used for a wide range of other materials, involves a sum over groups of three atoms, with the angles between the atoms being an important factor in the potential. Other examples are the embedded-atom method (EAM),[43] the EDIP,[41] and the Tight-Binding Second Moment Approximation (TBSMA) potentials,[44] where the electron density of states in the region of an atom is calculated from a sum of contributions from surrounding atoms, and the potential energy contribution is then a function of this sum.

Semi-empirical potentials[edit]
Semi-empirical potentials make use of the matrix representation from quantum mechanics. However, the values of the matrix elements are found through empirical formulae that estimate the degree of overlap of specific atomic orbitals. The matrix is then diagonalized to determine the occupancy of the different atomic orbitals, and empirical formulae are used once again to determine the energy contributions of the orbitals.
There are a wide variety of semi-empirical potentials, termed tight-binding potentials, which vary according to the atoms being modeled.

Polarizable potentials[edit]
Main article: Force field
Most classical force fields implicitly include the effect of polarizability, e.g., by scaling up the partial charges obtained from quantum chemical calculations. These partial charges are stationary with respect to the mass of the atom. But molecular dynamics simulations can explicitly model polarizability with the introduction of induced dipoles through different methods, such as Drude particles or fluctuating charges. This allows for a dynamic redistribution of charge between atoms which responds to the local chemical environment.
For many years, polarizable MD simulations have been touted as the next generation. For homogenous liquids such as water, increased accuracy has been achieved through the inclusion of polarizability.[45][46][47] Some promising results have also been achieved for proteins.[48][49] However, it is still uncertain how to best approximate polarizability in a simulation.[citation needed] The point becomes more important when a particle experiences different environments during its simulation trajectory, e.g. translocation of a drug through a cell membrane.[50]

Potentials in ab initio methods[edit]
Main articles: Quantum chemistry and List of quantum chemistry and solid state physics software
In classical molecular dynamics, one potential energy surface (usually the ground state) is represented in the force field. This is a consequence of the Born–Oppenheimer approximation. In excited states, chemical reactions or when a more accurate representation is needed, electronic behavior can be obtained from first principles using a quantum mechanical method, such as density functional theory. This is named Ab Initio Molecular Dynamics (AIMD). Due to the cost of treating the electronic degrees of freedom, the computational burden of these simulations is far higher than classical molecular dynamics. For this reason, AIMD is typically limited to smaller systems and shorter times.
Ab initio quantum mechanical and chemical methods may be used to calculate the potential energy of a system on the fly, as needed for conformations in a trajectory. This calculation is usually made in the close neighborhood of the reaction coordinate. Although various approximations may be used, these are based on theoretical considerations, not on empirical fitting. Ab initio calculations produce a vast amount of information that is not available from empirical methods, such as density of electronic states or other electronic properties. A significant advantage of using ab initio methods is the ability to study reactions that involve breaking or formation of covalent bonds, which correspond to multiple electronic states. Moreover, ab initio methods also allow recovering effects beyond the Born–Oppenheimer approximation using approaches like mixed quantum-classical dynamics.

Hybrid QM/MM[edit]
Main article: QM/MM
QM (quantum-mechanical) methods are very powerful. However, they are computationally expensive, while the MM (classical or molecular mechanics) methods are fast but suffer from several limits (require extensive parameterization; energy estimates obtained are not very accurate; cannot be used to simulate reactions where covalent bonds are broken/formed; and are limited in their abilities for providing accurate details regarding the chemical environment). A new class of method has emerged that combines the good points of QM (accuracy) and MM (speed) calculations. These methods are termed mixed or hybrid quantum-mechanical and molecular mechanics methods (hybrid QM/MM).[51]
The most important advantage of hybrid QM/MM method is the speed. The cost of doing classical molecular dynamics (MM) in the most straightforward case scales O(n2), where n is the number of atoms in the system. This is mainly due to electrostatic interactions term (every particle interacts with every other particle). However, use of cutoff radius, periodic pair-list updates and more recently the variations of the particle-mesh Ewald's (PME) method has reduced this to between O(n) to O(n2). In other words, if a system with twice as many atoms is simulated then it would take between two and four times as much computing power. On the other hand, the simplest ab initio calculations typically scale O(n3) or worse (restricted Hartree–Fock calculations have been suggested to scale ~O(n2.7)). To overcome the limit, a small part of the system is treated quantum-mechanically (typically active-site of an enzyme) and the remaining system is treated classically.
In more sophisticated implementations, QM/MM methods exist to treat both light nuclei susceptible to quantum effects (such as hydrogens) and electronic states. This allows generating hydrogen wave-functions (similar to electronic wave-functions). This methodology has been useful in investigating phenomena such as hydrogen tunneling. One example where QM/MM methods have provided new discoveries is the calculation of hydride transfer in the enzyme liver alcohol dehydrogenase. In this case, quantum tunneling is important for the hydrogen, as it determines the reaction rate.[52]

Coarse-graining and reduced representations[edit]
At the other end of the detail scale are coarse-grained and lattice models. Instead of explicitly representing every atom of the system, one uses ""pseudo-atoms"" to represent groups of atoms. MD simulations on very large systems may require such large computer resources that they cannot easily be studied by traditional all-atom methods. Similarly, simulations of processes on long timescales (beyond about 1 microsecond) are prohibitively expensive, because they require so many time steps. In these cases, one can sometimes tackle the problem by using reduced representations, which are also called coarse-grained models.[53]
Examples for coarse graining (CG) methods are discontinuous molecular dynamics (CG-DMD)[54][55] and Go-models.[56] Coarse-graining is done sometimes taking larger pseudo-atoms. Such united atom approximations have been used in MD simulations of biological membranes. Implementation of such approach on systems where electrical properties are of interest can be challenging owing to the difficulty of using a proper charge distribution on the pseudo-atoms.[57] The aliphatic tails of lipids are represented by a few pseudo-atoms by gathering 2 to 4 methylene groups into each pseudo-atom.
The parameterization of these very coarse-grained models must be done empirically, by matching the behavior of the model to appropriate experimental data or all-atom simulations. Ideally, these parameters should account for both enthalpic and entropic contributions to free energy in an implicit way.[58] When coarse-graining is done at higher levels, the accuracy of the dynamic description may be less reliable. But very coarse-grained models have been used successfully to examine a wide range of questions in structural biology, liquid crystal organization, and polymer glasses.
Examples of applications of coarse-graining:

protein folding and protein structure prediction studies are often carried out using one, or a few, pseudo-atoms per amino acid;[53]
liquid crystal phase transitions have been examined in confined geometries and/or during flow using the Gay-Berne potential, which describes anisotropic species;
Polymer glasses during deformation have been studied using simple harmonic or FENE springs to connect spheres described by the Lennard-Jones potential;
DNA supercoiling has been investigated using 1–3 pseudo-atoms per basepair, and at even lower resolution;
Packaging of double-helical DNA into bacteriophage has been investigated with models where one pseudo-atom represents one turn (about 10 basepairs) of the double helix;
RNA structure in the ribosome and other large systems has been modeled with one pseudo-atom per nucleotide.
The simplest form of coarse-graining is the united atom (sometimes called extended atom) and was used in most early MD simulations of proteins, lipids, and nucleic acids. For example, instead of treating all four atoms of a CH3 methyl group explicitly (or all three atoms of CH2 methylene group), one represents the whole group with one pseudo-atom. It must, of course, be properly parameterized so that its van der Waals interactions with other groups have the proper distance-dependence. Similar considerations apply to the bonds, angles, and torsions in which the pseudo-atom participates. In this kind of united atom representation, one typically eliminates all explicit hydrogen atoms except those that have the capability to participate in hydrogen bonds (polar hydrogens). An example of this is the CHARMM 19 force-field.
The polar hydrogens are usually retained in the model, because proper treatment of hydrogen bonds requires a reasonably accurate description of the directionality and the electrostatic interactions between the donor and acceptor groups. A hydroxyl group, for example, can be both a hydrogen bond donor, and a hydrogen bond acceptor, and it would be impossible to treat this with one OH pseudo-atom. About half the atoms in a protein or nucleic acid are non-polar hydrogens, so the use of united atoms can provide a substantial savings in computer time.

Machine Learning Force Fields[edit]
Machine Learning Force Fields] (MLFFs) represent one approach to modeling interatomic interactions in molecular dynamics simulations.[59] MLFFs can achieve accuracy close to that of ab initio methods. Once trained, MLFFs are much faster than direct quantum mechanical calculations. MLFFs address the limitations of traditional force fields by learning complex potential energy surfaces directly from high-level quantum mechanical data. Several software packages now support MLFFs, including VASP[60] and open-source libraries like DeePMD-kit[61][62] and SchNetPack.[63][64]

Incorporating solvent effects[edit]
In many simulations of a solute-solvent system the main focus is on the behavior of the solute with little interest of the solvent behavior particularly in those solvent molecules residing in regions far from the solute molecule.[65] Solvents may influence the dynamic behavior of solutes via random collisions and by imposing a frictional drag on the motion of the solute through the solvent. The use of non-rectangular periodic boundary conditions, stochastic boundaries and solvent shells can all help reduce the number of solvent molecules required and enable a larger proportion of the computing time to be spent instead on simulating the solute. It is also possible to incorporate the effects of a solvent without needing any explicit solvent molecules present. One example of this approach is to use a potential mean force (PMF) which describes how the free energy changes as a particular coordinate is varied. The free energy change described by PMF contains the averaged effects of the solvent.
Without incorporating the effects of solvent simulations of macromolecules (such as proteins) may yield unrealistic behavior and even small molecules may adopt more compact conformations due to favourable van der Waals forces and electrostatic interactions which would be dampened in the presence of a solvent.[66]

Long-range forces[edit]
A long range interaction is an interaction in which the spatial interaction falls off no faster than 




r

−
d




{\displaystyle r^{-d}}

 where 



d


{\displaystyle d}

 is the dimensionality of the system. Examples include charge-charge interactions between ions and dipole-dipole interactions between molecules. Modelling these forces presents quite a challenge as they are significant over a distance which may be larger than half the box length with simulations of many thousands of particles. Though one solution would be to significantly increase the size of the box length, this brute force approach is less than ideal as the simulation would become computationally very expensive. Spherically truncating the potential is also out of the question as unrealistic behaviour may be observed when the distance is close to the cut off distance.[67]

Steered molecular dynamics (SMD)[edit]
Steered molecular dynamics (SMD) simulations, or force probe simulations, apply forces to a protein in order to manipulate its structure by pulling it along desired degrees of freedom. These experiments can be used to reveal structural changes in a protein at the atomic level. SMD is often used to simulate events such as mechanical unfolding or stretching.[68]
There are two typical protocols of SMD: one in which pulling velocity is held constant, and one in which applied force is constant. Typically, part of the studied system (e.g., an atom in a protein) is restrained by a harmonic potential. Forces are then applied to specific atoms at either a constant velocity or a constant force. Umbrella sampling is used to move the system along the desired reaction coordinate by varying, for example, the forces, distances, and angles manipulated in the simulation. Through umbrella sampling, all of the system's configurations—both high-energy and low-energy—are adequately sampled. Then, each configuration's change in free energy can be calculated as the potential of mean force.[69] A popular method of computing PMF is through the weighted histogram analysis method (WHAM), which analyzes a series of umbrella sampling simulations.[70][71]
A lot of important applications of SMD are in the field of drug discovery and biomolecular sciences. For e.g. SMD was used to investigate the stability of Alzheimer's protofibrils,[72] to study the protein ligand interaction in cyclin-dependent kinase 5[73] and even to show the effect of electric field on thrombin (protein) and aptamer (nucleotide) complex[74] among many other interesting studies.

Examples of applications[edit]
Molecular dynamics simulation of a synthetic molecular motor composed of three molecules in a nanopore (outer diameter 6.7 nm) at 250 K[75]This section relies excessively on references to primary sources. Please improve this section by adding secondary or tertiary sources. Find sources: ""Molecular dynamics"" – news · newspapers · books · scholar · JSTOR (January 2024) (Learn how and when to remove this message)
Molecular dynamics is used in many fields of science.

First MD simulation of a simplified biological folding process was published in 1975. Its simulation published in Nature paved the way for the vast area of modern computational protein-folding.[76]
First MD simulation of a biological process was published in 1976. Its simulation published in Nature paved the way for understanding protein motion as essential in function and not just accessory.[77]
MD is the standard method to treat collision cascades in the heat spike regime, i.e., the effects that energetic neutron and ion irradiation have on solids and solid surfaces.[78]
The following biophysical examples illustrate notable efforts to produce simulations of a systems of very large size (a complete virus) or very long simulation times (up to 1.112 milliseconds):

MD simulation of the full satellite tobacco mosaic virus (STMV) (2006, Size: 1 million atoms, Simulation time: 50 ns, program: NAMD) This virus is a small, icosahedral plant virus that worsens the symptoms of infection by Tobacco Mosaic Virus (TMV). Molecular dynamics simulations were used to probe the mechanisms of viral assembly. The entire STMV particle consists of 60 identical copies of one protein that make up the viral capsid (coating), and a 1063 nucleotide single stranded RNA genome. One key finding is that the capsid is very unstable when there is no RNA inside. The simulation would take one 2006 desktop computer around 35 years to complete. It was thus done in many processors in parallel with continuous communication between them.[79]
Folding simulations of the Villin Headpiece in all-atom detail (2006, Size: 20,000 atoms; Simulation time: 500 μs= 500,000 ns, Program: Folding@home) This simulation was run in 200,000 CPU's of participating personal computers around the world. These computers had the Folding@home program installed, a large-scale distributed computing effort coordinated by Vijay Pande at Stanford University. The kinetic properties of the Villin Headpiece protein were probed by using many independent, short trajectories run by CPU's without continuous real-time communication. One method employed was the Pfold value analysis, which measures the probability of folding before unfolding of a specific starting conformation. Pfold gives information about transition state structures and an ordering of conformations along the folding pathway. Each trajectory in a Pfold calculation can be relatively short, but many independent trajectories are needed.[80]
Long continuous-trajectory simulations have been performed on Anton, a massively parallel supercomputer designed and built around custom application-specific integrated circuits (ASICs) and interconnects by D. E. Shaw Research. The longest published result of a simulation performed using Anton is a 1.112-millisecond simulation of NTL9 at 355 K; a second, independent 1.073-millisecond simulation of this configuration was also performed (and many other simulations of over 250 μs continuous chemical time).[81] In How Fast-Folding Proteins Fold, researchers Kresten Lindorff-Larsen, Stefano Piana, Ron O. Dror, and David E. Shaw discuss ""the results of atomic-level molecular dynamics simulations, over periods ranging between 100 μs and 1 ms, that reveal a set of common principles underlying the folding of 12 structurally diverse proteins."" Examination of these diverse long trajectories, enabled by specialized, custom hardware, allow them to conclude that ""In most cases, folding follows a single dominant route in which elements of the native structure appear in an order highly correlated with their propensity to form in the unfolded state.""[81] In a separate study, Anton was used to conduct a 1.013-millisecond simulation of the native-state dynamics of bovine pancreatic trypsin inhibitor (BPTI) at 300 K.[82]
Another important application of MD method benefits from its ability of 3-dimensional characterization and analysis of microstructural evolution at atomic scale.

MD simulations are used in characterization of grain size evolution, for example, when describing wear and friction of nanocrystalline Al and Al(Zr) materials.[83] Dislocations evolution and grain size evolution are analyzed during the friction process in this simulation. Since MD method provided the full information of the microstructure, the grain size evolution was calculated in 3D using the Polyhedral Template Matching,[84] Grain Segmentation,[85] and Graph clustering[86] methods. In such simulation, MD method provided an accurate measurement of grain size. Making use of these information, the actual grain structures were extracted, measured, and presented. Compared to the traditional method of using SEM with a single 2-dimensional slice of the material, MD provides a 3-dimensional and accurate way to characterize the microstructural evolution at atomic scale.
Molecular dynamics algorithms[edit]
Screened Coulomb potentials implicit solvent model
Integrators[edit]
Symplectic integrator
Verlet–Stoermer integration
Runge–Kutta integration
Beeman's algorithm
Constraint algorithms (for constrained systems)
Short-range interaction algorithms[edit]
Cell lists
Verlet list
Bonded interactions
Long-range interaction algorithms[edit]
Ewald summation
Particle mesh Ewald summation (PME)
Particle–particle-particle–mesh (P3M)
Shifted force method
Parallelization strategies[edit]
Domain decomposition method (Distribution of system data for parallel computing)
Ab-initio molecular dynamics[edit]
Car–Parrinello molecular dynamics
Specialized hardware for MD simulations[edit]
Anton – A specialized, massively parallel supercomputer designed to execute MD simulations
MDGRAPE – A special purpose system built for molecular dynamics simulations, especially protein structure prediction
Graphics card as a hardware for MD simulations[edit]
This section is an excerpt from Molecular modeling on GPUs.[edit]
Ionic liquid simulation on GPU (Abalone)
Molecular modeling on GPU is the technique of using a graphics processing unit (GPU) for molecular simulations.[87]

In 2007, Nvidia introduced video cards that could be used not only to show graphics but also for scientific calculations. These cards include many arithmetic units (as of 2016[update], up to 3,584 in Tesla P100) working in parallel. Long before this event, the computational power of video cards was purely used to accelerate graphics calculations. The new features of these cards made it possible to develop parallel programs in a high-level application programming interface (API) named CUDA. This technology  substantially simplified programming by enabling programs to be written in C/C++. More recently, OpenCL allows cross-platform GPU acceleration.
See also[edit]

Molecular modeling
Computational chemistry
Force field (chemistry)
Comparison of force field implementations
Monte Carlo method
Molecular design software
Molecular mechanics
Multiscale Green's function
Car–Parrinello method
Comparison of software for molecular mechanics modeling
Quantum chemistry
Discrete element method
Comparison of nucleic acid simulation software
Molecule editor
Mixed quantum-classical dynamics

References[edit]


^ Schlick T (1996). ""Pursuing Laplace's Vision on Modern Computers"". Mathematical Approaches to Biomolecular Structure and Dynamics. The IMA Volumes in Mathematics and its Applications. Vol. 82. pp. 219–247. doi:10.1007/978-1-4612-4066-2_13. ISBN 978-0-387-94838-6.

^ Bernal JD (January 1997). ""The Bakerian Lecture, 1962 The structure of liquids"". Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences. 280 (1382): 299–322. Bibcode:1964RSPSA.280..299B. doi:10.1098/rspa.1964.0147. S2CID 178710030.

^ Fermi E., Pasta J., Ulam S., Los Alamos report LA-1940 (1955).

^ Alder BJ, Wainwright T (August 1959). ""Studies in Molecular Dynamics. I. General Method"". The Journal of Chemical Physics. 31 (2): 459–466. Bibcode:1959JChPh..31..459A. doi:10.1063/1.1730376.

^ Gibson JB, Goland AN, Milgram M, Vineyard G (1960). ""Dynamics of Radiation Damage"". Phys. Rev. 120 (4): 1229–1253. Bibcode:1960PhRv..120.1229G. doi:10.1103/PhysRev.120.1229.

^ Rahman A (19 October 1964). ""Correlations in the Motion of Atoms in Liquid Argon"". Physical Review. 136 (2A): A405 – A411. Bibcode:1964PhRv..136..405R. doi:10.1103/PhysRev.136.A405.

^ Stephan S, Thol M, Vrabec J, Hasse H (October 2019). ""Thermophysical Properties of the Lennard-Jones Fluid: Database and Data Assessment"". Journal of Chemical Information and Modeling. 59 (10): 4248–4265. doi:10.1021/acs.jcim.9b00620. PMID 31609113. S2CID 204545481.

^ Wang X, Ramírez-Hinestrosa S, Dobnikar J, Frenkel D (May 2020). ""The Lennard-Jones potential: when (not) to use it"". Physical Chemistry Chemical Physics. 22 (19): 10624–10633. arXiv:1910.05746. Bibcode:2020PCCP...2210624W. doi:10.1039/C9CP05445F. PMID 31681941. S2CID 204512243.

^ Mick J, Hailat E, Russo V, Rushaidat K, Schwiebert L, Potoff J (December 2013). ""GPU-accelerated Gibbs ensemble Monte Carlo simulations of Lennard-Jonesium"". Computer Physics Communications. 184 (12): 2662–2669. Bibcode:2013CoPhC.184.2662M. doi:10.1016/j.cpc.2013.06.020.

^ Chapela GA, Scriven LE, Davis HT (October 1989). ""Molecular dynamics for discontinuous potential. IV. Lennard-Jonesium"". The Journal of Chemical Physics. 91 (7): 4307–4313. Bibcode:1989JChPh..91.4307C. doi:10.1063/1.456811. ISSN 0021-9606.

^ Lenhard J, Stephan S, Hasse H (February 2024). ""A child of prediction. On the History, Ontology, and Computation of the Lennard-Jonesium"". Studies in History and Philosophy of Science. 103: 105–113. doi:10.1016/j.shpsa.2023.11.007. PMID 38128443. S2CID 266440296.

^ Eggimann BL, Sunnarborg AJ, Stern HD, Bliss AP, Siepmann JI (2013-12-24). ""An online parameter and property database for the TraPPE force field"". Molecular Simulation. 40 (1–3): 101–105. doi:10.1080/08927022.2013.842994. ISSN 0892-7022. S2CID 95716947.

^ Stephan S, Horsch MT, Vrabec J, Hasse H (2019-07-03). ""MolMod – an open access database of force fields for molecular simulations of fluids"". Molecular Simulation. 45 (10): 806–814. arXiv:1904.05206. doi:10.1080/08927022.2019.1601191. ISSN 0892-7022. S2CID 119199372.

^ Koehl P, Levitt M (February 1999). ""A brighter future for protein structure prediction"". Nature Structural Biology. 6 (2): 108–111. doi:10.1038/5794. PMID 10048917. S2CID 3162636.

^ Raval A, Piana S, Eastwood MP, Dror RO, Shaw DE (August 2012). ""Refinement of protein structure homology models via long, all-atom molecular dynamics simulations"". Proteins. 80 (8): 2071–2079. doi:10.1002/prot.24098. PMID 22513870. S2CID 10613106.

^ Beauchamp KA, Lin YS, Das R, Pande VS (April 2012). ""Are Protein Force Fields Getting Better? A Systematic Benchmark on 524 Diverse NMR Measurements"". Journal of Chemical Theory and Computation. 8 (4): 1409–1414. doi:10.1021/ct2007814. PMC 3383641. PMID 22754404.

^ Piana S, Klepeis JL, Shaw DE (February 2014). ""Assessing the accuracy of physical models used in protein-folding simulations: quantitative evidence from long molecular dynamics simulations"". Current Opinion in Structural Biology. 24: 98–105. doi:10.1016/j.sbi.2013.12.006. PMID 24463371.

^ Choudhury C, Priyakumar UD, Sastry GN (April 2015). ""Dynamics based pharmacophore models for screening potential inhibitors of mycobacterial cyclopropane synthase"". Journal of Chemical Information and Modeling. 55 (4): 848–60. doi:10.1021/ci500737b. PMID 25751016.

^ Pinto M, Perez JJ, Rubio-Martinez J (January 2004). ""Molecular dynamics study of peptide segments of the BH3 domain of the proapoptotic proteins Bak, Bax, Bid and Hrk bound to the Bcl-xL and Bcl-2 proteins"". Journal of Computer-aided Molecular Design. 18 (1): 13–22. Bibcode:2004JCAMD..18...13P. doi:10.1023/b:jcam.0000022559.72848.1c. PMID 15143800. S2CID 11339000.

^ Hatmal MM, Jaber S, Taha MO (December 2016). ""Combining molecular dynamics simulation and ligand-receptor contacts analysis as a new approach for pharmacophore modeling: beta-secretase 1 and check point kinase 1 as case studies"". Journal of Computer-aided Molecular Design. 30 (12): 1149–1163. Bibcode:2016JCAMD..30.1149H. doi:10.1007/s10822-016-9984-2. PMID 27722817. S2CID 11561853.

^ Myers JK, Pace CN (October 1996). ""Hydrogen bonding stabilizes globular proteins"". Biophysical Journal. 71 (4): 2033–2039. Bibcode:1996BpJ....71.2033M. doi:10.1016/s0006-3495(96)79401-8. PMC 1233669. PMID 8889177.

^ Lenhard J, Stephan S, Hasse H (June 2024). ""On the History of the Lennard-Jones Potential"". Annalen der Physik. 536 (6). doi:10.1002/andp.202400115. ISSN 0003-3804.

^ Fischer J, Wendland M (October 2023). ""On the history of key empirical intermolecular potentials"". Fluid Phase Equilibria. 573: 113876. Bibcode:2023FlPEq.57313876F. doi:10.1016/j.fluid.2023.113876.

^ a b Israelachvili J (1992). Intermolecular and surface forces. San Diego: Academic Press.

^ Cruz FJ, de Pablo JJ, Mota JP (June 2014). ""Endohedral confinement of a DNA dodecamer onto pristine carbon nanotubes and the stability of the canonical B form"". The Journal of Chemical Physics. 140 (22): 225103. arXiv:1605.01317. Bibcode:2014JChPh.140v5103C. doi:10.1063/1.4881422. PMID 24929415. S2CID 15149133.

^ Cruz FJ, Mota JP (2016). ""Conformational Thermodynamics of DNA Strands in Hydrophilic Nanopores"". J. Phys. Chem. C. 120 (36): 20357–20367. doi:10.1021/acs.jpcc.6b06234.

^ Plimpton S. ""Molecular Dynamics - Parallel Algorithms"". sandia.gov.

^ Streett WB, Tildesley DJ, Saville G (1978). ""Multiple time-step methods in molecular dynamics"". Mol Phys. 35 (3): 639–648. Bibcode:1978MolPh..35..639S. doi:10.1080/00268977800100471.

^ Tuckerman ME, Berne BJ, Martyna GJ (1991). ""Molecular dynamics algorithm for multiple time scales: systems with long range forces"". J Chem Phys. 94 (10): 6811–6815. Bibcode:1991JChPh..94.6811T. doi:10.1063/1.460259.

^ Tuckerman ME, Berne BJ, Martyna GJ (1992). ""Reversible multiple time scale molecular dynamics"". J Chem Phys. 97 (3): 1990–2001. Bibcode:1992JChPh..97.1990T. doi:10.1063/1.463137. S2CID 488073.

^ Sugita Y, Okamoto Y (November 1999). ""Replica-exchange molecular dynamics method for protein folding"". Chemical Physics Letters. 314 (1–2): 141–151. Bibcode:1999CPL...314..141S. doi:10.1016/S0009-2614(99)01123-9.

^ Rizzuti B (2022). ""Molecular simulations of proteins: From simplified physical interactions to complex biological phenomena"". Biochimica et Biophysica Acta (BBA) - Proteins and Proteomics. 1870 (3): 140757. doi:10.1016/j.bbapap.2022.140757. PMID 35051666. S2CID 263455009.

^ Sinnott SB, Brenner DW (2012). ""Three decades of many-body potentials in materials research"". MRS Bulletin. 37 (5): 469–473. Bibcode:2012MRSBu..37..469S. doi:10.1557/mrs.2012.88.

^ Albe K, Nordlund K, Averback RS (2002). ""Modeling metal-semiconductor interaction: Analytical bond-order potential for platinum-carbon"". Phys. Rev. B. 65 (19): 195124. Bibcode:2002PhRvB..65s5124A. doi:10.1103/physrevb.65.195124.

^ Brenner DW (November 1990). ""Empirical potential for hydrocarbons for use in simulating the chemical vapor deposition of diamond films"" (PDF). Physical Review B. 42 (15): 9458–9471. Bibcode:1990PhRvB..42.9458B. doi:10.1103/physrevb.42.9458. PMID 9995183. Archived from the original on September 22, 2017.

^ Beardmore K, Smith R (1996). ""Empirical potentials for C-Si-H systems with application to C60 interactions with Si crystal surfaces"". Philosophical Magazine A. 74 (6): 1439–1466. Bibcode:1996PMagA..74.1439B. doi:10.1080/01418619608240734.

^ Ni B, Lee KH, Sinnott SB (2004). ""A reactive empirical bond order (rebo) potential for hydrocarbon oxygen interactions"". Journal of Physics: Condensed Matter. 16 (41): 7261–7275. Bibcode:2004JPCM...16.7261N. doi:10.1088/0953-8984/16/41/008. S2CID 250760409.

^ Van Duin AC, Dasgupta S, Lorant F, Goddard WA (October 2001). ""ReaxFF: A Reactive Force Field for Hydrocarbons"". The Journal of Physical Chemistry A. 105 (41): 9396–9409. Bibcode:2001JPCA..105.9396V. CiteSeerX 10.1.1.507.6992. doi:10.1021/jp004368u.

^ Cruz FJ, Lopes JN, Calado JC, Minas da Piedade ME (December 2005). ""A molecular dynamics study of the thermodynamic properties of calcium apatites. 1. Hexagonal phases"". The Journal of Physical Chemistry B. 109 (51): 24473–24479. doi:10.1021/jp054304p. PMID 16375450.

^ Cruz FJ, Lopes JN, Calado JC (March 2006). ""Molecular dynamics simulations of molten calcium hydroxyapatite"". Fluid Phase Equilibria. 241 (1–2): 51–58. Bibcode:2006FlPEq.241...51C. doi:10.1016/j.fluid.2005.12.021.

^ a b Justo JF, Bazant MZ, Kaxiras E, Bulatov VV, Yip S (1998). ""Interatomic potential for silicon defects and disordered phases"". Phys. Rev. B. 58 (5): 2539–2550. arXiv:cond-mat/9712058. Bibcode:1998PhRvB..58.2539J. doi:10.1103/PhysRevB.58.2539. S2CID 14585375.

^ Tersoff J (March 1989). ""Modeling solid-state chemistry: Interatomic potentials for multicomponent systems"". Physical Review B. 39 (8): 5566–5568. Bibcode:1989PhRvB..39.5566T. doi:10.1103/physrevb.39.5566. PMID 9948964.

^ Daw MS, Foiles SM, Baskes MI (March 1993). ""The embedded-atom method: a review of theory and applications"". Materials Science Reports. 9 (7–8): 251–310. doi:10.1016/0920-2307(93)90001-U.

^ Cleri F, Rosato V (July 1993). ""Tight-binding potentials for transition metals and alloys"". Physical Review B. 48 (1): 22–33. Bibcode:1993PhRvB..48...22C. doi:10.1103/physrevb.48.22. PMID 10006745.

^ Lamoureux G, Harder E, Vorobyov IV, Roux B, MacKerell AD (2006). ""A polarizable model of water for molecular dynamics simulations of biomolecules"". Chem Phys Lett. 418 (1): 245–249. Bibcode:2006CPL...418..245L. doi:10.1016/j.cplett.2005.10.135.

^ Sokhan VP, Jones AP, Cipcigan FS, Crain J, Martyna GJ (May 2015). ""Signature properties of water: Their molecular electronic origins"". Proceedings of the National Academy of Sciences of the United States of America. 112 (20): 6341–6346. Bibcode:2015PNAS..112.6341S. doi:10.1073/pnas.1418982112. PMC 4443379. PMID 25941394.

^ Cipcigan FS, Sokhan VP, Jones AP, Crain J, Martyna GJ (April 2015). ""Hydrogen bonding and molecular orientation at the liquid-vapour interface of water"". Physical Chemistry Chemical Physics. 17 (14): 8660–8669. Bibcode:2015PCCP...17.8660C. doi:10.1039/C4CP05506C. hdl:20.500.11820/0bd0cd1a-94f1-4053-809c-9fb68bbec1c9. PMID 25715668.

^ Mahmoudi M, Lynch I, Ejtehadi MR, Monopoli MP, Bombelli FB, Laurent S (September 2011). ""Protein-nanoparticle interactions: opportunities and challenges"". Chemical Reviews. 111 (9): 5610–5637. doi:10.1021/cr100440g. PMID 21688848.

^ Patel S, Mackerell AD, Brooks CL (September 2004). ""CHARMM fluctuating charge force field for proteins: II protein/solvent properties from molecular dynamics simulations using a nonadditive electrostatic model"". Journal of Computational Chemistry. 25 (12): 1504–1514. doi:10.1002/jcc.20077. PMID 15224394. S2CID 16741310.

^ Najla Hosseini A, Lund M, Ejtehadi MR (May 2022). ""Electronic polarization effects on membrane translocation of anti-cancer drugs"". Physical Chemistry Chemical Physics. 24 (20): 12281–12292. Bibcode:2022PCCP...2412281N. doi:10.1039/D2CP00056C. PMID 35543365. S2CID 248696332.

^ The methodology for such methods was introduced by Warshel and coworkers. In the recent years have been pioneered by several groups including: Arieh Warshel (University of Southern California), Weitao Yang (Duke University), Sharon Hammes-Schiffer (The Pennsylvania State University), Donald Truhlar and Jiali Gao (University of Minnesota) and Kenneth Merz (University of Florida).

^ Billeter SR, Webb SP, Agarwal PK, Iordanov T, Hammes-Schiffer S (November 2001). ""Hydride transfer in liver alcohol dehydrogenase: quantum dynamics, kinetic isotope effects, and role of enzyme motion"". Journal of the American Chemical Society. 123 (45): 11262–11272. doi:10.1021/ja011384b. PMID 11697969.

^ a b Kmiecik S, Gront D, Kolinski M, Wieteska L, Dawid AE, Kolinski A (July 2016). ""Coarse-Grained Protein Models and Their Applications"". Chemical Reviews. 116 (14): 7898–7936. doi:10.1021/acs.chemrev.6b00163. PMID 27333362.

^ Voegler Smith A, Hall CK (August 2001). ""alpha-helix formation: discontinuous molecular dynamics on an intermediate-resolution protein model"". Proteins. 44 (3): 344–360. doi:10.1002/prot.1100. PMID 11455608. S2CID 21774752.

^ Ding F, Borreguero JM, Buldyrey SV, Stanley HE, Dokholyan NV (November 2003). ""Mechanism for the alpha-helix to beta-hairpin transition"". Proteins. 53 (2): 220–228. doi:10.1002/prot.10468. PMID 14517973. S2CID 17254380.

^ Paci E, Vendruscolo M, Karplus M (December 2002). ""Validity of Gō models: comparison with a solvent-shielded empirical energy decomposition"". Biophysical Journal. 83 (6): 3032–3038. Bibcode:2002BpJ....83.3032P. doi:10.1016/S0006-3495(02)75308-3. PMC 1302383. PMID 12496075.

^ Chakrabarty A, Cagin T (May 2010). ""Coarse grain modeling of polyimide copolymers"". Polymer. 51 (12): 2786–2794. doi:10.1016/j.polymer.2010.03.060.

^ Foley TT, Shell MS, Noid WG (December 2015). ""The impact of resolution upon entropy and information in coarse-grained models"". The Journal of Chemical Physics. 143 (24): 243104. Bibcode:2015JChPh.143x3104F. doi:10.1063/1.4929836. PMID 26723589.

^ Unke OT, Chmiela S, Sauceda HE, Gastegger M, Poltavsky I, Schütt KT, et al. (August 2021). ""Machine Learning Force Fields"". Chemical Reviews. 121 (16): 10142–10186. doi:10.1021/acs.chemrev.0c01111. PMC 8391964. PMID 33705118.

^ Hafner J (October 2008). ""Ab-initio simulations of materials using VASP: Density-functional theory and beyond"". Journal of Computational Chemistry. 29 (13): 2044–78. doi:10.1002/jcc.21057. PMID 18623101.

^ Wang H, Zhang L, Han J, Weinan E (July 2018). ""DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics"". Computer Physics Communications. 228: 178–184. arXiv:1712.03641. doi:10.1016/j.cpc.2018.03.016.

^ Zeng J, Zhang D, Lu D, Mo P, Li Z, Chen Y, et al. (August 2023). ""DeePMD-kit v2: A software package for deep potential models"". The Journal of Chemical Physics. 159 (5). doi:10.1063/5.0155600. PMC 10445636. PMID 37526163.

^ Schütt KT, Kessel P, Gastegger M, Nicoli KA, Tkatchenko A, Müller KR (January 2019). ""SchNetPack: A Deep Learning Toolbox For Atomistic Systems"". Journal of Chemical Theory and Computation. 15 (1): 448–455. arXiv:1809.01072. doi:10.1021/acs.jctc.8b00908. PMID 30481453.

^ Schütt KT, Hessmann SS, Gebauer NW, Lederer J, Gastegger M (April 2023). ""SchNetPack 2.0: A neural network toolbox for atomistic machine learning"". The Journal of Chemical Physics. 158 (14): 144801. arXiv:2212.05517. doi:10.1063/5.0138367.

^ Leach A (30 January 2001). Molecular Modelling: Principles and Applications (2nd ed.). Harlow: Prentice Hall. ISBN 9780582382107. ASIN 0582382106.

^ Leach AR (2001). Molecular modelling : principles and applications (2nd ed.). Harlow, England: Prentice Hall. p. 320. ISBN 0-582-38210-6. OCLC 45008511.

^ Allen MP, Tildesley DJ (2017-08-22). Computer Simulation of Liquids (2nd ed.). Oxford University Press. p. 216. ISBN 9780198803201. ASIN 0198803206.

^ Nienhaus GU (2005). Protein-ligand interactions: methods and applications. Humana Press. pp. 54–56. ISBN 978-1-61737-525-5.

^ Leszczyński J (2005). Computational chemistry: reviews of current trends, Volume 9. World Scientific. pp. 54–56. ISBN 978-981-256-742-0.

^ Kumar S, Rosenberg JM, Bouzida D, Swendsen RH, Kollman PA (October 1992). ""The weighted histogram analysis method for free-energy calculations on biomolecules. I. The method"". Journal of Computational Chemistry. 13 (8): 1011–1021. doi:10.1002/jcc.540130812. S2CID 8571486.

^ Bartels C (December 2000). ""Analyzing biased Monte Carlo and molecular dynamics simulations"". Chemical Physics Letters. 331 (5–6): 446–454. Bibcode:2000CPL...331..446B. doi:10.1016/S0009-2614(00)01215-X.

^ Lemkul JA, Bevan DR (February 2010). ""Assessing the stability of Alzheimer's amyloid protofibrils using molecular dynamics"". The Journal of Physical Chemistry B. 114 (4): 1652–1660. doi:10.1021/jp9110794. PMID 20055378.

^ Patel JS, Berteotti A, Ronsisvalle S, Rocchia W, Cavalli A (February 2014). ""Steered molecular dynamics simulations for studying protein-ligand interaction in cyclin-dependent kinase 5"". Journal of Chemical Information and Modeling. 54 (2): 470–480. doi:10.1021/ci4003574. PMID 24437446.

^ Gosai A, Ma X, Balasubramanian G, Shrotriya P (November 2016). ""Electrical Stimulus Controlled Binding/Unbinding of Human Thrombin-Aptamer Complex"". Scientific Reports. 6 (1): 37449. Bibcode:2016NatSR...637449G. doi:10.1038/srep37449. PMC 5118750. PMID 27874042.

^ Palma CA, Björk J, Rao F, Kühne D, Klappenberger F, Barth JV (August 2014). ""Topological dynamics in supramolecular rotors"". Nano Letters. 14 (8): 4461–4468. Bibcode:2014NanoL..14.4461P. doi:10.1021/nl5014162. PMID 25078022.

^ Levitt M, Warshel A (February 1975). ""Computer simulation of protein folding"". Nature. 253 (5494): 694–698. Bibcode:1975Natur.253..694L. doi:10.1038/253694a0. PMID 1167625. S2CID 4211714.

^ Warshel A (April 1976). ""Bicycle-pedal model for the first step in the vision process"". Nature. 260 (5553): 679–683. Bibcode:1976Natur.260..679W. doi:10.1038/260679a0. PMID 1264239. S2CID 4161081.

^ Smith, R., ed. (1997). Atomic & ion collisions in solids and at surfaces: theory, simulation and applications. Cambridge, UK: Cambridge University Press.[page needed]

^ Freddolino P, Arkhipov A, Larson SB, McPherson A, Schulten K. ""Molecular dynamics simulation of the Satellite Tobacco Mosaic Virus (STMV)"". Theoretical and Computational Biophysics Group. University of Illinois at Urbana Champaign.

^ Jayachandran G, Vishal V, Pande VS (April 2006). ""Using massively parallel simulation and Markovian models to study protein folding: examining the dynamics of the villin headpiece"". The Journal of Chemical Physics. 124 (16): 164902. Bibcode:2006JChPh.124p4902J. doi:10.1063/1.2186317. PMID 16674165.

^ a b Lindorff-Larsen K, Piana S, Dror RO, Shaw DE (October 2011). ""How fast-folding proteins fold"". Science. 334 (6055): 517–520. Bibcode:2011Sci...334..517L. CiteSeerX 10.1.1.1013.9290. doi:10.1126/science.1208351. PMID 22034434. S2CID 27988268.

^ Shaw DE, Maragakis P, Lindorff-Larsen K, Piana S, Dror RO, Eastwood MP, et al. (October 2010). ""Atomic-level characterization of the structural dynamics of proteins"". Science. 330 (6002): 341–346. Bibcode:2010Sci...330..341S. doi:10.1126/science.1187409. PMID 20947758. S2CID 3495023.

^ Shi Y, Szlufarska I (November 2020). ""Wear-induced microstructural evolution of nanocrystalline aluminum and the role of zirconium dopants"". Acta Materialia. 200: 432–441. Bibcode:2020AcMat.200..432S. doi:10.1016/j.actamat.2020.09.005. S2CID 224954349.

^ Larsen PM, Schmidt S, Schiøtz J (1 June 2016). ""Robust structural identification via polyhedral template matching"". Modelling and Simulation in Materials Science and Engineering. 24 (5): 055007. arXiv:1603.05143. Bibcode:2016MSMSE..24e5007M. doi:10.1088/0965-0393/24/5/055007. S2CID 53980652.

^ Hoffrogge PW, Barrales-Mora LA (February 2017). ""Grain-resolved kinetics and rotation during grain growth of nanocrystalline Aluminium by molecular dynamics"". Computational Materials Science. 128: 207–222. arXiv:1608.07615. doi:10.1016/j.commatsci.2016.11.027. S2CID 118371554.

^ Bonald T, Charpentier B, Galland A, Hollocou A (22 June 2018). ""Hierarchical Graph Clustering using Node Pair Sampling"". arXiv:1806.01664 [cs.SI].

^ Stone JE, Phillips JC, Freddolino PL, Hardy DJ, Trabuco LG, Schulten K (December 2007). ""Accelerating molecular modeling applications with graphics processors"". Journal of Computational Chemistry. 28 (16): 2618–2640. CiteSeerX 10.1.1.466.3823. doi:10.1002/jcc.20829. PMID 17894371. S2CID 15313533.


General references[edit]

Allen MP, Tildesley DJ (1989). Computer simulation of liquids. Oxford University Press. ISBN 0-19-855645-4.
McCammon JA, Harvey SC (1987). Dynamics of Proteins and Nucleic Acids. Cambridge University Press. ISBN 0-521-30750-3.
Rapaport DC (1996). The Art of Molecular Dynamics Simulation. ISBN 0-521-44561-2.
Griebel M, Knapek S, Zumbusch G (2007). Numerical Simulation in Molecular Dynamics. Berlin, Heidelberg: Springer. ISBN 978-3-540-68094-9.
Frenkel D, Smit B (2002) [2001]. Understanding Molecular Simulation : from algorithms to applications. San Diego: Academic Press. ISBN 978-0-12-267351-1.
Haile JM (2001). Molecular Dynamics Simulation: Elementary Methods. Wiley. ISBN 0-471-18439-X.
Sadus RJ (2002). Molecular Simulation of Fluids: Theory, Algorithms and Object-Orientation. Elsevier. ISBN 0-444-51082-6.
Becker OM, Mackerell Jr AD, Roux B, Watanabe M (2001). Computational Biochemistry and Biophysics. Marcel Dekker. ISBN 0-8247-0455-X.
Leach A (2001). Molecular Modelling: Principles and Applications (2nd ed.). Prentice Hall. ISBN 978-0-582-38210-7.
Schlick T (2002). Molecular Modeling and Simulation. Springer. ISBN 0-387-95404-X.
Hoover WB (1991). Computational Statistical Mechanics. Elsevier. ISBN 0-444-88192-1.
Evans DJ, Morriss G (2008). Statistical Mechanics of Nonequilibrium Liquids (Second ed.). Cambridge University Press. ISBN 978-0-521-85791-8.

External links[edit]



Wikimedia Commons has media related to Molecular dynamics simulation.

The GPUGRID.net Project (GPUGRID.net)
The Blue Gene Project (IBM) JawBreakers.org
Materials modelling and computer simulation codes
A few tips on molecular dynamics
Movie of MD simulation of water (YouTube)
vteBranches of chemistry
Glossary of chemical formulae
List of biomolecules
List of inorganic compounds
Periodic table
Analytical
Instrumental chemistry
Electroanalytical methods
Spectroscopy
IR
Raman
UV-Vis
NMR
Mass spectrometry
EI
ICP
MALDI
Separation process
Chromatography
GC
HPLC
Crystallography
Characterization
Titration
Wet chemistry
Calorimetry
Elemental analysis
Theoretical
Quantum chemistry
Computational chemistry
Mathematical chemistry
Molecular modelling
Molecular mechanics
Molecular dynamics
Molecular geometry
VSEPR theory
Physical
Electrochemistry
Spectroelectrochemistry
Photoelectrochemistry
Thermochemistry
Chemical thermodynamics
Surface science
Interface and colloid science
Micromeritics
Cryochemistry
Sonochemistry
Structural chemistry
Chemical physics
Molecular physics
Femtochemistry
Chemical kinetics
Spectroscopy
Photochemistry
Spin chemistry
Microwave chemistry
Equilibrium chemistry
Mechanochemistry
Inorganic
Coordination chemistry
Magnetochemistry
Organometallic chemistry
Organolanthanide chemistry
Cluster chemistry
Solid-state chemistry
Ceramic chemistry
Organic
Stereochemistry
Alkane stereochemistry
Physical organic chemistry
Organic reactions
Organic synthesis
Retrosynthetic analysis
Enantioselective synthesis
Total synthesis / Semisynthesis
Fullerene chemistry
Polymer chemistry
Petrochemistry
Dynamic covalent chemistry
Biological
Biochemistry
Molecular biology
Cell biology
Chemical biology
Bioorthogonal chemistry
Medicinal chemistry
Pharmacology
Clinical chemistry
Neurochemistry
Bioorganic chemistry
Bioorganometallic chemistry
Bioinorganic chemistry
Biophysical chemistry
Interdisciplinarity
Nuclear chemistry
Radiochemistry
Radiation chemistry
Actinide chemistry
Cosmochemistry / Astrochemistry / Stellar chemistry
Geochemistry
Biogeochemistry
Photogeochemistry
Environmental chemistry
Atmospheric chemistry
Ocean chemistry
Clay chemistry
Carbochemistry
Food chemistry
Carbohydrate chemistry
Food physical chemistry
Agricultural chemistry
Soil chemistry
Chemistry education
Amateur chemistry
General chemistry
Clandestine chemistry
Forensic chemistry
Forensic toxicology
Post-mortem chemistry
Nanochemistry
Supramolecular chemistry
Chemical synthesis
Green chemistry
Click chemistry
Combinatorial chemistry
Biosynthesis
Chemical engineering
Stoichiometry
Materials science
Metallurgy
Ceramic engineering
Polymer science
See also
History of chemistry
Nobel Prize in Chemistry
Timeline of chemistry
of element discoveries
""The central science""
Chemical reaction
Catalysis
Chemical element
Chemical compound
Atom
Molecule
Ion
Chemical substance
Chemical bond
Alchemy
Quantum mechanics

 Category
 Commons
 Portal
 WikiProject





Retrieved from ""https://en.wikipedia.org/w/index.php?title=Molecular_dynamics&oldid=1256721057""
Categories: Molecular dynamicsComputational chemistryMolecular modellingSimulationHidden categories: Wikipedia articles needing page number citations from April 2020Articles with short descriptionShort description is different from WikidataUse American English from February 2019All Wikipedia articles written in American EnglishAll articles with unsourced statementsArticles with unsourced statements from February 2024Articles with unsourced statements from December 2017Articles with unsourced statements from April 2009Articles lacking reliable references from January 2024All articles lacking reliable referencesArticles with excerptsCommons category link is on Wikidata






 This page was last edited on 11 November 2024, at 07:29 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike 4.0 License;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Code of Conduct
Developers
Statistics
Cookie statement
Mobile view














Search













Search









Toggle the table of contents







Molecular dynamics




























30 languages


Add topic
















"
